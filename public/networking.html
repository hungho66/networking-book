<!DOCTYPE html>
<html>
<head><meta http-equiv="content-type" content="text/html; charset=UTF-8"><meta name="generator" content="ABBYY FineReader 15"><meta name="author" content="James Kurose and Keith Ross"><title>Computer Networking  A Top-Down Approach, Global Edition, 8ed</title>
<style type="text/css">
 table.main {}
 tr.row {}
 td.cell {}
 div.block {}
 div.paragraph {}
 /* .p {
margin-right: 5px;
margin-left: 5px;
} */

 .font0 { font:4pt Arial, sans-serif; }
 .font1 { font:5pt Arial, sans-serif; }
 .font2 { font:6pt Arial, sans-serif; }
 .font3 { font:7pt Arial, sans-serif; }
 .font4 { font:8pt Arial, sans-serif; }
 .font5 { font:9pt Arial, sans-serif; }
 .font6 { font:10pt Arial, sans-serif; }
 .font7 { font:11pt Arial, sans-serif; }
 .font8 { font:12pt Arial, sans-serif; }
 .font9 { font:13pt Arial, sans-serif; }
 .font10 { font:15pt Arial, sans-serif; }
 .font11 { font:16pt Arial, sans-serif; }
 .font12 { font:17pt Arial, sans-serif; }
 .font13 { font:18pt Arial, sans-serif; }
 .font14 { font:22pt Arial, sans-serif; }
 .font15 { font:24pt Arial, sans-serif; }
 .font16 { font:26pt Arial, sans-serif; }
 .font17 { font:40pt Arial, sans-serif; }
 .font18 { font:48pt Arial, sans-serif; }
 .font19 { font:12pt Arial Narrow, sans-serif; }
 .font20 { font:15pt Arial Narrow, sans-serif; }
 .font21 { font:16pt Arial Narrow, sans-serif; }
 .font22 { font:10pt Book Antiqua, serif; }
 .font23 { font:12pt Book Antiqua, serif; }
 .font24 { font:13pt Book Antiqua, serif; }
 .font25 { font:28pt Book Antiqua, serif; }
 .font26 { font:32pt Book Antiqua, serif; }
 .font27 { font:33pt Book Antiqua, serif; }
 .font28 { font:43pt Book Antiqua, serif; }
 .font29 { font:10pt Calibri, sans-serif; }
 .font30 { font:11pt Calibri, sans-serif; }
 .font31 { font:15pt Calibri, sans-serif; }
 .font32 { font:20pt Calibri, sans-serif; }
 .font33 { font:7pt Courier New, monospace; }
 .font34 { font:8pt Courier New, monospace; }
 .font35 { font:9pt Courier New, monospace; }
 .font36 { font:10pt Courier New, monospace; }
 .font37 { font:11pt Courier New, monospace; }
 .font38 { font:16pt Courier New, monospace; }
 .font39 { font:17pt Courier New, monospace; }
 .font40 { font:6pt Segoe UI, sans-serif; }
 .font41 { font:7pt Segoe UI, sans-serif; }
 .font42 { font:8pt Segoe UI, sans-serif; }
 .font43 { font:9pt Segoe UI, sans-serif; }
 .font44 { font:14pt Segoe UI, sans-serif; }
 .font45 { font:19pt Segoe UI, sans-serif; }
 .font46 { font:9pt Tahoma, sans-serif; }
 .font47 { font:16pt Tahoma, sans-serif; }
 .font48 { font:4pt Times New Roman, serif; }
 .font49 { font:6pt Times New Roman, serif; }
 .font50 { font:7pt Times New Roman, serif; }
 .font51 { font:8pt Times New Roman, serif; }
 .font52 { font:9pt Times New Roman, serif; }
 .font53 { font:10pt Times New Roman, serif; }
 .font54 { font:11pt Times New Roman, serif; }
 .font55 { font:12pt Times New Roman, serif; }
 .font56 { font:13pt Times New Roman, serif; }
 .font57 { font:14pt Times New Roman, serif; }
 .font58 { font:15pt Times New Roman, serif; }
 .font59 { font:16pt Times New Roman, serif; }
 .font60 { font:18pt Times New Roman, serif; }
 .font61 { font:22pt Times New Roman, serif; }
 .font62 { font:27pt Times New Roman, serif; }
 .font63 { font:28pt Times New Roman, serif; }
 .font64 { font:36pt Times New Roman, serif; }
 .font65 { font:44pt Times New Roman, serif; }
 .font66 { font:47pt Times New Roman, serif; }
 .font67 { font:49pt Times New Roman, serif; }
 .font68 { font:52pt Times New Roman, serif; }
 .font69 { font:10pt Verdana, sans-serif; }
 .font70 { font:18pt Verdana, sans-serif; }

</style>
</head>
<body>
<p><span class="font14">GLOBAL</span></p>
<p><span class="font14">EDITION</span></p><img src="networking_files/networking-1.jpg" alt="" style="width:58pt;height:61pt;">
<p><span class="font18">Computer Networking</span></p>
<p><span class="font15" style="font-weight:bold;font-style:italic;">A Top-Down Approach</span></p>
<p><span class="font13">EIGHTH EDITION</span></p>
<p><span class="font13">James F. Kurose • Keith W. Ross</span></p><img src="networking_files/networking-2.jpg" alt="" style="width:532pt;height:319pt;">
<p><span class="font45" style="font-weight:bold;">DIGITAL RESOURCES FOR STUDENTS</span></p>
<p><span class="font30">Your new textbook provides 12-month access to digital resources that may include VideoNotes (illustrating key concepts from the text), interactive exercises, interactive animations, quizzes, and more. Refer to the preface in the textbook for a detailed list of resources.</span></p>
<p><span class="font30">Follow the instructions below to register for the Companion Website for James F. Kurose and Keith W. Ross's </span><span class="font30" style="font-weight:bold;font-style:italic;">Computer Networking: A Top-Down Approach, Eighth Edition, Global Edition.</span></p>
<p><span class="font29" style="text-decoration:underline;">J|</span><span class="font29"> Go to </span><a href="http://www.pearsonglobaleditions.com"><span class="font29" style="font-weight:bold;">www.pearsonglobaleditions.com</span></a><span class="font29">.</span></p>
<p><span class="font29" style="text-decoration:underline;">j)</span><span class="font29"> Enter the title of your textbook or browse by author name.</span></p>
<p><span class="font29" style="font-weight:bold;text-decoration:underline;">^3</span><span class="font29" style="font-weight:bold;"> </span><span class="font29">Click Companion Website.</span></p>
<p><span class="font29" style="text-decoration:underline;">j)</span><span class="font29"> Click Register and follow the on-screen instructions to create a login name and password.</span></p>
<p><span class="font31">ISSJKK-FROMM-DAIRY-CUPPA-PLUSH-POSES</span></p>
<p><span class="font30" style="font-weight:bold;">Use the login name and password you created during registration to start using the digital resources that accompany your textbook.</span></p>
<p><span class="font30">For technical support go to</span><a href="https://support.pearson.com/getsupport"><span class="font30"> </span><span class="font30" style="font-weight:bold;">https://support.pearson.com/getsupport</span></a></p>
<div>
<p><span class="font64" style="font-weight:bold;">COMPUTER</span></p>
</div><br clear="all">
<div>
<p><span class="font53">EIGHTH EDITION</span></p>
<p><span class="font53">GLOBAL EDITION</span></p>
</div><br clear="all">
<div>
<p><span class="font64" style="font-weight:bold;">NETWORKING</span></p>
</div><br clear="all">
<div>
<p><span class="font32">A Top-Down Approach</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-3.jpg" alt="" style="width:530pt;height:106pt;">
</div><br clear="all">
<p><span class="font21" style="font-weight:bold;font-variant:small-caps;">J</span><span class="font44" style="font-weight:bold;font-variant:small-caps;">ames</span><span class="font20" style="font-weight:bold;"> F. </span><span class="font21" style="font-weight:bold;font-variant:small-caps;">K</span><span class="font44" style="font-weight:bold;font-variant:small-caps;">urose</span></p>
<p><span class="font19" style="font-weight:bold;font-style:italic;">University of Massachusetts, Amherst</span></p>
<p><span class="font21" style="font-weight:bold;font-variant:small-caps;">K</span><span class="font44" style="font-weight:bold;font-variant:small-caps;">eith</span><span class="font20" style="font-weight:bold;"> W. </span><span class="font21" style="font-weight:bold;font-variant:small-caps;">R</span><span class="font44" style="font-weight:bold;font-variant:small-caps;">oss</span></p>
<p><span class="font19" style="font-weight:bold;font-style:italic;">NYU and NYU Shanghai</span></p>
<p><span class="font63">Pearson</span></p>
<p><span class="font51" style="font-style:italic;">Pearson Education Limited</span></p>
<p><span class="font51">KAO Two</span></p>
<p><span class="font51">KAO Park</span></p>
<p><span class="font51">Hockham Way</span></p>
<p><span class="font51">Harlow</span></p>
<p><span class="font51">CM17 9SR</span></p>
<p><span class="font51">United Kingdom</span></p>
<p><span class="font51">and Associated Companies throughout the world</span></p>
<p><span class="font51" style="font-style:italic;">Visit us on the World Wide Web at:</span><span class="font51"> </span><a href="http://www.pearsonglobaleditions.com"><span class="font51">www.pearsonglobaleditions.com</span></a></p>
<p><span class="font51">Please contact </span><a href="https://support.pearson.com/getsupport/s/contactsupport"><span class="font51">https://support.pearson.com/getsupport/s/contactsupport </span></a><span class="font51">with any queries on this content</span></p>
<p><span class="font51">© Pearson Education Limited 2022</span></p>
<p><span class="font51">The rights of James F. Kurose and Keith W. Ross to be identified as the authors of this work have been asserted by them in accordance with the Copyright, Designs and Patents Act 1988.</span></p>
<p><span class="font51" style="font-style:italic;">Authorized adaptation from the United States edition, entitled</span><span class="font51"> Computer Networking: A Top-Down Approach, </span><span class="font51" style="font-style:italic;">8th Edition, ISBN978-0-13-668155-7 by James F Kurose and Keith W Ross, published by Pearson Education © 2021.</span></p>
<p><span class="font51">All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording or otherwise, without either the prior written permission of the publisher or a license permitting restricted copying in the United Kingdom issued by the Copyright Licensing Agency Ltd, Saffron House, 6-10 Kirby Street, London EC1N 8TS. For information regarding permissions, request forms and the appropriate contacts within the Pearson Education Global Rights &amp;&nbsp;Permissions department, please visit </span><a href="http://www.pearsoned.com/permissions/"><span class="font51">www.pearsoned. com/permissions/</span></a><span class="font51">.</span></p>
<p><span class="font51">All trademarks used herein are the property of their respective owners. The use of any trademark in this text does not vest in the author or publisher any trademark ownership rights in such trademarks, nor does the use of such trademarks imply any affiliation with or endorsement of this book by such owners.</span></p>
<p><span class="font51">PEARSON, ALWAYS LEARNING, and MYLAB are exclusive trademarks in the U.S. and/or other countries owned by Pearson Education, Inc. or its affiliates.</span></p>
<p><span class="font51">Unless otherwise indicated herein, any third-party trademarks that may appear in this work are the property of their respective owners and any references to third-party trademarks, logos or other trade dress are for demonstrative or descriptive purposes only. Such references are not intended to imply any sponsorship, endorsement, authorization, or promotion of Pearson’s products by the owners of such marks, or any relationship between the owner and Pearson Education, Inc. or its affiliates, authors, licensees, or distributors.</span></p>
<p><span class="font51" style="font-weight:bold;">ISBN 10: </span><span class="font51">1-292-40546-5</span></p>
<p><span class="font51" style="font-weight:bold;">ISBN 13: </span><span class="font51">978-1-292-40546-9</span></p>
<p><span class="font51" style="font-weight:bold;">eBook ISBN 13: </span><span class="font51">978-1-292-40551-3</span></p>
<p><span class="font51" style="font-weight:bold;">British Library Cataloguing-in-Publication Data</span></p>
<p><span class="font51">A catalogue record for this book is available from the British Library</span></p>
<p><span class="font51">Typeset by SPi Global</span></p>
<p><span class="font51">eBook formatted by B2R Technologies Pvt. Ltd.</span></p>
<p><span class="font25">About the Authors</span></p>
<p><span class="font47" style="font-weight:bold;">Jim Kurose</span></p>
<p><span class="font46">Jim Kurose is a Distinguished University Professor in the College of Information and Computer Sciences at the University of Massachusetts Amherst, where he has been on the faculty since receiving his PhD in computer science from Columbia University. He received a BA in physics from Wesleyan University. He has held a number of visiting scientist positions in the United States and abroad, including IBM Research, INRIA, and the Sorbonne University in France. He recently completed a five-year term as Assistant Director at the US National Science Foundation, where he led the Directorate of Computer and Information Science and Engineering in its mission to uphold the nation’s leadership in scientific discovery and engineering innovation.</span></p>
<p><span class="font46">Jim is proud to have mentored and taught an amazing group of students, and to have received a number of awards for his research, teaching, and service, including the IEEE Infocom Award, the ACM SIGCOMM Lifetime Achievement Award, the ACM Sigcomm Test of Time Award, and the IEEE Computer Society Taylor Booth Education Medal. Dr. Kurose is a former Editor-in-Chief of IEEE Transactions on Communications and of IEEE/ ACM Transactions on Networking. He has served as Technical Program co-Chair for IEEE Infocom, ACM SIGCOMM, ACM Internet Measurement Conference, and ACM SIGMETRICS. He is a Fellow of the IEEE, the ACM and a member of the National Academy of Engineering. His research interests include network protocols and architecture, network measurement, multimedia communication, and modeling and performance evaluation.</span></p>
<p><span class="font47" style="font-weight:bold;">Keith Ross</span></p>
<p><span class="font46">Keith Ross is the Dean of Engineering and Computer Science at NYU Shanghai and the Leonard J. Shustek Chair Professor in the Computer Science and Engineering Department at NYU. Previously he was at University of Pennsylvania (13 years), Eurecom Institute (5 years) and NYU-Poly (10 years). He received a B.S.E.E from Tufts University, a M.S.E.E. from Columbia University, and a Ph.D. in Computer and Control Engineering from The University of Michigan. Keith Ross is also the co-founder and original CEO of Wimba, which develops online multimedia applications for e-learning and was acquired by Blackboard in 2010.</span></p>
<p><span class="font46">Professor Ross's research interests have been in modeling and meaurement of computer networks, peer-to-peer systems, content distribution networks, social networks, and privacy. He is currently working in deep reinforcement</span></p>
<div><img src="networking_files/networking-4.jpg" alt="" style="width:93pt;height:110pt;">
</div><br clear="all">
<div><img src="networking_files/networking-5.jpg" alt="" style="width:85pt;height:110pt;">
</div><br clear="all">
<p><span class="font43" style="font-weight:bold;">4 ABOUT THE AUTHORS</span></p>
<p><span class="font46">learning. He is an ACM Fellow, an IEEE Fellow, recipient of the Infocom 2009 Best Paper Award, and recipient of 2011 and 2008 Best Paper Awards for Multimedia Communications (awarded by IEEE Communications Society). He has served on numerous journal editorial boards and conference program committees, including </span><span class="font46" style="font-style:italic;">IEEE/ACM Transactions on Networking, ACM SIGCOMM, ACM CoNext, and ACM Internet Measurement Conference.</span></p>
<p><span class="font46">He also has served as an advisor to the Federal Trade Commission on P2P file sharing.</span></p>
<p><span class="font57">To Julie and our three precious ones—Chris, Charlie, and Nina</span></p>
<p><span class="font57">JFK</span></p>
<p><span class="font57">A big THANKS to my professors, colleagues, and students all over the world.</span></p>
<p><span class="font57">KWR</span></p>
<p><span class="font70" style="font-style:italic;">This page is intentionally left blank</span></p>
<p><span class="font26">Preface</span></p>
<p><span class="font53">Welcome to the eighth edition of </span><span class="font53" style="font-style:italic;">Computer Networking: A Top-Down Approach. </span><span class="font53">Since the publication of the first edition 20 years ago, our book has been adopted for use at many hundreds of colleges and universities, translated into 14 languages, and used by many hundreds of thousands students and practitioners worldwide. We’ve heard from many of these readers and have been overwhelmed by the positive response.</span></p>
<p><span class="font24" style="font-weight:bold;">What’s New in the Eighth Edition?</span></p>
<p><span class="font53">We think one important reason for this success has been that our book continues to offer a fresh and timely approach to computer networking instruction. We’ve made changes in this eighth edition, but we’ve also kept unchanged what we believe (and the instructors and students who have used our book have confirmed) to be the most important aspects of this book: its top-down approach, its focus on the Internet and a modern treatment of computer networking, its attention to both principles and practice, and its accessible style and approach toward learning about computer networking. Nevertheless, the eighth edition has been revised and updated substantially.</span></p>
<p><span class="font53">Readers of earlier editions of our book may recall that in moving from the sixth to the seventh edition, we deepened our coverage of the network layer, expanding material which had been previously covered in a single chapter into a new chapter focused on the so-called “data plane” component of the network layer (Chapter 4) and a new chapter focused on the network layer’s “control plane” (Chapter 5). That change turned out to be prescient, as software-defined networking (SDN), arguably the most important and exciting advance in networking in decades, has been rapidly adopted in practice—so much so that it’s already hard to imagine an introduction to modern computer networking that doesn’t cover SDN. SDN has also enabled new advances in the practice of network management, which we also cover in modernized and deeper detail in this edition. And as we’ll see in Chapter 7 of this eighth edition, the separation of the data and control planes is now also deeply embedded in 4G/5G mobile cellular network architectures, as is an “all-IP” approach to their core networks. The rapid adoption of 4G/5G networks and the mobile applications they enable are undoubtedly the most significant changes we’ve seen in networking since the publication of our seventh edition. We’ve thus significantly updated and deepened our treatment of this exciting area. Indeed, the ongoing wireless network revolution is so important that we think it has become a critical part of an introductory networking course.</span></p>
<p><span class="font53">In addition to these changes, we’ve also updated many sections throughout the book and added new material to reflect changes across the breadth of networking. In some cases, we have also retired material from the previous edition. As always, material that has been retired from the printed text can always be found on our book’s Companion Website. The most important changes in this eighth edition are the following:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-weight:bold;">Chapter 1 </span><span class="font53">has been updated to reflect the ever-growing reach and use of the Internet, and of 4G/5G networks.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-weight:bold;">Chapter 2</span><span class="font53">, which covers the application layer, has been significantly updated, including material on the new HTTP/2 and HTTP/3 protocols for the Web.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-weight:bold;">Chapter 3</span><span class="font53">, has been updated to reflect advances in, and evolution in use of, transport-layer congestion control and error-control protocols over the past five years. While this material had remained relatively stable for quite some time, there have been a number of important advances since the seventh edition. Several new congestion-control algorithms have been developed and deployed beyond the “classic” TCP algorithms. We provide a deeper coverage of TCP CUBIC, the default TCP protocol in many deployed systems, and examine delay-based approaches to congestion control, including the new BBR protocol, which is deployed in Google’s backbone network. We also study the QUIC protocol, which is being incorporated into the HTTP/3 standard. Although QUIC is technically not a transport-layer protocol—it provides application-layer reliability, congestion control, and connection multiplexing services at the application layer—it uses many of the error- and congestion-control principles that we develop in the early sections of Chapter 3.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-weight:bold;">Chapter 4</span><span class="font53">, which covers the network-layer data plane, has general updates throughout. We’ve added a new section on so-called middleboxes, which perform network-layer functions other than routing and forwarding, such as firewalling and load balancing. Middleboxes build naturally on the generalized “match plus action” forwarding operation of network-layer devices that we cover earlier in Chapter 4. We’ve also added timely new material on topics such as the amount of buffering that is “just right” in network routers, on net neutrality, and on the architectural principles of the Internet.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-weight:bold;">Chapter 5</span><span class="font53">, which cover the network-layer’s control plane, contains updated material on SDN, and a significantly new treatment of network management. The use of SDN has evolved beyond management of packet-forwarding tables to include configuration management of network devices as well. We introduce two new protocols, NETCONF and YANG, whose adoption and use have fueled this new approach toward network management.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-weight:bold;">Chapter 6</span><span class="font53">, which covers the link layer, has been updated to reflect the continuing evolution of link-layer technologies such as Ethernet. We have also updated and expanded our treatment of datacenter networks, which are at the heart of the technology driving much of today’s Internet commerce.</span></p></li>
<li>
<p><span class="font53">• &nbsp;As noted earlier, </span><span class="font53" style="font-weight:bold;">Chapter 7 </span><span class="font53">has been significantly updated and revised to reflect the many changes in wireless networking since the seventh edition, from shortrange Bluetooth piconets, to medium-range wireless 802.11 local area networks (WLANs), to wide-area 4G/5G wireless cellular networks. We have retired our coverage of earlier 2G and 3G networks in favor of a broader and deeper treatment of today’s 4G LTE networks and tomorrow’s 5G networks. We have also updated our coverage of mobility issues, from the local issue of handover of mobile devices between base stations to the global issue of identity management and mobile device roaming among different global cellular networks.</span></p></li></ul>
<p><span class="font53">• </span><span class="font53" style="font-weight:bold;">Chapter 8</span><span class="font53">, which covers network security, has been updated to reflect changes in wireless network security in particular, with new material on WPA3 security in WLANs, and mutual device/network mutual authentication and confidentiality in 4G/5G networks.</span></p>
<p><span class="font53">We have also retired Chapter 9, on multimedia networking, from this edition. Over time, as multimedia applications became more prevalent, we had already migrated Chapter 9 material on topics such as video streaming, packet scheduling, and content distribution networks into earlier chapters. As noted earlier, all retired material from this and earlier editions can be found on our book’s Companion Website.</span></p>
<p><span class="font23" style="font-weight:bold;">Audience</span></p>
<p><span class="font53">This textbook is for a first course on computer networking. It can be used in both computer science and electrical engineering departments. In terms of programming languages, the book assumes only that the student has experience with C, C++, Java, or Python (and even then only in a few places). Although this book is more precise and analytical than many other introductory computer networking texts, it rarely uses any mathematical concepts that are not taught in high school. We have made a deliberate effort to avoid using any advanced calculus, probability, or stochastic process concepts (although we’ve included some homework problems for students with this advanced background). The book is therefore appropriate for undergraduate courses and for first-year graduate courses. It should also be useful to practitioners in the networking industry.</span></p>
<p><span class="font24" style="font-weight:bold;">What Is Unique About This Textbook?</span></p>
<p><span class="font53">The subject of computer networking is enormously complex, involving many concepts, protocols, and technologies that are woven together in an intricate manner. To cope with this scope and complexity, many computer networking texts are often organized around the “layers” of a network architecture. With a layered organization, students can see through the complexity of computer networking—they learn about the distinct concepts and protocols in one part of the architecture while seeing the big picture of how all parts fit together. From a pedagogical perspective, our personal experience has been that such a layered approach indeed works well. Nevertheless, we have found that the traditional approach of teaching—bottom up; that is, from the physical layer toward the application layer—is not the best approach for a modern course on computer networking.</span></p>
<p><span class="font23" style="font-weight:bold;">A Top-Down Approach</span></p>
<p><span class="font53">Our book broke new ground 20 years ago by treating networking in a top-down manner—that is, by beginning at the application layer and working its way down toward the physical layer. The feedback we received from teachers and students alike have confirmed that this top-down approach has many advantages and does indeed work well pedagogically. First, it places emphasis on the application layer (a “high growth area” in networking). Indeed, many of the recent revolutions in computer networking—including the Web, and media streaming—have taken place at the application layer. An early emphasis on application-layer issues differs from the approaches taken in most other texts, which have only a small amount of material on network applications, their requirements, application-layer paradigms (e.g., clientserver and peer-to-peer), and application programming interfaces. Second, our experience as instructors (and that of many instructors who have used this text) has been that teaching networking applications near the beginning of the course is a powerful motivational tool. Students are thrilled to learn about how networking applications work—applications such as e-mail, streaming video, and the Web, which most students use on a daily basis. Once a student understands the applications, the student can then understand the network services needed to support these applications. The student can then, in turn, examine the various ways in which such services might be provided and implemented in the lower layers. Covering applications early thus provides motivation for the remainder of the text.</span></p>
<p><span class="font53">Third, a top-down approach enables instructors to introduce network application development at an early stage. Students not only see how popular applications and protocols work, but also learn how easy it is to create their own network applications and application-layer protocols. With the top-down approach, students get early exposure to the notions of socket programming, service models, and protocols—important concepts that resurface in all subsequent layers. By providing socket programming examples in Python, we highlight the central ideas without confusing students with complex code. Undergraduates in electrical engineering and computer science will have no difficulty following the Python code.</span></p>
<p><span class="font23" style="font-weight:bold;">An Internet Focus</span></p>
<p><span class="font53">Although we dropped the phrase “Featuring the Internet” from the title of this book with the fourth edition, this doesn’t mean that we dropped our focus on the Internet. Indeed, nothing could be further from the case! Instead, since the Internet has become so pervasive, we felt that any networking textbook must have a significant focus on the Internet, and thus this phrase was somewhat unnecessary. We continue to use the Internet’s architecture and protocols as primary vehicles for studying fundamental computer networking concepts. Of course, we also include concepts and protocols from other network architectures. But the spotlight is clearly on the Internet, a fact reflected in our organizing the book around the Internet’s five-layer architecture: the application, transport, network, link, and physical layers.</span></p>
<p><span class="font53">Another benefit of spotlighting the Internet is that most computer science and electrical engineering students are eager to learn about the Internet and its protocols. They know that the Internet has been a revolutionary and disruptive technology and can see that it is profoundly changing our world. Given the enormous relevance of the Internet, students are naturally curious about what is “under the hood.” Thus, it is easy for an instructor to get students excited about basic principles when using the Internet as the guiding focus.</span></p>
<p><span class="font23" style="font-weight:bold;">Teaching Networking Principles</span></p>
<p><span class="font53">Two of the unique features of the book—its top-down approach and its focus on the Internet—have appeared in the titles of our book. If we could have squeezed a </span><span class="font53" style="font-style:italic;">third </span><span class="font53">phrase into the subtitle, it would have contained the word </span><span class="font53" style="font-style:italic;">principles.</span><span class="font53"> The field of networking is now mature enough that a number of fundamentally important issues can be identified. For example, in the transport layer, the fundamental issues include reliable communication over an unreliable network layer, connection establishment/ teardown and handshaking, congestion and flow control, and multiplexing. Three fundamentally important network-layer issues are determining “good” paths between two routers, interconnecting a large number of heterogeneous networks, and managing the complexity of a modern network. In the link layer, a fundamental problem is sharing a multiple access channel. In network security, techniques for providing confidentiality, authentication, and message integrity are all based on cryptographic fundamentals. This text identifies fundamental networking issues and studies approaches toward addressing these issues. The student learning these principles will gain knowledge with a long “shelf life”—long after many of today’s network standards and protocols have become obsolete, the principles they embody will remain important and relevant. We believe that the combination of using the Internet to get the student’s foot in the door and then emphasizing fundamental issues and solution approaches will allow the student to quickly understand just about any networking technology.</span></p>
<p><span class="font23" style="font-weight:bold;">Student Resources</span></p>
<p><span class="font53">Student resources are available on the Companion Website (CW) at </span><a href="http://www.pearsonglobaleditions.com"><span class="font53">www.pearsonglobaleditions.com</span></a><span class="font53">. Resources include:</span></p>
<p><span class="font53">• </span><span class="font53" style="font-style:italic;">Interactive learning material.</span><span class="font53"> The book’s Website contains VideoNotes— video presentations of important topics throughout the book done by the authors, as well as walkthroughs of solutions to problems similar to those at the end of the chapter. We’ve seeded the Website with VideoNotes and online problems for Chapters 1 through 5. As in earlier editions, the Website contains the interactive animations that illustrate many key networking concepts. Professors can integrate these interactive features into their lectures or use them as mini labs.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Additional technical material.</span><span class="font53"> As we have added new material in each edition of our book, we’ve had to remove coverage of some existing topics to keep the book at manageable length. Material that appeared in earlier editions of the text is still of interest, and thus can be found on the book’s Website.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Programming assignments.</span><span class="font53"> The Website also provides a number of detailed programming assignments, which include building a multithreaded Web server, building an e-mail client with a GUI interface, programming the sender and receiver sides of a reliable data transport protocol, programming a distributed routing algorithm, and more.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Wireshark labs.</span><span class="font53"> One’s understanding of network protocols can be greatly deepened by seeing them in action. The Website provides numerous Wireshark assignments that enable students to actually observe the sequence of messages exchanged between two protocol entities. The Website includes separate Wireshark labs on HTTP, DNS, TCP, UDP, IP, ICMP, Ethernet, ARP, WiFi, TLS and on tracing all protocols involved in satisfying a request to fetch a Web page. We’ll continue to add new labs over time.</span></p></li></ul>
<p><span class="font24" style="font-weight:bold;">Pedagogical Features</span></p>
<p><span class="font53">We have each been teaching computer networking for more than 30 years. Together, we bring more than 60 years of teaching experience to this text, during which time we have taught many thousands of students. We have also been active researchers in computer networking during this time. (In fact, Jim and Keith first met each other as master’s students in a computer networking course taught by Mischa Schwartz in 1979 at Columbia University.) We think all this gives us a good perspective on where networking has been and where it is likely to go in the future. Nevertheless, we have resisted temptations to bias the material in this book toward our own pet research projects. We figure you can visit our personal Websites if you are interested in our research. Thus, this book is about modern computer networking—it is about contemporary protocols and technologies as well as the underlying principles behind these protocols and technologies. We also believe that learning (and teaching!) about networking can be fun. A sense of humor, use of analogies, and real-world examples in this book will hopefully make this material more fun.</span></p>
<p><span class="font24" style="font-weight:bold;">Supplements for Instructors</span></p>
<p><span class="font53">We provide a complete supplements package to aid instructors in teaching this course. This material can be accessed from Pearson’s Instructor Resource Center (</span><a href="http://www.pearsonglobaleditions.com"><span class="font53">http://www.pearsonglobaleditions.com</span></a><span class="font53">). Visit the Instructor Resource Center for information about accessing these instructor’s supplements.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">PowerPoint</span><span class="font50" style="font-style:italic;">® </span><span class="font53" style="font-style:italic;">slides.</span><span class="font53"> We provide PowerPoint slides for all eight chapters. The slides have been completely updated with this eighth edition. The slides cover each chapter in detail. They use graphics and animations (rather than relying only on monotonous text bullets) to make the slides interesting and visually appealing. We provide the original PowerPoint slides so you can customize them to best suit your own teaching needs. Some of these slides have been contributed by other instructors who have taught from our book.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Homework solutions.</span><span class="font53"> We provide a solutions manual for the homework problems in the text, programming assignments, and Wireshark labs. As noted earlier, we’ve introduced many new homework problems at each chapter’s end. For additional interactive problems and solutions, an instructor (and students) can consult this books Companion Website at Pearson.</span></p></li></ul>
<p><span class="font24" style="font-weight:bold;">Chapter Dependencies</span></p>
<p><span class="font53">The first chapter of this text presents a self-contained overview of computer networking. Introducing many key concepts and terminology, this chapter sets the stage for the rest of the book. All of the other chapters directly depend on this first chapter. After completing Chapter 1, we recommend instructors cover Chapters 2 through 6 in sequence, following our top-down philosophy. Each of these five chapters leverages material from the preceding chapters. After completing the first six chapters, the instructor has quite a bit of flexibility. There are no interdependencies among the last two chapters, so they can be taught in any order. However, the last two chapters depends on the material in the first six chapters. Many instructors first teach the first six chapters and then teach one of the last two chapters for “dessert.”</span></p>
<p><span class="font24" style="font-weight:bold;">One Final Note: We’d Love to Hear from You</span></p>
<p><span class="font53">We encourage students and instructors to e-mail us with any comments they might have about our book. It’s been wonderful for us to hear from so many instructors and students from around the world about our first seven editions. We’ve incorporated many of these suggestions into later editions of the book. We also encourage instructors to send us new homework problems (and solutions) that would complement the current homework problems. We’ll post these on the instructor-only portion of the Website. We also encourage instructors and students to create new interactive animations that illustrate the concepts and protocols in this book. If you have an animation that you think would be appropriate for this text, please submit it to us. If the animation (including notation and terminology) is appropriate, we’ll be happy to include it on the text’s Website, with an appropriate reference to the animation’s authors.</span></p>
<p><span class="font53">So, as the saying goes, “Keep those cards and letters coming!” Seriously, please </span><span class="font53" style="font-style:italic;">do</span><span class="font53"> continue to send us interesting URLs, point out typos, disagree with any of our claims, and tell us what works and what doesn’t work. Tell us what you think should or shouldn’t be included in the next edition. Send your e-mail to </span><a href="mailto:kurose@cs.umass.edu"><span class="font53">kurose@cs.umass</span></a><span class="font53"> </span><a href="mailto:kurose@cs.umass.edu"><span class="font53">.edu </span></a><span class="font53">and </span><a href="mailto:keithwross@nyu.edu"><span class="font53">keithwross@nyu.edu</span></a><span class="font53">.</span></p>
<p><span class="font24" style="font-weight:bold;">Acknowledgments</span></p>
<p><span class="font53">Since we began writing this book in 1996, many people have given us invaluable help and have been influential in shaping our thoughts on how to best organize and teach a networking course. We want to say A BIG THANKS to everyone who has helped us from the earliest first drafts of this book, up to this eighth edition. We are also </span><span class="font53" style="font-style:italic;">very</span><span class="font53"> thankful to the thousands of readers from around the world—students, faculty, practitioners—who have sent us thoughts and comments on earlier editions of the book and suggestions for future editions of the book. Special thanks go out to:</span></p>
<p><span class="font53">Al Aho (Columbia University)</span></p>
<p><span class="font53">Hisham Al-Mubaid (University of Houston-Clear Lake)</span></p>
<p><span class="font53">Pratima Akkunoor (Arizona State University)</span></p>
<p><span class="font53">Paul Amer (University of Delaware)</span></p>
<p><span class="font53">Shamiul Azom (Arizona State University)</span></p>
<p><span class="font53">Lichun Bao (University of California at Irvine)</span></p>
<p><span class="font53">Paul Barford (University of Wisconsin)</span></p>
<p><span class="font53">Bobby Bhattacharjee (University of Maryland)</span></p>
<p><span class="font53">Steven Bellovin (Columbia University)</span></p>
<p><span class="font53">Pravin Bhagwat (Wibhu)</span></p>
<p><span class="font53">Supratik Bhattacharyya (Amazon)</span></p>
<p><span class="font53">Ernst Biersack (Eurecom Institute)</span></p>
<p><span class="font53">Shahid Bokhari (University of Engineering &amp;&nbsp;Technology, Lahore)</span></p>
<p><span class="font53">Jean Bolot (Technicolor Research)</span></p>
<p><span class="font53">Daniel Brushteyn (former University of Pennsylvania student)</span></p>
<p><span class="font53">Ken Calvert (University of Kentucky)</span></p>
<p><span class="font53">Evandro Cantu (Federal University of Santa Catarina)</span></p>
<p><span class="font53">Jeff Case (SNMP Research International)</span></p>
<p><span class="font53">Jeff Chaltas (Sprint)</span></p>
<p><span class="font53">Vinton Cerf (Google)</span></p>
<p><span class="font53">Byung Kyu Choi (Michigan Technological University)</span></p>
<p><span class="font53">Bram Cohen (BitTorrent, Inc.)</span></p>
<p><span class="font53">Constantine Coutras (Pace University)</span></p>
<p><span class="font53">John Daigle (University of Mississippi)</span></p>
<p><span class="font53">Edmundo A. de Souza e Silva (Federal University of Rio de Janeiro)</span></p>
<p><span class="font53">Philippe Decuetos (former Eurecom Institute student)</span></p>
<p><span class="font53">Christophe Diot (Google)</span></p>
<p><span class="font53">Prithula Dhunghel (Akamai)</span></p>
<p><span class="font53">Deborah Estrin (Cornell University)</span></p>
<p><span class="font53">Michalis Faloutsos (University of California at Riverside)</span></p>
<p><span class="font53">Wu-chi Feng (Oregon Graduate Institute)</span></p>
<p><span class="font53">Sally Floyd (ICIR, University of California at Berkeley)</span></p>
<p><span class="font53">Paul Francis (Max Planck Institute)</span></p>
<p><span class="font53">David Fullager (Netflix)</span></p>
<p><span class="font53">Lixin Gao (University of Massachusetts)</span></p>
<p><span class="font53">JJ Garcia-Luna-Aceves (University of California at Santa Cruz)</span></p>
<p><span class="font53">Mario Gerla (University of California at Los Angeles)</span></p>
<p><span class="font53">David Goodman (NYU-Poly)</span></p>
<p><span class="font53">Yang Guo (Alcatel/Lucent Bell Labs)</span></p>
<p><span class="font53">Tim Griffin (Cambridge University)</span></p>
<p><span class="font53">Max Hailperin (Gustavus Adolphus College)</span></p>
<p><span class="font53">Bruce Harvey (Florida A&amp;M University, Florida State University)</span></p>
<p><span class="font53">Carl Hauser (Washington State University)</span></p>
<p><span class="font53">Rachelle Heller (George Washington University)</span></p>
<p><span class="font53">Phillipp Hoschka (INRIA/W3C)</span></p>
<p><span class="font53">Wen Hsin (Park University)</span></p>
<p><span class="font53">Albert Huang (former University of Pennsylvania student)</span></p>
<p><span class="font53">Cheng Huang (Microsoft Research)</span></p>
<p><span class="font53">Esther A. Hughes (Virginia Commonwealth University)</span></p>
<p><span class="font53">Van Jacobson (Google)</span></p>
<p><span class="font53">Pinak Jain (former NYU-Poly student)</span></p>
<p><span class="font53">Jobin James (University of California at Riverside)</span></p>
<p><span class="font53">Sugih Jamin (University of Michigan)</span></p>
<p><span class="font53">Shivkumar Kalyanaraman (IBM Research, India)</span></p>
<p><span class="font53">Jussi Kangasharju (University of Helsinki)</span></p>
<p><span class="font53">Sneha Kasera (University of Utah)</span></p>
<p><span class="font53">Parviz Kermani (U. Massachusetts)</span></p>
<p><span class="font53">Hyojin Kim (former University of Pennsylvania student)</span></p>
<p><span class="font53">Leonard Kleinrock (University of California at Los Angeles)</span></p>
<p><span class="font53">David Kotz (Dartmouth College)</span></p>
<p><span class="font53">Beshan Kulapala (Arizona State University)</span></p>
<p><span class="font53">Rakesh Kumar (Bloomberg)</span></p>
<p><span class="font53">Miguel A. Labrador (University of South Florida)</span></p>
<p><span class="font53">Simon Lam (University of Texas)</span></p>
<p><span class="font53">Steve Lai (Ohio State University)</span></p>
<p><span class="font53">Tom LaPorta (Penn State University)</span></p>
<p><span class="font53">Tim-Berners Lee (World Wide Web Consortium)</span></p>
<p><span class="font53">Arnaud Legout (INRIA)</span></p>
<p><span class="font53">Lee Leitner (Drexel University)</span></p>
<p><span class="font53">Brian Levine (University of Massachusetts)</span></p>
<p><span class="font53">Chunchun Li (former NYU-Poly student)</span></p>
<p><span class="font53">Yong Liu (NYU-Poly)</span></p>
<p><span class="font53">William Liang (former University of Pennsylvania student)</span></p>
<p><span class="font53">Willis Marti (Texas A&amp;M University)</span></p>
<p><span class="font53">Nick McKeown (Stanford University)</span></p>
<p><span class="font53">Josh McKinzie (Park University)</span></p>
<p><span class="font53">Deep Medhi (University of Missouri, Kansas City)</span></p>
<p><span class="font53">Bob Metcalfe (International Data Group)</span></p>
<p><span class="font53">Vishal Misra (Columbia University)</span></p>
<p><span class="font53">Sue Moon (KAIST)</span></p>
<p><span class="font53">Jenni Moyer (Comcast)</span></p>
<p><span class="font53">Erich Nahum (IBM Research)</span></p>
<p><span class="font53">Christos Papadopoulos (Colorado Sate University)</span></p>
<p><span class="font53">Guru Parulkar (Open Networking Foundation)</span></p>
<p><span class="font53">Craig Partridge (Colorado State University)</span></p>
<p><span class="font53">Radia Perlman (Dell EMC)</span></p>
<p><span class="font53">Jitendra Padhye (Microsoft Research)</span></p>
<p><span class="font53">Vern Paxson (University of California at Berkeley)</span></p>
<p><span class="font53">Kevin Phillips (Sprint)</span></p>
<p><span class="font53">George Polyzos (Athens University of Economics and Business)</span></p>
<p><span class="font53">Sriram Rajagopalan (Arizona State University)</span></p>
<p><span class="font53">Ramachandran Ramjee (Microsoft Research)</span></p>
<p><span class="font53">Ken Reek (Rochester Institute of Technology)</span></p>
<p><span class="font53">Martin Reisslein (Arizona State University)</span></p>
<p><span class="font53">Jennifer Rexford (Princeton University)</span></p>
<p><span class="font53">Leon Reznik (Rochester Institute of Technology)</span></p>
<p><span class="font53">Pablo Rodrigez (Telefonica)</span></p>
<p><span class="font53">Sumit Roy (University of Washington)</span></p>
<p><span class="font53">Catherine Rosenberg (University of Waterloo)</span></p>
<p><span class="font53">Dan Rubenstein (Columbia University)</span></p>
<p><span class="font53">Avi Rubin (Johns Hopkins University)</span></p>
<p><span class="font53">Douglas Salane (John Jay College)</span></p>
<p><span class="font53">Despina Saparilla (Cisco Systems)</span></p>
<p><span class="font53">John Schanz (Comcast)</span></p>
<p><span class="font53">Henning Schulzrinne (Columbia University)</span></p>
<p><span class="font53">Mischa Schwartz (Columbia University)</span></p>
<p><span class="font53">Ardash Sethi (University of Delaware)</span></p>
<p><span class="font53">Harish Sethu (Drexel University)</span></p>
<p><span class="font53">K. Sam Shanmugan (University of Kansas)</span></p>
<p><span class="font53">Prashant Shenoy (University of Massachusetts)</span></p>
<p><span class="font53">Clay Shields (Georgetown University)</span></p>
<p><span class="font53">Subin Shrestra (University of Pennsylvania)</span></p>
<p><span class="font53">Bojie Shu (former NYU-Poly student)</span></p>
<p><span class="font53">Mihail L. Sichitiu (NC State University)</span></p>
<p><span class="font53">Peter Steenkiste (Carnegie Mellon University)</span></p>
<p><span class="font53">Tatsuya Suda (University of California at Irvine)</span></p>
<p><span class="font53">Kin Sun Tam (State University of New York at Albany)</span></p>
<p><span class="font53">Don Towsley (University of Massachusetts)</span></p>
<p><span class="font53">David Turner (California State University, San Bernardino)</span></p>
<p><span class="font53">Nitin Vaidya (Georgetown University)</span></p>
<p><span class="font53">Michele Weigle (Clemson University)</span></p>
<p><span class="font53">David Wetherall (Google)</span></p>
<p><span class="font53">Ira Winston (University of Pennsylvania)</span></p>
<p><span class="font53">Di Wu (Sun Yat-sen University)</span></p>
<p><span class="font53">Shirley Wynn (former NYU-Poly student)</span></p>
<p><span class="font53">Raj Yavatkar (Google)</span></p>
<p><span class="font53">Yechiam Yemini (Columbia University)</span></p>
<p><span class="font53">Dian Yu (former NYU-Shanghai student)</span></p>
<p><span class="font53">Ming Yu (State University of New York at Binghamton)</span></p>
<p><span class="font53">Ellen Zegura (Georgia Institute of Technology)</span></p>
<p><span class="font53">Honggang Zhang (Suffolk University)</span></p>
<p><span class="font53">Hui Zhang (Carnegie Mellon University)</span></p>
<p><span class="font53">Lixia Zhang (University of California at Los Angeles)</span></p>
<p><span class="font53">Meng Zhang (former NYU-Poly student)</span></p>
<p><span class="font53">Shuchun Zhang (former University of Pennsylvania student)</span></p>
<p><span class="font53">Xiaodong Zhang (Ohio State University)</span></p>
<p><span class="font53">ZhiLi Zhang (University of Minnesota)</span></p>
<p><span class="font53">Phil Zimmermann (independent consultant)</span></p>
<p><span class="font53">Mike Zink (University of Massachusetts)</span></p>
<p><span class="font53">Cliff C. Zou (University of Central Florida)</span></p>
<p><span class="font53">We also want to thank the entire Pearson team—in particular, Carole Snyder and Tracy Johnson—who have done an absolutely outstanding job on this eighth edition (and who have put up with two very finicky authors who seem congenitally unable to meet deadlines!). Thanks also to artists, Janet Theurer and Patrice Rossi Calkin, for their work on the beautiful figures in earlier editions of our book, and to Manas Roy and his team at SPi Global for their wonderful production work on this edition. Finally, a most special thanks go to our previous editors at Addison-Wesley and Pearson—Matt Goldstein, Michael Hirsch, and Susan Hartman. This book would not be what it is (and may well not have been at all) without their graceful management, constant encouragement, nearly infinite patience, good humor, and perseverance.</span></p>
<p><span class="font24" style="font-weight:bold;">Acknowledgments for the Global Edition</span></p>
<p><span class="font53">Pearson would like to thank and acknowledge the following people for their contributions to the Global Edition.</span></p>
<p><span class="font53" style="font-weight:bold;">Contributors</span></p>
<p><span class="font53">Vangelis Angelakis (Linkoping University)</span></p>
<p><span class="font53" style="font-weight:bold;">Reviewers</span></p>
<p><span class="font53">Wim Lamotte (Universiteit Hasselt)</span></p>
<p><span class="font53">Wei Tsang Ooi (National University of Singapore)</span></p>
<p><span class="font53">Peter Quax (Universiteit Hasselt)</span></p>
<p><span class="font53" style="font-weight:bold;">Contributor and Reviewer</span></p>
<p><span class="font53">Patrik Osterberg (Mid Sweden University)</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font28">Brief Contents</span></h1>
<p><a href="#bookmark1"><span class="font56" style="font-weight:bold;">Chapter 1 Computer Networks and the Internet</span></a></p>
<p><a href="#bookmark2"><span class="font56" style="font-weight:bold;">Chapter 2 Application Layer</span></a></p>
<p><a href="#bookmark3"><span class="font56" style="font-weight:bold;">Chapter 3 Transport Layer</span></a></p>
<p><a href="#bookmark4"><span class="font56" style="font-weight:bold;">Chapter 4 The Network Layer: Data Plane</span></a></p>
<p><a href="#bookmark5"><span class="font56" style="font-weight:bold;">Chapter 5 The Network Layer: Control Plane</span></a></p>
<p><a href="#bookmark6"><span class="font56" style="font-weight:bold;">Chapter 6 The Link Layer and LANs</span></a></p>
<p><a href="#bookmark7"><span class="font56" style="font-weight:bold;">Chapter 7 Wireless and Mobile Networks</span></a></p>
<p><a href="#bookmark8"><span class="font56" style="font-weight:bold;">Chapter 8 Security in Computer Networks</span></a></p>
<p><a href="#bookmark9"><span class="font53" style="font-weight:bold;">References</span></a></p>
<p><a href="#bookmark10"><span class="font53" style="font-weight:bold;">Index</span></a></p>
<p><span class="font70" style="font-style:italic;">This page is intentionally left blank</span></p>
<h1><a name="bookmark11"></a><span class="font28">Table of Contents</span></h1>
<p><a href="#bookmark12"><span class="font56" style="font-weight:bold;">Chapter 1 Computer Networks and the Internet</span></a></p>
<ul style="list-style:none;"><li>
<p><a href="#bookmark13"><span class="font53">1.1 &nbsp;&nbsp;&nbsp;What Is the Internet?</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark14"><span class="font53">1.1.1 &nbsp;&nbsp;A Nuts-and-Bolts Description</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark15"><span class="font53">1.1.2 &nbsp;&nbsp;A Services Description</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark16"><span class="font53">1.1.3 &nbsp;&nbsp;What Is a Protocol?</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark17"><span class="font53">1.2 &nbsp;&nbsp;The Network Edge</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark18"><span class="font53">1.2.1 &nbsp;&nbsp;Access Networks</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark19"><span class="font53">1.2.2 &nbsp;&nbsp;Physical Media</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark20"><span class="font53">1.3 &nbsp;&nbsp;The Network Core</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark21"><span class="font53">1.3.1 &nbsp;&nbsp;Packet Switching</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark22"><span class="font53">1.3.2 &nbsp;&nbsp;Circuit Switching</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark23"><span class="font53">1.3.3 &nbsp;A Network of Networks</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark24"><span class="font53">1.4 &nbsp;&nbsp;Delay, Loss, and Throughput in Packet-Switched Networks</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark25"><span class="font53">1.4.1 &nbsp;&nbsp;Overview of Delay in Packet-Switched Networks</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark26"><span class="font53">1.4.2 &nbsp;Queuing Delay and Packet Loss</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark27"><span class="font53">1.4.3 &nbsp;&nbsp;End-to-End Delay</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark28"><span class="font53">1.4.4 &nbsp;Throughput in Computer Networks</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark29"><span class="font53">1.5 &nbsp;&nbsp;&nbsp;Protocol Layers and Their Service Models</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark30"><span class="font53">1.5.1 &nbsp;&nbsp;Layered Architecture</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark31"><span class="font53">1.5.2 &nbsp;&nbsp;Encapsulation</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark32"><span class="font53">1.6 &nbsp;&nbsp;Networks Under Attack</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark33"><span class="font53">1.7 &nbsp;&nbsp;&nbsp;History of Computer Networking and the Internet</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark34"><span class="font53">1.7.1 &nbsp;&nbsp;The Development of Packet Switching: 1961-1972</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark35"><span class="font53">1.7.2 &nbsp;&nbsp;Proprietary Networks and Internetworking: 1972-1980</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark36"><span class="font53">1.7.3 &nbsp;&nbsp;A Proliferation of Networks: 1980-1990</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark37"><span class="font53">1.7.4 &nbsp;&nbsp;The Internet Explosion: The 1990s</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark38"><span class="font53">1.7.5 &nbsp;The New Millennium</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark39"><span class="font53">1.8 &nbsp;&nbsp;Summary</span></a></p></li></ul>
<p><a href="#bookmark40"><span class="font53">Homework Problems and Questions</span></a></p>
<p><a href="#bookmark41"><span class="font53">Wireshark Lab</span></a></p>
<p><a href="#bookmark42"><span class="font53">Interview: Leonard Kleinrock</span></a></p>
<p><a href="#bookmark43"><span class="font56" style="font-weight:bold;">Chapter 2 Application Layer</span></a></p>
<div>
<p><span class="font56" style="font-weight:bold;">111</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<p><a href="#bookmark44"><span class="font53">2.1 &nbsp;&nbsp;&nbsp;Principles of Network Applications</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark45"><span class="font53">2.1.1 &nbsp;&nbsp;Network Application Architectures</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark46"><span class="font53">2.1.2 &nbsp;Processes Communicating</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark47"><span class="font53">2.1.3 &nbsp;&nbsp;Transport Services Available to Applications</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark48"><span class="font53">2.1.4 &nbsp;&nbsp;Transport Services Provided by the Internet</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark49"><span class="font53">2.1.5 &nbsp;&nbsp;Application-Layer Protocols</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark50"><span class="font53">2.1.6 &nbsp;Network Applications Covered in This Book</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark51"><span class="font53">2.2 &nbsp;&nbsp;The Web and HTTP</span></a></p>
<table border="1">
<tr><td>
<p><a href="#bookmark52"><span class="font53">2.2.1 Overview of HTTP</span></a></p></td><td>
<p><span class="font53">126</span></p></td></tr>
<tr><td>
<p><a href="#bookmark53"><span class="font53">2.2.2 Non-Persistent and Persistent Connections</span></a></p></td><td>
<p><span class="font53">128</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><a href="#bookmark54"><span class="font53">2.2.3 HTTP Message Format</span></a></p></td><td style="vertical-align:bottom;">
<p><span class="font53">131</span></p></td></tr>
<tr><td>
<p><a href="#bookmark55"><span class="font53">2.2.4 User-Server Interaction: Cookies</span></a></p></td><td>
<p><span class="font53">135</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><a href="#bookmark56"><span class="font53">2.2.5 Web Caching</span></a></p></td><td style="vertical-align:bottom;">
<p><span class="font53">138</span></p></td></tr>
<tr><td>
<p><a href="#bookmark57"><span class="font53">2.2.6 HTTP/2</span></a></p></td><td>
<p><span class="font53">143</span></p></td></tr>
<tr><td>
<p><a href="#bookmark58"><span class="font53">2.3 Electronic Mail in the Internet</span></a></p></td><td>
<p><span class="font53">146</span></p></td></tr>
<tr><td>
<p><a href="#bookmark59"><span class="font53">2.3.1 SMTP</span></a></p></td><td>
<p><span class="font53">148</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><a href="#bookmark60"><span class="font53">2.3.2 Mail Message Formats</span></a></p></td><td style="vertical-align:bottom;">
<p><span class="font53">151</span></p></td></tr>
<tr><td>
<p><a href="#bookmark60"><span class="font53">2.3.3 Mail Access Protocols</span></a></p></td><td>
<p><span class="font53">151</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><a href="#bookmark61"><span class="font53">2.4 &nbsp;&nbsp;DNS—The Internet’s Directory Service</span></a></p></td><td style="vertical-align:bottom;">
<p><span class="font53">152</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><a href="#bookmark62"><span class="font53">2.4.1 Services Provided by DNS</span></a></p></td><td style="vertical-align:bottom;">
<p><span class="font53">153</span></p></td></tr>
<tr><td>
<p><a href="#bookmark63"><span class="font53">2.4.2 &nbsp;Overview of How DNS Works</span></a></p></td><td>
<p><span class="font53">155</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><a href="#bookmark64"><span class="font53">2.4.3 DNS Records and Messages</span></a></p></td><td style="vertical-align:bottom;">
<p><span class="font53">161</span></p></td></tr>
<tr><td>
<p><a href="#bookmark65"><span class="font53">2.5 Peer-to-Peer File Distribution</span></a></p></td><td>
<p><span class="font53">166</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><a href="#bookmark66"><span class="font53">2.6 Video Streaming and Content Distribution Networks</span></a></p></td><td style="vertical-align:bottom;">
<p><span class="font53">173</span></p></td></tr>
<tr><td>
<p><a href="#bookmark66"><span class="font53">2.6.1 Internet Video</span></a></p></td><td>
<p><span class="font53">173</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><a href="#bookmark67"><span class="font53">2.6.2 HTTP Streaming and DASH</span></a></p></td><td style="vertical-align:bottom;">
<p><span class="font53">174</span></p></td></tr>
<tr><td>
<p><a href="#bookmark68"><span class="font53">2.6.3 Content Distribution Networks</span></a></p></td><td>
<p><span class="font53">175</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><a href="#bookmark69"><span class="font53">2.6.4 Case Studies: Netflix and YouTube</span></a></p></td><td style="vertical-align:bottom;">
<p><span class="font53">179</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><a href="#bookmark70"><span class="font53">2.7 Socket Programming: Creating Network Applications</span></a></p></td><td style="vertical-align:bottom;">
<p><span class="font53">182</span></p></td></tr>
<tr><td>
<p><a href="#bookmark71"><span class="font53">2.7.1 Socket Programming with UDP</span></a></p></td><td>
<p><span class="font53">184</span></p></td></tr>
<tr><td>
<p><a href="#bookmark72"><span class="font53">2.7.2 Socket Programming with TCP</span></a></p></td><td>
<p><span class="font53">189</span></p></td></tr>
<tr><td>
<p><a href="#bookmark73"><span class="font53">2.8 Summary</span></a></p></td><td>
<p><span class="font53">195</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><a href="#bookmark74"><span class="font53">Homework Problems and Questions</span></a></p></td><td style="vertical-align:bottom;">
<p><span class="font53">196</span></p></td></tr>
<tr><td>
<p><a href="#bookmark75"><span class="font53">Socket Programming Assignments</span></a></p></td><td>
<p><span class="font53">205</span></p></td></tr>
<tr><td>
<p><a href="#bookmark76"><span class="font53">Wireshark Labs: HTTP, DNS</span></a></p></td><td>
<p><span class="font53">207</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><a href="#bookmark77"><span class="font53">Interview: Tim Berners-Lee</span></a></p></td><td style="vertical-align:bottom;">
<p><span class="font53">208</span></p></td></tr>
</table></li></ul>
<p><a href="#bookmark78"><span class="font56" style="font-weight:bold;">Chapter 3 Transport Layer</span></a></p>
<ul style="list-style:none;"><li>
<p><a href="#bookmark79"><span class="font53">3.1 &nbsp;&nbsp;&nbsp;Introduction and Transport-Layer Services</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark80"><span class="font53">3.1.1 &nbsp;&nbsp;Relationship Between Transport and Network Layers</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark81"><span class="font53">3.1.2 &nbsp;&nbsp;Overview of the Transport Layer in the Internet</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark82"><span class="font53">3.2 &nbsp;&nbsp;Multiplexing and Demultiplexing</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark83"><span class="font53">3.3 &nbsp;&nbsp;Connectionless Transport: UDP</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark84"><span class="font53">3.3.1 &nbsp;UDP Segment Structure</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark85"><span class="font53">3.3.2 &nbsp;UDP Checksum</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark86"><span class="font53">3.4 &nbsp;&nbsp;&nbsp;Principles of Reliable Data Transfer</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark87"><span class="font53">3.4.1 &nbsp;&nbsp;Building a Reliable Data Transfer Protocol</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark88"><span class="font53">3.4.2 &nbsp;&nbsp;Pipelined Reliable Data Transfer Protocols</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark89"><span class="font53">3.4.3 &nbsp;Go-Back-N (GBN)</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark90"><span class="font53">3.4.4 &nbsp;&nbsp;Selective Repeat (SR)</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark91"><span class="font53">3.5 &nbsp;&nbsp;Connection-Oriented Transport: TCP</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark92"><span class="font53">3.5.1 &nbsp;&nbsp;The TCP Connection</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark93"><span class="font53">3.5.2 &nbsp;TCP Segment Structure</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark94"><span class="font53">3.5.3 &nbsp;Round-Trip Time Estimation and Timeout</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark95"><span class="font53">3.5.4 &nbsp;&nbsp;Reliable Data Transfer</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark96"><span class="font53">3.5.5 &nbsp;&nbsp;Flow Control</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark97"><span class="font53">3.5.6 &nbsp;TCP Connection Management</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark98"><span class="font53">3.6 &nbsp;&nbsp;&nbsp;Principles of Congestion Control</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark99"><span class="font53">3.6.1 &nbsp;The Causes and the Costs of Congestion</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark100"><span class="font53">3.6.2 &nbsp;Approaches to Congestion Control</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark101"><span class="font53">3.7 &nbsp;&nbsp;TCP Congestion Control</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark102"><span class="font53">3.7.1 &nbsp;&nbsp;Classic TCP Congestion Control</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font53">3.7.2 &nbsp;Network-Assisted Explicit Congestion Notification and</span></p></li></ul>
<p><a href="#bookmark103"><span class="font53">Delayed-based Congestion Control</span></a></p>
<ul style="list-style:none;"><li>
<p><a href="#bookmark104"><span class="font53">3.7.3 &nbsp;&nbsp;Fairness</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark105"><span class="font53">3.8 &nbsp;&nbsp;&nbsp;Evolution of Transport-Layer Functionality</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark106"><span class="font53">3.9 &nbsp;&nbsp;Summary</span></a></p></li></ul>
<p><a href="#bookmark107"><span class="font53">Homework Problems and Questions</span></a></p>
<p><a href="#bookmark108"><span class="font53">Programming Assignments</span></a></p>
<p><a href="#bookmark109"><span class="font53">Wireshark Labs: Exploring TCP, UDP</span></a></p>
<p><a href="#bookmark110"><span class="font53">Interview: Van Jacobson</span></a></p>
<p><a href="#bookmark111"><span class="font56" style="font-weight:bold;">Chapter 4 The Network Layer: Data Plane</span></a></p>
<ul style="list-style:none;"><li>
<p><a href="#bookmark112"><span class="font53">4.1 &nbsp;&nbsp;Overview of Network Layer</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark113"><span class="font53">4.1.1 &nbsp;&nbsp;Forwarding and Routing: The Data and Control Planes</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark114"><span class="font53">4.1.2 &nbsp;Network Service Model</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark115"><span class="font53">4.2 &nbsp;&nbsp;What’s Inside a Router?</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark116"><span class="font53">4.2.1 &nbsp;&nbsp;Input Port Processing and Destination-Based Forwarding</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark117"><span class="font53">4.2.2 &nbsp;&nbsp;Switching</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark118"><span class="font53">4.2.3 &nbsp;&nbsp;Output Port Processing</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark119"><span class="font53">4.2.4 &nbsp;Where Does Queuing Occur?</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark120"><span class="font53">4.2.5 &nbsp;&nbsp;Packet Scheduling</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark121"><span class="font53">4.3 &nbsp;&nbsp;&nbsp;The Internet Protocol (IP): IPv4, Addressing, IPv6, and More</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark122"><span class="font53">4.3.1 &nbsp;&nbsp;IPv4 Datagram Format</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark123"><span class="font53">4.3.2 &nbsp;&nbsp;IPv4 Addressing</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark124"><span class="font53">4.3.3 &nbsp;Network Address Translation (NAT)</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark125"><span class="font53">4.3.4 &nbsp;&nbsp;IPv6</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark126"><span class="font53">4.4 &nbsp;&nbsp;Generalized Forwarding and SDN</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark127"><span class="font53">4.4.1 &nbsp;Match</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark128"><span class="font53">4.4.2 &nbsp;&nbsp;Action</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark129"><span class="font53">4.4.3 &nbsp;OpenFlow Examples of Match-plus-action in Action</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark130"><span class="font53">4.5 &nbsp;&nbsp;Middleboxes</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark131"><span class="font53">4.6 &nbsp;&nbsp;Summary</span></a></p></li></ul>
<p><a href="#bookmark132"><span class="font53">Homework Problems and Questions</span></a></p>
<p><a href="#bookmark133"><span class="font53">Wireshark Lab: IP</span></a></p>
<p><a href="#bookmark134"><span class="font53">Interview: Vinton G. Cerf</span></a></p>
<p><a href="#bookmark135"><span class="font56" style="font-weight:bold;">Chapter 5 The Network Layer: Control Plane</span></a></p>
<ul style="list-style:none;"><li>
<p><a href="#bookmark136"><span class="font53">5.1 &nbsp;&nbsp;&nbsp;Introduction</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark137"><span class="font53">5.2 &nbsp;&nbsp;Routing Algorithms</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark138"><span class="font53">5.2.1 &nbsp;&nbsp;The Link-State (LS) Routing Algorithm</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark139"><span class="font53">5.2.2 &nbsp;The Distance-Vector (DV) Routing Algorithm</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark140"><span class="font53">5.3 &nbsp;&nbsp;&nbsp;Intra-AS Routing in the Internet: OSPF</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark141"><span class="font53">5.4 &nbsp;&nbsp;Routing Among the ISPs: BGP</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark142"><span class="font53">5.4.1 &nbsp;The Role of BGP</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark143"><span class="font53">5.4.2 &nbsp;Advertising BGP Route Information</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark144"><span class="font53">5.4.3 &nbsp;&nbsp;Determining the Best Routes</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark145"><span class="font53">5.4.4 &nbsp;&nbsp;IP-Anycast</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark146"><span class="font53">5.4.5 &nbsp;&nbsp;Routing Policy</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark147"><span class="font53">5.4.6 &nbsp;&nbsp;Putting the Pieces Together: Obtaining Internet Presence</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark148"><span class="font53">5.5 &nbsp;&nbsp;The SDN Control Plane</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font53">5.5.1 &nbsp;&nbsp;The SDN Control Plane: SDN Controller and</span></p></li></ul>
<p><a href="#bookmark149"><span class="font53">SDN Network-control Applications</span></a></p>
<ul style="list-style:none;"><li>
<p><a href="#bookmark150"><span class="font53">5.5.2 &nbsp;OpenFlow Protocol</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark151"><span class="font53">5.5.3 &nbsp;&nbsp;Data and Control Plane Interaction: An Example</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark152"><span class="font53">5.5.4 &nbsp;SDN: Past and Future</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark153"><span class="font53">5.6 &nbsp;&nbsp;ICMP: The Internet Control Message Protocol</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark154"><span class="font53">5.7 &nbsp;&nbsp;Network Management and SNMP, NETCONF/YANG</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark155"><span class="font53">5.7.1 &nbsp;The Network Management Framework</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font53">5.7.2 &nbsp;The Simple Network Management Protocol (SNMP)</span></p></li></ul>
<p><a href="#bookmark156"><span class="font53">and the Management Information Base (MIB)</span></a></p>
<ul style="list-style:none;"><li>
<p><a href="#bookmark157"><span class="font53">5.7.3 &nbsp;The Network Configuration Protocol (NETCONF) and YANG 462</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark158"><span class="font53">5.8 &nbsp;&nbsp;Summary</span></a></p></li></ul>
<p><a href="#bookmark159"><span class="font53">Homework Problems and Questions</span></a></p>
<p><a href="#bookmark160"><span class="font53">Socket Programming Assignment 5: ICMP Ping</span></a></p>
<p><a href="#bookmark161"><span class="font53">Programming Assignment: Routing</span></a></p>
<p><a href="#bookmark162"><span class="font53">Wireshark Lab: ICMP</span></a></p>
<p><a href="#bookmark163"><span class="font53">Interview: Jennifer Rexford</span></a></p>
<p><a href="#bookmark164"><span class="font56" style="font-weight:bold;">Chapter 6 The Link Layer and LANs</span></a></p>
<ul style="list-style:none;"><li>
<p><a href="#bookmark165"><span class="font53">6.1 &nbsp;&nbsp;&nbsp;Introduction to the Link Layer</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark166"><span class="font53">6.1.1 &nbsp;&nbsp;The Services Provided by the Link Layer</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark167"><span class="font53">6.1.2 &nbsp;Where Is the Link Layer Implemented?</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark168"><span class="font53">6.2 &nbsp;&nbsp;&nbsp;Error-Detection and -Correction Techniques</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark169"><span class="font53">6.2.1 &nbsp;&nbsp;Parity Checks</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark170"><span class="font53">6.2.2 &nbsp;Checksumming Methods</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark171"><span class="font53">6.2.3 &nbsp;Cyclic Redundancy Check (CRC)</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark172"><span class="font53">6.3 &nbsp;&nbsp;&nbsp;Multiple Access Links and Protocols</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark173"><span class="font53">6.3.1 &nbsp;&nbsp;Channel Partitioning Protocols</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark174"><span class="font53">6.3.2 &nbsp;Random Access Protocols</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark175"><span class="font53">6.3.3 &nbsp;&nbsp;Taking-Turns Protocols</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark176"><span class="font53">6.3.4 &nbsp;DOCSIS: The Link-Layer Protocol for Cable Internet Access</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark177"><span class="font53">6.4 &nbsp;&nbsp;Switched Local Area Networks</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark178"><span class="font53">6.4.1 &nbsp;&nbsp;Link-Layer Addressing and ARP</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark179"><span class="font53">6.4.2 &nbsp;&nbsp;Ethernet</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark180"><span class="font53">6.4.3 &nbsp;&nbsp;Link-Layer Switches</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark181"><span class="font53">6.4.4 &nbsp;Virtual Local Area Networks (VLANs)</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark182"><span class="font53">6.5 &nbsp;&nbsp;&nbsp;Link Virtualization: A Network as a Link Layer</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark183"><span class="font53">6.5.1 &nbsp;Multiprotocol Label Switching (MPLS)</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark184"><span class="font53">6.6 &nbsp;&nbsp;Data Center Networking</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark185"><span class="font53">6.6.1 &nbsp;&nbsp;Data Center Architectures</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark186"><span class="font53">6.6.2 &nbsp;Trends in Data Center Networking</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark187"><span class="font53">6.7 &nbsp;&nbsp;Retrospective: A Day in the Life of a Web Page Request</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark188"><span class="font53">6.7.1 &nbsp;&nbsp;Getting Started: DHCP, UDP, IP, and Ethernet</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark189"><span class="font53">6.7.2 &nbsp;&nbsp;Still Getting Started: DNS and ARP</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark190"><span class="font53">6.7.3 &nbsp;&nbsp;Still Getting Started: Intra-Domain Routing to the DNS Server</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark191"><span class="font53">6.7.4 &nbsp;Web Client-Server Interaction: TCP and HTTP</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark192"><span class="font53">6.8 &nbsp;&nbsp;Summary</span></a></p></li></ul>
<p><a href="#bookmark193"><span class="font53">Homework Problems and Questions</span></a></p>
<p><a href="#bookmark194"><span class="font53">Wireshark Labs: 802.11 Ethernet</span></a></p>
<p><a href="#bookmark195"><span class="font53">Interview: Albert Greenberg</span></a></p>
<p><a href="#bookmark196"><span class="font56" style="font-weight:bold;">Chapter 7 Wireless and Mobile Networks</span></a></p>
<ul style="list-style:none;"><li>
<p><a href="#bookmark197"><span class="font53">7.1 &nbsp;&nbsp;&nbsp;Introduction</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark198"><span class="font53">7.2 &nbsp;&nbsp;Wireless Links and Network Characteristics</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p class="font53"><a href="#bookmark199">7.2.1 CDMA</a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark200"><span class="font53">7.3 &nbsp;&nbsp;WiFi: 802.11 Wireless LANs</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark201"><span class="font53">7.3.1 &nbsp;&nbsp;The 802.11 Wireless LAN Architecture</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark202"><span class="font53">7.3.2 &nbsp;The 802.11 MAC Protocol</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark203"><span class="font53">7.3.3 &nbsp;The IEEE 802.11 Frame</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark204"><span class="font53">7.3.4 &nbsp;Mobility in the Same IP Subnet</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark205"><span class="font53">7.3.5 &nbsp;&nbsp;Advanced Features in 802.11</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark206"><span class="font53">7.3.6 &nbsp;&nbsp;Personal Area Networks: Bluetooth</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark207"><span class="font53">7.4 &nbsp;&nbsp;Cellular Networks: 4G and 5G</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark208"><span class="font53">7.4.1 &nbsp;&nbsp;4G LTE Cellular Networks: Architecture and Elements</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark209"><span class="font53">7.4.2 &nbsp;&nbsp;LTE Protocols Stacks</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark210"><span class="font53">7.4.3 &nbsp;LTE Radio Access Network</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font53">7.4.4 &nbsp;Additional LTE Functions: Network Attachment and</span></p></li></ul>
<p><a href="#bookmark211"><span class="font53">Power Management</span></a></p>
<ul style="list-style:none;"><li>
<p><a href="#bookmark212"><span class="font53">7.4.5 &nbsp;The Global Cellular Network: A Network of Networks</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark213"><span class="font53">7.4.6 &nbsp;5G Cellular Networks</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark214"><span class="font53">7.5 &nbsp;&nbsp;&nbsp;Mobility Management: Principles</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark215"><span class="font53">7.5.1 &nbsp;&nbsp;Device Mobility: a Network-layer Perspective</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark216"><span class="font53">7.5.2 &nbsp;Home Networks and Roaming on Visited Networks</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark217"><span class="font53">7.5.3 &nbsp;&nbsp;Direct and Indirect Routing to/from a Mobile Device</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark218"><span class="font53">7.6 &nbsp;&nbsp;Mobility Management in Practice</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark219"><span class="font53">7.6.1 &nbsp;Mobility Management in 4G/5G Networks</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark220"><span class="font53">7.6.2 &nbsp;Mobile IP</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark221"><span class="font53">7.7 &nbsp;&nbsp;&nbsp;Wireless and Mobility: Impact on Higher-Layer Protocols</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark222"><span class="font53">7.8 &nbsp;&nbsp;Summary</span></a></p></li></ul>
<p><a href="#bookmark223"><span class="font53">Homework Problems and Questions</span></a></p>
<p><a href="#bookmark224"><span class="font53">Wireshark Lab: WiFi</span></a></p>
<p><a href="#bookmark225"><span class="font53">Interview: Deborah Estrin</span></a></p>
<p><a href="#bookmark226"><span class="font56" style="font-weight:bold;">Chapter 8 Security in Computer Networks</span></a></p>
<ul style="list-style:none;"><li>
<p><a href="#bookmark227"><span class="font53">8.1 &nbsp;&nbsp;What Is Network Security?</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark228"><span class="font53">8.2 &nbsp;&nbsp;&nbsp;Principles of Cryptography</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark229"><span class="font53">8.2.1 &nbsp;&nbsp;Symmetric Key Cryptography</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark230"><span class="font53">8.2.2 &nbsp;&nbsp;Public Key Encryption</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark231"><span class="font53">8.3 &nbsp;&nbsp;&nbsp;Message Integrity and Digital Signatures</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark232"><span class="font53">8.3.1 &nbsp;&nbsp;Cryptographic Hash Functions</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark233"><span class="font53">8.3.2 &nbsp;Message Authentication Code</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark234"><span class="font53">8.3.3 &nbsp;&nbsp;Digital Signatures</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark235"><span class="font53">8.4 &nbsp;&nbsp;&nbsp;End-Point Authentication</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark236"><span class="font53">8.5 &nbsp;&nbsp;&nbsp;Securing E-Mail</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark237"><span class="font53">8.5.1 &nbsp;&nbsp;Secure E-Mail</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark238"><span class="font53">8.5.2 &nbsp;PGP</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark239"><span class="font53">8.6 &nbsp;&nbsp;Securing TCP Connections: TLS</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark240"><span class="font53">8.6.1 &nbsp;&nbsp;The Big Picture</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark241"><span class="font53">8.6.2 &nbsp;A More Complete Picture</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark242"><span class="font53">8.7 &nbsp;&nbsp;&nbsp;Network-Layer Security: IPsec and Virtual Private Networks</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark243"><span class="font53">8.7.1 &nbsp;&nbsp;IPsec and Virtual Private Networks (VPNs)</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark244"><span class="font53">8.7.2 &nbsp;The AH and ESP Protocols</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark245"><span class="font53">8.7.3 &nbsp;&nbsp;Security Associations</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark246"><span class="font53">8.7.4 &nbsp;The IPsec Datagram</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark247"><span class="font53">8.7.5 &nbsp;IKE: Key Management in IPsec</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark248"><span class="font53">8.8 &nbsp;&nbsp;Securing Wireless LANs and 4G/5G Cellular Networks</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark249"><span class="font53">8.8.1 &nbsp;&nbsp;Authentication and Key Agreement in 802.11 Wireless LANs</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark250"><span class="font53">8.8.2 &nbsp;Authentication and Key Agreement in 4G/5G Cellular Networks</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark251"><span class="font53">8.9 &nbsp;&nbsp;&nbsp;Operational Security: Firewalls and Intrusion Detection Systems</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark252"><span class="font53">8.9.1 &nbsp;&nbsp;Firewalls</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark253"><span class="font53">8.9.2 &nbsp;&nbsp;Intrusion Detection Systems</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark254"><span class="font53">8.10 &nbsp;Summary</span></a></p></li></ul>
<p><a href="#bookmark255"><span class="font53">Homework Problems and Questions</span></a></p>
<p><a href="#bookmark256"><span class="font53">Wireshark Lab: SSL</span></a></p>
<p><a href="#bookmark257"><span class="font53">IPsec Lab</span></a></p>
<p><a href="#bookmark258"><span class="font53">Interview: Steven M. Bellovin</span></a></p>
<p><a href="#bookmark259"><span class="font53" style="font-weight:bold;">References</span></a></p>
<p><a href="#bookmark260"><span class="font53" style="font-weight:bold;">Index</span></a></p>
<p><span class="font70" style="font-style:italic;">This page is intentionally left blank</span></p>
<div>
<p><span class="font64" style="font-weight:bold;">COMPUTER</span></p>
</div><br clear="all">
<div>
<p><span class="font53">EIGHTH EDITION</span></p>
<p><span class="font53">GLOBAL EDITION</span></p>
</div><br clear="all">
<p><span class="font64" style="font-weight:bold;">NETWORKING</span></p>
<div>
<p><span class="font32">A Top-Down Approach</span></p><img src="networking_files/networking-6.jpg" alt="" style="width:530pt;height:106pt;">
</div><br clear="all">
<p><span class="font70" style="font-style:italic;">This page is intentionally left blank</span></p><img src="networking_files/networking-7.jpg" alt="" style="width:531pt;height:153pt;">
<h1><a name="bookmark1"></a><span class="font27" style="font-weight:bold;">Computer Networks and the Internet</span></h1>
<p><span class="font53">Today’s Internet is arguably the largest engineered system ever created by mankind, with hundreds of millions of connected computers, communication links, and switches; with billions of users who connect via laptops, tablets, and smartphones; and with an array of new Internet-connected “things” including game consoles, surveillance systems, watches, eye glasses, thermostats, and cars. Given that the Internet is so large and has so many diverse components and uses, is there any hope of understanding how it works? Are there guiding principles and structure that can provide a foundation for understanding such an amazingly large and complex system? And if so, is it possible that it actually could be both interesting </span><span class="font53" style="font-style:italic;">and</span><span class="font53"> fun to learn about computer networks? Fortunately, the answer to all of these questions is a resounding YES! Indeed, it’s our aim in this book to provide you with a modern introduction to the dynamic field of computer networking, giving you the principles and practical insights you’ll need to understand not only today’s networks, but tomorrow’s as well.</span></p>
<p><span class="font53">This first chapter presents a broad overview of computer networking and the Internet. Our goal here is to paint a broad picture and set the context for the rest of this book, to see the forest through the trees. We’ll cover a lot of ground in this introductory chapter and discuss a lot of the pieces of a computer network, without losing sight of the big picture.</span></p>
<p><a name="bookmark261"></a><span class="font53">We’ll structure our overview of computer networks in this chapter as follows. After introducing some basic terminology and concepts, we’ll first examine the basic hardware and software components that make up a network. We’ll begin at the network’s edge and look at the end systems and network applications running in the network. We’ll then explore the core of a computer network, examining the links and the switches that transport data, as well as the access networks and physical media that connect end systems to the network core. We’ll learn that the Internet is a network of networks, and we’ll learn how these networks connect with each other.</span></p>
<p><span class="font53">After having completed this overview of the edge and core of a computer network, we’ll take the broader and more abstract view in the second half of this chapter. We’ll examine delay, loss, and throughput of data in a computer network and provide simple quantitative models for end-to-end throughput and delay: models that take into account transmission, propagation, and queuing delays. We’ll then introduce some of the key architectural principles in computer networking, namely, protocol layering and service models. We’ll also learn that computer networks are vulnerable to many different types of attacks; we’ll survey some of these attacks and consider how computer networks can be made more secure. Finally, we’ll close this chapter with a brief history of computer networking.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">1.1 </span><span class="font24" style="font-weight:bold;">What Is the Internet?</span></p></li></ul>
<p><span class="font53">In this book, we’ll use the public Internet, a specific computer network, as our principal vehicle for discussing computer networks and their protocols. But what </span><span class="font53" style="font-style:italic;">is</span><span class="font53"> the Internet? There are a couple of ways to answer this question. First, we can describe the nuts and bolts of the Internet, that is, the basic hardware and software components that make up the Internet. Second, we can describe the Internet in terms of a networking infrastructure that provides services to distributed applications. Let’s begin with the nuts-and-bolts description, using Figure 1.1 to illustrate our discussion.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">1.1.1 </span><span class="font23" style="font-weight:bold;">A Nuts-and-Bolts Description</span></p></li></ul>
<p><a name="bookmark262"></a><span class="font53">The Internet is a computer network that interconnects billions of computing devices throughout the world. Not too long ago, these computing devices were primarily traditional desktop computers, Linux workstations, and so-called servers that store and transmit information such as Web pages and e-mail messages. Increasingly, however, users connect to the Internet with smartphones and tablets—today, close to half of the world’s population are active mobile Internet users with the percentage expected to increase to 75% by 2025 [Statista 2019]. Furthermore, nontraditional Internet “things” such as TVs, gaming consoles, thermostats, home security systems, home appliances, watches, eye glasses, cars, traffic control systems, and more are being connected to the Internet. Indeed, the term </span><span class="font53" style="font-style:italic;">computer network</span><span class="font53"> is beginning to sound a bit dated, given the many nontraditional devices that are being hooked up to the Internet. In Internet jargon, all of these devices are called </span><span class="font53" style="font-weight:bold;">hosts </span><span class="font53">or </span><span class="font53" style="font-weight:bold;">end systems</span><span class="font53">. By some estimates, there were about 18 billion devices connected to the Internet in 2017, and the number will reach 28.5 billion by 2022 [Cisco VNI 2020].</span></p>
<div>
<p><span class="font4" style="font-weight:bold;">National or Global ISP</span></p><img src="networking_files/networking-8.jpg" alt="" style="width:312pt;height:227pt;">
<p><span class="font4" style="font-weight:bold;">Datacenter Network</span></p>
<p><span class="font4" style="font-weight:bold;">Home Network</span></p>
<p><span class="font4" style="font-weight:bold;">Content Provider Network</span></p>
<p><span class="font4" style="font-weight:bold;">Local or Regional ISP</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Mobile Network</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Datacenter Network</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-9.jpg" alt="" style="width:244pt;height:113pt;">
</div><br clear="all">
<div>
<p><span class="font4">Key:</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-10.jpg" alt="" style="width:193pt;height:28pt;">
<p><span class="font41">Host Server Mobile Router Link-layer Base (= end system) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Computer &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;switch &nbsp;&nbsp;&nbsp;station</span></p>
</div><br clear="all">
<div>
<p><span class="font12">I</span></p>
<p><span class="font41">Smartphone or tablet</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-11.jpg" alt="" style="width:12pt;height:23pt;">
</div><br clear="all">
<div>
<p><span class="font41">Cell phone tower</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-12.jpg" alt="" style="width:189pt;height:36pt;">
<p><span class="font7" style="font-weight:bold;">Figure 1.1 </span><span class="font50">♦ </span><span class="font5">Some pieces of the Internet</span></p>
</div><br clear="all">
<p><span class="font53">End systems are connected together by a network of </span><span class="font53" style="font-weight:bold;">communication links </span><span class="font53">and </span><span class="font53" style="font-weight:bold;">packet switches</span><span class="font53">. We’ll see in Section 1.2 that there are many types of communication links, which are made up of different types of physical media, including coaxial cable, copper wire, optical fiber, and radio spectrum. Different links can transmit data at different rates, with the </span><span class="font53" style="font-weight:bold;">transmission rate </span><span class="font53">of a link measured in bits/second. When one end system has data to send to another end system, the sending end system segments the data and adds header bytes to each segment. The resulting packages of information, known as </span><span class="font53" style="font-weight:bold;">packets </span><span class="font53">in the jargon of computer networks, are then sent through the network to the destination end system, where they are reassembled into the original data.</span></p>
<p><span class="font53">A packet switch takes a packet arriving on one of its incoming communication links and forwards that packet on one of its outgoing communication links. Packet switches come in many shapes and flavors, but the two most prominent types in today’s Internet are </span><span class="font53" style="font-weight:bold;">routers </span><span class="font53">and </span><span class="font53" style="font-weight:bold;">link-layer switches</span><span class="font53">. Both types of switches forward packets toward their ultimate destinations. Link-layer switches are typically used in access networks, while routers are typically used in the network core. The sequence of communication links and packet switches traversed by a packet from the sending end system to the receiving end system is known as a </span><span class="font53" style="font-weight:bold;">route </span><span class="font53">or </span><span class="font53" style="font-weight:bold;">path </span><span class="font53">through the network. Cisco predicts annual global IP traffic will reach nearly five zettabytes (10<sup>21</sup> bytes) by 2022 [Cisco VNI 2020].</span></p>
<p><span class="font53">Packet-switched networks (which transport packets) are in many ways similar to transportation networks of highways, roads, and intersections (which transport vehicles). Consider, for example, a factory that needs to move a large amount of cargo to some destination warehouse located thousands of kilometers away. At the factory, the cargo is segmented and loaded into a fleet of trucks. Each of the trucks then independently travels through the network of highways, roads, and intersections to the destination warehouse. At the destination warehouse, the cargo is unloaded and grouped with the rest of the cargo arriving from the same shipment. Thus, in many ways, packets are analogous to trucks, communication links are analogous to highways and roads, packet switches are analogous to intersections, and end systems are analogous to buildings. Just as a truck takes a path through the transportation network, a packet takes a path through a computer network.</span></p>
<p><span class="font53">End systems access the Internet through </span><span class="font53" style="font-weight:bold;">Internet Service Providers (ISPs)</span><span class="font53">, including residential ISPs such as local cable or telephone companies; corporate ISPs; university ISPs; ISPs that provide WiFi access in airports, hotels, coffee shops, and other public places; and cellular data ISPs, providing mobile access to our smartphones and other devices. Each ISP is in itself a network of packet switches and communication links. ISPs provide a variety of types of network access to the end systems, including residential broadband access such as cable modem or DSL, high-speed local area network access, and mobile wireless access. ISPs also provide Internet access to content providers, connecting servers directly to the Internet. The Internet is all about connecting end systems to each other, so the ISPs that provide access to end systems must also be interconnected. These lower-tier ISPs are thus interconnected through national and international upper-tier ISPs and these upper-tier ISPs are connected directly to each other. An upper-tier ISP consists of high-speed routers interconnected with high-speed fiber-optic links. Each ISP network, whether upper-tier or lower-tier, is managed independently, runs the IP protocol (see below), and conforms to certain naming and address conventions. We’ll examine ISPs and their interconnection more closely in Section 1.3.</span></p>
<p><span class="font53">End systems, packet switches, and other pieces of the Internet run </span><span class="font53" style="font-weight:bold;">protocols </span><span class="font53">that control the sending and receiving of information within the Internet. The </span><span class="font53" style="font-weight:bold;">Transmission Control Protocol (TCP) </span><span class="font53">and the </span><span class="font53" style="font-weight:bold;">Internet Protocol (IP) </span><span class="font53">are two of the most important protocols in the Internet. The IP protocol specifies the format of the packets that are sent and received among routers and end systems. The Internet’s principal protocols are collectively known as </span><span class="font53" style="font-weight:bold;">TCP/IP</span><span class="font53">. We’ll begin looking into protocols in this introductory chapter. But that’s just a start—much of this book is concerned with networking protocols!</span></p>
<p><span class="font53">Given the importance of protocols to the Internet, it’s important that everyone agree on what each and every protocol does, so that people can create systems and products that interoperate. This is where standards come into play. </span><span class="font53" style="font-weight:bold;">Internet standards </span><span class="font53">are developed by the Internet Engineering Task Force (IETF) [IETF 2020]. The IETF standards documents are called </span><span class="font53" style="font-weight:bold;">requests for comments (RFCs)</span><span class="font53">. RFCs started out as general requests for comments (hence the name) to resolve network and protocol design problems that faced the precursor to the Internet [Allman 2011]. RFCs tend to be quite technical and detailed. They define protocols such as TCP, IP, HTTP (for the Web), and SMTP (for e-mail). There are currently nearly 9000 RFCs. Other bodies also specify standards for network components, most notably for network links. The IEEE 802 LAN Standards Committee [IEEE 802 2020], for example, specifies the Ethernet and wireless WiFi standards.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">1.1.2 </span><span class="font23" style="font-weight:bold;">A Services Description</span></p></li></ul>
<p><a name="bookmark263"></a><span class="font53">Our discussion above has identified many of the pieces that make up the Internet. But we can also describe the Internet from an entirely different angle—namely, as </span><span class="font53" style="font-style:italic;">an infrastructure that provides services to applications.</span><span class="font53"> In addition to traditional applications such as e-mail and Web surfing, Internet applications include mobile smartphone and tablet applications, including Internet messaging, mapping with real-time road-traffic information, music streaming movie and television streaming, online social media, video conferencing, multi-person games, and location-based recommendation systems. The applications are said to be </span><span class="font53" style="font-weight:bold;">distributed applications</span><span class="font53">, since they involve multiple end systems that exchange data with each other. Importantly, Internet applications run on end systems—they do not run in the packet switches in the network core. Although packet switches facilitate the exchange of data among end systems, they are not concerned with the application that is the source or sink of data.</span></p>
<p><span class="font53">Let’s explore a little more what we mean by an infrastructure that provides services to applications. To this end, suppose you have an exciting new idea for a distributed Internet application, one that may greatly benefit humanity or one that may simply make you rich and famous. How might you go about transforming this idea into an actual Internet application? Because applications run on end systems, you are going to need to write programs that run on the end systems. You might, for example, write your programs in Java, C, or Python. Now, because you are developing a distributed Internet application, the programs running on the different end systems will need to send data to each other. And here we get to a central issue—one that leads to the alternative way of describing the Internet as a platform for applications. How does one program running on one end system instruct the Internet to deliver data to another program running on another end system?</span></p>
<p><span class="font53">End systems attached to the Internet provide a </span><span class="font53" style="font-weight:bold;">socket interface </span><span class="font53">that specifies how a program running on one end system asks the Internet infrastructure to deliver data to a specific destination program running on another end system. This Internet socket interface is a set of rules that the sending program must follow so that the Internet can deliver the data to the destination program. We’ll discuss the Internet socket interface in detail in Chapter 2. For now, let’s draw upon a simple analogy, one that we will frequently use in this book. Suppose Alice wants to send a letter to Bob using the postal service. Alice, of course, can’t just write the letter (the data) and drop the letter out her window. Instead, the postal service requires that Alice put the letter in an envelope; write Bob’s full name, address, and zip code in the center of the envelope; seal the envelope; put a stamp in the upperright-hand corner of the envelope; and finally, drop the envelope into an official postal service mailbox. Thus, the postal service has its own “postal service interface,” or set of rules, that Alice must follow to have the postal service deliver her letter to Bob. In a similar manner, the Internet has a socket interface that the program sending data must follow to have the Internet deliver the data to the program that will receive the data.</span></p>
<p><span class="font53">The postal service, of course, provides more than one service to its customers. It provides express delivery, reception confirmation, ordinary use, and many more services. In a similar manner, the Internet provides multiple services to its applications. When you develop an Internet application, you too must choose one of the Internet’s services for your application. We’ll describe the Internet’s services in Chapter 2.</span></p>
<p><span class="font53">We have just given two descriptions of the Internet; one in terms of its hardware and software components, the other in terms of an infrastructure for providing services to distributed applications. But perhaps you are still confused as to what the Internet is. What are packet switching and TCP/IP? What are routers? What kinds of communication links are present in the Internet? What is a distributed application? How can a thermostat or body scale be attached to the Internet? If you feel a bit overwhelmed by all of this now, don’t worry—the purpose of this book is to introduce you to both the nuts and bolts of the Internet and the principles that govern how and why it works. We’ll explain these important terms and questions in the following sections and chapters.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">1.1.3 </span><span class="font23" style="font-weight:bold;">What Is a Protocol?</span></p></li></ul>
<p><span class="font53">Now that we’ve got a bit of a feel for what the Internet is, let’s consider another important buzzword in computer networking: </span><span class="font53" style="font-style:italic;">protocol.</span><span class="font53"> What is a protocol? What does a protocol do </span><span class="font53" style="font-style:italic;">?</span></p>
<p><span class="font22" style="font-weight:bold;">A Human Analogy</span></p>
<p><span class="font53">It is probably easiest to understand the notion of a computer network protocol by first considering some human analogies, since we humans execute protocols all of the time. Consider what you do when you want to ask someone for the time of day. A typical exchange is shown in Figure 1.2. Human protocol (or good manners, at least) dictates that one first offer a greeting (the first “Hi” in Figure 1.2) to initiate communication with someone else. The typical response to a “Hi” is a returned “Hi” message. Implicitly, one then takes a cordial “Hi” response as an indication that one can proceed and ask for the time of day. A different response to the initial “Hi” (such as “Don’t bother me!” or “I don’t speak English,” or some unprintable reply) might indicate an unwillingness or inability to communicate. In this case, the human protocol would be not to ask for the time of day. Sometimes one gets no response at all to a question, in which case one typically gives up asking that person for the time. Note that in our human protocol, </span><span class="font53" style="font-style:italic;">there are specific messages we send, and specific actions we take in response to the received reply messages or other events</span><span class="font53"> (such as no reply within some given amount of time). Clearly, transmitted and received messages, and actions taken when these messages are sent or received or other events occur, play a central role in a human protocol. If people run different protocols (for example, if one person has manners but the other does not, or if one understands the concept of time and the other does not) the protocols do not interoperate and no useful work can be accomplished. The same is true in network-ing—it takes two (or more) communicating entities running the same protocol in order to accomplish a task.</span></p>
<div><img src="networking_files/networking-13.jpg" alt="" style="width:180pt;height:37pt;">
</div><br clear="all">
<div><img src="networking_files/networking-14.jpg" alt="" style="width:196pt;height:35pt;">
</div><br clear="all">
<div><img src="networking_files/networking-15.jpg" alt="" style="width:168pt;height:218pt;">
<p><a name="bookmark264"></a><span class="font7" style="font-weight:bold;">Figure 1.2 </span><span class="font50">♦ </span><span class="font5">A human protocol and a computer network protocol</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-16.jpg" alt="" style="width:190pt;height:218pt;">
</div><br clear="all">
<p><span class="font53">Let’s consider a second human analogy. Suppose you’re in a college class (a computer networking class, for example!). The teacher is droning on about protocols and you’re confused. The teacher stops to ask, “Are there any questions?” (a message that is transmitted to, and received by, all students who are not sleeping). You raise your hand (transmitting an implicit message to the teacher). Your teacher acknowledges you with a smile, saying “Yes . . .” (a transmitted message encouraging you to ask your question—teachers </span><span class="font53" style="font-style:italic;">love</span><span class="font53"> to be asked questions), and you then ask your question (that is, transmit your message to your teacher). Your teacher hears your question (receives your question message) and answers (transmits a reply to you). Once again, we see that the transmission and receipt of messages, and a set of conventional actions taken when these messages are sent and received, are at the heart of this question-and-answer protocol.</span></p>
<p><span class="font22" style="font-weight:bold;">Network Protocols</span></p>
<p><span class="font53">A network protocol is similar to a human protocol, except that the entities exchanging messages and taking actions are hardware or software components of some device (for example, computer, smartphone, tablet, router, or other network-capable device). All activity in the Internet that involves two or more communicating remote entities is governed by a protocol. For example, hardware-implemented protocols in two physically connected computers control the flow of bits on the “wire” between the two network interface cards; congestion-control protocols in end systems control the rate at which packets are transmitted between sender and receiver; protocols in routers determine a packet’s path from source to destination. Protocols are running everywhere in the Internet, and consequently much of this book is about computer network protocols.</span></p>
<p><span class="font53">As an example of a computer network protocol with which you are probably familiar, consider what happens when you make a request to a Web server, that is, when you type the URL of a Web page into your Web browser. The scenario is illustrated in the right half of Figure 1.2. First, your computer will send a connection request message to the Web server and wait for a reply. The Web server will eventually receive your connection request message and return a connection reply message. Knowing that it is now OK to request the Web document, your computer then sends the name of the Web page it wants to fetch from that Web server in a GET message. Finally, the Web server returns the Web page (file) to your computer.</span></p>
<p><span class="font53">Given the human and networking examples above, the exchange of messages and the actions taken when these messages are sent and received are the key defining elements of a protocol:</span></p>
<p><span class="font53" style="font-style:italic;">A </span><span class="font53" style="font-weight:bold;font-style:italic;">protocol </span><span class="font53" style="font-style:italic;">defines the format and the order of messages exchanged between two or more communicating entities, as well as the actions taken on the transmission and/or receipt of a message or other event.</span></p>
<p><span class="font53">The Internet, and computer networks in general, make extensive use of protocols. Different protocols are used to accomplish different communication tasks. As you read through this book, you will learn that some protocols are simple and straightforward, while others are complex and intellectually deep. Mastering the field of computer networking is equivalent to understanding the what, why, and how of networking protocols.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">1.2 </span><span class="font24" style="font-weight:bold;">The Network Edge</span></p></li></ul>
<p><span class="font53">In the previous section, we presented a high-level overview of the Internet and networking protocols. We are now going to delve a bit more deeply into the components of the Internet. We begin in this section at the edge of the network and look at the components with which we are most familiar—namely, the computers, smartphones and other devices that we use on a daily basis. In the next section, we’ll move from the network edge to the network core and examine switching and routing in computer networks.</span></p>
<p><a name="bookmark265"></a><span class="font53">Recall from the previous section that in computer networking jargon, the computers and other devices connected to the Internet are often referred to as end systems. They are referred to as end systems because they sit at the edge of the Internet, as shown in Figure 1.3. The Internet’s end systems include desktop computers</span></p>
<div>
<p><span class="font4" style="font-weight:bold;">National or Global ISP</span></p>
<p><span class="font4" style="font-weight:bold;">Home Network</span></p><img src="networking_files/networking-17.jpg" alt="" style="width:321pt;height:371pt;">
<p><span class="font4" style="font-weight:bold;">Enterprise Network</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 1.3 </span><span class="font50">♦ </span><span class="font5">End-system interaction</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Mobile Network</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Local or Regional ISP</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Datacenter Network</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Datacenter Network</span></p>
</div><br clear="all">
<p><span class="font53">(e.g., desktop PCs, Macs, and Linux boxes), servers (e.g., Web and e-mail servers), and mobile devices (e.g., laptops, smartphones, and tablets). Furthermore, an increasing number of non-traditional “things” are being attached to the Internet as end systems (see the Case History feature).</span></p>
<p><span class="font53">End systems are also referred to as </span><span class="font53" style="font-style:italic;">hosts</span><span class="font53"> because they host (that is, run) application programs such as a Web browser program, a Web server program, an e-mail</span></p>
<p><span class="font58" style="font-weight:bold;">I^r &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<sup>CASE</sup> </span><span class="font59" style="font-weight:bold;font-variant:small-caps;">history</span></p>
<p><span class="font4" style="font-weight:bold;">DATA CENTERS AND CLOUD COMPUTING</span></p>
<p><span class="font4">Internet companies such as Google, Microsoft, Amazon, and Alibaba have built massive data centers, each housing tens to hundreds of thousands of hosts. These data centers are not only connected to the Internet, as shown in Figure 1.1, but also internally include complex computer networks that interconnect the datacenter’s hosts. The data centers are the engines behind the Internet applications that we use on a daily basis.</span></p>
<p><span class="font4">Broadly speaking, data centers serve three purposes, which we describe here in the context of Amazon for concreteness. First, they serve Amazon e-commerce pages to users, for example, pages describing products and purchase information. Second, they serve as massively parallel computing infrastructures for Amazon-specific data processing tasks. Third, they provide </span><span class="font5" style="font-weight:bold;">cloud computing </span><span class="font4">to other companies. Indeed, today a major trend in computing is for companies to use a cloud provider such as Amazon to handle essentially </span><span class="font4" style="font-style:italic;">all</span><span class="font4"> of their IT needs. For example, Airbnb and many other Internet-based companies do not own and manage their own data centers but instead run their entire Web-based services in the Amazon cloud, called Amazon Web Services (AWS).</span></p>
<p><span class="font4">The worker bees in a data center are the hosts. They serve content (e.g., Web pages and videos), store e-mails and documents, and collectively perform massively distributed computations. The hosts in data centers, called blades and resembling pizza boxes, are generally commodity hosts that include CPU, memory, and disk storage. The hosts are stacked in racks, with each rack typically having 20 to 40 blades. The racks are then interconnected using sophisticated and evolving data center network designs. Data center networks are discussed in greater detail in Chapter 6.</span></p>
<p><span class="font53">client program, or an e-mail server program. Throughout this book we will use the terms hosts and end systems interchangeably; that is, </span><span class="font53" style="font-style:italic;">host = end system.</span><span class="font53"> Hosts are sometimes further divided into two categories: </span><span class="font53" style="font-weight:bold;">clients </span><span class="font53">and </span><span class="font53" style="font-weight:bold;">servers</span><span class="font53">. Informally, clients tend to be desktops, laptops, smartphones, and so on, whereas servers tend to be more powerful machines that store and distribute Web pages, stream video, relay e-mail, and so on. Today, most of the servers from which we receive search results, e-mail, Web pages, videos and mobile app content reside in large </span><span class="font53" style="font-weight:bold;">data centers</span><span class="font53">. For example, as of 2020, Google has 19 data centers on four continents, collectively containing several million servers. Figure 1.3 includes two such data centers, and the Case History sidebar describes data centers in more detail.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">1.2.1 </span><span class="font23" style="font-weight:bold;">Access Networks</span></p></li></ul>
<p><span class="font53">Having considered the applications and end systems at the “edge of the network,” let’s next consider the access network—the network that physically connects an end system to the first router (also known as the “edge router”) on a path from the end system to any other distant end system. Figure 1.4 shows several types of access networks with thick, shaded lines and the settings (home, enterprise, and wide-area mobile wireless) in which they are used.</span></p>
<div>
<p><span class="font4" style="font-weight:bold;">National or Global ISP</span></p><img src="networking_files/networking-18.jpg" alt="" style="width:316pt;height:228pt;">
<p><span class="font4" style="font-weight:bold;">Home Network</span></p>
<p><span class="font4" style="font-weight:bold;">Content Provider Network</span></p>
<p><span class="font4" style="font-weight:bold;">Local or Regional ISP</span></p>
</div><br clear="all">
<div>
<table border="1">
<tr><td></td><td></td></tr>
<tr><td></td><td></td></tr>
<tr><td>
<p><span class="font12">0 <sup>u</sup></span></p></td><td>
<p><span class="font43" style="font-weight:bold;">r3&gt; I</span></p></td></tr>
<tr><td></td><td></td></tr>
</table>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Mobile Network</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Datacenter Network</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Datacenter Network</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-19.jpg" alt="" style="width:243pt;height:112pt;">
<p><a name="bookmark266"></a><span class="font7" style="font-weight:bold;">Figure 1.4 </span><span class="font50">♦ </span><span class="font5">Access networks</span></p>
</div><br clear="all">
<p><span class="font22" style="font-weight:bold;">Home Access: DSL, Cable, FTTH, and 5G Fixed Wireless</span></p>
<p><span class="font53">As of 2020, more than 80% of the households in Europe and the USA have Internet access [Statista 2019]. Given this widespread use of home access networks let’s begin our overview of access networks by considering how homes connect to the Internet.</span></p>
<p><span class="font53">Today, the two most prevalent types of broadband residential access are </span><span class="font53" style="font-weight:bold;">digital subscriber line (DSL) </span><span class="font53">and cable. A residence typically obtains DSL Internet access from the same local telephone company (telco) that provides its wired local phone access. Thus, when DSL is used, a customer’s telco is also its ISP. As shown in Figure 1.5, each customer’s DSL modem uses the existing telephone line exchange data with a digital subscriber line access multiplexer (DSLAM) located in the telco’s local central office (CO). The home’s DSL modem takes digital data and translates it to high-frequency tones for transmission over telephone wires to the CO; the analog signals from many such houses are translated back into digital format at the DSLAM.</span></p>
<p><span class="font53">The residential telephone line carries both data and traditional telephone signals simultaneously, which are encoded at different frequencies:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;A high-speed downstream channel, in the 50 kHz to 1 MHz band</span></p></li>
<li>
<p><span class="font53">• &nbsp;A medium-speed upstream channel, in the 4 kHz to 50 kHz band</span></p></li>
<li>
<p><span class="font53">• &nbsp;An ordinary two-way telephone channel, in the 0 to 4 kHz band</span></p></li></ul>
<p><span class="font53">This approach makes the single DSL link appear as if there were three separate links, so that a telephone call and an Internet connection can share the DSL link at the same time. (We’ll describe this technique of frequency-division multiplexing in Section 1.3.1.) On the customer side, a splitter separates the data and telephone signals arriving to the home and forwards the data signal to the DSL modem. On the telco side, in the CO, the DSLAM separates the data and phone signals and sends the data into the Internet. Hundreds or even thousands of households connect to a single DSLAM.</span></p>
<div>
<p><span class="font4">Home phone</span></p><img src="networking_files/networking-20.jpg" alt="" style="width:90pt;height:100pt;">
<p><span class="font4">Existing phone line: 0-4KHz phone; 4-50KHz upstream data; 50KHz-1MHz downstream data</span></p>
<p><span class="font4">Splitter</span></p>
<p><span class="font4">Home PC</span></p>
<p><span class="font4">DSL modem</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 1.5 </span><span class="font50">♦ </span><span class="font5">DSL Internet access</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Internet</span></p>
<p><span class="font4">DSLAM</span></p>
<p><span class="font4">Central office</span></p><img src="networking_files/networking-21.jpg" alt="" style="width:139pt;height:107pt;">
<p><span class="font4">Telephone network</span></p>
</div><br clear="all">
<p><span class="font53">The DSL standards define multiple transmission rates, including downstream transmission rates of 24 Mbs and 52 Mbs, and upstream rates of 3.5 Mbps and 16 Mbps; the newest standard provides for aggregate upstream plus downstream rates of 1 Gbps [ITU 2014]. Because the downstream and upstream rates are different, the access is said to be asymmetric. The actual downstream and upstream transmission rates achieved may be less than the rates noted above, as the DSL provider may purposefully limit a residential rate when tiered service (different rates, available at different prices) are offered. The maximum rate is also limited by the distance between the home and the CO, the gauge of the twisted-pair line and the degree of electrical interference. Engineers have expressly designed DSL for short distances between the home and the CO; generally, if the residence is not located within 5 to 10 miles of the CO, the residence must resort to an alternative form of Internet access.</span></p>
<p><span class="font53">While DSL makes use of the telco’s existing local telephone infrastructure, </span><span class="font53" style="font-weight:bold;">cable Internet access </span><span class="font53">makes use of the cable television company’s existing cable television infrastructure. A residence obtains cable Internet access from the same company that provides its cable television. As illustrated in Figure 1.6, fiber optics</span></p><img src="networking_files/networking-22.jpg" alt="" style="width:396pt;height:184pt;">
<p><span class="font7" style="font-weight:bold;">Figure 1.6 </span><span class="font50">♦ </span><span class="font5">A hybrid fiber-coaxial access network</span></p>
<p><span class="font53">connect the cable head end to neighborhood-level junctions, from which traditional coaxial cable is then used to reach individual houses and apartments. Each neighborhood junction typically supports 500 to 5,000 homes. Because both fiber and coaxial cable are employed in this system, it is often referred to as hybrid fiber coax (HFC).</span></p>
<p><span class="font53">Cable internet access requires special modems, called cable modems. As with a DSL modem, the cable modem is typically an external device and connects to the home PC through an Ethernet port. (We will discuss Ethernet in great detail in Chapter 6.) At the cable head end, the cable modem termination system (CMTS) serves a similar function as the DSL network’s DSLAM— turning the analog signal sent from the cable modems in many downstream homes back into digital format. Cable modems divide the HFC network into two channels, a downstream and an upstream channel. As with DSL, access is typically asymmetric, with the downstream channel typically allocated a higher transmission rate than the upstream channel. The DOCSIS 2.0 and 3.0 standards define downstream bitrates of 40 Mbps and 1.2 Gbps, and upstream rates of 30 Mbps and 100 Mbps, respectively. As in the case of DSL networks, the maximum achievable rate may not be realized due to lower contracted data rates or media impairments.</span></p>
<p><span class="font53">One important characteristic of cable Internet access is that it is a shared broadcast medium. In particular, every packet sent by the head end travels downstream on every link to every home and every packet sent by a home travels on the upstream channel to the head end. For this reason, if several users are simultaneously downloading a video file on the downstream channel, the actual rate at which each user receives its video file will be significantly lower than the aggregate cable downstream rate. On the other hand, if there are only a few active users and they are all Web surfing, then each of the users may actually receive Web pages at the full cable downstream rate, because the users will rarely request a Web page at exactly the same time. Because the upstream channel is also shared, a distributed multiple access protocol is needed to coordinate transmissions and avoid collisions. (We’ll discuss this collision issue in some detail in Chapter 6.)</span></p>
<p><span class="font53">Although DSL and cable networks currently represent the majority of residential broadband access in the United States, an up-and-coming technology that provides even higher speeds is </span><span class="font53" style="font-weight:bold;">fiber to the home (FTTH) </span><span class="font53">[Fiber Broadband 2020]. As the name suggests, the FTTH concept is simple—provide an optical fiber path from the CO directly to the home. FTTH can potentially provide Internet access rates in the gigabits per second range.</span></p>
<p><span class="font53">There are several competing technologies for optical distribution from the CO to the homes. The simplest optical distribution network is called direct fiber, with one fiber leaving the CO for each home. More commonly, each fiber leaving the central office is actually shared by many homes; it is not until the fiber gets relatively close to the homes that it is split into individual customer-specific fibers. There are two competing optical-distribution network architectures that perform</span></p><img src="networking_files/networking-23.jpg" alt="" style="width:319pt;height:119pt;">
<p><span class="font7" style="font-weight:bold;">Figure 1.7 </span><span class="font50">♦ </span><span class="font5">FTTH Internet access</span></p>
<p><span class="font53">this splitting: active optical networks (AONs) and passive optical networks (PONs). AON is essentially switched Ethernet, which is discussed in Chapter 6.</span></p>
<p><span class="font53">Here, we briefly discuss PON, which is used in Verizon’s FiOS service. Figure 1.7 shows FTTH using the PON distribution architecture. Each home has an optical network terminator (ONT), which is connected by dedicated optical fiber to a neighborhood splitter. The splitter combines a number of homes (typically less than 100) onto a single, shared optical fiber, which connects to an optical line terminator (OLT) in the telco’s CO. The OLT, providing conversion between optical and electrical signals, connects to the Internet via a telco router. At home, users connect a home router (typically a wireless router) to the ONT and access the Internet via this home router. In the PON architecture, all packets sent from OLT to the splitter are replicated at the splitter (similar to a cable head end).</span></p>
<p><span class="font53">In addition to DSL, Cable, and FTTH, </span><span class="font53" style="font-weight:bold;">5G fixed wireless </span><span class="font53">is beginning to be deployed. 5G fixed wireless not only promises high-speed residential access, but will do so without installing costly and failure-prone cabling from the telco’s CO to the home. With 5G fixed wireless, using beam-forming technology, data is sent wirelessly from a provider’s base station to the a modem in the home. A WiFi wireless router is connected to the modem (possibly bundled together), similar to how a WiFi wireless router is connected to a cable or DSL modem. 5G cellular networks are covered in Chapter 7.</span></p>
<p><span class="font22" style="font-weight:bold;">Access in the Enterprise (and the Home): Ethernet and WiFi</span></p>
<p><span class="font53">On corporate and university campuses, and increasingly in home settings, a local area network (LAN) is used to connect an end system to the edge router. Although there are many types of LAN technologies, Ethernet is by far the most prevalent access technology in corporate, university, and home networks. As shown in</span></p>
<div><img src="networking_files/networking-24.jpg" alt="" style="width:28pt;height:30pt;">
<p><span class="font4" style="text-decoration:underline;">1 Gbps</span></p>
</div><br clear="all">
<div>
<p><span class="font4">1 Gbps</span></p><img src="networking_files/networking-25.jpg" alt="" style="width:106pt;height:143pt;">
<p><span class="font4">1 Gbps</span></p>
<p><span class="font4">Server</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 1.8 </span><span class="font50">♦ </span><span class="font5">Ethernet Internet access</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Ethernet switch</span></p><img src="networking_files/networking-26.jpg" alt="" style="width:165pt;height:84pt;">
</div><br clear="all">
<p><span class="font53">Figure 1.8, Ethernet users use twisted-pair copper wire to connect to an Ethernet switch, a technology discussed in detail in Chapter 6. The Ethernet switch, or a network of such interconnected switches, is then in turn connected into the larger Internet. With Ethernet access, users typically have 100 Mbps to tens of Gbps access to the Ethernet switch, whereas servers may have 1 Gbps 10 Gbps access.</span></p>
<p><span class="font53">Increasingly, however, people are accessing the Internet wirelessly from laptops, smartphones, tablets, and other “things”. In a wireless LAN setting, wireless users transmit/receive packets to/from an access point that is connected into the enterprise’s network (most likely using wired Ethernet), which in turn is connected to the wired Internet. A wireless LAN user must typically be within a few tens of meters of the access point. Wireless LAN access based on IEEE 802.11 technology, more colloquially known as WiFi, is now just about everywhere—universities, business offices, cafes, airports, homes, and even in airplanes. As discussed in detail in Chapter 7, 802.11 today provides a shared transmission rate of up to more than 100 Mbps.</span></p>
<p><span class="font53">Even though Ethernet and WiFi access networks were initially deployed in enterprise (corporate, university) settings, they are also common components of home networks. Many homes combine broadband residential access (that is, cable modems or DSL) with these inexpensive wireless LAN technologies to create powerful home networks Figure 1.9 shows a typical home network. This home network consists of a roaming laptop, multiple Internet-connected home appliances, as well as a wired PC; a base station (the wireless access point), which communicates with the wireless PC and other wireless devices in the home; and a home router that connects the wireless access point, and any other wired home devices, to the Internet. This network allows household members to have broadband access to the Internet with one member roaming from the kitchen to the backyard to the bedrooms.</span></p><img src="networking_files/networking-27.jpg" alt="" style="width:338pt;height:112pt;">
<p><span class="font7" style="font-weight:bold;">Figure 1.9 </span><span class="font50">♦ </span><span class="font5">A typical home network</span></p>
<p><span class="font22" style="font-weight:bold;">Wide-Area Wireless Access: 3G and LTE 4G and 5G</span></p>
<p><span class="font53">Mobile devices such as iPhones and Android devices are being used to message, share photos in social networks, make mobile payments, watch movies, stream music, and much more while on the run. These devices employ the same wireless infrastructure used for cellular telephony to send/receive packets through a base station that is operated by the cellular network provider. Unlike WiFi, a user need only be within a few tens of kilometers (as opposed to a few tens of meters) of the base station.</span></p>
<p><span class="font53">Telecommunications companies have made enormous investments in so-called fourth-generation (4G) wireless, which provides real-world download speeds of up to 60 Mbps. But even higher-speed wide-area access technologies—a fifth-generation (5G) of wide-area wireless networks—are already being deployed. We’ll cover the basic principles of wireless networks and mobility, as well as WiFi, 4G and 5G technologies (and more!) in Chapter 7.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">1.2.2 </span><span class="font23" style="font-weight:bold;">Physical Media</span></p></li></ul>
<p><span class="font53">In the previous subsection, we gave an overview of some of the most important network access technologies in the Internet. As we described these technologies, we also indicated the physical media used. For example, we said that HFC uses a combination of fiber cable and coaxial cable. We said that DSL and Ethernet use copper wire. And we said that mobile access networks use the radio spectrum. In this subsection, we provide a brief overview of these and other transmission media that are commonly used in the Internet.</span></p>
<p><a name="bookmark267"></a><span class="font53">In order to define what is meant by a physical medium, let us reflect on the brief life of a bit. Consider a bit traveling from one end system, through a series of links and routers, to another end system. This poor bit gets kicked around and transmitted many, many times! The source end system first transmits the bit, and shortly thereafter the first router in the series receives the bit; the first router then transmits the bit, and shortly thereafter the second router receives the bit; and so on. Thus our bit, when traveling from source to destination, passes through a series of transmitter-receiver pairs. For each transmitter-receiver pair, the bit is sent by propagating electromagnetic waves or optical pulses across a </span><span class="font53" style="font-weight:bold;">physical medium</span><span class="font53">. The physical medium can take many shapes and forms and does not have to be of the same type for each transmitter-receiver pair along the path. Examples of physical media include twisted-pair copper wire, coaxial cable, multimode fiber-optic cable, terrestrial radio spectrum, and satellite radio spectrum. Physical media fall into two categories: </span><span class="font53" style="font-weight:bold;">guided media </span><span class="font53">and </span><span class="font53" style="font-weight:bold;">unguided media</span><span class="font53">. With guided media, the waves are guided along a solid medium, such as a fiber-optic cable, a twisted-pair copper wire, or a coaxial cable. With unguided media, the waves propagate in the atmosphere and in outer space, such as in a wireless LAN or a digital satellite channel.</span></p>
<p><span class="font53">But before we get into the characteristics of the various media types, let us say a few words about their costs. The actual cost of the physical link (copper wire, fiberoptic cable, and so on) is often relatively minor compared with other networking costs. In particular, the labor cost associated with the installation of the physical link can be orders of magnitude higher than the cost of the material. For this reason, many builders install twisted pair, optical fiber, and coaxial cable in every room in a building. Even if only one medium is initially used, there is a good chance that another medium could be used in the near future, and so money is saved by not having to lay additional wires in the future.</span></p>
<p><span class="font22" style="font-weight:bold;">Twisted-Pair Copper Wire</span></p>
<p><span class="font53">The least expensive and most commonly used guided transmission medium is twisted-pair copper wire. For over a hundred years it has been used by telephone networks. In fact, more than 99 percent of the wired connections from the telephone handset to the local telephone switch use twisted-pair copper wire. Most of us have seen twisted pair in our homes (or those of our parents or grandparents!) and work environments. Twisted pair consists of two insulated copper wires, each about 1 mm thick, arranged in a regular spiral pattern. The wires are twisted together to reduce the electrical interference from similar pairs close by. Typically, a number of pairs are bundled together in a cable by wrapping the pairs in a protective shield. A wire pair constitutes a single communication link. </span><span class="font53" style="font-weight:bold;">Unshielded twisted pair (UTP) </span><span class="font53">is commonly used for computer networks within a building, that is, for LANs. Data rates for LANs using twisted pair today range from 10 Mbps to 10 Gbps. The data rates that can be achieved depend on the thickness of the wire and the distance between transmitter and receiver.</span></p>
<p><span class="font53">When fiber-optic technology emerged in the 1980s, many people disparaged twisted pair because of its relatively low bit rates. Some people even felt that fiber-optic technology would completely replace twisted pair. But twisted pair did not give up so easily. Modern twisted-pair technology, such as category 6a cable, can achieve data rates of 10 Gbps for distances up to a hundred meters. In the end, twisted pair has emerged as the dominant solution for high-speed LAN networking.</span></p>
<p><span class="font53">As discussed earlier, twisted pair is also commonly used for residential Internet access. We saw that dial-up modem technology enables access at rates of up to 56 kbps over twisted pair. We also saw that DSL (digital subscriber line) technology has enabled residential users to access the Internet at tens of Mbps over twisted pair (when users live close to the ISP’s central office).</span></p>
<p><span class="font22" style="font-weight:bold;">Coaxial Cable</span></p>
<p><span class="font53">Like twisted pair, coaxial cable consists of two copper conductors, but the two conductors are concentric rather than parallel. With this construction and special insulation and shielding, coaxial cable can achieve high data transmission rates. Coaxial cable is quite common in cable television systems. As we saw earlier, cable television systems have recently been coupled with cable modems to provide residential users with Internet access at rates of hundreds of Mbps. In cable television and cable Internet access, the transmitter shifts the digital signal to a specific frequency band, and the resulting analog signal is sent from the transmitter to one or more receivers. Coaxial cable can be used as a guided </span><span class="font53" style="font-weight:bold;">shared medium</span><span class="font53">. Specifically, a number of end systems can be connected directly to the cable, with each of the end systems receiving whatever is sent by the other end systems.</span></p>
<p><span class="font22" style="font-weight:bold;">Fiber Optics</span></p>
<p><span class="font53">An optical fiber is a thin, flexible medium that conducts pulses of light, with each pulse representing a bit. A single optical fiber can support tremendous bit rates, up to tens or even hundreds of gigabits per second. They are immune to electromagnetic interference, have very low signal attenuation up to 100 kilometers, and are very hard to tap. These characteristics have made fiber optics the preferred long-haul guided transmission media, particularly for overseas links. Many of the long-distance telephone networks in the United States and elsewhere now use fiber optics exclusively. Fiber optics is also prevalent in the backbone of the Internet. However, the high cost of optical devices—such as transmitters, receivers, and switches—has hindered their deployment for short-haul transport, such as in a LAN or into the home in a residential access network. The Optical Carrier (OC) standard link speeds range from 51.8 Mbps to 39.8 Gbps; these specifications are often referred to as OC-</span><span class="font53" style="font-style:italic;">n</span><span class="font53">, where the link speed equals </span><span class="font53" style="font-style:italic;">n</span><span class="font54"> X </span><span class="font53">51.8 Mbps. Standards in use today include OC-1, OC-3, OC-12, OC-24, OC-48, OC-96, OC-192, OC-768.</span></p>
<p><span class="font22" style="font-weight:bold;">Terrestrial Radio Channels</span></p>
<p><span class="font53">Radio channels carry signals in the electromagnetic spectrum. They are an attractive medium because they require no physical wire to be installed, can penetrate walls, provide connectivity to a mobile user, and can potentially carry a signal for long distances. The characteristics of a radio channel depend significantly on the propagation environment and the distance over which a signal is to be carried. Environmental considerations determine path loss and shadow fading (which decrease the signal strength as the signal travels over a distance and around/through obstructing objects), multipath fading (due to signal reflection off of interfering objects), and interference (due to other transmissions and electromagnetic signals).</span></p>
<p><span class="font53">Terrestrial radio channels can be broadly classified into three groups: those that operate over very short distance (e.g., with one or two meters); those that operate in local areas, typically spanning from ten to a few hundred meters; and those that operate in the wide area, spanning tens of kilometers. Personal devices such as wireless headsets, keyboards, and medical devices operate over short distances; the wireless LAN technologies described in Section 1.2.1 use local-area radio channels; the cellular access technologies use wide-area radio channels. We’ll discuss radio channels in detail in Chapter 7.</span></p>
<p><span class="font22" style="font-weight:bold;">Satellite Radio Channels</span></p>
<p><span class="font53">A communication satellite links two or more Earth-based microwave transmitter/ receivers, known as ground stations. The satellite receives transmissions on one frequency band, regenerates the signal using a repeater (discussed below), and transmits the signal on another frequency. Two types of satellites are used in communications: </span><span class="font53" style="font-weight:bold;">geostationary satellites </span><span class="font53">and </span><span class="font53" style="font-weight:bold;">low-earth orbiting (LEO) satellites</span><span class="font53">.</span></p>
<p><span class="font53">Geostationary satellites permanently remain above the same spot on Earth. This stationary presence is achieved by placing the satellite in orbit at 36,000 kilometers above Earth’s surface. This huge distance from ground station through satellite back to ground station introduces a substantial signal propagation delay of 280 milliseconds. Nevertheless, satellite links, which can operate at speeds of hundreds of Mbps, are often used in areas without access to DSL or cable-based Internet access.</span></p>
<p><span class="font53">LEO satellites are placed much closer to Earth and do not remain permanently above one spot on Earth. They rotate around Earth (just as the Moon does) and may communicate with each other, as well as with ground stations. To provide continuous coverage to an area, many satellites need to be placed in orbit. There are currently many low-altitude communication systems in development. LEO satellite technology may be used for Internet access sometime in the future.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">1.3 </span><span class="font24" style="font-weight:bold;">The Network Core</span></p></li></ul>
<p><span class="font53">Having examined the Internet’s edge, let us now delve more deeply inside the network core—the mesh of packet switches and links that interconnects the Internet’s end systems. Figure 1.10 highlights the network core with thick, shaded lines.</span></p>
<p><span class="font4" style="font-weight:bold;">National or Global ISP</span></p>
<p><span class="font4" style="font-weight:bold;">Network</span></p>
<p><span class="font4" style="font-weight:bold;">Datacenter Network</span></p>
<p><span class="font4" style="font-weight:bold;">Datacenter Network</span></p>
<p><span class="font4" style="font-weight:bold;">Local or</span></p>
<p><span class="font4" style="font-weight:bold;">Home Network &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Regional ISP</span></p>
<p><span class="font4" style="font-weight:bold;">Content Provider Network</span></p><img src="networking_files/networking-28.jpg" alt="" style="width:292pt;height:115pt;">
<p><a name="bookmark268"></a><span class="font7" style="font-weight:bold;">Figure 1.10 </span><span class="font50">♦ </span><span class="font5">The network core</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">1.3.1 </span><span class="font23" style="font-weight:bold;">Packet Switching</span></p></li></ul>
<p><span class="font53">In a network application, end systems exchange </span><span class="font53" style="font-weight:bold;">messages </span><span class="font53">with each other. Messages can contain anything the application designer wants. Messages may perform a control function (for example, the “Hi” messages in our handshaking example in Figure 1.2) or can contain data, such as an e-mail message, a JPEG image, or an MP3 audio file. To send a message from a source end system to a destination end system, the source breaks long messages into smaller chunks of data known as </span><span class="font53" style="font-weight:bold;">packets</span><span class="font53">. Between source and destination, each packet travels through communication links and </span><span class="font53" style="font-weight:bold;">packet switches </span><span class="font53">(for which there are two predominant types, </span><span class="font53" style="font-weight:bold;">routers </span><span class="font53">and </span><span class="font53" style="font-weight:bold;">link-layer switches</span><span class="font53">). Packets are transmitted over each communication link at a rate equal to the </span><span class="font53" style="font-style:italic;">full</span><span class="font53"> transmission rate of the link. So, if a source end system or a packet switch is sending a packet of </span><span class="font53" style="font-style:italic;">L</span><span class="font53"> bits over a link with transmission rate </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> bits/sec, then the time to transmit the packet is </span><span class="font53" style="font-style:italic;">L/R</span><span class="font53"> seconds.</span></p>
<p><span class="font22" style="font-weight:bold;">Store-and-Forward Transmission</span></p>
<p><a name="bookmark269"></a><span class="font53">Most packet switches use </span><span class="font53" style="font-weight:bold;">store-and-forward transmission </span><span class="font53">at the inputs to the links. Store-and-forward transmission means that the packet switch must receive the entire packet before it can begin to transmit the first bit of the packet onto the outbound link. To explore store-and-forward transmission in more detail, consider a simple network consisting of two end systems connected by a single router, as shown in Figure 1.11. A router will typically have many incident links, since its job is to switch an incoming packet onto an outgoing link; in this simple example, the router has the rather simple task of transferring a packet from one (input) link to the only other attached link. In this example, the source has three packets, each consisting of </span><span class="font53" style="font-style:italic;">L</span><span class="font53"> bits, to send to the destination. At the snapshot of time shown in Figure 1.11, the source has transmitted some of packet 1, and the front of packet 1 has already arrived at the router. Because the router employs store-and-forwarding, at this instant of time, the router cannot transmit the bits it has received; instead it must first buffer (i.e., “store”) the packet’s bits. Only after the router has received </span><span class="font53" style="font-style:italic;">all</span><span class="font53"> of the packet’s bits can it begin to transmit (i.e., “forward”) the packet onto the outbound link. To gain some insight into store-and-forward transmission, let’s now calculate the amount of time that elapses from when the source begins to send the packet until the destination has received the entire packet. (Here we will ignore propagation delay—the time it takes for the bits to travel across the wire at near the speed of light—which will be discussed in Section 1.4.) The source begins to transmit at time 0; at time </span><span class="font53" style="font-style:italic;">L/R</span><span class="font53"> seconds, the source has transmitted the entire packet, and the entire packet has been received and stored at the router (since there is no propagation delay). At time </span><span class="font53" style="font-style:italic;">L</span><span class="font53">/</span><span class="font53" style="font-style:italic;">R</span><span class="font53"> seconds, since the router has just received the entire packet, it can begin to transmit the packet onto the outbound link towards the destination; at time 2</span><span class="font53" style="font-style:italic;">L</span><span class="font53">/</span><span class="font53" style="font-style:italic;">R</span><span class="font53">, the router has transmitted the entire packet, and the entire packet has been received by the destination. Thus, the total delay is 2</span><span class="font53" style="font-style:italic;">L</span><span class="font53">/</span><span class="font53" style="font-style:italic;">R</span><span class="font53">. If the</span></p>
<div><img src="networking_files/networking-29.jpg" alt="" style="width:34pt;height:37pt;">
<p><span class="font4">Source</span></p>
</div><br clear="all">
<div>
<p><span class="font4">32 1</span></p><img src="networking_files/networking-30.jpg" alt="" style="width:42pt;height:13pt;">
</div><br clear="all">
<div>
<p><span class="font4" style="font-style:italic;">R</span><span class="font4"> bps</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-31.jpg" alt="" style="width:27pt;height:34pt;">
</div><br clear="all">
<div><img src="networking_files/networking-32.jpg" alt="" style="width:34pt;height:37pt;">
<p><span class="font4">Destination</span></p>
</div><br clear="all">
<p><span class="font4">Front of packet 1 stored in router, awaiting remaining bits before forwarding</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 1.11 </span><span class="font50">♦ </span><span class="font5">Store-and-forward packet switching</span></p>
<p><span class="font53">switch instead forwarded bits as soon as they arrive (without first receiving the entire packet), then the total delay would be </span><span class="font53" style="font-style:italic;">L/R</span><span class="font53"> since bits are not held up at the router. But, as we will discuss in Section 1.4, routers need to receive, store, and </span><span class="font53" style="font-style:italic;">process</span><span class="font53"> the entire packet before forwarding.</span></p>
<p><span class="font53">Now let’s calculate the amount of time that elapses from when the source begins to send the first packet until the destination has received all three packets. As before, at time </span><span class="font53" style="font-style:italic;">L</span><span class="font53">/</span><span class="font53" style="font-style:italic;">R</span><span class="font53">, the router begins to forward the first packet. But also at time </span><span class="font53" style="font-style:italic;">L</span><span class="font53">/</span><span class="font53" style="font-style:italic;">R</span><span class="font53"> the source will begin to send the second packet, since it has just finished sending the entire first packet. Thus, at time 2</span><span class="font53" style="font-style:italic;">L</span><span class="font53">/</span><span class="font53" style="font-style:italic;">R</span><span class="font53">, the destination has received the first packet and the router has received the second packet. Similarly, at time 3</span><span class="font53" style="font-style:italic;">L</span><span class="font53">/</span><span class="font53" style="font-style:italic;">R</span><span class="font53">, the destination has received the first two packets and the router has received the third packet. Finally, at time 4</span><span class="font53" style="font-style:italic;">L</span><span class="font53">/</span><span class="font53" style="font-style:italic;">R</span><span class="font53"> the destination has received all three packets!</span></p>
<p><span class="font53">Let’s now consider the general case of sending one packet from source to destination over a path consisting of </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> links each of rate </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> (thus, there are </span><span class="font53" style="font-style:italic;">N</span><span class="font53">-1 routers between source and destination). Applying the same logic as above, we see that the end-to-end delay is:</span></p>
<p><span class="font53" style="font-style:italic;">_ L <sup>d</sup></span><span class="font50">end-to-end &nbsp;&nbsp;&nbsp;</span><span class="font53" style="font-style:italic;"><sup>N</sup> r</span></p>
<div>
<p><span class="font53">(1.1)</span></p>
</div><br clear="all">
<p><span class="font53">You may now want to try to determine what the delay would be for </span><span class="font53" style="font-style:italic;">P</span><span class="font53"> packets sent over a series of </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> links.</span></p>
<p><span class="font22" style="font-weight:bold;">Queuing Delays and Packet Loss</span></p>
<p><span class="font53">Each packet switch has multiple links attached to it. For each attached link, the packet switch has an </span><span class="font53" style="font-weight:bold;">output buffer </span><span class="font53">(also called an </span><span class="font53" style="font-weight:bold;">output queue</span><span class="font53">), which stores packets that the router is about to send into that link. The output buffers play a key role in packet switching. If an arriving packet needs to be transmitted onto a link but finds the link busy with the transmission of another packet, the arriving packet must wait in the output buffer. Thus, in addition to the store-and-forward delays, packets suffer output buffer </span><span class="font53" style="font-weight:bold;">queuing delays</span><span class="font53">. These delays are variable and depend on the</span></p><img src="networking_files/networking-33.jpg" alt="" style="width:273pt;height:146pt;">
<p><span class="font41">Packets &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font9"><sup>D &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;E</sup></span></p>
<p><span class="font7" style="font-weight:bold;">Figure 1.12 </span><span class="font50">♦ </span><span class="font5">Packet switching</span></p>
<p><span class="font53">level of congestion in the network. Since the amount of buffer space is finite, an arriving packet may find that the buffer is completely full with other packets waiting for transmission. In this case, </span><span class="font53" style="font-weight:bold;">packet loss </span><span class="font53">will occur—either the arriving packet or one of the already-queued packets will be dropped.</span></p>
<p><span class="font53">Figure 1.12 illustrates a simple packet-switched network. As in Figure 1.11, packets are represented by three-dimensional slabs. The width of a slab represents the number of bits in the packet. In this figure, all packets have the same width and hence the same length. Suppose Hosts A and B are sending packets to Host E. Hosts A and B first send their packets along 100 Mbps Ethernet links to the first router. The router then directs these packets to the 15 Mbps link. If, during a short interval of time, the arrival rate of packets to the router (when converted to bits per second) exceeds 15 Mbps, congestion will occur at the router as packets queue in the link’s output buffer before being transmitted onto the link. For example, if Host A and B each send a burst of five packets back-to-back at the same time, then most of these packets will spend some time waiting in the queue. The situation is, in fact, entirely analogous to many common-day situations—for example, when we wait in line for a bank teller or wait in front of a tollbooth. We’ll examine this queuing delay in more detail in Section 1.4.</span></p>
<p><span class="font22" style="font-weight:bold;">Forwarding Tables and Routing Protocols</span></p>
<p><span class="font53">Earlier, we said that a router takes a packet arriving on one of its attached communication links and forwards that packet onto another one of its attached communication links. But how does the router determine which link it should forward the packet onto? Packet forwarding is actually done in different ways in different types of computer networks. Here, we briefly describe how it is done in the Internet.</span></p>
<p><span class="font53">In the Internet, every end system has an address called an IP address. When a source end system wants to send a packet to a destination end system, the source includes the destination’s IP address in the packet’s header. As with postal addresses, this address has a hierarchical structure. When a packet arrives at a router in the network, the router examines a portion of the packet’s destination address and forwards the packet to an adjacent router. More specifically, each router has a </span><span class="font53" style="font-weight:bold;">forwarding table </span><span class="font53">that maps destination addresses (or portions of the destination addresses) to that router’s outbound links. When a packet arrives at a router, the router examines the address and searches its forwarding table, using this destination address, to find the appropriate outbound link. The router then directs the packet to this outbound link.</span></p>
<p><span class="font53">The end-to-end routing process is analogous to a car driver who does not use maps but instead prefers to ask for directions. For example, suppose Joe is driving from Philadelphia to 156 Lakeside Drive in Orlando, Florida. Joe first drives to his neighborhood gas station and asks how to get to 156 Lakeside Drive in Orlando, Florida. The gas station attendant extracts the Florida portion of the address and tells Joe that he needs to get onto the interstate highway I-95 South, which has an entrance just next to the gas station. He also tells Joe that once he enters Florida, he should ask someone else there. Joe then takes I-95 South until he gets to Jacksonville, Florida, at which point he asks another gas station attendant for directions. The attendant extracts the Orlando portion of the address and tells Joe that he should continue on I-95 to Daytona Beach and then ask someone else. In Daytona Beach, another gas station attendant also extracts the Orlando portion of the address and tells Joe that he should take I-4 directly to Orlando. Joe takes I-4 and gets off at the Orlando exit. Joe goes to another gas station attendant, and this time the attendant extracts the Lakeside Drive portion of the address and tells Joe the road he must follow to get to Lakeside Drive. Once Joe reaches Lakeside Drive, he asks a kid on a bicycle how to get to his destination. The kid extracts the 156 portion of the address and points to the house. Joe finally reaches his ultimate destination. In the above analogy, the gas station attendants and kids on bicycles are analogous to routers.</span></p>
<p><span class="font53">We just learned that a router uses a packet’s destination address to index a forwarding table and determine the appropriate outbound link. But this statement begs yet another question: How do forwarding tables get set? Are they configured by hand in each and every router, or does the Internet use a more automated procedure? This issue will be studied in depth in Chapter 5. But to whet your appetite here, we’ll note now that the Internet has a number of special </span><span class="font53" style="font-weight:bold;">routing protocols </span><span class="font53">that are used to automatically set the forwarding tables. A routing protocol may, for example, determine the shortest path from each router to each destination and use the shortest path results to configure the forwarding tables in the routers.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">1.3.2 </span><span class="font23" style="font-weight:bold;">Circuit Switching</span></p></li></ul>
<p><span class="font53">There are two fundamental approaches to moving data through a network of links and switches: </span><span class="font53" style="font-weight:bold;">circuit switching </span><span class="font53">and </span><span class="font53" style="font-weight:bold;">packet switching</span><span class="font53">. Having covered packet-switched networks in the previous subsection, we now turn our attention to circuit-switched networks.</span></p>
<p><span class="font53">In circuit-switched networks, the resources needed along a path (buffers, link transmission rate) to provide for communication between the end systems are </span><span class="font53" style="font-style:italic;">reserved</span><span class="font53"> for the duration of the communication session between the end systems. In packet-switched networks, these resources are </span><span class="font53" style="font-style:italic;">not</span><span class="font53"> reserved; a session’s messages use the resources on demand and, as a consequence, may have to wait (that is, queue) for access to a communication link. As a simple analogy, consider two restaurants, one that requires reservations and another that neither requires reservations nor accepts them. For the restaurant that requires reservations, we have to go through the hassle of calling before we leave home. But when we arrive at the restaurant we can, in principle, immediately be seated and order our meal. For the restaurant that does not require reservations, we don’t need to bother to reserve a table. But when we arrive at the restaurant, we may have to wait for a table before we can be seated.</span></p>
<p><span class="font53">Traditional telephone networks are examples of circuit-switched networks. Consider what happens when one person wants to send information (voice or facsimile) to another over a telephone network. Before the sender can send the information, the network must establish a connection between the sender and the receiver. This is a </span><span class="font53" style="font-style:italic;">bona fide</span><span class="font53"> connection for which the switches on the path between the sender and receiver maintain connection state for that connection. In the jargon of telephony, this connection is called a </span><span class="font53" style="font-weight:bold;">circuit</span><span class="font53">. When the network establishes the circuit, it also reserves a constant transmission rate in the network’s links (representing a fraction of each link’s transmission capacity) for the duration of the connection. Since a given transmission rate has been reserved for this sender-to-receiver connection, the sender can transfer the data to the receiver at the </span><span class="font53" style="font-style:italic;">guaranteed</span><span class="font53"> constant rate.</span></p>
<p><a name="bookmark270"></a><span class="font53">Figure 1.13 illustrates a circuit-switched network. In this network, the four circuit switches are interconnected by four links. Each of these links has four circuits, so that each link can support four simultaneous connections. The hosts (for example, PCs and workstations) are each directly connected to one of the switches. When two hosts want to communicate, the network establishes a dedicated </span><span class="font53" style="font-weight:bold;">end-to-end connection </span><span class="font53">between the two hosts. Thus, in order for Host A to communicate with Host B, the network must first reserve one circuit on each of two links. In this example, the dedicated end-to-end connection uses the second circuit in the first link and the fourth circuit in the second link. Because each link has four circuits, for each link used by the end-to-end connection, the connection gets one fourth of the link’s total transmission capacity for the duration of the connection. Thus, for example, if each link between adjacent switches has a transmission rate of 1 Mbps, then each end-to-end circuit-switch connection gets 250 kbps of dedicated transmission rate.</span></p><img src="networking_files/networking-34.jpg" alt="" style="width:214pt;height:149pt;">
<p><span class="font7" style="font-weight:bold;">Figure 1.13 </span><span class="font50">♦ </span><span class="font5">A simple circuit-switched network consisting of four switches and four links</span></p>
<p><span class="font53">In contrast, consider what happens when one host wants to send a packet to another host over a packet-switched network, such as the Internet. As with circuit switching, the packet is transmitted over a series of communication links. But different from circuit switching, the packet is sent into the network without reserving any link resources whatsoever. If one of the links is congested because other packets need to be transmitted over the link at the same time, then the packet will have to wait in a buffer at the sending side of the transmission link and suffer a delay. The Internet makes its best effort to deliver packets in a timely manner, but it does not make any guarantees.</span></p>
<p><span class="font22" style="font-weight:bold;">Multiplexing in Circuit-Switched Networks</span></p>
<p><span class="font53">A circuit in a link is implemented with either </span><span class="font53" style="font-weight:bold;">frequency-division multiplexing (FDM) </span><span class="font53">or </span><span class="font53" style="font-weight:bold;">time-division multiplexing (TDM)</span><span class="font53">. With FDM, the frequency spectrum of a link is divided up among the connections established across the link. Specifically, the link dedicates a frequency band to each connection for the duration of the connection. In telephone networks, this frequency band typically has a width of 4 kHz (that is, 4,000 hertz or 4,000 cycles per second). The width of the band is called, not surprisingly, the </span><span class="font53" style="font-weight:bold;">bandwidth</span><span class="font53">. FM radio stations also use FDM to share the frequency spectrum between 88 MHz and 108 MHz, with each station being allocated a specific frequency band.</span></p>
<p><span class="font53">For a TDM link, time is divided into frames of fixed duration, and each frame is divided into a fixed number of time slots. When the network establishes a connection across a link, the network dedicates one time slot in every frame to this connection. These slots are dedicated for the sole use of that connection, with one time slot available for use (in every frame) to transmit the connection’s data.</span></p>
<div>
<p><span class="font4">4KHz</span></p>
<p><span class="font4">4KHz</span></p><img src="networking_files/networking-35.jpg" alt="" style="width:215pt;height:149pt;">
<p><span class="font4">Key:</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Time</span></p>
</div><br clear="all">
<p><span class="font4">2 </span><span class="font41">All slots labeled “2” are dedicated ■ to a specific sender-receiver pair.</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 1.14 </span><span class="font50">♦ </span><span class="font5">With FDM, each circuit continuously gets a fraction of the bandwidth. With TDM, each circuit gets all of the bandwidth periodically during brief intervals of time (that is, during slots)</span></p>
<p><span class="font53">Figure 1.14 illustrates FDM and TDM for a specific network link supporting up to four circuits. For FDM, the frequency domain is segmented into four bands, each of bandwidth 4 kHz. For TDM, the time domain is segmented into frames, with four time slots in each frame; each circuit is assigned the same dedicated slot in the revolving TDM frames. For TDM, the transmission rate of a circuit is equal to the frame rate multiplied by the number of bits in a slot. For example, if the link transmits 8,000 frames per second and each slot consists of 8 bits, then the transmission rate of each circuit is 64 kbps.</span></p>
<p><span class="font53">Proponents of packet switching have always argued that circuit switching is wasteful because the dedicated circuits are idle during </span><span class="font53" style="font-weight:bold;">silent periods</span><span class="font53">. For example, when one person in a telephone call stops talking, the idle network resources (frequency bands or time slots in the links along the connection’s route) cannot be used by other ongoing connections. As another example of how these resources can be underutilized, consider a radiologist who uses a circuit-switched network to remotely access a series of x-rays. The radiologist sets up a connection, requests an image, contemplates the image, and then requests a new image. Network resources are allocated to the connection but are not used (i.e., are wasted) during the radiologist’s contemplation periods. Proponents of packet switching also enjoy pointing out that establishing end-to-end circuits and reserving end-to-end transmission capacity is complicated and requires complex signaling software to coordinate the operation of the switches along the end-to-end path.</span></p>
<p><span class="font53">Before we finish our discussion of circuit switching, let’s work through a numerical example that should shed further insight on the topic. Let us consider how long it takes to send a file of 640,000 bits from Host A to Host B over a circuit-switched network. Suppose that all links in the network use TDM with 24 slots and have a bit rate of 1.536 Mbps. Also suppose that it takes 500 msec to establish an end-to-end circuit before Host A can begin to transmit the file. How long does it take to send the file? Each circuit has a transmission rate of (1.536 Mbps)/24 </span><span class="font54">= </span><span class="font53">64 kbps, so it takes (640,000 bits)/(64 kbps) </span><span class="font54">= </span><span class="font53">10 seconds to transmit the file. To this 10 seconds we add the circuit establishment time, giving 10.5 seconds to send the file. Note that the transmission time is independent of the number of links: The transmission time would be 10 seconds if the end-to-end circuit passed through one link or a hundred links. (The actual end-to-end delay also includes a propagation delay; see Section 1.4.)</span></p>
<p><span class="font22" style="font-weight:bold;">Packet Switching Versus Circuit Switching</span></p>
<p><span class="font53">Having described circuit switching and packet switching, let us compare the two. Critics of packet switching have often argued that packet switching is not suitable for real-time services (for example, telephone calls and video conference calls) because of its variable and unpredictable end-to-end delays (due primarily to variable and unpredictable queuing delays). Proponents of packet switching argue that (1) it offers better sharing of transmission capacity than circuit switching and (2) it is simpler, more efficient, and less costly to implement than circuit switching. An interesting discussion of packet switching versus circuit switching is [Molinero-Fernandez 2002]. Generally speaking, people who do not like to hassle with restaurant reservations prefer packet switching to circuit switching.</span></p>
<p><span class="font53">Why is packet switching more efficient? Let’s look at a simple example. Suppose users share a 1 Mbps link. Also suppose that each user alternates between periods of activity, when a user generates data at a constant rate of 100 kbps, and periods of inactivity, when a user generates no data. Suppose further that a user is active only 10 percent of the time (and is idly drinking coffee during the remaining 90 percent of the time). With circuit switching, 100 kbps must be </span><span class="font53" style="font-style:italic;">reserved</span><span class="font53"> for </span><span class="font53" style="font-style:italic;">each</span><span class="font53"> user at all times. For example, with circuit-switched TDM, if a one-second frame is divided into 10 time slots of 100 ms each, then each user would be allocated one time slot per frame.</span></p>
<p><span class="font53">Thus, the circuit-switched link can support only 10 (</span><span class="font54">= </span><span class="font53">1 Mbps/100 kbps) simultaneous users. With packet switching, the probability that a specific user is active is 0.1 (that is, 10 percent). If there are 35 users, the probability that there are 11 or more simultaneously active users is approximately 0.0004. (Homework Problem P8 outlines how this probability is obtained.) When there are 10 or fewer simultaneously active users (which happens with probability 0.9996), the aggregate arrival rate of data is less than or equal to 1 Mbps, the output rate of the link. Thus, when there are 10 or fewer active users, users’ packets flow through the link essentially without delay, as is the case with circuit switching. When there are more than 10 simultaneously active users, then the aggregate arrival rate of packets exceeds the output capacity of the link, and the output queue will begin to grow. (It continues to grow until the aggregate input rate falls back below 1 Mbps, at which point the queue will begin to diminish in length.) Because the probability of having more than 10 simultaneously active users is minuscule in this example, packet switching provides essentially the same performance as circuit switching, </span><span class="font53" style="font-style:italic;">but does so while allowing for more than three times the number of users.</span></p>
<p><span class="font53">Let’s now consider a second simple example. Suppose there are 10 users and that one user suddenly generates one thousand 1,000-bit packets, while other users remain quiescent and do not generate packets. Under TDM circuit switching with 10 slots per frame and each slot consisting of 1,000 bits, the active user can only use its one time slot per frame to transmit data, while the remaining nine time slots in each frame remain idle. It will be 10 seconds before all of the active user’s one million bits of data has been transmitted. In the case of packet switching, the active user can continuously send its packets at the full link rate of 1 Mbps, since there are no other users generating packets that need to be multiplexed with the active user’s packets. In this case, all of the active user’s data will be transmitted within 1 second.</span></p>
<p><span class="font53">The above examples illustrate two ways in which the performance of packet switching can be superior to that of circuit switching. They also highlight the crucial difference between the two forms of sharing a link’s transmission rate among multiple data streams. Circuit switching pre-allocates use of the transmission link regardless of demand, with allocated but unneeded link time going unused. Packet switching on the other hand allocates link use </span><span class="font53" style="font-style:italic;">on demand.</span><span class="font53"> Link transmission capacity will be shared on a packet-by-packet basis only among those users who have packets that need to be transmitted over the link.</span></p>
<p><span class="font53">Although packet switching and circuit switching are both prevalent in today’s telecommunication networks, the trend has certainly been in the direction of packet switching. Even many of today’s circuit-switched telephone networks are slowly migrating toward packet switching. In particular, telephone networks often use packet switching for the expensive overseas portion of a telephone call.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">1.3.3 </span><span class="font23" style="font-weight:bold;">A Network of Networks</span></p></li></ul>
<p><a name="bookmark271"></a><span class="font53">We saw earlier that end systems (PCs, smartphones, Web servers, mail servers, and so on) connect into the Internet via an access ISP. The access ISP can provide either wired or wireless connectivity, using an array of access technologies including DSL, cable, FTTH, Wi-Fi, and cellular. Note that the access ISP does not have to be a telco or a cable company; instead it can be, for example, a university (providing Internet access to students, staff, and faculty), or a company (providing access for its employees). But connecting end users and content providers into an access ISP is only a small piece of solving the puzzle of connecting the billions of end systems that make up the Internet. To complete this puzzle, the access ISPs themselves must be interconnected. This is done by creating a </span><span class="font53" style="font-style:italic;">network of networks—</span><span class="font53">understanding this phrase is the key to understanding the Internet.</span></p>
<p><span class="font53">Over the years, the network of networks that forms the Internet has evolved into a very complex structure. Much of this evolution is driven by economics and national policy, rather than by performance considerations. In order to understand today’s Internet network structure, let’s incrementally build a series of network structures, with each new structure being a better approximation of the complex Internet that we have today. Recall that the overarching goal is to interconnect the access ISPs so that all end systems can send packets to each other. One naive approach would be to have each access ISP </span><span class="font53" style="font-style:italic;">directly</span><span class="font53"> connect with every other access ISP. Such a mesh design is, of course, much too costly for the access ISPs, as it would require each access ISP to have a separate communication link to each of the hundreds of thousands of other access ISPs all over the world.</span></p>
<p><span class="font53">Our first network structure, </span><span class="font53" style="font-style:italic;">Network Structure 1,</span><span class="font53"> interconnects all of the access ISPs with a </span><span class="font53" style="font-style:italic;">single global transit ISP.</span><span class="font53"> Our (imaginary) global transit ISP is a network of routers and communication links that not only spans the globe, but also has at least one router near each of the hundreds of thousands of access ISPs. Of course, it would be very costly for the global ISP to build such an extensive network. To be profitable, it would naturally charge each of the access ISPs for connectivity, with the pricing reflecting (but not necessarily directly proportional to) the amount of traffic an access ISP exchanges with the global ISP. Since the access ISP pays the global transit ISP, the access ISP is said to be a </span><span class="font53" style="font-weight:bold;">customer </span><span class="font53">and the global transit ISP is said to be a </span><span class="font53" style="font-weight:bold;">provider</span><span class="font53">.</span></p>
<p><span class="font53">Now if some company builds and operates a global transit ISP that is profitable, then it is natural for other companies to build their own global transit ISPs and compete with the original global transit ISP. This leads to </span><span class="font53" style="font-style:italic;">Network Structure 2, </span><span class="font53">which consists of the hundreds of thousands of access ISPs and </span><span class="font53" style="font-style:italic;">multiple</span><span class="font53"> global transit ISPs. The access ISPs certainly prefer Network Structure 2 over Network Structure 1 since they can now choose among the competing global transit providers as a function of their pricing and services. Note, however, that the global transit ISPs themselves must interconnect: Otherwise access ISPs connected to one of the global transit providers would not be able to communicate with access ISPs connected to the other global transit providers.</span></p>
<p><span class="font53">Network Structure 2, just described, is a two-tier hierarchy with global transit providers residing at the top tier and access ISPs at the bottom tier. This assumes that global transit ISPs are not only capable of getting close to each and every access ISP, but also find it economically desirable to do so. In reality, although some ISPs do have impressive global coverage and do directly connect with many access ISPs, no ISP has presence in each and every city in the world. Instead, in any given region, there may be a </span><span class="font53" style="font-weight:bold;">regional ISP </span><span class="font53">to which the access ISPs in the region connect. Each regional ISP then connects to </span><span class="font53" style="font-weight:bold;">tier-1 ISPs</span><span class="font53">. Tier-1 ISPs are similar to our (imaginary) global transit ISP; but tier-1 ISPs, which actually do exist, do not have a presence in every city in the world. There are approximately a dozen tier-1 ISPs, including Level 3 Communications, AT&amp;T, Sprint, and NTT. Interestingly, no group officially</span></p>
<p><span class="font53">sanctions tier-1 status; as the saying goes—if you have to ask if you’re a member of a group, you’re probably not.</span></p>
<p><span class="font53">Returning to this network of networks, not only are there multiple competing tier-1 ISPs, there may be multiple competing regional ISPs in a region. In such a hierarchy, each access ISP pays the regional ISP to which it connects, and each regional ISP pays the tier-1 ISP to which it connects. (An access ISP can also connect directly to a tier-1 ISP, in which case it pays the tier-1 ISP). Thus, there is customerprovider relationship at each level of the hierarchy. Note that the tier-1 ISPs do not pay anyone as they are at the top of the hierarchy. To further complicate matters, in some regions, there may be a larger regional ISP (possibly spanning an entire country) to which the smaller regional ISPs in that region connect; the larger regional ISP then connects to a tier-1 ISP. For example, in China, there are access ISPs in each city, which connect to provincial ISPs, which in turn connect to national ISPs, which finally connect to tier-1 ISPs [Tian 2012]. We refer to this multi-tier hierarchy, which is still only a crude approximation of today’s Internet, as </span><span class="font53" style="font-style:italic;">Network Structure 3.</span></p>
<p><span class="font53">To build a network that more closely resembles today’s Internet, we must add points of presence (PoPs), multi-homing, peering, and Internet exchange points (IXPs) to the hierarchical Network Structure 3. PoPs exist in all levels of the hierarchy, except for the bottom (access ISP) level. A </span><span class="font53" style="font-weight:bold;">PoP </span><span class="font53">is simply a group of one or more routers (at the same location) in the provider’s network where customer ISPs can connect into the provider ISP. For a customer network to connect to a provider’s PoP, it can lease a high-speed link from a third-party telecommunications provider to directly connect one of its routers to a router at the PoP. Any ISP (except for tier-1 ISPs) may choose to </span><span class="font53" style="font-weight:bold;">multi-home</span><span class="font53">, that is, to connect to two or more provider ISPs. So, for example, an access ISP may multi-home with two regional ISPs, or it may multihome with two regional ISPs and also with a tier-1 ISP. Similarly, a regional ISP may multi-home with multiple tier-1 ISPs. When an ISP multi-homes, it can continue to send and receive packets into the Internet even if one of its providers has a failure.</span></p>
<p><span class="font53">As we just learned, customer ISPs pay their provider ISPs to obtain global Internet interconnectivity. The amount that a customer ISP pays a provider ISP reflects the amount of traffic it exchanges with the provider. To reduce these costs, a pair of nearby ISPs at the same level of the hierarchy can </span><span class="font53" style="font-weight:bold;">peer</span><span class="font53">, that is, they can directly connect their networks together so that all the traffic between them passes over the direct connection rather than through upstream intermediaries. When two ISPs peer, it is typically settlement-free, that is, neither ISP pays the other. As noted earlier, tier-1 ISPs also peer with one another, settlement-free. For a readable discussion of peering and customer-provider relationships, see [Van der Berg 2008]. Along these same lines, a third-party company can create an </span><span class="font53" style="font-weight:bold;">Internet Exchange Point (IXP)</span><span class="font53">, which is a meeting point where multiple ISPs can peer together. An IXP is typically in a stand-alone building with its own switches [Ager 2012]. There are over 600 IXPs in the Internet today [PeeringDB 2020]. We refer to this ecosystem—consisting of access ISPs, regional ISPs, tier-1 ISPs, PoPs, multi-homing, peering, and IXPs—as </span><span class="font53" style="font-style:italic;">Network Structure 4.</span></p>
<p><span class="font53">We now finally arrive at </span><span class="font53" style="font-style:italic;">Network Structure 5,</span><span class="font53"> which describes today’s Internet. Network Structure 5, illustrated in Figure 1.15, builds on top of Network Structure 4 by adding </span><span class="font53" style="font-weight:bold;">content-provider networks</span><span class="font53">. Google is currently one of the leading examples of such a content-provider network. As of this writing, it Google has 19 major data centers distributed across North America, Europe, Asia, South America, and Australia with each data center having tens or hundreds of thousands of servers. Additionally, Google has smaller data centers, each with a few hundred servers; these smaller data centers are often located within IXPs. The Google data centers are all interconnected via Google’s private TCP/IP network, which spans the entire globe but is nevertheless separate from the public Internet. Importantly, the Google private network only carries traffic to/from Google servers. As shown in Figure 1.15, the Google private network attempts to “bypass” the upper tiers of the Internet by peering (settlement free) with lower-tier ISPs, either by directly connecting with them or by connecting with them at IXPs [Labovitz 2010]. However, because many access ISPs can still only be reached by transiting through tier-1 networks, the Google network also connects to tier-1 ISPs, and pays those ISPs for the traffic it exchanges with them. By creating its own network, a content provider not only reduces its payments to upper-tier ISPs, but also has greater control of how its services are ultimately delivered to end users. Google’s network infrastructure is described in greater detail in Section 2.6.</span></p>
<p><span class="font53">In summary, today’s Internet—a network of networks—is complex, consisting of a dozen or so tier-1 ISPs and hundreds of thousands of lower-tier ISPs. The ISPs are diverse in their coverage, with some spanning multiple continents and oceans, and others limited to narrow geographic regions. The lower-tier ISPs connect to the higher-tier ISPs, and the higher-tier ISPs interconnect with one another. Users and content providers are customers of lower-tier ISPs, and lower-tier ISPs are customers of higher-tier ISPs. In recent years, major content providers have also created their own networks and connect directly into lower-tier ISPs where possible.</span></p><img src="networking_files/networking-36.jpg" alt="" style="width:339pt;height:18pt;">
<p><span class="font4">Tier 1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Tier 1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Content provider</span></p><img src="networking_files/networking-37.jpg" alt="" style="width:335pt;height:117pt;">
<p><span class="font7" style="font-weight:bold;">Figure 1.15 </span><span class="font50">♦ </span><span class="font5">Interconnection of ISPs</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">1.4 </span><span class="font24" style="font-weight:bold;">Delay, Loss, and Throughput in Packet-Switched Networks</span></p></li></ul>
<p><span class="font53">Back in Section 1.1 we said that the Internet can be viewed as an infrastructure that provides services to distributed applications running on end systems. Ideally, we would like Internet services to be able to move as much data as we want between any two end systems, instantaneously, without any loss of data. Alas, this is a lofty goal, one that is unachievable in reality. Instead, computer networks necessarily constrain throughput (the amount of data per second that can be transferred) between end systems, introduce delays between end systems, and can actually lose packets. On one hand, it is unfortunate that the physical laws of reality introduce delay and loss as well as constrain throughput. On the other hand, because computer networks have these problems, there are many fascinating issues surrounding how to deal with the problems—more than enough issues to fill a course on computer networking and to motivate thousands of PhD theses! In this section, we’ll begin to examine and quantify delay, loss, and throughput in computer networks.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">1.4.1 </span><span class="font23" style="font-weight:bold;">Overview of Delay in Packet-Switched Networks</span></p></li></ul>
<p><span class="font53">Recall that a packet starts in a host (the source), passes through a series of routers, and ends its journey in another host (the destination). As a packet travels from one node (host or router) to the subsequent node (host or router) along this path, the packet suffers from several types of delays at </span><span class="font53" style="font-style:italic;">each</span><span class="font53"> node along the path. The most important of these delays are the </span><span class="font53" style="font-weight:bold;">nodal processing delay</span><span class="font53">, </span><span class="font53" style="font-weight:bold;">queuing delay</span><span class="font53">, </span><span class="font53" style="font-weight:bold;">transmission delay</span><span class="font53">, and </span><span class="font53" style="font-weight:bold;">propagation delay</span><span class="font53">; together, these delays accumulate to give a </span><span class="font53" style="font-weight:bold;">total nodal delay</span><span class="font53">. The performance of many Internet applications—such as search, Web browsing, e-mail, maps, instant messaging, and voice-over-IP—are greatly affected by network delays. In order to acquire a deep understanding of packet switching and computer networks, we must understand the nature and importance of these delays.</span></p>
<p><span class="font22" style="font-weight:bold;">Types of Delay</span></p>
<p><a name="bookmark272"></a><span class="font53">Let’s explore these delays in the context of Figure 1.16. As part of its end-to-end route between source and destination, a packet is sent from the upstream node through router A to router B. Our goal is to characterize the nodal delay at router A. Note that router A has an outbound link leading to router B. This link is preceded by a queue (also known as a buffer). When the packet arrives at router A from the upstream node, router A examines the packet’s header to determine the appropriate outbound link for the packet and then directs the packet to this link. In this example, the outbound link for the packet is the one that leads to router B. A packet can be transmitted on a link only if there is no other packet currently being transmitted on the link and if there are no other packets preceding it in the queue; if the link is</span></p><img src="networking_files/networking-38.jpg" alt="" style="width:266pt;height:105pt;">
<p><span class="font7" style="font-weight:bold;">Figure 1.16 </span><span class="font50">♦ </span><span class="font5">The nodal delay at router A</span></p>
<p><span class="font53">currently busy or if there are other packets already queued for the link, the newly arriving packet will then join the queue.</span></p>
<p><span class="font53" style="font-weight:bold;font-style:italic;">Processing Delay</span></p>
<p><span class="font53">The time required to examine the packet’s header and determine where to direct the packet is part of the </span><span class="font53" style="font-weight:bold;">processing delay</span><span class="font53">. The processing delay can also include other factors, such as the time needed to check for bit-level errors in the packet that occurred in transmitting the packet’s bits from the upstream node to router A. Processing delays in high-speed routers are typically on the order of microseconds or less. After this nodal processing, the router directs the packet to the queue that precedes the link to router B. (In Chapter 4 we’ll study the details of how a router operates.)</span></p>
<p><span class="font53" style="font-weight:bold;font-style:italic;">Queuing Delay</span></p>
<p><span class="font53">At the queue, the packet experiences a </span><span class="font53" style="font-weight:bold;">queuing delay </span><span class="font53">as it waits to be transmitted onto the link. The length of the queuing delay of a specific packet will depend on the number of earlier-arriving packets that are queued and waiting for transmission onto the link. If the queue is empty and no other packet is currently being transmitted, then our packet’s queuing delay will be zero. On the other hand, if the traffic is heavy and many other packets are also waiting to be transmitted, the queuing delay will be long. We will see shortly that the number of packets that an arriving packet might expect to find is a function of the intensity and nature of the traffic arriving at the queue. Queuing delays can be on the order of microseconds to milliseconds in practice.</span></p>
<p><span class="font53" style="font-weight:bold;font-style:italic;">Transmission Delay</span></p>
<p><span class="font53">Assuming that packets are transmitted in a first-come-first-served manner, as is common in packet-switched networks, our packet can be transmitted only after all the packets that have arrived before it have been transmitted. Denote the length of the packet by </span><span class="font53" style="font-style:italic;">L</span><span class="font53"> bits, and denote the transmission rate of the link from router A to router B by </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> bits/sec. For example, for a 10 Mbps Ethernet link, the rate is </span><span class="font53" style="font-style:italic;">R =</span><span class="font53"> 10 Mbps; for a 100 Mbps Ethernet link, the rate is </span><span class="font53" style="font-style:italic;">R =</span><span class="font53"> 100 Mbps. The </span><span class="font53" style="font-weight:bold;">transmission delay </span><span class="font53">is </span><span class="font53" style="font-style:italic;">L/R.</span><span class="font53"> This is the amount of time required to push (that is, transmit) all of the packet’s bits into the link. Transmission delays are typically on the order of microseconds to milliseconds in practice.</span></p>
<p><span class="font53" style="font-weight:bold;font-style:italic;">Propagation Delay</span></p>
<p><span class="font53">Once a bit is pushed into the link, it needs to propagate to router B. The time required to propagate from the beginning of the link to router B is the </span><span class="font53" style="font-weight:bold;">propagation delay</span><span class="font53">. The bit propagates at the propagation speed of the link. The propagation speed depends on the physical medium of the link (that is, fiber optics, twisted-pair copper wire, and so on) and is in the range of</span></p>
<p><span class="font53">2 </span><span class="font60">• </span><span class="font53">10</span><span class="font50">8 </span><span class="font53">meters/sec to 3 </span><span class="font60">• </span><span class="font53">10</span><span class="font50">8 </span><span class="font53">meters/sec</span></p>
<p><span class="font53">which is equal to, or a little less than, the speed of light. The propagation delay is the distance between two routers divided by the propagation speed. That is, the propagation delay is </span><span class="font53" style="font-style:italic;">d/s,</span><span class="font53"> where </span><span class="font53" style="font-style:italic;">d</span><span class="font53"> is the distance between router A and router B and </span><span class="font53" style="font-style:italic;">s</span><span class="font53"> is the propagation speed of the link. Once the last bit of the packet propagates to node B, it and all the preceding bits of the packet are stored in router B. The whole process then continues with router B now performing the forwarding. In wide-area networks, propagation delays are on the order of milliseconds.</span></p>
<p><span class="font22" style="font-weight:bold;">Comparing Transmission and Propagation Delay</span></p>
<div>
<p><span class="font16" style="font-weight:bold;">o</span></p>
<p><span class="font2" style="font-weight:bold;">VideoNote</span></p>
<p><span class="font1" style="font-weight:bold;">Exploring propagation delay and transmission delay</span></p>
</div><br clear="all">
<p><span class="font53">Newcomers to the field of computer networking sometimes have difficulty understanding the difference between transmission delay and propagation delay. The difference is subtle but important. The transmission delay is the amount of time required for the router to push out the packet; it is a function of the packet’s length and the transmission rate of the link, but has nothing to do with the distance between the two routers. The propagation delay, on the other hand, is the time it takes a bit to propagate from one router to the next; it is a function of the distance between the two routers, but has nothing to do with the packet’s length or the transmission rate of the link.</span></p>
<p><span class="font53">An analogy might clarify the notions of transmission and propagation delay. Consider a highway that has a tollbooth every 100 kilometers, as shown in Figure 1.17. You can think of the highway segments between tollbooths as links and the tollbooths as routers. Suppose that cars travel (that is, propagate) on the highway at a rate of 100 km/hour (that is, when a car leaves a tollbooth, it instantaneously accelerates to 100 km/hour and maintains that speed between tollbooths). Suppose next that 10 cars, traveling together as a caravan, follow each other in a fixed order. You can think of each car as a bit and the caravan as a packet. Also suppose that each</span></p>
<div><img src="networking_files/networking-39.jpg" alt="" style="width:208pt;height:48pt;">
<p><span class="font4">100 km</span></p>
<p><span class="font4">Ten-car &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Toll</span></p>
<p><span class="font4">caravan &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;booth</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 1.17 </span><span class="font50">♦ </span><span class="font5">Caravan analogy</span></p>
</div><br clear="all">
<div>
<p><span class="font4">◄--100 km —</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Toll booth</span></p>
</div><br clear="all">
<p><span class="font53">tollbooth services (that is, transmits) a car at a rate of one car per 12 seconds, and that it is late at night so that the caravan’s cars are the only cars on the highway. Finally, suppose that whenever the first car of the caravan arrives at a tollbooth, it waits at the entrance until the other nine cars have arrived and lined up behind it. (Thus, the entire caravan must be stored at the tollbooth before it can begin to be forwarded.) The time required for the tollbooth to push the entire caravan onto the highway is (10 cars)/(5 cars/minute) </span><span class="font54">= </span><span class="font53">2 minutes. This time is analogous to the transmission delay in a router. The time required for a car to travel from the exit of one tollbooth to the next tollbooth is 100 km/(100 km/hour) </span><span class="font54">= </span><span class="font53">1 hour. This time is analogous to propagation delay. Therefore, the time from when the caravan is stored in front of a tollbooth until the caravan is stored in front of the next tollbooth is the sum of transmission delay and propagation delay—in this example, 62 minutes.</span></p>
<p><span class="font53">Let’s explore this analogy a bit more. What would happen if the tollbooth service time for a caravan were greater than the time for a car to travel between tollbooths? For example, suppose now that the cars travel at the rate of 1,000 km/hour and the tollbooth services cars at the rate of one car per minute. Then the traveling delay between two tollbooths is 6 minutes and the time to serve a caravan is 10 minutes. In this case, the first few cars in the caravan will arrive at the second tollbooth before the last cars in the caravan leave the first tollbooth. This situation also arises in packet-switched networks—the first bits in a packet can arrive at a router while many of the remaining bits in the packet are still waiting to be transmitted by the preceding router.</span></p>
<p><span class="font53">If a picture speaks a thousand words, then an animation must speak a million words. The Web site for this textbook provides an interactive animation that nicely illustrates and contrasts transmission delay and propagation delay. The reader is highly encouraged to visit that animation. [Smith 2009] also provides a very readable discussion of propagation, queuing, and transmission delays.</span></p>
<p><span class="font53">If we let </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>proc</sub>, </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>queue</sub>, </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>t</sub></span><span class="font50">ran</span><span class="font53"><sub>s</sub>, and </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>prop</sub> denote the processing, queuing, transmission, and propagation delays, then the total nodal delay is given by</span></p>
<p><span class="font53" style="font-style:italic;"><sup>d</sup></span><span class="font50">nodal &nbsp;&nbsp;&nbsp;</span><span class="font53" style="font-style:italic;">^</span><span class="font50">proc </span><span class="font55">+ </span><span class="font53" style="font-style:italic;"><sup>d</sup></span><span class="font50">queue </span><span class="font55">+ </span><span class="font53" style="font-style:italic;"><sup>d</sup></span><span class="font50">trans </span><span class="font55">+ </span><span class="font53" style="font-style:italic;">^</span><span class="font50">prop</span></p>
<p><span class="font53">The contribution of these delay components can vary significantly. For example, </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>prop</sub> can be negligible (for example, a couple of microseconds) for a link connecting two routers on the same university campus; however, </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>prop</sub> is hundreds of milliseconds for two routers interconnected by a geostationary satellite link, and can be the dominant term in </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>nodal</sub>. Similarly, </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>trans</sub> can range from negligible to significant. Its contribution is typically negligible for transmission rates of 10 Mbps and higher (for example, for LANs); however, it can be hundreds of milliseconds for large Internet packets sent over low-speed dial-up modem links. The processing delay, </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>proc</sub>, is often negligible; however, it strongly influences a router’s maximum throughput, which is the maximum rate at which a router can forward packets.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">1.4.2 </span><span class="font23" style="font-weight:bold;">Queuing Delay and Packet Loss</span></p></li></ul>
<p><span class="font53">The most complicated and interesting component of nodal delay is the queuing delay, </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>queue</sub>. In fact, queuing delay is so important and interesting in computer networking that thousands of papers and numerous books have been written about it [Bertsekas 1991; Kleinrock 1975, Kleinrock 1976]. We give only a high-level, intuitive discussion of queuing delay here; the more curious reader may want to browse through some of the books (or even eventually write a PhD thesis on the subject!). Unlike the other three delays (namely, </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>proc</sub>, </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>trans</sub>, and </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>prop</sub>), the queuing delay can vary from packet to packet. For example, if 10 packets arrive at an empty queue at the same time, the first packet transmitted will suffer no queuing delay, while the last packet transmitted will suffer a relatively large queuing delay (while it waits for the other nine packets to be transmitted). Therefore, when characterizing queuing delay, one typically uses statistical measures, such as average queuing delay, variance of queuing delay, and the probability that the queuing delay exceeds some specified value.</span></p>
<p><span class="font53">When is the queuing delay large and when is it insignificant? The answer to this question depends on the rate at which traffic arrives at the queue, the transmission rate of the link, and the nature of the arriving traffic, that is, whether the traffic arrives periodically or arrives in bursts. To gain some insight here, let </span><span class="font53" style="font-style:italic;">a</span><span class="font53"> denote the average rate at which packets arrive at the queue (</span><span class="font53" style="font-style:italic;">a</span><span class="font53"> is in units of packets/sec). Recall that </span><span class="font53" style="font-style:italic;">R </span><span class="font53">is the transmission rate; that is, it is the rate (in bits/sec) at which bits are pushed out of the queue. Also suppose, for simplicity, that all packets consist of </span><span class="font53" style="font-style:italic;">L</span><span class="font53"> bits. Then the average rate at which bits arrive at the queue is </span><span class="font53" style="font-style:italic;">La</span><span class="font53"> bits/sec. Finally, assume that the queue is very big, so that it can hold essentially an infinite number of bits. The ratio </span><span class="font53" style="font-style:italic;">La/R,</span><span class="font53"> called the </span><span class="font53" style="font-weight:bold;">traffic intensity</span><span class="font53">, often plays an important role in estimating the extent of the queuing delay. If </span><span class="font53" style="font-style:italic;">La/R &gt;</span><span class="font53">&nbsp;1, then the average rate at which bits arrive at the queue exceeds the rate at which the bits can be transmitted from the queue. In this unfortunate situation, the queue will tend to increase without bound and the queuing delay will approach infinity! Therefore, one of the golden rules in traffic engineering is: </span><span class="font53" style="font-style:italic;">Design your system so that the traffic intensity is no greater than 1.</span></p>
<p><a name="bookmark273"></a><span class="font53">Now consider the case </span><span class="font53" style="font-style:italic;">La/R</span><span class="font54"> &lt;&nbsp;</span><span class="font53">1. Here, the nature of the arriving traffic impacts the queuing delay. For example, if packets arrive periodically—that is, one packet arrives every </span><span class="font53" style="font-style:italic;">L/R</span><span class="font53"> seconds—then every packet will arrive at an empty queue and there will be no queuing delay. On the other hand, if packets arrive in bursts but periodically, there can be a significant average queuing delay. For example, suppose </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> packets arrive simultaneously every </span><span class="font53" style="font-style:italic;">(L/R)N</span><span class="font53"> seconds. Then the first packet transmitted has no queuing delay; the second packet transmitted has a queuing delay of </span><span class="font53" style="font-style:italic;">L/R</span><span class="font53"> seconds; and more generally, the </span><span class="font53" style="font-style:italic;">n</span><span class="font53">th packet transmitted has a queuing delay of (</span><span class="font53" style="font-style:italic;">n</span><span class="font55"> — </span><span class="font53" style="font-style:italic;">1)L/R</span><span class="font53"> seconds. We leave it as an exercise for you to calculate the average queuing delay in this example.</span></p>
<p><span class="font53">The two examples of periodic arrivals described above are a bit academic. Typically, the arrival process to a queue is </span><span class="font53" style="font-style:italic;">random;</span><span class="font53"> that is, the arrivals do not follow any pattern and the packets are spaced apart by random amounts of time. In this more realistic case, the quantity </span><span class="font53" style="font-style:italic;">La/R</span><span class="font53"> is not usually sufficient to fully characterize the queuing delay statistics. Nonetheless, it is useful in gaining an intuitive understanding of the extent of the queuing delay. In particular, if the traffic intensity is close to zero, then packet arrivals are few and far between and it is unlikely that an arriving packet will find another packet in the queue. Hence, the average queuing delay will be close to zero. On the other hand, when the traffic intensity is close to 1, there will be intervals of time when the arrival rate exceeds the transmission capacity (due to variations in packet arrival rate), and a queue will form during these periods of time; when the arrival rate is less than the transmission capacity, the length of the queue will shrink. Nonetheless, as the traffic intensity approaches 1, the average queue length gets larger and larger. The qualitative dependence of average queuing delay on the traffic intensity is shown in Figure 1.18.</span></p>
<p><span class="font53">One important aspect of Figure 1.18 is the fact that as the traffic intensity approaches 1, the average queuing delay increases rapidly. A small percentage increase in the intensity will result in a much larger percentage-wise increase in delay. Perhaps you have experienced this phenomenon on the highway. If you regularly drive on a road that is typically congested, the fact that the road is typically congested means that its traffic intensity is close to 1. If some event causes an even slightly larger-than-usual amount of traffic, the delays you experience can be huge.</span></p>
<p><span class="font53">To really get a good feel for what queuing delays are about, you are encouraged once again to visit the textbook Web site, which provides an interactive animation for a queue. If you set the packet arrival rate high enough so that the traffic intensity exceeds 1, you will see the queue slowly build up over time.</span></p><img src="networking_files/networking-40.jpg" alt="" style="width:158pt;height:135pt;">
<p><span class="font4" style="font-style:italic;">La/R</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 1.18 </span><span class="font50">♦ </span><span class="font5">Dependence of average queuing delay on traffic intensity</span></p>
<p><span class="font22" style="font-weight:bold;">Packet Loss</span></p>
<p><span class="font53">In our discussions above, we have assumed that the queue is capable of holding an infinite number of packets. In reality a queue preceding a link has finite capacity, although the queuing capacity greatly depends on the router design and cost. Because the queue capacity is finite, packet delays do not really approach infinity as the traffic intensity approaches 1. Instead, a packet can arrive to find a full queue. With no place to store such a packet, a router will </span><span class="font53" style="font-weight:bold;">drop </span><span class="font53">that packet; that is, the packet will be </span><span class="font53" style="font-weight:bold;">lost</span><span class="font53">. This overflow at a queue can again be seen in the interactive animation when the traffic intensity is greater than 1.</span></p>
<p><span class="font53">From an end-system viewpoint, a packet loss will look like a packet having been transmitted into the network core but never emerging from the network at the destination. The fraction of lost packets increases as the traffic intensity increases. Therefore, performance at a node is often measured not only in terms of delay, but also in terms of the probability of packet loss. As we’ll discuss in the subsequent chapters, a lost packet may be retransmitted on an end-to-end basis in order to ensure that all data are eventually transferred from source to destination.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">1.4.3 </span><span class="font23" style="font-weight:bold;">End-to-End Delay</span></p></li></ul>
<p><span class="font53">Our discussion up to this point has focused on the nodal delay, that is, the delay at a single router. Let’s now consider the total delay from source to destination. To get a handle on this concept, suppose there are </span><span class="font53" style="font-style:italic;">N —</span><span class="font53"> 1 routers between the source host and the destination host. Let’s also suppose for the moment that the network is uncongested (so that queuing delays are negligible), the processing delay at each router and at the source host is </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>proc</sub>, the transmission rate out of each router and out of the source host is </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> bits/sec, and the propagation on each link is </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>prop</sub>. The nodal delays accumulate and give an end-to-end delay,</span></p>
<p><span class="font53" style="font-style:italic;"><sup>d</sup></span><span class="font50">end </span><span class="font3">— </span><span class="font50">end &nbsp;&nbsp;</span><span class="font53" style="font-style:italic;"><sup>N </sup></span><span class="font50" style="font-style:italic;"><sup>(</sup></span><span class="font53" style="font-style:italic;"><sup>d</sup></span><span class="font49" style="font-style:italic;">proc</span><span class="font55"> + </span><span class="font53" style="font-style:italic;"><sup>d</sup></span><span class="font50">rans </span><span class="font55">+ </span><span class="font53" style="font-style:italic;"><sup>d</sup></span><span class="font50">prop</span><span class="font53">)</span></p>
<div>
<p><span class="font53">(1.2)</span></p>
</div><br clear="all">
<p><span class="font53">where, once again, </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>trans</sub> </span><span class="font54">= </span><span class="font53" style="font-style:italic;">L/R,</span><span class="font53"> where </span><span class="font53" style="font-style:italic;">L</span><span class="font53"> is the packet size. Note that Equation 1.2 is a generalization of Equation 1.1, which did not take into account processing and propagation delays. We leave it to you to generalize Equation 1.2 to the case of heterogeneous delays at the nodes and to the presence of an average queuing delay at each node.</span></p>
<div>
<p><span class="font16" style="font-weight:bold;">D</span></p>
<p><span class="font2" style="font-weight:bold;">VideoNote</span></p>
<p><span class="font1" style="font-weight:bold;">Using Traceroute to discover network paths and measure network delay</span></p>
</div><br clear="all">
<p><span class="font22" style="font-weight:bold;">Traceroute</span></p>
<p><a name="bookmark274"></a><span class="font53">To get a hands-on feel for end-to-end delay in a computer network, we can make use of the Traceroute program. Traceroute is a simple program that can run in any Internet host. When the user specifies a destination hostname, the program in the source host sends multiple, special packets toward that destination. As these packets work their way toward the destination, they pass through a series of routers. When a router receives one of these special packets, it sends back to the source a short message that contains the name and address of the router.</span></p>
<p><span class="font53">More specifically, suppose there are </span><span class="font53" style="font-style:italic;">N —</span><span class="font53"> 1 routers between the source and the destination. Then the source will send </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> special packets into the network, with each packet addressed to the ultimate destination. These </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> special packets are marked </span><span class="font53" style="font-style:italic;">1 </span><span class="font53">through </span><span class="font53" style="font-style:italic;">N,</span><span class="font53"> with the first packet marked </span><span class="font53" style="font-style:italic;">1</span><span class="font53"> and the last packet marked </span><span class="font53" style="font-style:italic;">N</span><span class="font53">. When the </span><span class="font53" style="font-style:italic;">n</span><span class="font53">th router receives the </span><span class="font53" style="font-style:italic;">n</span><span class="font53">th packet marked </span><span class="font53" style="font-style:italic;">n,</span><span class="font53"> the router does not forward the packet toward its destination, but instead sends a message back to the source. When the destination host receives the </span><span class="font53" style="font-style:italic;">N</span><span class="font53">th packet, it too returns a message back to the source. The source records the time that elapses between when it sends a packet and when it receives the corresponding return message; it also records the name and address of the router (or the destination host) that returns the message. In this manner, the source can reconstruct the route taken by packets flowing from source to destination, and the source can determine the round-trip delays to all the intervening routers. Traceroute actually repeats the experiment just described three times, so the source actually sends </span><span class="font53" style="font-style:italic;">3</span><span class="font53"> • </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> packets to the destination. RFC 1393 describes Traceroute in detail.</span></p>
<p><span class="font53">Here is an example of the output of the Traceroute program, where the route was being traced from the source host </span><a href="http://gaia.cs.umass.edu"><span class="font53">gaia.cs.umass.edu </span></a><span class="font53">(at the University of Massachusetts) to a host in the computer science department at the University of Sorbonne in Paris (formerly the university was known as UPMC). The output has six columns: the first column is the </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> value described above, that is, the number of the router along the route; the second column is the name of the router; the third column is the address of the router (of the form xxx.xxx.xxx.xxx); the last three columns are the round-trip delays for three experiments. If the source receives fewer than three messages from any given router (due to packet loss in the network), Traceroute places an asterisk just after the router number and reports fewer than three round-trip times for that router.</span></p>
<p><a href="http://gw-vlan-2451.cs.umass.edu"><span class="font36">gw-vlan-2451.cs.umass.edu </span></a><span class="font36">(128.119.245.1) &nbsp;1.899 ms 3.266 ms 3.280 ms</span></p>
<p class="font36"><a href="http://j-cs-gw-int-10-240.cs.umass.edu">j-cs-gw-int-10-240.cs.umass.edu </a>(10.119.240.254) 1.296 ms 1.276 ms</p>
<ul style="list-style:none;"><li>
<p><span class="font36">1.245 ms </span><a href="http://n5-rt-1-1-xe-2-1-0.gw.umass.edu"><span class="font36">n5-rt-1-1-xe-2-1-0.gw.umass.edu </span></a><span class="font36">(128.119.3.33) 2.237 ms 2.217 ms 2.187 ms </span><a href="http://core1-rt-et-5-2-0.gw.umass.edu"><span class="font36">core1-rt-et-5-2-0.gw.umass.edu </span></a><span class="font36">(128.119.0.9) 0.351 ms 0.392 ms 0.380 ms </span><a href="http://border1-rt-et-5-0-0.gw.umass.edu"><span class="font36">border1-rt-et-5-0-0.gw.umass.edu </span></a><span class="font36">(192.80.83.102) 0.345 ms 0.345 ms 0.344 ms </span><a href="http://nox300gw1-umass-re.nox.org"><span class="font36">nox300gw1-umass-re.nox.org </span></a><span class="font36">(192.5.89.101) 3.260 ms 0.416 ms 3.127 ms </span><a href="http://nox300gw1-umass-re.nox.org"><span class="font36">nox300gw1-umass-re.nox.org</span></a><span class="font36"> (192.5.89.101) 3.165 ms 7.326 ms 7.311 ms 198.71.45.237 (198.71.45.237) 77.826 ms 77.246 ms 77.744 ms </span><a href="http://renater-lb1-gw.mx1.par.fr.geant.net"><span class="font36">renater-lb1-gw.mx1.par.fr.geant.net</span></a><span class="font36"> (62.40.124.70) 79.357 ms 77.729 79.152 ms 193.51.180.109 (193.51.180.109) 78.379 ms 79.936 80.042 ms</span></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font36">* 193.51.180.109 (193.51.180.109) 80.640 ms *</span></p></li>
<li>
<p><span class="font36">* 195.221.127.182 (195.221.127.182) 78.408 ms * 195.221.127.182 (195.221.127.182) 80.686 ms 80.796 ms 78.434 ms </span><a href="http://r-upmc1.reseau.jussieu.fr"><span class="font35">r-upmc1.reseau.jussieu.fr</span></a><span class="font35"> (134.157.254.10) 78.399 ms * 81.353 ms</span></p></li></ul>
<p><span class="font53">In the trace above, there are 14 routers between the source and the destination. Most of these routers have a name, and all of them have addresses. For example, the name of Router 4 is</span><a href="http://core1-rt-et-5-2-0.gw.umass.edu"><span class="font53"> </span><span class="font36">core1-rt-et-5-2-0.gw.umass.edu </span></a><span class="font53">and its address is </span><span class="font36">128.119.0.9</span><span class="font53">. Looking at the data provided for this same router, we see that in the first of the three trials the round-trip delay between the source and the router was 0.351 msec. The round-trip delays for the subsequent two trials were 0.392 and 0.380 msec. These round-trip delays include all of the delays just discussed, including transmission delays, propagation delays, router processing delays, and queuing delay.</span></p>
<p><span class="font53">Because the queuing delay is varying with time, the round-trip delay of packet </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> sent to a router </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> can sometimes be longer than the round-trip delay of packet </span><span class="font53" style="font-style:italic;">n+</span><span class="font53">1 sent to router </span><span class="font53" style="font-style:italic;">n+</span><span class="font53">1. Indeed, we observe this phenomenon in the above example: the delay to Router 12 is smaller than the delay to Router 11! Also note the big increase in the round-trip delay when going from router 7 to router 8. This is due to a transatlantic fiber-optic link between routers 7 and 8, giving rise to a relatively large propagation delay. There are a number of free software programs that provide a graphical interface to Traceroute; one of our favorites is PingPlotter [PingPlotter 2020].</span></p>
<p><span class="font22" style="font-weight:bold;">End System, Application, and Other Delays</span></p>
<p><span class="font53">In addition to processing, transmission, and propagation delays, there can be additional significant delays in the end systems. For example, an end system wanting to transmit a packet into a shared medium (e.g., as in a WiFi or cable modem scenario) may </span><span class="font53" style="font-style:italic;">purposefully</span><span class="font53"> delay its transmission as part of its protocol for sharing the medium with other end systems; we’ll consider such protocols in detail in Chapter 6. Another important delay is media packetization delay, which is present in Voiceover-IP (VoIP) applications. In VoIP, the sending side must first fill a packet with encoded digitized speech before passing the packet to the Internet. This time to fill a packet—called the packetization delay—can be significant and can impact the user-perceived quality of a VoIP call. This issue will be further explored in a homework problem at the end of this chapter.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">1.4.4 </span><span class="font23" style="font-weight:bold;">Throughput in Computer Networks</span></p></li></ul>
<p><a name="bookmark275"></a><span class="font53">In addition to delay and packet loss, another critical performance measure in computer networks is end-to-end throughput. To define throughput, consider transferring a large file from Host A to Host B across a computer network. This transfer might be, for example, a large video clip from one computer to another. The </span><span class="font53" style="font-weight:bold;">instantaneous throughput </span><span class="font53">at any instant of time is the rate (in bits/sec) at which Host B is receiving the file. (Many applications display the instantaneous throughput during downloads in the user interface—perhaps you have observed this before! You might like to try measuring the end-to-end delay and download throughput between your and servers around the Internet using the speedtest application [Speedtest 2020].) If the file consists of </span><span class="font53" style="font-style:italic;">F</span><span class="font53"> bits and the transfer takes </span><span class="font53" style="font-style:italic;">T</span><span class="font53"> seconds for Host B to receive all </span><span class="font53" style="font-style:italic;">F</span><span class="font53"> bits, then the </span><span class="font53" style="font-weight:bold;">average throughput </span><span class="font53">of the file transfer is </span><span class="font53" style="font-style:italic;">F/T</span><span class="font53"> bits/sec. For some applications, such as Internet telephony, it is desirable to have a low delay and an instantaneous throughput consistently above some threshold (for example, over 24 kbps for some Internet telephony applications and over 256 kbps for some real-time video applications). For other applications, including those involving file transfers, delay is not critical, but it is desirable to have the highest possible throughput.</span></p>
<p><span class="font53">To gain further insight into the important concept of throughput, let’s consider a few examples. Figure 1.19(a) shows two end systems, a server and a client, connected by two communication links and a router. Consider the throughput for a file transfer from the server to the client. Let </span><span class="font53" style="font-style:italic;">R<sub>s</sub></span><span class="font53"> denote the rate of the link between the server and the router; and </span><span class="font53" style="font-style:italic;">R<sub>c</sub></span><span class="font53"> denote the rate of the link between the router and the client. Suppose that the only bits being sent in the entire network are those from the server to the client. We now ask, in this ideal scenario, what is the server-to-client throughput? To answer this question, we may think of bits as </span><span class="font53" style="font-style:italic;">fluid</span><span class="font53"> and communication links as </span><span class="font53" style="font-style:italic;">pipes.</span><span class="font53"> Clearly, the server cannot pump bits through its link at a rate faster than </span><span class="font53" style="font-style:italic;">R<sub>s</sub></span><span class="font53"> bps; and the router cannot forward bits at a rate faster than </span><span class="font53" style="font-style:italic;">R<sub>c</sub></span><span class="font53"> bps. If </span><span class="font53" style="font-style:italic;">R</span><span class="font50" style="font-style:italic;">s</span><span class="font55"> &lt;&nbsp;</span><span class="font53" style="font-style:italic;">R<sub>c</sub>,</span><span class="font53"> then the bits pumped by the server will “flow” right through the router and arrive at the client at a rate of </span><span class="font53" style="font-style:italic;">R<sub>s</sub></span><span class="font53"> bps, giving a throughput of </span><span class="font53" style="font-style:italic;">R<sub>s</sub></span><span class="font53"> bps. If, on the other hand, </span><span class="font53" style="font-style:italic;">R<sub>c</sub></span><span class="font55"> &lt;&nbsp;</span><span class="font53" style="font-style:italic;">R<sub>s</sub></span><span class="font53">, then the router will not be able to forward bits as quickly as it receives them. In this case, bits will only leave the router at rate </span><span class="font53" style="font-style:italic;">R<sub>c</sub></span><span class="font53">, giving an end-to-end throughput of </span><span class="font53" style="font-style:italic;">R<sub>c</sub>.</span><span class="font53"> (Note also that if bits continue to arrive at the router at rate </span><span class="font53" style="font-style:italic;">R<sub>s</sub></span><span class="font53">, and continue to leave the router at </span><span class="font53" style="font-style:italic;">R<sub>c</sub></span><span class="font53">, the backlog of bits at the router waiting for transmission to the client will grow and grow—a most undesirable situation!)</span></p><img src="networking_files/networking-41.jpg" alt="" style="width:265pt;height:40pt;">
<p><span class="font4" style="font-style:italic;">R</span><span class="font50" style="font-style:italic;">s</span></p>
<p><span class="font4" style="font-style:italic;">R</span><span class="font50" style="font-style:italic;">c</span></p>
<p><span class="font4" style="font-style:italic;">R.</span></p>
<p><span class="font4" style="font-style:italic;">R</span><span class="font50" style="font-style:italic;">c</span></p>
<p><span class="font4">Server</span></p>
<p><span class="font4">Client</span></p>
<ul style="list-style:none;"><li>
<p><span class="font4" style="font-weight:bold;">a.</span></p></li></ul><img src="networking_files/networking-42.jpg" alt="" style="width:265pt;height:40pt;">
<p><span class="font4" style="font-style:italic;">R</span><span class="font50">i</span></p>
<p><span class="font4" style="font-style:italic;">R</span><span class="font50">i</span></p>
<p><span class="font4">Server </span><span class="font4" style="font-weight:bold;">b.</span></p>
<p><span class="font4">Client</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 1.19 </span><span class="font50">♦ </span><span class="font5">Throughput for a file transfer from server to client</span></p>
<p><span class="font53">Thus, for this simple two-link network, the throughput is min{</span><span class="font53" style="font-style:italic;">R<sub>c</sub></span><span class="font53">, </span><span class="font53" style="font-style:italic;">R<sub>s</sub>},</span><span class="font53"> that is, it is the transmission rate of the </span><span class="font53" style="font-weight:bold;">bottleneck link</span><span class="font53">. Having determined the throughput, we can now approximate the time it takes to transfer a large file of </span><span class="font53" style="font-style:italic;">F</span><span class="font53"> bits from server to client as </span><span class="font53" style="font-style:italic;">F</span><span class="font53">/min{</span><span class="font53" style="font-style:italic;">R<sub>s</sub></span><span class="font53">, </span><span class="font53" style="font-style:italic;">R<sub>c</sub></span><span class="font53">}. For a specific example, suppose that you are downloading an MP3 file of </span><span class="font53" style="font-style:italic;">F =</span><span class="font53"> 32 million bits, the server has a transmission rate of </span><span class="font53" style="font-style:italic;">R<sub>s</sub> =</span><span class="font53"> 2 Mbps, and you have an access link of </span><span class="font53" style="font-style:italic;">R<sub>c</sub> =</span><span class="font53"> 1 Mbps. The time needed to transfer the file is then 32 seconds. Of course, these expressions for throughput and transfer time are only approximations, as they do not account for store-and-forward and processing delays as well as protocol issues.</span></p>
<p><span class="font53">Figure 1.19(b) now shows a network with </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> links between the server and the client, with the transmission rates of the </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> links being </span><span class="font53" style="font-style:italic;">R</span><span class="font50">1</span><span class="font53">, </span><span class="font53" style="font-style:italic;">R</span><span class="font50"><sub>2</sub>, . ..</span><span class="font53">, </span><span class="font53" style="font-style:italic;">R<sub>N</sub></span><span class="font53">. Applying the same analysis as for the two-link network, we find that the throughput for a file transfer from server to client is min{</span><span class="font53" style="font-style:italic;">R</span><span class="font50">1</span><span class="font53">, </span><span class="font53" style="font-style:italic;">R</span><span class="font53"><sub>2</sub>, . , </span><span class="font53" style="font-style:italic;">R<sub>N</sub></span><span class="font53">}, which is once again the transmission rate of the bottleneck link along the path between server and client.</span></p>
<p><span class="font53">Now consider another example motivated by today’s Internet. Figure 1.20(a) shows two end systems, a server and a client, connected to a computer network. Consider the throughput for a file transfer from the server to the client. The server is connected to the network with an access link of rate </span><span class="font53" style="font-style:italic;">R<sub>s</sub></span><span class="font53"> and the client is connected to the network with an access link of rate </span><span class="font53" style="font-style:italic;">R<sub>c</sub></span><span class="font53">. Now suppose that all the links in the core of the communication network have very high transmission rates, much higher than </span><span class="font53" style="font-style:italic;">R<sub>s</sub></span><span class="font53"> and </span><span class="font53" style="font-style:italic;">R<sub>c</sub>.</span><span class="font53"> Indeed, today, the core of the Internet is over-provisioned with high speed links that experience little congestion. Also suppose that the only bits being sent in the entire network are those from the server to the client. Because the core of the computer network is like a wide pipe in this example, the rate at which bits can flow from source to destination is again the minimum of </span><span class="font53" style="font-style:italic;">R<sub>s</sub></span><span class="font53"> and </span><span class="font53" style="font-style:italic;">R<sub>c</sub>,</span><span class="font53"> that is, throughput </span><span class="font54">= </span><span class="font53">min{</span><span class="font53" style="font-style:italic;">R<sub>s</sub></span><span class="font53">, </span><span class="font53" style="font-style:italic;">R<sub>c</sub></span><span class="font53">}. Therefore, the constraining factor for throughput in today’s Internet is typically the access network.</span></p>
<p><span class="font53">For a final example, consider Figure 1.20(b) in which there are 10 servers and 10 clients connected to the core of the computer network. In this example, there are 10 simultaneous downloads taking place, involving 10 client-server pairs. Suppose that these 10 downloads are the only traffic in the network at the current time. As shown in the figure, there is a link in the core that is traversed by all 10 downloads. Denote </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> for the transmission rate of this link </span><span class="font53" style="font-style:italic;">R</span><span class="font53">. Let’s suppose that all server access links have the same rate </span><span class="font53" style="font-style:italic;">R<sub>s</sub>,</span><span class="font53"> all client access links have the same rate </span><span class="font53" style="font-style:italic;">R<sub>c</sub>,</span><span class="font53"> and the transmission rates of all the links in the core—except the one common link of rate </span><span class="font53" style="font-style:italic;">R—</span><span class="font53">are much larger than </span><span class="font53" style="font-style:italic;">R<sub>s</sub>, R<sub>c</sub>,</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">R</span><span class="font53">. Now we ask, what are the throughputs of the downloads? Clearly, if the rate of the common link, </span><span class="font53" style="font-style:italic;">R</span><span class="font53">, is large—say a hundred times larger than both </span><span class="font53" style="font-style:italic;">R<sub>s</sub></span><span class="font53"> and </span><span class="font53" style="font-style:italic;">R<sub>c</sub>—</span><span class="font53">then the throughput for each download will once again be min{</span><span class="font53" style="font-style:italic;">R<sub>s</sub></span><span class="font53">, </span><span class="font53" style="font-style:italic;">R<sub>c</sub></span><span class="font53">}. But what if the rate of the common link is of the same order as </span><span class="font53" style="font-style:italic;">R<sub>s</sub></span><span class="font53"> and </span><span class="font53" style="font-style:italic;">R<sub>c</sub>?</span><span class="font53"> What will the throughput be in this case? Let’s take a look at a specific example. Suppose </span><span class="font53" style="font-style:italic;">R<sub>s</sub> =</span><span class="font53"> 2 Mbps, </span><span class="font53" style="font-style:italic;">R<sub>c</sub> =</span><span class="font53"> 1 Mbps, </span><span class="font53" style="font-style:italic;">R =</span><span class="font53"> 5 Mbps, and the common link divides its transmission rate equally among the 10 downloads. Then the</span></p>
<div>
<p><span class="font4" style="font-weight:bold;">a.</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Server</span></p><img src="networking_files/networking-43.jpg" alt="" style="width:20pt;height:39pt;">
<p><span class="font4" style="font-style:italic;">R</span><span class="font50" style="font-style:italic;">s</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-44.jpg" alt="" style="width:28pt;height:110pt;">
<p><span class="font4" style="font-style:italic;">R</span><span class="font50" style="font-style:italic;">c</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-45.jpg" alt="" style="width:35pt;height:37pt;">
<p><span class="font4">Client</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">b.</span></p>
</div><br clear="all">
<div>
<p><span class="font4">10 Servers</span></p><img src="networking_files/networking-46.jpg" alt="" style="width:145pt;height:93pt;">
</div><br clear="all">
<div>
<p><span class="font4">— Bottleneck link of capacity </span><span class="font4" style="font-style:italic;">R</span></p><img src="networking_files/networking-47.jpg" alt="" style="width:156pt;height:46pt;">
</div><br clear="all">
<div><img src="networking_files/networking-48.jpg" alt="" style="width:151pt;height:37pt;">
<p><span class="font4">10 Clients</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 1.20 </span><span class="font50">♦ </span><span class="font5">End-to-end throughput: (a) Client downloads a file from server; (b) 10 clients downloading with 10 servers</span></p>
</div><br clear="all">
<p><span class="font53">bottleneck for each download is no longer in the access network, but is now instead the shared link in the core, which only provides each download with 500 kbps of throughput. Thus, the end-to-end throughput for each download is now reduced to 500 kbps.</span></p>
<p><span class="font53">The examples in Figure 1.19 and Figure 1.20(a) show that throughput depends on the transmission rates of the links over which the data flows. We saw that when there is no other intervening traffic, the throughput can simply be approximated as the minimum transmission rate along the path between source and destination. The example in Figure 1.20(b) shows that more generally the throughput depends not only on the transmission rates of the links along the path, but also on the intervening traffic. In particular, a link with a high transmission rate may nonetheless be the bottleneck link for a file transfer if many other data flows are also passing through that link. We will examine throughput in computer networks more closely in the homework problems and in the subsequent chapters.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">1.5 </span><span class="font24" style="font-weight:bold;">Protocol Layers and Their Service Models</span></p></li></ul>
<p><span class="font53">From our discussion thus far, it is apparent that the Internet is an </span><span class="font53" style="font-style:italic;">extremely</span><span class="font53"> complicated system. We have seen that there are many pieces to the Internet: numerous applications and protocols, various types of end systems, packet switches, and various types of link-level media. Given this enormous complexity, is there any hope of organizing a network architecture, or at least our discussion of network architecture? Fortunately, the answer to both questions is yes.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">1.5.1 </span><span class="font23" style="font-weight:bold;">Layered Architecture</span></p></li></ul>
<p><span class="font53">Before attempting to organize our thoughts on Internet architecture, let’s look for a human analogy. Actually, we deal with complex systems all the time in our everyday life. Imagine if someone asked you to describe, for example, the airline system. How would you find the structure to describe this complex system that has ticketing agents, baggage checkers, gate personnel, pilots, airplanes, air traffic control, and a worldwide system for routing airplanes? One way to describe this system might be to describe the series of actions you take (or others take for you) when you fly on an airline. You purchase your ticket, check your bags, go to the gate, and eventually get loaded onto the plane. The plane takes off and is routed to its destination. After your plane lands, you deplane at the gate and claim your bags. If the trip was bad, you complain about the flight to the ticket agent (getting nothing for your effort). This scenario is shown in Figure 1.21.</span></p>
<div><img src="networking_files/networking-49.jpg" alt="" style="width:38pt;height:33pt;">
<p><span class="font4">(complain)</span></p>
</div><br clear="all">
<p><span class="font4">Ticket (purchase)</span></p>
<p><span class="font4">Baggage (check)</span></p>
<p><span class="font4">Gates (load)</span></p>
<p><span class="font4">Ticket</span></p>
<p><span class="font4">Baggage (claim)</span></p>
<div>
<p><span class="font4">Gates (unl</span></p>
</div><br clear="all">
<div>
<p><span class="font4">oad)</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Runway takeoff</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Airplane routing</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Airplane routing</span></p><img src="networking_files/networking-50.jpg" alt="" style="width:51pt;height:52pt;">
</div><br clear="all">
<div>
<p><span class="font4">ay landing</span></p>
</div><br clear="all">
<p><a name="bookmark276"></a><span class="font7" style="font-weight:bold;">Figure 1.21 </span><span class="font50">♦ </span><span class="font5">Taking an airplane trip: actions</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font4">Ticket (purchase)</span></p></td><td></td><td style="vertical-align:middle;">
<p><span class="font4">Ticket (complain)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font4">Baggage (check)</span></p></td><td></td><td style="vertical-align:middle;">
<p><span class="font4">Baggage (claim)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font4">Gates (load)</span></p></td><td></td><td style="vertical-align:middle;">
<p><span class="font4">Gates (unload)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font4">Runway takeoff</span></p></td><td></td><td style="vertical-align:middle;">
<p><span class="font4">Runway landing</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font4">Airplane routing</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Airplane routing &nbsp;&nbsp;&nbsp;&nbsp;Airplane routing</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Airplane routing</span></p></td></tr>
</table>
<p><span class="font4" style="font-weight:bold;">Ticket</span></p>
<p><span class="font4" style="font-weight:bold;">Baggage</span></p>
<p><span class="font4" style="font-weight:bold;">Gate</span></p>
<p><span class="font4" style="font-weight:bold;">Takeoff/Landing</span></p>
<p><span class="font4" style="font-weight:bold;">Airplane routing</span></p>
<p><span class="font4" style="font-weight:bold;">Departure airport</span></p>
<p><span class="font4" style="font-weight:bold;">Intermediate air-traffic control centers</span></p>
<p><span class="font4" style="font-weight:bold;">Arrival airport</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 1.22 </span><span class="font50">♦ </span><span class="font5">Horizontal layering of airline functionality</span></p>
<p><span class="font53">Already, we can see some analogies here with computer networking: You are being shipped from source to destination by the airline; a packet is shipped from source host to destination host in the Internet. But this is not quite the analogy we are after. We are looking for some </span><span class="font53" style="font-style:italic;">structure</span><span class="font53"> in Figure 1.21. Looking at Figure 1.21, we note that there is a ticketing function at each end; there is also a baggage function for already-ticketed passengers, and a gate function for already-ticketed and already-baggage-checked passengers. For passengers who have made it through the gate (that is, passengers who are already ticketed, baggage-checked, and through the gate), there is a takeoff and landing function, and while in flight, there is an airplanerouting function. This suggests that we can look at the functionality in Figure 1.21 in a </span><span class="font53" style="font-style:italic;">horizontal</span><span class="font53"> manner, as shown in Figure 1.22.</span></p>
<p><span class="font53">Figure 1.22 has divided the airline functionality into layers, providing a framework in which we can discuss airline travel. Note that each layer, combined with the layers below it, implements some functionality, some </span><span class="font53" style="font-style:italic;">service.</span><span class="font53"> At the ticketing layer and below, airline-counter-to-airline-counter transfer of a person is accomplished. At the baggage layer and below, baggage-check-to-baggage-claim transfer of a person and bags is accomplished. Note that the baggage layer provides this service only to an already-ticketed person. At the gate layer, departure-gate-to-arrival-gate transfer of a person and bags is accomplished. At the takeoff/landing layer, runway-to-runway transfer of people and their bags is accomplished. Each layer provides its service by (1) performing certain actions within that layer (for example, at the gate layer, loading and unloading people from an airplane) and by (2) using the services of the layer directly below it (for example, in the gate layer, using the runway-to-runway passenger transfer service of the takeoff/landing layer).</span></p>
<p><span class="font53">A layered architecture allows us to discuss a well-defined, specific part of a large and complex system. This simplification itself is of considerable value by providing modularity, making it much easier to change the implementation of the service provided by the layer. As long as the layer provides the same service to the layer above it, and uses the same services from the layer below it, the remainder of the system remains unchanged when a layer’s implementation is changed. (Note that changing the implementation of a service is very different from changing the service itself!) For example, if the gate functions were changed (for instance, to have people board and disembark by height), the remainder of the airline system would remain unchanged since the gate layer still provides the same function (loading and unloading people); it simply implements that function in a different manner after the change. For large and complex systems that are constantly being updated, the ability to change the implementation of a service without affecting other components of the system is another important advantage of layering.</span></p>
<p><span class="font22" style="font-weight:bold;">Protocol Layering</span></p>
<p><span class="font53">But enough about airlines. Let’s now turn our attention to network protocols. To provide structure to the design of network protocols, network designers organize protocols—and the network hardware and software that implement the protocols— in </span><span class="font53" style="font-weight:bold;">layers</span><span class="font53">. Each protocol belongs to one of the layers, just as each function in the airline architecture in Figure 1.22 belonged to a layer. We are again interested in the </span><span class="font53" style="font-weight:bold;">services </span><span class="font53">that a layer offers to the layer above—the so-called </span><span class="font53" style="font-weight:bold;">service model </span><span class="font53">of a layer. Just as in the case of our airline example, each layer provides its service by (1) performing certain actions within that layer and by (2) using the services of the layer directly below it. For example, the services provided by layer </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> may include reliable delivery of messages from one edge of the network to the other. This might be implemented by using an unreliable edge-to-edge message delivery service of layer </span><span class="font53" style="font-style:italic;">n —</span><span class="font53"> 1, and adding layer </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> functionality to detect and retransmit lost messages.</span></p>
<p><span class="font53">A protocol layer can be implemented in software, in hardware, or in a combination of the two. Application-layer protocols—such as HTTP and SMTP—are almost always implemented in software in the end systems; so are transport-layer protocols. Because the physical layer and data link layers are responsible for handling communication over a specific link, they are typically implemented in a network interface card (for example, Ethernet or WiFi interface cards) associated with a given link. The network layer is often a mixed implementation of hardware and software. Also note that just as the functions in the layered airline architecture were distributed among the various airports and flight control centers that make up the system, so too is a layer </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> protocol </span><span class="font53" style="font-style:italic;">distributed</span><span class="font53"> among the end systems, packet switches, and other components that make up the network. That is, there’s often a piece of a layer </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> protocol in each of these network components.</span></p>
<p><span class="font53">Protocol layering has conceptual and structural advantages [RFC 3439]. As we have seen, layering provides a structured way to discuss system components. Modularity makes it easier to update system components. We mention, however, that some researchers and networking engineers are vehemently opposed to layering [Wakeman 1992]. One potential drawback of layering is that one layer may duplicate lower-layer functionality. For example, many protocol stacks provide error recovery on both a per-link basis and an end-to-end basis. A second potential drawback is that functionality at one layer may need information (for example, a timestamp value) that is present only in another layer; this violates the goal of separation of layers.</span></p><img src="networking_files/networking-51.jpg" alt="" style="width:72pt;height:87pt;">
<p><span class="font4" style="font-weight:bold;">Five-layer Internet protocol stack</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 1.23 </span><span class="font50">♦ </span><span class="font5">The Internet protocol stack</span></p>
<p><span class="font53">When taken together, the protocols of the various layers are called the </span><span class="font53" style="font-weight:bold;">protocol stack</span><span class="font53">. The Internet protocol stack consists of five layers: the physical, link, network, transport, and application layers, as shown in Figure 1.23. If you examine the Table of Contents, you will see that we have roughly organized this book using the layers of the Internet protocol stack. We take a </span><span class="font53" style="font-weight:bold;">top-down approach</span><span class="font53">, first covering the application layer and then proceeding downward.</span></p>
<p><span class="font22" style="font-weight:bold;">Application Layer</span></p>
<p><span class="font53">The application layer is where network applications and their application-layer protocols reside. The Internet’s application layer includes many protocols, such as the HTTP protocol (which provides for Web document request and transfer), SMTP (which provides for the transfer of e-mail messages), and FTP (which provides for the transfer of files between two end systems). We’ll see that certain network functions, such as the translation of human-friendly names for Internet end systems like </span><a href="http://www.ietf.org"><span class="font53">www.ietf.org </span></a><span class="font53">to a 32-bit network address, are also done with the help of a specific application-layer protocol, namely, the domain name system (DNS). We’ll see in Chapter 2 that it is very easy to create and deploy our own new application-layer protocols.</span></p>
<p><span class="font53">An application-layer protocol is distributed over multiple end systems, with the application in one end system using the protocol to exchange packets of information with the application in another end system. We’ll refer to this packet of information at the application layer as a </span><span class="font53" style="font-weight:bold;">message</span><span class="font53">.</span></p>
<p><span class="font22" style="font-weight:bold;">Transport Layer</span></p>
<p><span class="font53">The Internet’s transport layer transports application-layer messages between application endpoints. In the Internet, there are two transport protocols, TCP and UDP, either of which can transport application-layer messages. TCP provides a connection-oriented service to its applications. This service includes guaranteed delivery of application-layer messages to the destination and flow control (that is, sender/receiver speed matching). TCP also breaks long messages into shorter segments and provides a congestion-control mechanism, so that a source throttles its transmission rate when the network is congested. The UDP protocol provides a connectionless service to its applications. This is a no-frills service that provides no reliability, no flow control, and no congestion control. In this book, we’ll refer to a transport-layer packet as a </span><span class="font53" style="font-weight:bold;">segment</span><span class="font53">.</span></p>
<p><span class="font22" style="font-weight:bold;">Network Layer</span></p>
<p><span class="font53">The Internet’s network layer is responsible for moving network-layer packets known as </span><span class="font53" style="font-weight:bold;">datagrams </span><span class="font53">from one host to another. The Internet transport-layer protocol (TCP or UDP) in a source host passes a transport-layer segment and a destination address to the network layer, just as you would give the postal service a letter with a destination address. The network layer then provides the service of delivering the segment to the transport layer in the destination host.</span></p>
<p><span class="font53">The Internet’s network layer includes the celebrated IP protocol, which defines the fields in the datagram as well as how the end systems and routers act on these fields. There is only one IP protocol, and all Internet components that have a network layer must run the IP protocol. The Internet’s network layer also contains routing protocols that determine the routes that datagrams take between sources and destinations. The Internet has many routing protocols. As we saw in Section 1.3, the Internet is a network of networks, and within a network, the network administrator can run any routing protocol desired. Although the network layer contains both the IP protocol and numerous routing protocols, it is often simply referred to as the IP layer, reflecting the fact that IP is the glue that binds the Internet together.</span></p>
<p><span class="font22" style="font-weight:bold;">Link Layer</span></p>
<p><span class="font53">The Internet’s network layer routes a datagram through a series of routers between the source and destination. To move a packet from one node (host or router) to the next node in the route, the network layer relies on the services of the link layer. In particular, at each node, the network layer passes the datagram down to the link layer, which delivers the datagram to the next node along the route. At this next node, the link layer passes the datagram up to the network layer.</span></p>
<p><span class="font53">The services provided by the link layer depend on the specific link-layer protocol that is employed over the link. For example, some link-layer protocols provide reliable delivery, from transmitting node, over one link, to receiving node. Note that this reliable delivery service is different from the reliable delivery service of TCP, which provides reliable delivery from one end system to another. Examples of link-layer protocols include Ethernet, WiFi, and the cable access network’s DOCSIS protocol. As datagrams typically need to traverse several links to travel from source to destination, a datagram may be handled by different link-layer protocols at different links along its route. For example, a datagram may be handled by Ethernet on one link and by PPP on the next link. The network layer will receive a different service from each of the different link-layer protocols. In this book, we’ll refer to the link-layer packets as </span><span class="font53" style="font-weight:bold;">frames</span><span class="font53">.</span></p>
<p><span class="font22" style="font-weight:bold;">Physical Layer</span></p>
<p><span class="font53">While the job of the link layer is to move entire frames from one network element to an adjacent network element, the job of the physical layer is to move the </span><span class="font53" style="font-style:italic;">individual bits</span><span class="font53"> within the frame from one node to the next. The protocols in this layer are again link dependent and further depend on the actual transmission medium of the link (for example, twisted-pair copper wire, single-mode fiber optics). For example, Ethernet has many physical-layer protocols: one for twisted-pair copper wire, another for coaxial cable, another for fiber, and so on. In each case, a bit is moved across the link in a different way.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">1.5.2 </span><span class="font23" style="font-weight:bold;">Encapsulation</span></p></li></ul>
<p><span class="font53">Figure 1.24 shows the physical path that data takes down a sending end system’s protocol stack, up and down the protocol stacks of an intervening link-layer switch</span></p>
<div>
<p><span class="font4">Message M</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font4">Segment</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">H</span><span class="font3">t</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">M</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">Datagram H<sub>n</sub></span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">H</span><span class="font3">t</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">M</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">Frame H</span><span class="font3">l </span><span class="font4">H<sub>n</sub></span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">H</span><span class="font3">t</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">M</span></p></td></tr>
</table>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Source</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font4">Application</span></p></td><td></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">Transport</span></p></td><td></td></tr>
<tr><td>
<p><span class="font4">Network</span></p></td><td></td></tr>
<tr><td>
<p><span class="font4">Link</span></p></td><td></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">Physical</span></p></td><td></td></tr>
<tr><td></td><td></td></tr>
</table>
</div><br clear="all">
<div><img src="networking_files/networking-52.jpg" alt="" style="width:60pt;height:93pt;">
</div><br clear="all">
<div>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font4">H</span><span class="font3">l</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">H<sub>n</sub> H<sub>t</sub> M</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">[ Link</span></p></td><td></td></tr>
<tr><td colspan="2"></td><td></td><td></td></tr>
<tr><td colspan="2"></td><td>
<p><span class="font4">Physical</span></p></td><td></td></tr>
</table>
<p><span class="font4">H</span><span class="font3">l </span><span class="font4">H</span><span class="font3">n</span></p>
<p><span class="font4">Link-layer switch</span></p>
</div><br clear="all">
<div>
<p><span class="font4">H</span><span class="font3">t</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Destination</span></p>
<p><a name="bookmark277"></a><span class="font4">H</span><span class="font3">l</span></p>
<table border="1">
<tr><td></td><td></td><td style="vertical-align:bottom;">
<p><span class="font4">M</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">Application</span></p></td><td></td></tr>
<tr><td></td><td style="vertical-align:bottom;">
<p><span class="font4">H</span><span class="font3">t</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">M</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">Transport</span></p></td><td></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">H</span><span class="font3">n</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">H</span><span class="font3">t</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">M</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">Network</span></p></td><td></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">H</span><span class="font3">n</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">H</span><span class="font3">t</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">M</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">Link</span></p></td><td></td></tr>
<tr><td></td><td></td><td></td><td>
<p><span class="font4">Physical</span></p></td><td></td></tr>
</table>
</div><br clear="all">
<div><img src="networking_files/networking-53.jpg" alt="" style="width:61pt;height:85pt;">
<p><span class="font4">H</span><span class="font3">l </span><span class="font4">H</span><span class="font3">n </span><span class="font4">H</span><span class="font3">t</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Router</span></p>
</div><br clear="all">
<div>
<p><span class="font4">H</span><span class="font3">n </span><span class="font4">H</span><span class="font3">t</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Network</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Link</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Physical</span></p>
</div><br clear="all">
<div>
<table border="1">
<tr><td></td><td style="vertical-align:bottom;">
<p><span class="font4">H</span><span class="font3">n</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">H</span><span class="font3">t</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">M</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">H</span><span class="font3">l</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">H</span><span class="font3">n</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">H</span><span class="font3">t</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">M</span></p></td></tr>
</table>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 1.24 </span><span class="font50">♦ </span><span class="font5">Hosts, routers, and link-layer switches; each contains a different set of layers, reflecting their differences in functionality </span><span class="font53">and router, and then up the protocol stack at the receiving end system. As we discuss later in this book, routers and link-layer switches are both packet switches. Similar to end systems, routers and link-layer switches organize their networking hardware and software into layers. But routers and link-layer switches do not implement </span><span class="font53" style="font-style:italic;">all</span><span class="font53"> of the layers in the protocol stack; they typically implement only the bottom layers. As shown in Figure 1.24, link-layer switches implement layers 1 and 2; routers implement layers 1 through 3. This means, for example, that Internet routers are capable of implementing the IP protocol (a layer 3 protocol), while link-layer switches are not. We’ll see later that while link-layer switches do not recognize IP addresses, they are capable of recognizing layer 2 addresses, such as Ethernet addresses. Note that hosts implement all five layers; this is consistent with the view that the Internet architecture puts much of its complexity at the edges of the network.</span></p>
<p><span class="font53">Figure 1.24 also illustrates the important concept of </span><span class="font53" style="font-weight:bold;">encapsulation</span><span class="font53">. At the sending host, an </span><span class="font53" style="font-weight:bold;">application-layer message </span><span class="font53">(M in Figure 1.24) is passed to the transport layer. In the simplest case, the transport layer takes the message and appends additional information (so-called transport-layer header information, H</span><span class="font53" style="font-style:italic;"><sub>t </sub></span><span class="font53">in Figure 1.24) that will be used by the receiver-side transport layer. The application-layer message and the transport-layer header information together constitute the </span><span class="font53" style="font-weight:bold;">transport-layer segment</span><span class="font53">. The transport-layer segment thus encapsulates the application-layer message. The added information might include information allowing the receiver-side transport layer to deliver the message up to the appropriate application, and error-detection bits that allow the receiver to determine whether bits in the message have been changed in route. The transport layer then passes the segment to the network layer, which adds network-layer header information (H</span><span class="font53" style="font-style:italic;"><sub>n</sub></span><span class="font53"> in Figure 1.24) such as source and destination end system addresses, creating a </span><span class="font53" style="font-weight:bold;">network-layer datagram</span><span class="font53">. The datagram is then passed to the link layer, which (of course!) will add its own link-layer header information and create a </span><span class="font53" style="font-weight:bold;">link-layer frame</span><span class="font53">. Thus, we see that at each layer, a packet has two types of fields: header fields and a </span><span class="font53" style="font-weight:bold;">payload field</span><span class="font53">. The payload is typically a packet from the layer above.</span></p>
<p><span class="font53">A useful analogy here is the sending of an interoffice memo from one corporate branch office to another via the public postal service. Suppose Alice, who is in one branch office, wants to send a memo to Bob, who is in another branch office. The </span><span class="font53" style="font-style:italic;">memo</span><span class="font53"> is analogous to the </span><span class="font53" style="font-style:italic;">application-layer message.</span><span class="font53"> Alice puts the memo in an interoffice envelope with Bob’s name and department written on the front of the envelope. The </span><span class="font53" style="font-style:italic;">interoffice envelope</span><span class="font53"> is analogous to a </span><span class="font53" style="font-style:italic;">transport-layer segment—</span><span class="font53">it contains header information (Bob’s name and department number) and it encapsulates the application-layer message (the memo). When the sending branchoffice mailroom receives the interoffice envelope, it puts the interoffice envelope inside yet another envelope, which is suitable for sending through the public postal service. The sending mailroom also writes the postal address of the sending and receiving branch offices on the postal envelope. Here, the </span><span class="font53" style="font-style:italic;">postal envelope </span><span class="font53">is analogous to the </span><span class="font53" style="font-style:italic;">datagram—</span><span class="font53">it encapsulates the transport-layer segment (the interoffice envelope), which encapsulates the original message (the memo). The postal service delivers the postal envelope to the receiving branch-office mailroom. There, the process of de-encapsulation is begun. The mailroom extracts the interoffice memo and forwards it to Bob. Finally, Bob opens the envelope and removes the memo.</span></p>
<p><span class="font53">The process of encapsulation can be more complex than that described above. For example, a large message may be divided into multiple transport-layer segments (which might themselves each be divided into multiple network-layer datagrams). At the receiving end, such a segment must then be reconstructed from its constituent datagrams.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">1.6 </span><span class="font24" style="font-weight:bold;">Networks Under Attack</span></p></li></ul>
<p><span class="font53">The Internet has become mission critical for many institutions today, including large and small companies, universities, and government agencies. Many individuals also rely on the Internet for many of their professional, social, and personal activities. Billions of “things,” including wearables and home devices, are currently being connected to the Internet. But behind all this utility and excitement, there is a dark side, a side where “bad guys” attempt to wreak havoc in our daily lives by damaging our Internet-connected computers, violating our privacy, and rendering inoperable the Internet services on which we depend.</span></p>
<p><span class="font53">The field of network security is about how the bad guys can attack computer networks and about how we, soon-to-be experts in computer networking, can defend networks against those attacks, or better yet, design new architectures that are immune to such attacks in the first place. Given the frequency and variety of existing attacks as well as the threat of new and more destructive future attacks, network security has become a central topic in the field of computer networking. One of the features of this textbook is that it brings network security issues to the forefront.</span></p>
<p><span class="font53">Since we don’t yet have expertise in computer networking and Internet protocols, we’ll begin here by surveying some of today’s more prevalent security-related problems. This will whet our appetite for more substantial discussions in the upcoming chapters. So we begin here by simply asking, what can go wrong? How are computer networks vulnerable? What are some of the more prevalent types of attacks today?</span></p>
<p><span class="font22" style="font-weight:bold;">The Bad Guys Can Put Malware into Your Host Via the Internet</span></p>
<p><a name="bookmark278"></a><span class="font53">We attach devices to the Internet because we want to receive/send data from/to the Internet. This includes all kinds of good stuff, including Instagram posts, Internet search results, streaming music, video conference calls, streaming movies, and so on. But, unfortunately, along with all that good stuff comes malicious stuff— collectively known as </span><span class="font53" style="font-weight:bold;">malware—</span><span class="font53">that can also enter and infect our devices. Once malware infects our device it can do all kinds of devious things, including deleting our files and installing spyware that collects our private information, such as social security numbers, passwords, and keystrokes, and then sends this (over the Internet, of course!) back to the bad guys. Our compromised host may also be enrolled in a network of thousands of similarly compromised devices, collectively known as a </span><span class="font53" style="font-weight:bold;">botnet</span><span class="font53">, which the bad guys control and leverage for spam e-mail distribution or distributed denial-of-service attacks (soon to be discussed) against targeted hosts.</span></p>
<p><span class="font53">Much of the malware out there today is </span><span class="font53" style="font-weight:bold;">self-replicating</span><span class="font53">: once it infects one host, from that host it seeks entry into other hosts over the Internet, and from the newly infected hosts, it seeks entry into yet more hosts. In this manner, self-replicating malware can spread exponentially fast.</span></p>
<p><span class="font22" style="font-weight:bold;">The Bad Guys Can Attack Servers and Network Infrastructure</span></p>
<p><span class="font53">Another broad class of security threats are known as </span><span class="font53" style="font-weight:bold;">denial-of-service (DoS) attacks</span><span class="font53">. As the name suggests, a DoS attack renders a network, host, or other piece of infrastructure unusable by legitimate users. Web servers, e-mail servers, DNS servers (discussed in Chapter 2), and institutional networks can all be subject to DoS attacks. The site Digital Attack Map allows use to visualize the top daily DoS attacks worldwide [DAM 2020]. Most Internet DoS attacks fall into one of three categories:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Vulnerability attack.</span><span class="font53"> This involves sending a few well-crafted messages to a vulnerable application or operating system running on a targeted host. If the right sequence of packets is sent to a vulnerable application or operating system, the service can stop or, worse, the host can crash.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Bandwidth flooding.</span><span class="font53"> The attacker sends a deluge of packets to the targeted host—so many packets that the target’s access link becomes clogged, preventing legitimate packets from reaching the server.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Connection flooding.</span><span class="font53"> The attacker establishes a large number of half-open or fully open TCP connections (TCP connections are discussed in Chapter 3) at the target host. The host can become so bogged down with these bogus connections that it stops accepting legitimate connections.</span></p></li></ul>
<p><span class="font53">Let’s now explore the bandwidth-flooding attack in more detail. Recalling our delay and loss analysis discussion in Section 1.4.2, it’s evident that if the server has an access rate of </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> bps, then the attacker will need to send traffic at a rate of approximately </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> bps to cause damage. If </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> is very large, a single attack source may not be able to generate enough traffic to harm the server. Furthermore, if all</span></p>
<div><img src="networking_files/networking-54.jpg" alt="" style="width:269pt;height:186pt;">
<p><span class="font7" style="font-weight:bold;">Figure 1.25 </span><span class="font50">♦ </span><span class="font5">A distributed denial-of-service attack</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-55.jpg" alt="" style="width:45pt;height:38pt;">
<p><span class="font4">Victim</span></p>
</div><br clear="all">
<p><span class="font53">the traffic emanates from a single source, an upstream router may be able to detect the attack and block all traffic from that source before the traffic gets near the server. In a </span><span class="font53" style="font-weight:bold;">distributed DoS (DDoS) </span><span class="font53">attack, illustrated in Figure 1.25, the attacker controls multiple sources and has each source blast traffic at the target. With this approach, the aggregate traffic rate across all the controlled sources needs to be approximately </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> to cripple the service. DDoS attacks leveraging botnets with thousands of comprised hosts are a common occurrence today [DAM 2020]. DDos attacks are much harder to detect and defend against than a DoS attack from a single host.</span></p>
<p><span class="font53">We encourage you to consider the following question as you work your way through this book: What can computer network designers do to defend against DoS attacks? We will see that different defenses are needed for the three types of DoS attacks.</span></p>
<p><span class="font22" style="font-weight:bold;">The Bad Guys Can Sniff Packets</span></p>
<p><span class="font53">Many users today access the Internet via wireless devices, such as WiFi-connected laptops or handheld devices with cellular Internet connections (covered in Chapter 7). While ubiquitous Internet access is extremely convenient and enables marvelous new applications for mobile users, it also creates a major security vulnerability—by placing a passive receiver in the vicinity of the wireless transmitter, that receiver can obtain a copy of every packet that is transmitted! These packets can contain all kinds of sensitive information, including passwords, social security numbers, trade secrets, and private personal messages. A passive receiver that records a copy of every packet that flies by is called a </span><span class="font53" style="font-weight:bold;">packet sniffer</span><span class="font53">.</span></p>
<p><span class="font53">Sniffers can be deployed in wired environments as well. In wired broadcast environments, as in many Ethernet LANs, a packet sniffer can obtain copies of broadcast packets sent over the LAN. As described in Section 1.2, cable access technologies also broadcast packets and are thus vulnerable to sniffing. Furthermore, a bad guy who gains access to an institution’s access router or access link to the Internet may be able to plant a sniffer that makes a copy of every packet going to/from the organization. Sniffed packets can then be analyzed offline for sensitive information.</span></p>
<p><span class="font53">Packet-sniffing software is freely available at various Web sites and as commercial products. Professors teaching a networking course have been known to assign lab exercises that involve writing a packet-sniffing and application-layer data reconstruction program. Indeed, the Wireshark [Wireshark 2020] labs associated with this text (see the introductory Wireshark lab at the end of this chapter) use exactly such a packet sniffer!</span></p>
<p><span class="font53">Because packet sniffers are passive—that is, they do not inject packets into the channel—they are difficult to detect. So, when we send packets into a wireless channel, we must accept the possibility that some bad guy may be recording copies of our packets. As you may have guessed, some of the best defenses against packet sniffing involve cryptography. We will examine cryptography as it applies to network security in Chapter 8.</span></p>
<p><span class="font22" style="font-weight:bold;">The Bad Guys Can Masquerade as Someone You Trust</span></p>
<p><span class="font53">It is surprisingly easy </span><span class="font53" style="font-style:italic;">(you</span><span class="font53"> will have the knowledge to do so shortly as you proceed through this text!) to create a packet with an arbitrary source address, packet content, and destination address and then transmit this hand-crafted packet into the Internet, which will dutifully forward the packet to its destination. Imagine the unsuspecting receiver (say an Internet router) who receives such a packet, takes the (false) source address as being truthful, and then performs some command embedded in the packet’s contents (say modifies its forwarding table). The ability to inject packets into the Internet with a false source address is known as </span><span class="font53" style="font-weight:bold;">IP spoofing</span><span class="font53">, and is but one of many ways in which one user can masquerade as another user.</span></p>
<p><span class="font53">To solve this problem, we will need </span><span class="font53" style="font-style:italic;">end-point authentication,</span><span class="font53"> that is, a mechanism that will allow us to determine with certainty if a message originates from where we think it does. Once again, we encourage you to think about how this can be done for network applications and protocols as you progress through the chapters of this book. We will explore mechanisms for end-point authentication in Chapter 8.</span></p>
<p><span class="font53">In closing this section, it’s worth considering how the Internet got to be such an insecure place in the first place. The answer, in essence, is that the Internet was originally designed to be that way, based on the model of “a group of mutually trusting users attached to a transparent network” [Blumenthal 2001]—a model in which (by definition) there is no need for security. Many aspects of the original Internet architecture deeply reflect this notion of mutual trust. For example, the ability for one user to send a packet to any other user is the default rather than a requested/ granted capability, and user identity is taken at declared face value, rather than being authenticated by default.</span></p>
<p><span class="font53">But today’s Internet certainly does not involve “mutually trusting users.” Nonetheless, today’s users still need to communicate when they don’t necessarily trust each other, may wish to communicate anonymously, may communicate indirectly through third parties (e.g., Web caches, which we’ll study in Chapter 2, or mobilityassisting agents, which we’ll study in Chapter 7), and may distrust the hardware, software, and even the air through which they communicate. We now have many security-related challenges before us as we progress through this book: We should seek defenses against sniffing, end-point masquerading, man-in-the-middle attacks, DDoS attacks, malware, and more. We should keep in mind that communication among mutually trusted users is the exception rather than the rule. Welcome to the world of modern computer networking!</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">1.7 </span><span class="font24" style="font-weight:bold;">History of Computer Networking and the Internet</span></p></li></ul>
<p><span class="font53">Sections 1.1 through 1.6 presented an overview of the technology of computer networking and the Internet. You should know enough now to impress your family and friends! However, if you really want to be a big hit at the next cocktail party, you should sprinkle your discourse with tidbits about the fascinating history of the Internet [Segaller 1998].</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">1.7.1 </span><span class="font23" style="font-weight:bold;">The Development of Packet Switching: 1961-1972</span></p></li></ul>
<p><a name="bookmark279"></a><span class="font53">The field of computer networking and today’s Internet trace their beginnings back to the early 1960s, when the telephone network was the world’s dominant communication network. Recall from Section 1.3 that the telephone network uses circuit switching to transmit information from a sender to a receiver—an appropriate choice given that voice is transmitted at a constant rate between sender and receiver. Given the increasing importance of computers in the early 1960s and the advent of timeshared computers, it was perhaps natural to consider how to hook computers together so that they could be shared among geographically distributed users. The traffic generated by such users was likely to be </span><span class="font53" style="font-style:italic;">bursty— </span><span class="font53">intervals of activity, such as the sending of a command to a remote computer, followed by periods of inactivity while waiting for a reply or while contemplating the received response.</span></p>
<p><span class="font53">Three research groups around the world, each unaware of the others’ work [Leiner 1998], began inventing packet switching as an efficient and robust alternative to circuit switching. The first published work on packet-switching techniques was that of Leonard Kleinrock [Kleinrock 1961; Kleinrock 1964], then a graduate student at MIT. Using queuing theory, Kleinrock’s work elegantly demonstrated the effectiveness of the packet-switching approach for bursty traffic sources. In 1964, Paul Baran [Baran 1964] at the Rand Institute had begun investigating the use of packet switching for secure voice over military networks, and at the National Physical Laboratory in England, Donald Davies and Roger Scantlebury were also developing their ideas on packet switching.</span></p>
<p><span class="font53">The work at MIT, Rand, and the NPL laid the foundations for today’s Internet. But the Internet also has a long history of a let’s-build-it-and-demonstrate-it attitude that also dates back to the 1960s. J. C. R. Licklider [DEC 1990] and Lawrence Roberts, both colleagues of Kleinrock’s at MIT, went on to lead the computer science program at the Advanced Research Projects Agency (ARPA) in the United States. Roberts published an overall plan for the ARPAnet [Roberts 1967], the first packet-switched computer network and a direct ancestor of today’s public Internet. On Labor Day in 1969, the first packet switch was installed at UCLA under Kleinrock’s supervision, and three additional packet switches were installed shortly thereafter at the Stanford Research Institute (SRI), UC Santa Barbara, and the University of Utah (Figure 1.26). The fledgling precursor to the Internet was four nodes large by the end of 1969. Kleinrock recalls the very first use of the network to perform a remote login from UCLA to SRI, crashing the system [Kleinrock 2004].</span></p>
<p><span class="font53">By 1972, ARPAnet had grown to approximately 15 nodes and was given its first public demonstration by Robert Kahn. The first host-to-host protocol between ARPAnet end systems, known as the network-control protocol (NCP), was completed [RFC 001]. With an end-to-end protocol available, applications could now be written. Ray Tomlinson wrote the first e-mail program in 1972.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">1.7.2 </span><span class="font23" style="font-weight:bold;">Proprietary Networks and Internetworking: 1972-1980</span></p></li></ul>
<p><a name="bookmark280"></a><span class="font53">The initial ARPAnet was a single, closed network. In order to communicate with an ARPAnet host, one had to be actually attached to another ARPAnet IMP. In the early to mid-1970s, additional stand-alone packet-switching networks besides ARPAnet came into being: ALOHANet, a microwave network linking universities on the Hawaiian islands [Abramson 1970], as well as DARPA’s packet-satellite [RFC 829] and packet-radio networks [Kahn 1978]; Telenet, a BBN commercial packet-switching</span></p><img src="networking_files/networking-56.jpg" alt="" style="width:256pt;height:346pt;">
<p><span class="font7" style="font-weight:bold;">Figure 1.26 </span><span class="font50">♦ </span><span class="font5">An early packet switch</span></p>
<p><span class="font53">network based on ARPAnet technology; Cyclades, a French packet-switching network pioneered by Louis Pouzin [Think 2012]; Time-sharing networks such as Tymnet and the GE Information Services network, among others, in the late 1960s and early 1970s [Schwartz 1977]; IBM’s SNA (1969-1974), which paralleled the ARPAnet work [Schwartz 1977].</span></p>
<p><span class="font53">The number of networks was growing. With perfect hindsight we can see that the time was ripe for developing an encompassing architecture for connecting networks together. Pioneering work on interconnecting networks (under the sponsorship of the Defense Advanced Research Projects Agency (DARPA)), in essence creating a </span><span class="font53" style="font-style:italic;">network of networks,</span><span class="font53"> was done by Vinton Cerf and Robert Kahn [Cerf 1974]; the term </span><span class="font53" style="font-style:italic;">internetting</span><span class="font53"> was coined to describe this work.</span></p>
<p><span class="font53">These architectural principles were embodied in TCP. The early versions of TCP, however, were quite different from today’s TCP. The early versions of TCP combined a reliable in-sequence delivery of data via end-system retransmission (still part of today’s TCP) with forwarding functions (which today are performed by IP). Early experimentation with TCP, combined with the recognition of the importance of an unreliable, non-flow-controlled, end-to-end transport service for applications such as packetized voice, led to the separation of IP out of TCP and the development of the UDP protocol. The three key Internet protocols that we see today—TCP, UDP, and IP—were conceptually in place by the end of the 1970s.</span></p>
<p><span class="font53">In addition to the DARPA Internet-related research, many other important networking activities were underway. In Hawaii, Norman Abramson was developing ALOHAnet, a packet-based radio network that allowed multiple remote sites on the Hawaiian Islands to communicate with each other. The ALOHA protocol [Abramson 1970] was the first multiple-access protocol, allowing geographically distributed users to share a single broadcast communication medium (a radio frequency). Metcalfe and Boggs built on Abramson’s multiple-access protocol work when they developed the Ethernet protocol [Metcalfe 1976] for wire-based shared broadcast networks. Interestingly, Metcalfe and Boggs’ Ethernet protocol was motivated by the need to connect multiple PCs, printers, and shared disks [Perkins 1994]. Twenty-five years ago, well before the PC revolution and the explosion of networks, Metcalfe and Boggs were laying the foundation for today’s PC LANs.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">1.7.3 </span><span class="font23" style="font-weight:bold;">A Proliferation of Networks: 1980-1990</span></p></li></ul>
<p><span class="font53">By the end of the 1970s, approximately two hundred hosts were connected to the ARPAnet. By the end of the 1980s the number of hosts connected to the public Internet, a confederation of networks looking much like today’s Internet, would reach a hundred thousand. The 1980s would be a time of tremendous growth.</span></p>
<p><span class="font53">Much of that growth resulted from several distinct efforts to create computer networks linking universities together. BITNET provided e-mail and file transfers among several universities in the Northeast. CSNET (computer science network) was formed to link university researchers who did not have access to ARPAnet. In 1986, NSFNET was created to provide access to NSF-sponsored supercomputing centers. Starting with an initial backbone speed of 56 kbps, NSFNET’s backbone would be running at 1.5 Mbps by the end of the decade and would serve as a primary backbone linking regional networks.</span></p>
<p><a name="bookmark281"></a><span class="font53">In the ARPAnet community, many of the final pieces of today’s Internet architecture were falling into place. January 1, 1983 saw the official deployment of TCP/IP as the new standard host protocol for ARPAnet (replacing the NCP protocol). The transition [RFC 801] from NCP to TCP/IP was a flag day event—all hosts were required to transfer over to TCP/IP as of that day. In the late 1980s, important extensions were made to TCP to implement host-based congestion control [Jacobson 1988]. The DNS, used to map between a human-readable Internet name (for example,</span><a href="http://gaia.cs.umass.edu"><span class="font53"> gaia.cs.umass.edu</span></a><span class="font53">) and its 32-bit IP address, was also developed [RFC 1034].</span></p>
<p><span class="font53">Paralleling this development of the ARPAnet (which was for the most part a US effort), in the early 1980s the French launched the Minitel project, an ambitious plan to bring data networking into everyone’s home. Sponsored by the French government, the Minitel system consisted of a public packet-switched network (based on the X.25 protocol suite), Minitel servers, and inexpensive terminals with built-in low-speed modems. The Minitel became a huge success in 1984 when the French government gave away a free Minitel terminal to each French household that wanted one. Minitel sites included free sites—such as a telephone directory site—as well as private sites, which collected a usage-based fee from each user. At its peak in the mid 1990s, it offered more than 20,000 services, ranging from home banking to specialized research databases. The Minitel was in a large proportion of French homes 10 years before most Americans had ever heard of the Internet.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">1.7.4 </span><span class="font23" style="font-weight:bold;">The Internet Explosion: The 1990s</span></p></li></ul>
<p><span class="font53">The 1990s were ushered in with a number of events that symbolized the continued evolution and the soon-to-arrive commercialization of the Internet. ARPAnet, the progenitor of the Internet, ceased to exist. In 1991, NSFNET lifted its restrictions on the use of NSFNET for commercial purposes. NSFNET itself would be decommissioned in 1995, with Internet backbone traffic being carried by commercial Internet Service Providers.</span></p>
<p><span class="font53">The main event of the 1990s was to be the emergence of the World Wide Web application, which brought the Internet into the homes and businesses of millions of people worldwide. The Web served as a platform for enabling and deploying hundreds of new applications that we take for granted today, including search (e.g., Google and Bing) Internet commerce (e.g., Amazon and eBay) and social networks (e.g., Facebook).</span></p>
<p><a name="bookmark282"></a><span class="font53">The Web was invented at CERN by Tim Berners-Lee between 1989 and 1991 [Berners-Lee 1989], based on ideas originating in earlier work on hypertext from the 1940s by Vannevar Bush [Bush 1945] and since the 1960s by Ted Nelson [Xanadu 2012]. Berners-Lee and his associates developed initial versions of HTML, HTTP, a Web server, and a browser—the four key components of the Web. Around the end of 1993 there were about two hundred Web servers in operation, this collection of servers being just a harbinger of what was about to come. At about this time several researchers were developing Web browsers with GUI interfaces, including Marc Andreessen, who along with Jim Clark, formed Mosaic Communications, which later became Netscape Communications Corporation [Cusumano 1998; Quittner 1998]. By 1995, university students were using Netscape browsers to surf the Web on a daily basis. At about this time companies—big and small—began to operate Web servers and transact commerce over the Web. In 1996, Microsoft started to make browsers, which started the browser war between Netscape and Microsoft, which Microsoft won a few years later [Cusumano 1998].</span></p>
<p><span class="font53">The second half of the 1990s was a period of tremendous growth and innovation for the Internet, with major corporations and thousands of startups creating Internet products and services. By the end of the millennium the Internet was supporting hundreds of popular applications, including four killer applications:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;E-mail, including attachments and Web-accessible e-mail</span></p></li>
<li>
<p><span class="font53">• &nbsp;The Web, including Web browsing and Internet commerce</span></p></li>
<li>
<p><span class="font53">• &nbsp;Instant messaging, with contact lists</span></p></li>
<li>
<p><span class="font53">• &nbsp;Peer-to-peer file sharing of MP3s, pioneered by Napster</span></p></li></ul>
<p><span class="font53">Interestingly, the first two killer applications came from the research community, whereas the last two were created by a few young entrepreneurs.</span></p>
<p><span class="font53">The period from 1995 to 2001 was a roller-coaster ride for the Internet in the financial markets. Before they were even profitable, hundreds of Internet startups made initial public offerings and started to be traded in a stock market. Many companies were valued in the billions of dollars without having any significant revenue streams. The Internet stocks collapsed in 2000-2001, and many startups shut down. Nevertheless, a number of companies emerged as big winners in the Internet space, including Microsoft, Cisco, Yahoo, eBay, Google, and Amazon.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">1.7.5 </span><span class="font23" style="font-weight:bold;">The New Millennium</span></p></li></ul>
<p><span class="font53">In the first two decades of the 21st century, perhaps no other technology has transformed society more than the Internet along with Internet-connected smartphones. And innovation in computer networking continues at a rapid pace. Advances are being made on all fronts, including deployments of faster routers and higher transmission speeds in both access networks and in network backbones. But the following developments merit special attention:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;Since the beginning of the millennium, we have been seeing aggressive deployment of broadband Internet access to homes—not only cable modems and DSL but also fiber to the home, and now 5G fixed wireless as discussed in Section 1.2. This high-speed Internet access has set the stage for a wealth of video applications, including the distribution of user-generated video (for example, YouTube), on-demand streaming of movies and television shows (e.g., Netflix), and multiperson video conference (e.g., Skype, Facetime, and Google Hangouts).</span></p></li>
<li>
<p><a name="bookmark283"></a><span class="font53">• &nbsp;The increasing ubiquity of high-speed wireless Internet access is not only making it possible to remain constantly connected while on the move, but also enabling new location-specific applications such as Yelp, Tinder, and Waz. The number of wireless devices connecting to the Internet surpassed the number of wired devices in 2011. This high-speed wireless access has set the stage for the rapid emergence of hand-held computers (iPhones, Androids, iPads, and so on), which enjoy constant and untethered access to the Internet.</span></p></li>
<li>
<p><span class="font53">• &nbsp;Online social networks—such as Facebook, Instagram, Twitter, and WeChat (hugely popular in China)—have created massive people networks on top of the Internet. Many of these social networks are extensively used for messaging as well as photo sharing. Many Internet users today “live” primarily within one or more social networks. Through their APIs, the online social networks create platforms for new networked applications, including mobile payments and distributed games.</span></p></li>
<li>
<p><span class="font53">• &nbsp;As discussed in Section 1.3.3, online service providers, such as Google and Microsoft, have deployed their own extensive private networks, which not only connect together their globally distributed data centers, but are used to bypass the Internet as much as possible by peering directly with lower-tier ISPs. As a result, Google provides search results and e-mail access almost instantaneously, as if their data centers were running within one’s own computer.</span></p></li>
<li>
<p><span class="font53">• &nbsp;Many Internet commerce companies are now running their applications in the “cloud”—such as in Amazon’s EC2, in Microsoft’s Azure, or in the Alibaba Cloud. Many companies and universities have also migrated their Internet applications (e.g., e-mail and Web hosting) to the cloud. Cloud companies not only provide applications scalable computing and storage environments, but also provide the applications implicit access to their high-performance private networks.</span></p></li></ul>
<p><span class="font59" style="font-weight:bold;">1.8 </span><span class="font24" style="font-weight:bold;">Summary</span></p>
<p><a name="bookmark284"></a><span class="font53">In this chapter, we’ve covered a tremendous amount of material! We’ve looked at the various pieces of hardware and software that make up the Internet in particular and computer networks in general. We started at the edge of the network, looking at end systems and applications, and at the transport service provided to the applications running on the end systems. We also looked at the link-layer technologies and physical media typically found in the access network. We then dove deeper inside the network, into the network core, identifying packet switching and circuit switching as the two basic approaches for transporting data through a telecommunication network, and we examined the strengths and weaknesses of each approach. We also examined the structure of the global Internet, learning that the Internet is a network of networks. We saw that the Internet’s hierarchical structure, consisting of higher- and lower-tier ISPs, has allowed it to scale to include thousands of networks.</span></p>
<p><span class="font53">In the second part of this introductory chapter, we examined several topics central to the field of computer networking. We first examined the causes of delay, throughput and packet loss in a packet-switched network. We developed simple quantitative models for transmission, propagation, and queuing delays as well as for throughput; we’ll make extensive use of these delay models in the homework problems throughout this book. Next we examined protocol layering and service models, key architectural principles in networking that we will also refer back to throughout this book. We also surveyed some of the more prevalent security attacks in the Internet day. We finished our introduction to networking with a brief history of computer networking. The first chapter in itself constitutes a mini-course in computer networking.</span></p>
<p><span class="font53">So, we have indeed covered a tremendous amount of ground in this first chapter! If you’re a bit overwhelmed, don’t worry. In the following chapters, we’ll revisit all of these ideas, covering them in much more detail (that’s a promise, not a threat!). At this point, we hope you leave this chapter with a still-developing intuition for the pieces that make up a network, a still-developing command of the vocabulary of networking (don’t be shy about referring back to this chapter), and an ever-growing desire to learn more about networking. That’s the task ahead of us for the rest of this book.</span></p>
<p><span class="font56" style="font-weight:bold;">Road-Mapping This Book</span></p>
<p><span class="font53">Before starting any trip, you should always glance at a road map in order to become familiar with the major roads and junctures that lie ahead. For the trip we are about to embark on, the ultimate destination is a deep understanding of the how, what, and why of computer networks. Our road map is the sequence of chapters of this book:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">1. Computer Networks and the Internet</span></p></li>
<li>
<p><span class="font53">2. Application Layer</span></p></li>
<li>
<p><span class="font53">3. Transport Layer</span></p></li>
<li>
<p><span class="font53">4. Network Layer: Data Plane</span></p></li>
<li>
<p><span class="font53">5. Network Layer: Control Plane</span></p></li>
<li>
<p><span class="font53">6. The Link Layer and LANs</span></p></li>
<li>
<p><span class="font53">7. Wireless and Mobile Networks</span></p></li>
<li>
<p><span class="font53">8. Security in Computer Networks</span></p></li></ul>
<p><span class="font53">Chapters 2 through 6 are the five core chapters of this book. You should notice that these chapters are organized around the top four layers of the five-layer Internet protocol. Further note that our journey will begin at the top of the Internet protocol stack, namely, the application layer, and will work its way downward. The rationale behind this top-down journey is that once we understand the applications, we can understand the network services needed to support these applications. We can then, in turn, examine the various ways in which such services might be implemented by a network architecture. Covering applications early thus provides motivation for the remainder of the text.</span></p>
<p><span class="font53">The second half of the book—Chapters 7 and 8—zooms in on two enormously important (and somewhat independent) topics in modern computer networking. In Chapter 7, we examine wireless and mobile networks, including wireless LANs (including WiFi and Bluetooth), Cellular networks (including 4G and 5G), and mobility. Chapter 8, which addresses security in computer networks, first looks at the underpinnings of encryption and network security, and then we examine how the basic theory is being applied in a broad range of Internet contexts.</span></p>
<p><span class="font24" style="font-weight:bold;">Homework Problems and Questions</span></p>
<p><span class="font23" style="font-weight:bold;">Chapter 1 Review Questions</span></p>
<p><span class="font43" style="font-weight:bold;">SECTION 1.1</span></p>
<p><span class="font53">R1. What is the difference between a host and an end system? List several different types of end systems. Is a Web server an end system?</span></p>
<p><span class="font53">R2. Describe the protocol that might be used by two people having a telephonic conversation to initiate and end the conversation, i.e., the way that they talk.</span></p>
<p><span class="font53">R3. Why are standards important for protocols?</span></p>
<p><span class="font43" style="font-weight:bold;">SECTION 1.2</span></p>
<p><span class="font53">R4. List four access technologies. Classify each one as home access, enterprise access, or wide-area wireless access.</span></p>
<p><span class="font53">R5. Is HFC transmission rate dedicated or shared among users? Are collisions possible in a downstream HFC channel? Why or why not?</span></p>
<p><span class="font53">R6. What access network technologies would be most suitable for providing internet access in rural areas?</span></p>
<p><span class="font53">R7. Dial-up modems and DSL both use the telephone line (a twisted-pair copper cable) as their transmission medium. Why then is DSL much faster than dialup access?</span></p>
<p><span class="font53">R8. What are some of the physical media that Ethernet can run over?</span></p>
<p><span class="font53">R9. HFC, DSL, and FTTH are all used for residential access. For each of these access technologies, provide a range of transmission rates and comment on whether the transmission rate is shared or dedicated.</span></p>
<p><a name="bookmark285"></a><span class="font53">R10. Describe the different wireless technologies you use during the day and their characteristics. If you have a choice between multiple technologies, why do you prefer one over another?</span></p>
<p><span class="font43" style="font-weight:bold;">SECTION 1.3</span></p>
<p><span class="font53">R11. Suppose there is exactly one packet switch between a sending host and a receiving host. The transmission rates between the sending host and the switch and between the switch and the receiving host are </span><span class="font53" style="font-style:italic;">R<sub>1</sub></span><span class="font53"> and </span><span class="font53" style="font-style:italic;">R</span><span class="font49" style="font-style:italic;">2</span><span class="font53" style="font-style:italic;">,</span><span class="font53"> respectively. Assuming that the switch uses store-and-forward packet switching, what is the total end-to-end delay to send a packet of length </span><span class="font53" style="font-style:italic;">L?</span><span class="font53"> (Ignore queuing, propagation delay, and processing delay.)</span></p>
<p><span class="font53">R12. What advantage does a circuit-switched network have over a packet-switched network? What advantages does TDM have over FDM in a circuit-switched network?</span></p>
<p><span class="font53">R13. Suppose users share a 2 Mbps link. Also suppose each user transmits continuously at 1 Mbps when transmitting, but each user transmits only 20 percent of the time. (See the discussion of statistical multiplexing in Section 1.3.)</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. When circuit switching is used, how many users can be supported?</span></p></li>
<li>
<p><span class="font53">b. For the remainder of this problem, suppose packet switching is used. Why will there be essentially no queuing delay before the link if two or fewer users transmit at the same time? Why will there be a queuing delay if three users transmit at the same time?</span></p></li>
<li>
<p><span class="font53">c. Find the probability that a given user is transmitting.</span></p></li>
<li>
<p><span class="font53">d. Suppose now there are three users. Find the probability that at any given time, all three users are transmitting simultaneously. Find the fraction of time during which the queue grows.</span></p></li></ul>
<p><span class="font53">R14. Why will two ISPs at the same level of the hierarchy often peer with each other? How does an IXP earn money?</span></p>
<p><span class="font53">R15. Why is a content provider considered a different Internet entity today? How does a content provider connect to other ISPs? Why?</span></p>
<p><span class="font43" style="font-weight:bold;">SECTION 1.4</span></p>
<p><span class="font53">R16. Consider sending a packet from a source host to a destination host over a fixed route. List the delay components in the end-to-end delay. Which of these delays are constant and which are variable?</span></p>
<p><span class="font53">R17. Visit the Transmission Versus Propagation Delay interactive animation at the Companion Website. Among the rates, propagation delay, and packet sizes available, find a combination for which the sender finishes transmitting before the first bit of the packet reaches the receiver. Find another combination for which the first bit of the packet reaches the receiver before the sender finishes transmitting.</span></p>
<p><span class="font53">R18. A user can directly connect to a server through either long-range wireless or a twisted-pair cable for transmitting a 1500-bytes file. The transmission rates of the wireless and wired media are 2 and 100 Mbps, respectively. Assume that the propagation speed in air is 3 </span><span class="font55">X </span><span class="font53">10<sup>8</sup> m/s, while the speed in the twisted pair is 2 </span><span class="font55">X </span><span class="font53">10<sup>8</sup> m/s. If the user is located 1 km away from the server, what is the nodal delay when using each of the two technologies?</span></p>
<p><span class="font53">R19. Suppose Host A wants to send a large file to Host B. The path from Host A to Host B has three links, of rates </span><span class="font53" style="font-style:italic;">R<sub>1</sub> =</span><span class="font53"> 500 kbps, </span><span class="font53" style="font-style:italic;">R</span><span class="font49" style="font-style:italic;">2 </span><span class="font53" style="font-style:italic;">=</span><span class="font53"> 2 Mbps, and </span><span class="font53" style="font-style:italic;">R</span><span class="font49" style="font-style:italic;">3 </span><span class="font53" style="font-style:italic;">=</span><span class="font53"> 1 Mbps.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Assuming no other traffic in the network, what is the throughput for the file transfer?</span></p></li>
<li>
<p><span class="font53">b. Suppose the file is 4 million bytes. Dividing the file size by the throughput, roughly how long will it take to transfer the file to Host B?</span></p></li>
<li>
<p><span class="font53">c. Repeat (a) and (b), but now with </span><span class="font53" style="font-style:italic;">R</span><span class="font53"><sub>2</sub> reduced to 100 kbps.</span></p></li></ul>
<p><span class="font53">R20. Suppose end system A wants to send a large file to end system B. At a very high level, describe how end system A creates packets from the file. When one of these packets arrives to a router, what information in the packet does the router use to determine the link onto which the packet is forwarded? Why is packet switching in the Internet analogous to driving from one city to another and asking directions along the way?</span></p>
<p><span class="font53">R21. Visit the Queuing and Loss interactive animation at the Companion Website. What is the maximum emission rate and the minimum transmission rate? With those rates, what is the traffic intensity? Run the interactive animation with these rates and determine how long it takes for packet loss to occur. Then repeat the experiment a second time and determine again how long it takes for packet loss to occur. Are the values different? Why or why not?</span></p>
<p><span class="font43" style="font-weight:bold;">SECTION 1.5</span></p>
<p><span class="font53">R22. If two end-systems are connected through multiple routers and the data-link level between them ensures reliable data delivery, is a transport protocol offering reliable data delivery between these two end-systems necessary? Why?</span></p>
<p><span class="font53">R23. What are the five layers in the Internet protocol stack? What are the principal responsibilities of each of these layers?</span></p>
<p><span class="font53">R24. What do encapsulation and de-encapsulation mean? Why are they needed in a layered protocol stack?</span></p>
<p><span class="font53">R25. Which layers in the Internet protocol stack does a router process? Which layers does a link-layer switch process? Which layers does a host process?</span></p>
<p><span class="font43" style="font-weight:bold;">SECTION 1.6</span></p>
<p><span class="font53">R26. What is self-replicating malware?</span></p>
<p><span class="font53">R27. Describe how a botnet can be created and how it can be used for a DDoS attack.</span></p>
<p><span class="font53">R28. Suppose Alice and Bob are sending packets to each other over a computer network. Suppose Trudy positions herself in the network so that she can capture all the packets sent by Alice and send whatever she wants to Bob; she can also capture all the packets sent by Bob and send whatever she wants to Alice. List some of the malicious things Trudy can do from this position.</span></p>
<p><span class="font24" style="font-weight:bold;">Problems</span></p>
<p><span class="font53">P1. Design and describe an application-level protocol to be used between an automatic teller machine and a bank’s centralized computer. Your protocol should allow a user’s card and password to be verified, the account balance (which is maintained at the centralized computer) to be queried, and an account withdrawal to be made (that is, money disbursed to the user). Your protocol entities should be able to handle the all-too-common case in which there is not enough money in the account to cover the withdrawal. Specify your protocol by listing the messages exchanged and the action taken by the automatic teller machine or the bank’s centralized computer on transmission and receipt of messages. Sketch the operation of your protocol for the case of a simple withdrawal with no errors, using a diagram similar to that in Figure 1.2. Explicitly state the assumptions made by your protocol about the underlying end-to-end transport service.</span></p>
<p><span class="font53">P2. Equation 1.1 gives a formula for the end-to-end delay of sending one packet of length </span><span class="font53" style="font-style:italic;">L</span><span class="font53"> over </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> links of transmission rate </span><span class="font53" style="font-style:italic;">R.</span><span class="font53"> Generalize this formula for sending </span><span class="font53" style="font-style:italic;">P</span><span class="font53"> such packets back-to-back over the </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> links.</span></p>
<p><span class="font53">P3. Consider an application that transmits data at a steady rate (for example, the sender generates an </span><span class="font53" style="font-style:italic;">N</span><span class="font53">-bit unit of data every </span><span class="font53" style="font-style:italic;">k</span><span class="font53"> time units, where </span><span class="font53" style="font-style:italic;">k</span><span class="font53"> is small and fixed). Also, when such an application starts, it will continue running for a relatively long period of time. Answer the following questions, briefly justifying your answer:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Would a packet-switched network or a circuit-switched network be more appropriate for this application? Why?</span></p></li>
<li>
<p><span class="font53">b. Suppose that a packet-switched network is used and the only traffic in this network comes from such applications as described above. Furthermore, assume that the sum of the application data rates is less than the capacities of each and every link. Is some form of congestion control needed? Why?</span></p></li></ul>
<p><span class="font53">P4. Consider the circuit-switched network in Figure 1.13. Recall that there are four circuits on each link. Label the four switches A, B, C, and D, going in the clockwise direction.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. What is the maximum number of simultaneous connections that can be in progress at any one time in this network?</span></p></li>
<li>
<p><span class="font53">b. Suppose that all connections are between switches A and C. What is the maximum number of simultaneous connections that can be in progress?</span></p></li>
<li>
<p><span class="font53">c. Suppose we want to make four connections between switches A and C, and another four connections between switches B and D. Can we route these calls through the four links to accommodate all eight connections?</span></p></li></ul>
<p><span class="font53">P5. Review the car-caravan analogy in Section 1.4. Assume a propagation speed of 100 km/hour.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Suppose the caravan travels 175 km, beginning in front of one tollbooth, passing through a second tollbooth, and finishing just after a third tollbooth. What is the end-to-end delay?</span></p></li>
<li>
<p><span class="font53">b. Repeat (a), now assuming that there are eight cars in the caravan instead of ten.</span></p>
<div>
<p><span class="font16" style="font-weight:bold;">o</span></p>
<p><span class="font2" style="font-weight:bold;">VideoNote</span></p>
<p><span class="font1" style="font-weight:bold;">Exploring propagation delay and transmission delay</span></p>
</div><br clear="all"></li></ul>
<p><span class="font53">P6. This elementary problem begins to explore propagation delay and transmission delay, two central concepts in data networking. Consider two hosts, A and B, connected by a single link of rate </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> bps. Suppose that the two hosts are separated by </span><span class="font53" style="font-style:italic;">m</span><span class="font53"> meters, and suppose the propagation speed along the link is </span><span class="font53" style="font-style:italic;">s</span><span class="font53"> meters/sec. Host A is to send a packet of size </span><span class="font53" style="font-style:italic;">L</span><span class="font53"> bits to Host B.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Express the propagation delay, </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>prop</sub>, in terms of </span><span class="font53" style="font-style:italic;">m</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">s.</span></p></li>
<li>
<p><span class="font53">b. Determine the transmission time of the packet, </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>trans</sub>, in terms of </span><span class="font53" style="font-style:italic;">L</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">R</span><span class="font53">.</span></p></li>
<li>
<p><span class="font53">c. Ignoring processing and queuing delays, obtain an expression for the end-to-end delay.</span></p></li>
<li>
<p><span class="font53">d. Suppose Host A begins to transmit the packet at time </span><span class="font53" style="font-style:italic;">t =</span><span class="font53"> 0. At time </span><span class="font53" style="font-style:italic;">t = d</span><span class="font53"><sub>trans</sub>, where is the last bit of the packet?</span></p></li>
<li>
<p><span class="font53">e. Suppose </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>prop</sub> is greater than </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>trans</sub>. At time </span><span class="font53" style="font-style:italic;">t = d</span><span class="font53"><sub>trans</sub>, where is the first bit of the packet?</span></p></li>
<li>
<p><span class="font53">f. &nbsp;Suppose </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>prop</sub> is less than </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>trans</sub>. At time </span><span class="font53" style="font-style:italic;">t = d</span><span class="font53"><sub>trans</sub>, where is the first bit of the packet?</span></p></li>
<li>
<p><span class="font53">g. Suppose </span><span class="font53" style="font-style:italic;">s</span><span class="font54"> = </span><span class="font53">2.5 </span><span class="font60">• </span><span class="font53">10</span><span class="font50">8</span><span class="font53">, </span><span class="font53" style="font-style:italic;">L =</span><span class="font53"> 1500 bytes, and </span><span class="font53" style="font-style:italic;">R =</span><span class="font53"> 10 Mbps. Find the distance </span><span class="font53" style="font-style:italic;">m</span><span class="font53"> so that </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>prop</sub> equals </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>trans</sub>.</span></p></li></ul>
<p><span class="font53">P7. In this problem, we consider sending real-time voice from Host A to Host B over a packet-switched network (VoIP). Host A converts analog voice to a digital 64 kbps bit stream on the fly. Host A then groups the bits into 56-byte packets. There is one link between Hosts A and B; its transmission rate is 10 Mbps and its propagation delay is 10 msec. As soon as Host A gathers a packet, it sends it to Host B. As soon as Host B receives an entire packet, it converts the packet’s bits to an analog signal. How much time elapses from the time a bit is created (from the original analog signal at Host A) until the bit is decoded (as part of the analog signal at Host B)?</span></p>
<p><span class="font53">P8. Suppose users share a 10 Mbps link. Also suppose each user requires 200 kbps when transmitting, but each user transmits only 10 percent of the time. (See the discussion of packet switching versus circuit switching in Section 1.3.)</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. When circuit switching is used, how many users can be supported?</span></p></li>
<li>
<p><span class="font53">b. For the remainder of this problem, suppose packet switching is used. Find the probability that a given user is transmitting.</span></p></li>
<li>
<p><span class="font53">c. Suppose there are 120 users. Find the probability that at any given time, exactly </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> users are transmitting simultaneously. </span><span class="font53" style="font-style:italic;">(Hint:</span><span class="font53"> Use the binomial distribution.)</span></p></li>
<li>
<p><span class="font53">d. Find the probability that there are 51 or more users transmitting simultaneously.</span></p></li></ul>
<p><span class="font53">P9. Consider the discussion in Section 1.3 of packet switching versus circuit switching in which an example is provided with a 1 Mbps link. Users are generating data at a rate of 100 kbps when busy, but are busy generating data only with probability </span><span class="font53" style="font-style:italic;">p =</span><span class="font53"> 0.1. Suppose that the 1 Mbps link is replaced by a 1 Gbps link.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. What is </span><span class="font53" style="font-style:italic;">N,</span><span class="font53"> the maximum number of users that can be supported simultaneously under circuit switching?</span></p></li>
<li>
<p><span class="font53">b. Now consider packet switching and a user population of </span><span class="font53" style="font-style:italic;">M</span><span class="font53"> users. Give a formula (in terms of </span><span class="font53" style="font-style:italic;">p</span><span class="font53">, </span><span class="font53" style="font-style:italic;">M</span><span class="font53">, </span><span class="font53" style="font-style:italic;">N)</span><span class="font53"> for the probability that more than </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> users are sending data.</span></p></li></ul>
<p><span class="font53">P10. Consider the network illustrated in Figure 1.16. Assume the two hosts on the left of the figure start transmitting packets of 1500 bytes at the same time towards Router B. Suppose the link rates between the hosts and Router A is 4-Mbps. One link has a 6-ms propagation delay and the other has a 2-ms propagation delay. Will queuing delay occur at Router A?</span></p>
<p><span class="font53">P11. Consider the scenario in Problem P10 again, but now assume the links between the hosts and Router A have different rates </span><span class="font53" style="font-style:italic;">R<sub>1</sub></span><span class="font53"> and </span><span class="font53" style="font-style:italic;">R<sub>2</sub></span><span class="font53"> byte/s in addition to different propagation delays </span><span class="font53" style="font-style:italic;">d<sub>1</sub></span><span class="font53"> and </span><span class="font53" style="font-style:italic;">d<sub>2</sub>.</span><span class="font53"> Assume the packet lengths for the two hosts are of L bytes. For what values of the propagation delay will no queuing delay occur at Router A?</span></p>
<p><span class="font53">P12. Consider a client and a server connected through one router. Assume the router can start transmitting an incoming packet after receiving its first </span><span class="font53" style="font-style:italic;">h</span><span class="font53"> bytes instead of the whole packet. Suppose that the link rates are </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> byte/s and that the client transmits one packet with a size of </span><span class="font53" style="font-style:italic;">L</span><span class="font53"> bytes to the server. What is the end-to-end delay? Assume the propagation, processing, and queuing delays are negligible. Generalize the previous result to a scenario where the client and the server are interconnected by </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> routers.</span></p>
<p><span class="font53">P13. (a) Suppose </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> packets arrive simultaneously to a link at which no packets are currently being transmitted or queued. Each packet is of length </span><span class="font53" style="font-style:italic;">L</span><span class="font53"> and the link has transmission rate </span><span class="font53" style="font-style:italic;">R</span><span class="font53">. What is the average queuing delay for the </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> packets?</span></p>
<p><span class="font53">(b) Now suppose that </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> such packets arrive to the link every </span><span class="font53" style="font-style:italic;">LN/R</span><span class="font53"> seconds. What is the average queuing delay of a packet?</span></p>
<p><span class="font53">P14. Consider the queuing delay in a router buffer. Let </span><span class="font53" style="font-style:italic;">I</span><span class="font53"> denote traffic intensity; that is, </span><span class="font53" style="font-style:italic;">I = La/R.</span><span class="font53"> Suppose that the queuing delay takes the form </span><span class="font53" style="font-style:italic;">IL/R</span><span class="font53"> (1 </span><span class="font55">— </span><span class="font53" style="font-style:italic;">I) </span><span class="font53">for </span><span class="font53" style="font-style:italic;">I 6</span><span class="font53"> 1.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Provide a formula for the total delay, that is, the queuing delay plus the transmission delay.</span></p></li>
<li>
<p><span class="font53">b. Plot the total delay as a function of </span><span class="font53" style="font-style:italic;">L/R.</span></p></li></ul>
<p><span class="font53">P15. Let </span><span class="font53" style="font-style:italic;">a</span><span class="font53"> denote the rate of packets arriving at a link in packets/sec, and let </span><span class="font53" style="font-style:italic;">p </span><span class="font53">denote the link’s transmission rate in packets/sec. Based on the formula for the total delay (i.e., the queuing delay plus the transmission delay) derived in the previous problem, derive a formula for the total delay in terms of </span><span class="font53" style="font-style:italic;">a </span><span class="font53">and </span><span class="font53" style="font-style:italic;">p</span><span class="font53">.</span></p>
<p><span class="font53">P16. Consider a router buffer preceding an outbound link. In this problem, you will use Little’s formula, a famous formula from queuing theory. Let </span><span class="font53" style="font-style:italic;">N </span><span class="font53">denote the average number of packets in the buffer plus the packet being transmitted. Let </span><span class="font53" style="font-style:italic;">a</span><span class="font53"> denote the rate of packets arriving at the link. Let </span><span class="font53" style="font-style:italic;">d</span><span class="font53"> denote the average total delay (i.e., the queuing delay plus the transmission delay) experienced by a packet. Little’s formula is </span><span class="font53" style="font-style:italic;">N = a </span><span class="font60" style="font-style:italic;">• </span><span class="font53" style="font-style:italic;">d.</span><span class="font53"> Suppose that on average, the buffer contains 100 packets, and the average packet queuing delay is 20 msec. The link’s transmission rate is 100 packets/sec. Using Little’s formula, what is the average packet arrival rate, assuming there is no packet loss?</span></p>
<p><span class="font53">P17. Consider the network illustrated in Figure 1.12. Would Equation 1.2 hold in such a scenario? If so, under which conditions? If not, why? (Assume </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> is the number of links between a source and a destination in the figure.)</span></p>
<div><img src="networking_files/networking-57.jpg" alt="" style="width:19pt;height:19pt;">
</div><br clear="all">
<div>
<p><span class="font2" style="font-weight:bold;">VideoNote</span></p>
<p><span class="font1" style="font-weight:bold;">Using Traceroute to discover network paths and measure network delay</span></p>
</div><br clear="all">
<p><span class="font53">P18. Perform a Traceroute between source and destination on the same continent at three different hours of the day.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Find the average and standard deviation of the round-trip delays at each of the three hours.</span></p></li>
<li>
<p><span class="font53">b. Find the number of routers in the path at each of the three hours. Did the paths change during any of the hours?</span></p></li>
<li>
<p><span class="font53">c. Try to identify the number of ISP networks that the Traceroute packets pass through from source to destination. Routers with similar names and/ or similar IP addresses should be considered as part of the same ISP. In your experiments, do the largest delays occur at the peering interfaces between adjacent ISPs?</span></p></li>
<li>
<p><span class="font53">d. Repeat the above for a source and destination on different continents. Compare the intra-continent and inter-continent results.</span></p></li></ul>
<p><span class="font53">P19. Metcalfe’s law states the value of a computer network is proportional to the square of the number of connected users of the system. Let n denote the number of users in a computer network. Assuming each user sends one message to each of the other users, how many messages will be sent? Does your answer support Metcalfe’s law?</span></p>
<p><span class="font53">P20. Consider the throughput example corresponding to Figure 1.20(b). Now suppose that there are </span><span class="font53" style="font-style:italic;">M</span><span class="font53"> client-server pairs rather than 10. Denote </span><span class="font53" style="font-style:italic;">R<sub>s</sub>, R<sub>c</sub>, </span><span class="font53">and </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> for the rates of the server links, client links, and network link. Assume all other links have abundant capacity and that there is no other traffic in the network besides the traffic generated by the </span><span class="font53" style="font-style:italic;">M</span><span class="font53"> client-server pairs. Derive a general expression for throughput in terms of </span><span class="font53" style="font-style:italic;">R<sub>s</sub>, R<sub>c</sub>, R,</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">M</span><span class="font53">.</span></p>
<p><span class="font53">P21. Assume a client and a server can connect through either network (a) or (b) in Figure 1.19. Assume that </span><span class="font53" style="font-style:italic;">R</span><span class="font50" style="font-style:italic;">, </span><span class="font53" style="font-style:italic;">= (R<sub>c</sub></span><span class="font55"> + </span><span class="font53" style="font-style:italic;">R<sub>s</sub>)</span><span class="font53"> / </span><span class="font53" style="font-style:italic;">i,</span><span class="font53"> for </span><span class="font53" style="font-style:italic;">i =</span><span class="font53"> 1, 2, ..., </span><span class="font53" style="font-style:italic;">N</span><span class="font53">. In what case will network (a) have a higher throughput than network (b)?</span></p>
<p><span class="font53">P22. Consider Figure 1.19(b). Suppose that each link between the server and the client has a packet loss probability </span><span class="font53" style="font-style:italic;">p,</span><span class="font53"> and the packet loss probabilities for these links are independent. What is the probability that a packet (sent by the server) is successfully received by the receiver? If a packet is lost in the path from the server to the client, then the server will re-transmit the packet. On average, how many times will the server re-transmit the packet in order for the client to successfully receive the packet?</span></p>
<p><span class="font53">P23. Consider Figure 1.19(a). Assume that we know the bottleneck link along the path from the server to the client is the first link with rate </span><span class="font53" style="font-style:italic;">R<sub>s</sub></span><span class="font53"> bits/sec. Suppose we send a pair of packets back to back from the server to the client, and there is no other traffic on this path. Assume each packet of size </span><span class="font53" style="font-style:italic;">L</span><span class="font53"> bits, and both links have the same propagation delay </span><span class="font53" style="font-style:italic;">d<sub>prop</sub>.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. What is the packet inter-arrival time at the destination? That is, how much time elapses from when the last bit of the first packet arrives until the last bit of the second packet arrives?</span></p></li>
<li>
<p><span class="font53">b. Now assume that the second link is the bottleneck link (i.e., </span><span class="font53" style="font-style:italic;">R<sub>c</sub></span><span class="font55"> &lt;&nbsp;</span><span class="font53" style="font-style:italic;">R<sub>s</sub></span><span class="font53">). Is it possible that the second packet queues at the input queue of the second link? Explain. Now suppose that the server sends the second packet </span><span class="font53" style="font-style:italic;">T </span><span class="font53">seconds after sending the first packet. How large must </span><span class="font53" style="font-style:italic;">T</span><span class="font53"> be to ensure no queuing before the second link? Explain.</span></p></li></ul>
<p><span class="font53">P24. Consider a user who needs to transmit 1.5 gigabytes of data to a server. The user lives in a village where only dial-up access is available. As an alternative, a bus collects data from users in rural areas and transfer them to the Internet through a 1 Gbps link once it gets back to the city. The bus visits the village once a day and stops in front of the user’s house just long enough to receive the data. The bus has a 100 Mbps WiFi connection. Suppose the average speed of the bus is 60 km/h and that the distance between the village and the city is 150 km. What is the fastest way the user can transfer the data to the server?</span></p>
<p><span class="font53">P25. Suppose two hosts, A and B, are separated by 20,000 kilometers and are connected by a direct link of </span><span class="font53" style="font-style:italic;">R =</span><span class="font53"> 5 Mbps. Suppose the propagation speed over the link is 2.5 </span><span class="font60">• </span><span class="font53">10<sup>8</sup> meters/sec.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Calculate the bandwidth-delay product, </span><span class="font53" style="font-style:italic;">R </span><span class="font60" style="font-style:italic;">• </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>prop</sub>.</span></p></li>
<li>
<p><span class="font53">b. Consider sending a file of 800,000 bits from Host A to Host B. Suppose the file is sent continuously as one large message. What is the maximum number of bits that will be in the link at any given time?</span></p></li>
<li>
<p><span class="font53">c. Provide an interpretation of the bandwidth-delay product.</span></p></li>
<li>
<p><span class="font53">d. What is the width (in meters) of a bit in the link? Is it longer than a football field?</span></p></li>
<li>
<p><span class="font53">e. Derive a general expression for the width of a bit in terms of the propagation speed </span><span class="font53" style="font-style:italic;">s,</span><span class="font53"> the transmission rate </span><span class="font53" style="font-style:italic;">R,</span><span class="font53"> and the length of the link </span><span class="font53" style="font-style:italic;">m.</span></p></li></ul>
<p><span class="font53">P26. Consider problem P25 but now with a link of </span><span class="font53" style="font-style:italic;">R =</span><span class="font53"> 1 Gbps.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Calculate the bandwidth-delay product, </span><span class="font53" style="font-style:italic;">R </span><span class="font60" style="font-style:italic;">• </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>prop</sub>.</span></p></li>
<li>
<p><span class="font53">b. Consider sending a file of 800,000 bits from Host A to Host B. Suppose the file is sent continuously as one big message. What is the maximum number of bits that will be in the link at any given time?</span></p></li>
<li>
<p><span class="font53">c. What is the width (in meters) of a bit in the link?</span></p></li></ul>
<p><span class="font53">P27. Consider the scenario illustrated in Figure 1.19(a). Assume </span><span class="font53" style="font-style:italic;">R<sub>s</sub></span><span class="font53"> is 20 Mbps, </span><span class="font53" style="font-style:italic;">R<sub>c</sub></span><span class="font53"> is 10 Mbps, and the server is continuously sending traffic to the client. Also assume the router between the server and the client can buffer at most four messages. After how many messages sent by the server will packet loss starts occurring at the router?</span></p>
<p><span class="font53">P28. Generalize the result obtained in Problem P27 for the case where the router can buffer </span><span class="font53" style="font-style:italic;">m</span><span class="font53"> messages.</span></p>
<p><span class="font53">P29. Suppose there is a 10 Mbps microwave link between a geostationary satellite and its base station on Earth. Every minute the satellite takes a digital photo and sends it to the base station. Assume a propagation speed of 2.4 </span><span class="font60">• </span><span class="font53">10<sup>8</sup> meters/sec.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. What is the propagation delay of the link?</span></p></li>
<li>
<p><span class="font53">b. What is the bandwidth-delay product, </span><span class="font53" style="font-style:italic;">R </span><span class="font60" style="font-style:italic;">• </span><span class="font53" style="font-style:italic;">d<sub>prop</sub>?</span></p></li>
<li>
<p><span class="font53">c. Let </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> denote the size of the photo. What is the minimum value of </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> for the microwave link to be continuously transmitting?</span></p></li></ul>
<p><span class="font53">P30. Consider the airline travel analogy in our discussion of layering in Section 1.5, and the addition of headers to protocol data units as they flow down the protocol stack. Is there an equivalent notion of header information that is added to passengers and baggage as they move down the airline protocol stack?</span></p>
<p><span class="font53">P31. In modern packet-switched networks, including the Internet, the source host segments long, application-layer messages (for example, an image or a music file) into smaller packets and sends the packets into the network. The receiver then reassembles the packets back into the original message. We refer to this process as </span><span class="font53" style="font-style:italic;">message segmentation.</span><span class="font53"> Figure 1.27 illustrates the end-to-end transport of a message with and without message segmentation. Consider a message that is 10</span><span class="font50">6 </span><span class="font53">bits long that is to be sent from source to destination in Figure 1.27. Suppose each link in the figure is 5 Mbps. Ignore propagation, queuing, and processing delays.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Consider sending the message from source to destination </span><span class="font53" style="font-style:italic;">without</span><span class="font53"> message segmentation. How long does it take to move the message from the source host to the first packet switch? Keeping in mind that each switch uses store-and-forward packet switching, what is the total time to move the message from source host to destination host?</span></p></li>
<li>
<p><span class="font53">b. Now suppose that the message is segmented into 100 packets, with each packet being 10,000 bits long. How long does it take to move the first packet from source host to the first switch? When the first packet is being sent from the first switch to the second switch, the second packet is being sent from the source host to the first switch. At what time will the second packet be fully received at the first switch?</span></p></li>
<li>
<p><span class="font53">c. How long does it take to move the file from source host to destination host when message segmentation is used? Compare this result with your answer in part (a) and comment.</span></p>
<div><img src="networking_files/networking-58.jpg" alt="" style="width:34pt;height:37pt;">
<p><span class="font4" style="font-weight:bold;">a. </span><span class="font4">Source</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-59.jpg" alt="" style="width:40pt;height:33pt;">
</div><br clear="all">
<div><img src="networking_files/networking-60.jpg" alt="" style="width:27pt;height:30pt;">
</div><br clear="all">
<div><img src="networking_files/networking-61.jpg" alt="" style="width:35pt;height:37pt;">
<p><span class="font4">Destination</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Packet switch Packet switch</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-62.jpg" alt="" style="width:54pt;height:37pt;">
</div><br clear="all">
<div>
<p><span class="font4">Packet</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-63.jpg" alt="" style="width:27pt;height:30pt;">
</div><br clear="all">
<div><img src="networking_files/networking-64.jpg" alt="" style="width:27pt;height:30pt;">
</div><br clear="all">
<div><img src="networking_files/networking-65.jpg" alt="" style="width:40pt;height:37pt;">
<p><span class="font4">Destination</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">b. </span><span class="font4">Source &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Packet switch Packet switch</span></p>
</div><br clear="all"></li></ul>
<p><span class="font7" style="font-weight:bold;">Figure 1.27 </span><span class="font50">♦ </span><span class="font5">End-to-end message transport: (a) without message segmentation; (b) with message segmentation</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">d. In addition to reducing delay, what are reasons to use message segmentation?</span></p></li>
<li>
<p><span class="font53">e. Discuss the drawbacks of message segmentation.</span></p></li></ul>
<p><span class="font53">P32. Consider Problem P31 and assume that the propagation delay is 250 ms. Recalculate the total time needed to transfer the source data with and without segmentation. Is segmentation more beneficial or less if there is propagation delay?</span></p>
<p><span class="font53">P33. Consider sending a large file of </span><span class="font53" style="font-style:italic;">F</span><span class="font53"> bits from Host A to Host B. There are three links (and two switches) between A and B, and the links are uncongested (that is, no queuing delays). Host A segments the file into segments of </span><span class="font53" style="font-style:italic;">S</span><span class="font53"> bits each and adds 80 bits of header to each segment, forming packets of </span><span class="font53" style="font-style:italic;">L =</span><span class="font53"> 80 </span><span class="font55">+ </span><span class="font53" style="font-style:italic;">S</span><span class="font53"> bits. Each link has a transmission rate of </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> bps. Find the value of </span><span class="font53" style="font-style:italic;">S</span><span class="font53"> that minimizes the delay of moving the file from Host A to Host B. Disregard propagation delay.</span></p>
<p><span class="font53">P34. Early versions of TCP combined functions for both forwarding and reliable delivery. How are these TCP variants located in the ISO/OSI protocol stack? Why were forwarding functions later separated from TCP? What were the consequences?</span></p>
<p><span class="font24" style="font-weight:bold;">Wireshark Lab</span></p>
<p><span class="font53" style="font-style:italic;">“Tell me and I forget. Show me and I remember. Involve me and I understand.” </span><span class="font53">Chinese proverb</span></p>
<p><span class="font53">One’s understanding of network protocols can often be greatly deepened by seeing them in action and by playing around with them—observing the sequence of messages exchanged between two protocol entities, delving into the details of protocol operation, causing protocols to perform certain actions, and observing these actions and their consequences. This can be done in simulated scenarios or in a real network environment such as the Internet. The interactive animations at the textbook Web site take the first approach. In the Wireshark labs, we’ll take the latter approach. You’ll run network applications in various scenarios using a computer on your desk, at home, or in a lab. You’ll observe the network protocols in your computer, interacting and exchanging messages with protocol entities executing elsewhere in the Internet. Thus, you and your computer will be an integral part of these live labs. You’ll observe—and you’ll learn—by doing.</span></p>
<p><a name="bookmark286"></a><span class="font53">The basic tool for observing the messages exchanged between executing protocol entities is called a </span><span class="font53" style="font-weight:bold;">packet sniffer</span><span class="font53">. As the name suggests, a packet sniffer passively copies (sniffs) messages being sent from and received by your computer; it also displays the contents of the various protocol fields of these captured messages. A screenshot of the Wireshark packet sniffer is shown in Figure 1.28. Wireshark is a</span></p>
<div>
<p><span class="font4" style="font-weight:bold;">Command</span></p>
<p><span class="font4">menus</span></p>
</div><br clear="all">
<p><span class="font4" style="font-weight:bold;">Listing </span><span class="font4">of captured packets</span></p>
<p><span class="font4" style="font-weight:bold;">Details </span><span class="font4">of selected packet header</span></p>
<p><span class="font4">Packet </span><span class="font4" style="font-weight:bold;">contents </span><span class="font4">in hexadecimal and ASCII</span></p>
<div style="border-bottom:solid;"><img src="networking_files/networking-66.jpg" alt="" style="width:360pt;height:247pt;">
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 1.28 </span><span class="font50">♦ </span><span class="font5">A Wireshark screenshot (Wireshark screenshot reprinted by permission of the Wireshark Foundation.)</span></p>
<p><span class="font53">free packet sniffer that runs on Windows, Linux/Unix, and Mac computers. Throughout the textbook, you will find Wireshark labs that allow you to explore a number of the protocols studied in the chapter. In this first Wireshark lab, you’ll obtain and install a copy of Wireshark, access a Web site, and capture and examine the protocol messages being exchanged between your Web browser and the Web server.</span></p>
<p><span class="font53">You can find full details about this first Wireshark lab (including instructions about how to obtain and install Wireshark) at the Web site </span><a href="http://www.pearsonglobaleditions.com"><span class="font53">www.pearsonglobaleditions</span></a><span class="font53"> </span><a href="http://www.pearsonglobaleditions.com"><span class="font53">.com</span></a><span class="font53">.</span></p>
<p><span class="font23" style="font-weight:bold;">AN INTERVIEW WITH...</span></p>
<p><span class="font11" style="font-weight:bold;">Leonard Kleinrock</span></p>
<div><img src="networking_files/networking-67.jpg" alt="" style="width:86pt;height:113pt;">
<p><span class="font3">Courtesy of Leonard Kleinrock</span></p>
</div><br clear="all">
<p><span class="font46">Leonard Kleinrock is a professor of computer science at the University of California, Los Angeles. In 1969, his computer at UCLA became the first node of the Internet. His creation of the mathematical theory of packet-switching principles in 1961 became the technology behind the Internet. He received his B.E.E. from the City College of New York (CCNY) and his masters and PhD in electrical engineering from MIT.</span></p>
<p><span class="font4" style="font-weight:bold;">What made you decide to specialize in networking/Internet technology?</span></p>
<p><span class="font52">As a PhD student at MIT in 1959, I looked around and found that most of my classmates were doing research in the area of information theory and coding theory that had been established by the great researcher, Claude Shannon. I judged that he had solved most of the important problems already. The research problems that were left were hard and seemed to me to be of lesser consequence. So I decided to launch out in a new area that no one else had yet conceived of. Happily, at MIT I was surrounded by many computers, and it was clear to me that, sooner or later, these machines would need to communicate with each other. At the time, there was no effective way for them to do so and that the solution to this important problem would have impact. I had an approach to this problem and so, for my PhD research, I decided to create a mathematical theory to model, evaluate, design and optimize efficient and reliable data networks.</span></p>
<p><span class="font4" style="font-weight:bold;">What was your first job in the computer industry? What did it entail?</span></p>
<p><span class="font52">I went to the evening session at CCNY from 1951 to 1957 for my bachelor’s degree in electrical engineering. During the day, I worked first as a technician and then as an electrical engineer at a small, industrial electronics firm called </span><span class="font52" style="font-style:italic;">Photobell.</span><span class="font52"> While there, I introduced digital technology to their product line. Essentially, we were using photoelectric devices to detect the presence of certain items (boxes, people, etc.) and the use of a circuit known then as a </span><span class="font52" style="font-style:italic;">bistable multivibrator</span><span class="font52"> was just what we needed to bring digital processing into this field of detection. These circuits happen to be the building blocks for computers, and have come to be known as </span><span class="font52" style="font-style:italic;">flip-flops</span><span class="font52"> or switches in today’s vernacular.</span></p>
<p><span class="font4" style="font-weight:bold;">What was going through your mind when you sent the first host-to-host message (from UCLA to the Stanford Research Institute)?</span></p>
<p><span class="font52">Frankly, we had no idea of the importance of that event. We had not prepared a special message of historic significance, as did so many inventors of the past (Samuel Morse with “What hath God wrought.” or Alexander Graham Bell with “Watson, come here! I want you.” or Neal Armstrong with “That’s one small step for a man, one giant leap for mankind.”) Those guys were </span><span class="font52" style="font-style:italic;">smart</span><span class="font52">! They understood media and public relations. All we wanted to do was to demonstrate our ability to remotely login to the SRI computer. So we typed the “L”, which was correctly received, we typed the “o” which was correctly received, and then we typed the “g” which caused the SRI host computer to crash! So, it turned out that our message was the shortest and perhaps the most prophetic message ever, namely “Lo!” as in “Lo and behold!”</span></p>
<p><span class="font52">Earlier that year, I was quoted in a UCLA press release saying that once the network was up and running, it would be possible to gain access to computer utilities from our homes and offices as easily as we gain access to electricity and telephone connectivity. So my vision at that time was that the Internet would be ubiquitous, always on, always available, anyone with any device could connect from any location, and it would be invisible. However, I never anticipated that my 99-year-old mother would use the Internet at the same time that my 5 year-old granddaughter was—and indeed she did!</span></p>
<p><span class="font4" style="font-weight:bold;">What is your vision for the future of networking?</span></p>
<p><span class="font52">The easy part of the vision is to predict the </span><span class="font52" style="font-style:italic;">infrastructure</span><span class="font52"> itself. I anticipate that we will see considerable deployment of wireless and mobile devices in smart spaces to produce what I like to refer to as the Invisible Internet. This step will enable us to move out from the netherworld of cyberspace to the physical world of smart spaces. Our environments (desks, walls, vehicles, watches, belts, fingernails, bodies and so on) will come alive with technology, through actuators, sensors, logic, processing, storage, cameras, microphones, speakers, displays, and communication. This embedded technology will allow our environment to provide the IP services wherever and whenever we want. When I walk into a room, the room will know I entered. I will be able to communicate with my environment naturally, as in spoken English, haptics, gestures, and eventually through brain-Internet interfaces; my requests will generate replies that present Web pages to me from wall displays, through my eyeglasses, as speech, holograms, and so forth. Looking a bit further out, I see a networking future that includes the following additional key components. I see customized intelligent software agents deployed across the network whose function it is to mine data, act on that data, observe trends, and carry out tasks dynamically and adaptively. I see the deployment of blockchain technology that provides irrefutable, immutable distributed ledgers coupled with reputation systems that provide credibility to the contents and functionality. I see considerably more network traffic generated not so much by humans, but by the embedded devices, the intelligent software agents and the distributed ledgers. I see large collections of self-organizing systems controlling this vast, fast network. I see huge amounts of information flashing across this network instantaneously with this information undergoing enormous processing and filtering. The Invisible Internet will essentially be a pervasive global nervous system . I see all these things and more as we move headlong through the twenty-first century.</span></p>
<p><span class="font52">The harder part of the vision is to predict the </span><span class="font52" style="font-style:italic;">applications and services,</span><span class="font52"> which have consistently surprised us in dramatic ways (e-mail, search technologies, the World Wide Web, blogs, peer-to-peer networks, social networks, user generated content, sharing of music, photos, and videos, etc.). These applications have “come of the blue”, sudden, unanticipated and explosive. What a wonderful world for the next generation to explore</span></p>
<p><span class="font4" style="font-weight:bold;">What people have inspired you professionally?</span></p>
<p><span class="font52">By far, it was Claude Shannon from MIT, a brilliant researcher who had the ability to relate his mathematical ideas to the physical world in highly intuitive ways. He was a superb member of my PhD thesis committee.</span></p>
<p><span class="font4" style="font-weight:bold;">Do you have any advice for students entering the networking/Internet field?</span></p>
<p><span class="font52">The Internet and all that it enables is a vast new frontier, continuously full of amazing challenges. There is room for great innovation. Don’t be constrained by today’s technology. Reach out and imagine what could be and then make it happen.</span></p><img src="networking_files/networking-68.jpg" alt="" style="width:531pt;height:153pt;">
<h1><a name="bookmark287"></a><span class="font27" style="font-weight:bold;">Application</span></h1>
<h1><span class="font27" style="font-weight:bold;">Layer</span></h1>
<p><span class="font53">Network applications are the </span><span class="font53" style="font-style:italic;">raisons d’etre</span><span class="font53"> of a computer network—if we couldn’t conceive of any useful applications, there wouldn’t be any need for networking infrastructure and protocols to support them. Since the Internet’s inception, numerous useful and entertaining applications have indeed been created. These applications have been the driving force behind the Internet’s success, motivating people in homes, schools, governments, and businesses to make the Internet an integral part of their daily activities.</span></p>
<p><a name="bookmark43"></a><span class="font53">Internet applications include the classic text-based applications that became popular in the 1970s and 1980s: text e-mail, remote access to computers, file transfers, and newsgroups. They include </span><span class="font53" style="font-style:italic;">the</span><span class="font53"> killer application of the mid-1990s, the World Wide Web, encompassing Web surfing, search, and electronic commerce. Since the beginning of new millennium, new and highly compelling applications continue to emerge, including voice over IP and video conferencing such as Skype, Facetime, and Google Hangouts; user generated video such as YouTube and movies on demand such as Netflix; and multiplayer online games such as Second Life and World of Warcraft. During this same period, we have seen the emergence of a new generation of social networking applications—such as Facebook, Instagram, and Twitter—which have created human networks on top of the Internet’s network or routers and communication links. And most recently, along with the arrival of the smartphone and the ubiquity of 4G/5G wireless Internet access, there has been a profusion of location based mobile apps, including popular check-in, dating, and road-traffic forecasting apps (such as Yelp, Tinder, and Waz), mobile payment apps (such as WeChat and Apple Pay) and messaging apps (such as WeChat and WhatsApp). Clearly, there has been no slowing down of new and exciting Internet applications. Perhaps some of the readers of this text will create the next generation of killer Internet applications!</span></p>
<p><span class="font53">In this chapter, we study the conceptual and implementation aspects of network applications. We begin by defining key application-layer concepts, including network services required by applications, clients and servers, processes, and transport-layer interfaces. We examine several network applications in detail, including the Web, e-mail, DNS, peer-to-peer (P2P) file distribution, and video streaming. We then cover network application development, over both TCP and UDP. In particular, we study the socket interface and walk through some simple client-server applications in Python. We also provide several fun and interesting socket programming assignments at the end of the chapter.</span></p>
<p><span class="font53">The application layer is a particularly good place to start our study of protocols. It’s familiar ground. We’re acquainted with many of the applications that rely on the protocols we’ll study. It will give us a good feel for what protocols are all about and will introduce us to many of the same issues that we’ll see again when we study transport, network, and link layer protocols.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">2.1 </span><span class="font24" style="font-weight:bold;">Principles of Network Applications</span></p></li></ul>
<p><span class="font53">Suppose you have an idea for a new network application. Perhaps this application will be a great service to humanity, or will please your professor, or will bring you great wealth, or will simply be fun to develop. Whatever the motivation may be, let’s now examine how you transform the idea into a real-world network application.</span></p>
<p><span class="font53">At the core of network application development is writing programs that run on different end systems and communicate with each other over the network. For example, in the Web application there are two distinct programs that communicate with each other: the browser program running in the user’s host (desktop, laptop, tablet, smartphone, and so on); and the Web server program running in the Web server host. As another example, in a Video on Demand application such as Netflix (see Section 2.6), there is a Netflix-provided program running on the user’s smartphone, tablet, or computer; and a Netflix server program running on the Netflix server host. Servers often (but certainly not always) are housed in a data center, as shown in Figure 2.1.</span></p>
<p><a name="bookmark288"></a><span class="font53">Thus, when developing your new application, you need to write software that will run on multiple end systems. This software could be written, for example, in C, Java, or Python. Importantly, you do not need to write software that runs on network-core devices, such as routers or link-layer switches. Even if you wanted to write application software for these network-core devices, you wouldn’t be able to do so. As we learned in Chapter 1, and as shown earlier in Figure 1.24, network-core devices do not function at the application layer but instead function at lower layers— specifically at the network layer and below. This basic design—namely, confining application software to the end systems—as shown in Figure 2.1, has facilitated the rapid development and deployment of a vast array of network applications.</span></p>
<div>
<p><span class="font4" style="font-weight:bold;">Application</span></p>
<p><span class="font4">Transport</span></p>
<p><span class="font4">Network</span></p>
<p><span class="font4">Data Link</span></p>
<p><span class="font4">Physical</span></p>
<p><span class="font4" style="font-weight:bold;">Application</span></p>
<p><span class="font4">Transport</span></p>
<p><span class="font4">Network</span></p>
<p><span class="font4">Data Link</span></p>
<p><span class="font4">Physical</span></p><img src="networking_files/networking-69.jpg" alt="" style="width:329pt;height:428pt;">
<p><span class="font4" style="font-weight:bold;">Datacenter Network</span></p>
<p><span class="font4" style="font-weight:bold;">Datacenter Network</span></p>
<p><span class="font4" style="font-weight:bold;">Content Provider Network</span></p>
<p><span class="font4" style="font-weight:bold;">Application</span></p>
<p><span class="font4">Transport</span></p>
<p><span class="font4">Network</span></p>
<p><span class="font4">Data Link</span></p>
<p><span class="font4">Physical</span></p>
<p><span class="font4" style="font-weight:bold;">Enterprise Network</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 2.1 </span><span class="font50">♦ </span><span class="font5">Communication for a network application takes place between end systems at the application layer</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">National or Global ISP</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Mobile Network</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">e Network</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Local or Regional ISP</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">2.1.1 </span><span class="font23" style="font-weight:bold;">Network Application Architectures</span></p></li></ul>
<p><span class="font53">Before diving into software coding, you should have a broad architectural plan for your application. Keep in mind that an application’s architecture is distinctly different from the network architecture (e.g., the five-layer Internet architecture discussed in Chapter 1). From the application developer’s perspective, the network architecture is fixed and provides a specific set of services to applications. The </span><span class="font53" style="font-weight:bold;">application architecture</span><span class="font53">, on the other hand, is designed by the application developer and dictates how the application is structured over the various end systems. In choosing the application architecture, an application developer will likely draw on one of the two predominant architectural paradigms used in modern network applications: the client-server architecture or the peer-to-peer (P2P) architecture.</span></p>
<p><span class="font53">In a </span><span class="font53" style="font-weight:bold;">client-server architecture</span><span class="font53">, there is an always-on host, called the </span><span class="font53" style="font-style:italic;">server, </span><span class="font53">which services requests from many other hosts, called </span><span class="font53" style="font-style:italic;">clients.</span><span class="font53"> A classic example is the Web application for which an always-on Web server services requests from browsers running on client hosts. When a Web server receives a request for an object from a client host, it responds by sending the requested object to the client host. Note that with the client-server architecture, clients do not directly communicate with each other; for example, in the Web application, two browsers do not directly communicate. Another characteristic of the client-server architecture is that the server has a fixed, well-known address, called an IP address (which we’ll discuss soon). Because the server has a fixed, well-known address, and because the server is always on, a client can always contact the server by sending a packet to the server’s IP address. Some of the better-known applications with a client-server architecture include the Web, FTP, Telnet, and e-mail. The client-server architecture is shown in Figure 2.2(a).</span></p>
<p><span class="font53">Often in a client-server application, a single-server host is incapable of keeping up with all the requests from clients. For example, a popular social-networking site can quickly become overwhelmed if it has only one server handling all of its requests. For this reason, a </span><span class="font53" style="font-weight:bold;">data center</span><span class="font53">, housing a large number of hosts, is often used to create a powerful virtual server. The most popular Internet services—such as search engines (e.g., Google, Bing, Baidu), Internet commerce (e.g., Amazon, eBay, Alibaba), Web-based e-mail (e.g., Gmail and Yahoo Mail), social media (e.g., Facebook, Instagram, Twitter, and WeChat)—run in one or more data centers. As discussed in Section 1.3.3, Google has 19 data centers distributed around the world, which collectively handle search, YouTube, Gmail, and other services. A data center can have hundreds of thousands of servers, which must be powered and maintained. Additionally, the service providers must pay recurring interconnection and bandwidth costs for sending data from their data centers.</span></p>
<p><a name="bookmark289"></a><span class="font53">In a </span><span class="font53" style="font-weight:bold;">P2P architecture</span><span class="font53">, there is minimal (or no) reliance on dedicated servers in data centers. Instead the application exploits direct communication between pairs of intermittently connected hosts, called </span><span class="font53" style="font-style:italic;">peers.</span><span class="font53"> The peers are not owned by the service provider, but are instead desktops and laptops controlled by users, with most of the peers residing in homes, universities, and offices. Because the peers communicate</span></p>
<div><img src="networking_files/networking-70.jpg" alt="" style="width:204pt;height:237pt;">
<p><span class="font4" style="font-weight:bold;">a. Client-server architecture</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 2.2 </span><span class="font50">♦ </span><span class="font5">(a) Client-server architecture; (b) P2P architecture</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-71.jpg" alt="" style="width:204pt;height:237pt;">
<p><span class="font4" style="font-weight:bold;">b. Peer-to-peer architecture</span></p>
</div><br clear="all">
<p><span class="font53">without passing through a dedicated server, the architecture is called peer-to-peer. An example of a popular P2P application is the file-sharing application BitTorrent.</span></p>
<p><span class="font53">One of the most compelling features of P2P architectures is their </span><span class="font53" style="font-weight:bold;">selfscalability</span><span class="font53">. For example, in a P2P file-sharing application, although each peer generates workload by requesting files, each peer also adds service capacity to the system by distributing files to other peers. P2P architectures are also cost effective, since they normally don’t require significant server infrastructure and server bandwidth (in contrast with clients-server designs with datacenters). However, P2P applications face challenges of security, performance, and reliability due to their highly decentralized structure.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">2.1.2 </span><span class="font23" style="font-weight:bold;">Processes Communicating</span></p></li></ul>
<p><a name="bookmark290"></a><span class="font53">Before building your network application, you also need a basic understanding of how the programs, running in multiple end systems, communicate with each other. In the jargon of operating systems, it is not actually programs but </span><span class="font53" style="font-weight:bold;">processes </span><span class="font53">that communicate. A process can be thought of as a program that is running within an end system. When processes are running on the same end system, they can communicate with each other with interprocess communication, using rules that are governed by the end system’s operating system. But in this book, we are not particularly interested in how processes in the same host communicate, but instead in how processes running on </span><span class="font53" style="font-style:italic;">different</span><span class="font53"> hosts (with potentially different operating systems) communicate.</span></p>
<p><span class="font53">Processes on two different end systems communicate with each other by exchanging </span><span class="font53" style="font-weight:bold;">messages </span><span class="font53">across the computer network. A sending process creates and sends messages into the network; a receiving process receives these messages and possibly responds by sending messages back. Figure 2.1 illustrates that processes communicating with each other reside in the application layer of the five-layer protocol stack.</span></p>
<p><span class="font22" style="font-weight:bold;">Client and Server Processes</span></p>
<p><span class="font53">A network application consists of pairs of processes that send messages to each other over a network. For example, in the Web application a client browser process exchanges messages with a Web server process. In a P2P file-sharing system, a file is transferred from a process in one peer to a process in another peer. For each pair of communicating processes, we typically label one of the two processes as the </span><span class="font53" style="font-weight:bold;">client </span><span class="font53">and the other process as the </span><span class="font53" style="font-weight:bold;">server</span><span class="font53">. With the Web, a browser is a client process and a Web server is a server process. With P2P file sharing, the peer that is downloading the file is labeled as the client, and the peer that is uploading the file is labeled as the server.</span></p>
<p><span class="font53">You may have observed that in some applications, such as in P2P file sharing, a process can be both a client and a server. Indeed, a process in a P2P file-sharing system can both upload and download files. Nevertheless, in the context of any given communication session between a pair of processes, we can still label one process as the client and the other process as the server. We define the client and server processes as follows:</span></p>
<p><span class="font53" style="font-style:italic;">In the context of a communication session between a pair of processes, the process that initiates the communication (that is, initially contacts the other process at the beginning of the session) is labeled as the</span><span class="font53"> client</span><span class="font53" style="font-style:italic;">. The process that waits to be contacted to begin the session is the</span><span class="font53"> server</span><span class="font53" style="font-style:italic;">.</span></p>
<p><span class="font53">In the Web, a browser process initializes contact with a Web server process; hence the browser process is the client and the Web server process is the server. In P2P file sharing, when Peer A asks Peer B to send a specific file, Peer A is the client and Peer B is the server in the context of this specific communication session. When there’s no confusion, we’ll sometimes also use the terminology “client side and server side of an application.” At the end of this chapter, we’ll step through simple code for both the client and server sides of network applications.</span></p>
<p><span class="font22" style="font-weight:bold;">The Interface Between the Process and the Computer Network</span></p>
<p><span class="font53">As noted above, most applications consist of pairs of communicating processes, with the two processes in each pair sending messages to each other. Any message sent from one process to another must go through the underlying network. A process sends messages into, and receives messages from, the network through a software interface called a </span><span class="font53" style="font-weight:bold;">socket</span><span class="font53">. Let’s consider an analogy to help us understand processes and sockets. A process is analogous to a house and its socket is analogous to its door. When a process wants to send a message to another process on another host, it shoves the message out its door (socket). This sending process assumes that there is a transportation infrastructure on the other side of its door that will transport the message to the door of the destination process. Once the message arrives at the destination host, the message passes through the receiving process’s door (socket), and the receiving process then acts on the message.</span></p>
<p><span class="font53">Figure 2.3 illustrates socket communication between two processes that communicate over the Internet. (Figure 2.3 assumes that the underlying transport protocol used by the processes is the Internet’s TCP protocol.) As shown in this figure, a socket is the interface between the application layer and the transport layer within a host. It is also referred to as the </span><span class="font53" style="font-weight:bold;">Application Programming Interface (API) </span><span class="font53">between the application and the network, since the socket is the programming interface with which network applications are built. The application developer has control of everything on the application-layer side of the socket but has little control of the transport-layer side of the socket. The only control that the application developer has on the transportlayer side is (1) the choice of transport protocol and (2) perhaps the ability to fix a few</span></p>
<p><span class="font4" style="font-weight:bold;">Host or server</span></p>
<p><span class="font4" style="font-weight:bold;">Host or server</span></p><img src="networking_files/networking-72.jpg" alt="" style="width:229pt;height:37pt;"><img src="networking_files/networking-73.jpg" alt="" style="width:391pt;height:118pt;">
<p><span class="font7" style="font-weight:bold;">Figure 2.3 </span><span class="font50">♦ </span><span class="font5">Application processes, sockets, and underlying transport protocol</span></p>
<p><span class="font53">transport-layer parameters such as maximum buffer and maximum segment sizes (to be covered in Chapter 3). Once the application developer chooses a transport protocol (if a choice is available), the application is built using the transport-layer services provided by that protocol. We’ll explore sockets in some detail in Section 2.7.</span></p>
<p><span class="font22" style="font-weight:bold;">Addressing Processes</span></p>
<p><span class="font53">In order to send postal mail to a particular destination, the destination needs to have an address. Similarly, in order for a process running on one host to send packets to a process running on another host, the receiving process needs to have an address. To identify the receiving process, two pieces of information need to be specified: (1) the address of the host and (2) an identifier that specifies the receiving process in the destination host.</span></p>
<p><span class="font53">In the Internet, the host is identified by its </span><span class="font53" style="font-weight:bold;">IP address</span><span class="font53">. We’ll discuss IP addresses in great detail in Chapter 4. For now, all we need to know is that an IP address is a 32-bit quantity that we can think of as uniquely identifying the host. In addition to knowing the address of the host to which a message is destined, the sending process must also identify the receiving process (more specifically, the receiving socket) running in the host. This information is needed because in general a host could be running many network applications. A destination </span><span class="font53" style="font-weight:bold;">port number </span><span class="font53">serves this purpose. Popular applications have been assigned specific port numbers. For example, a Web server is identified by port number 80. A mail server process (using the SMTP protocol) is identified by port number 25. A list of well-known port numbers for all Internet standard protocols can be found at </span><a href="http://www.iana.org"><span class="font53">www.iana.org</span></a><span class="font53">. We’ll examine port numbers in detail in Chapter 3.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">2.1.3 </span><span class="font23" style="font-weight:bold;">Transport Services Available to Applications</span></p></li></ul>
<p><span class="font53">Recall that a socket is the interface between the application process and the transport-layer protocol. The application at the sending side pushes messages through the socket. At the other side of the socket, the transport-layer protocol has the responsibility of getting the messages to the socket of the receiving process.</span></p>
<p><span class="font53">Many networks, including the Internet, provide more than one transport-layer protocol. When you develop an application, you must choose one of the available transport-layer protocols. How do you make this choice? Most likely, you would study the services provided by the available transport-layer protocols, and then pick the protocol with the services that best match your application’s needs. The situation is similar to choosing either train or airplane transport for travel between two cities. You have to choose one or the other, and each transportation mode offers different services. (For example, the train offers downtown pickup and drop-off, whereas the plane offers shorter travel time.)</span></p>
<p><a name="bookmark291"></a><span class="font53">What are the services that a transport-layer protocol can offer to applications invoking it? We can broadly classify the possible services along four dimensions: reliable data transfer, throughput, timing, and security.</span></p>
<p><span class="font22" style="font-weight:bold;">Reliable Data Transfer</span></p>
<p><span class="font53">As discussed in Chapter 1, packets can get lost within a computer network. For example, a packet can overflow a buffer in a router, or can be discarded by a host or router after having some of its bits corrupted. For many applications—such as electronic mail, file transfer, remote host access, Web document transfers, and financial appli-cations—data loss can have devastating consequences (in the latter case, for either the bank or the customer!). Thus, to support these applications, something has to be done to guarantee that the data sent by one end of the application is delivered correctly and completely to the other end of the application. If a protocol provides such a guaranteed data delivery service, it is said to provide </span><span class="font53" style="font-weight:bold;">reliable data transfer</span><span class="font53">. One important service that a transport-layer protocol can potentially provide to an application is process-to-process reliable data transfer. When a transport protocol provides this service, the sending process can just pass its data into the socket and know with complete confidence that the data will arrive without errors at the receiving process.</span></p>
<p><span class="font53">When a transport-layer protocol doesn’t provide reliable data transfer, some of the data sent by the sending process may never arrive at the receiving process. This may be acceptable for </span><span class="font53" style="font-weight:bold;">loss-tolerant applications</span><span class="font53">, most notably multimedia applications such as conversational audio/video that can tolerate some amount of data loss. In these multimedia applications, lost data might result in a small glitch in the audio/ video—not a crucial impairment.</span></p>
<p><span class="font22" style="font-weight:bold;">Throughput</span></p>
<p><span class="font53">In Chapter 1, we introduced the concept of available throughput, which, in the context of a communication session between two processes along a network path, is the rate at which the sending process can deliver bits to the receiving process. Because other sessions will be sharing the bandwidth along the network path, and because these other sessions will be coming and going, the available throughput can fluctuate with time. These observations lead to another natural service that a transport-layer protocol could provide, namely, guaranteed available throughput at some specified rate. With such a service, the application could request a guaranteed throughput of </span><span class="font53" style="font-style:italic;">r</span><span class="font53"> bits/sec, and the transport protocol would then ensure that the available throughput is always at least </span><span class="font53" style="font-style:italic;">r</span><span class="font53"> bits/sec. Such a guaranteed throughput service would appeal to many applications. For example, if an Internet telephony application encodes voice at 32 kbps, it needs to send data into the network and have data delivered to the receiving application at this rate. If the transport protocol cannot provide this throughput, the application would need to encode at a lower rate (and receive enough throughput to sustain this lower coding rate) or may have to give up, since receiving, say, half of the needed throughput is of little or no use to this Internet telephony application. Applications that have throughput requirements are said to be </span><span class="font53" style="font-weight:bold;">bandwidth-sensitive applications</span><span class="font53">. Many current multimedia applications are bandwidth sensitive, although some multimedia applications may use adaptive coding techniques to encode digitized voice or video at a rate that matches the currently available throughput.</span></p>
<p><span class="font53">While bandwidth-sensitive applications have specific throughput requirements, </span><span class="font53" style="font-weight:bold;">elastic applications </span><span class="font53">can make use of as much, or as little, throughput as happens to be available. Electronic mail, file transfer, and Web transfers are all elastic applications. Of course, the more throughput, the better. There’s an adage that says that one cannot be too rich, too thin, or have too much throughput!</span></p>
<p><span class="font22" style="font-weight:bold;">Timing</span></p>
<p><span class="font53">A transport-layer protocol can also provide timing guarantees. As with throughput guarantees, timing guarantees can come in many shapes and forms. An example guarantee might be that every bit that the sender pumps into the socket arrives at the receiver’s socket no more than 100 msec later. Such a service would be appealing to interactive real-time applications, such as Internet telephony, virtual environments, teleconferencing, and multiplayer games, all of which require tight timing constraints on data delivery in order to be effective, see [Gauthier 1999; Ramjee 1994]. Long delays in Internet telephony, for example, tend to result in unnatural pauses in the conversation; in a multiplayer game or virtual interactive environment, a long delay between taking an action and seeing the response from the environment (for example, from another player at the end of an end-to-end connection) makes the application feel less realistic. For non-real-time applications, lower delay is always preferable to higher delay, but no tight constraint is placed on the end-to-end delays.</span></p>
<p><span class="font22" style="font-weight:bold;">Security</span></p>
<p><span class="font53">Finally, a transport protocol can provide an application with one or more security services. For example, in the sending host, a transport protocol can encrypt all data transmitted by the sending process, and in the receiving host, the transport-layer protocol can decrypt the data before delivering the data to the receiving process. Such a service would provide confidentiality between the two processes, even if the data is somehow observed between sending and receiving processes. A transport protocol can also provide other security services in addition to confidentiality, including data integrity and end-point authentication, topics that we’ll cover in detail in Chapter 8.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">2.1.4 </span><span class="font23" style="font-weight:bold;">Transport Services Provided by the Internet</span></p></li></ul>
<p><a name="bookmark292"></a><span class="font53">Up until this point, we have been considering transport services that a computer network </span><span class="font53" style="font-style:italic;">could</span><span class="font53"> provide in general. Let’s now get more specific and examine the type of transport services provided by the Internet. The Internet (and, more generally, TCP/ IP networks) makes two transport protocols available to applications, UDP and TCP. When you (as an application developer) create a new network application for the</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Application</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Data Loss</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Throughput</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Time-Sensitive</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">File transfer/download</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">No loss</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Elastic</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">No</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">E-mail</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">No loss</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Elastic</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">No</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Web documents</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">No loss</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Elastic (few kbps)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">No</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Internet telephony/ Video conferencing</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">Loss-tolerant</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Audio: few kbps—1 Mbps</span></p>
<p><span class="font6">Video: 10 kbps—5 Mbps</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">Yes: 100s of msec</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Streaming stored audio/video</span></p></td><td>
<p><span class="font6">Loss-tolerant</span></p></td><td>
<p><span class="font6">Same as above</span></p></td><td>
<p><span class="font6">Yes: few seconds</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Interactive games</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Loss-tolerant</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Few kbps-10 kbps</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Yes: 100s of msec</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Smartphone messaging</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">No loss</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Elastic</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Yes and no</span></p></td></tr>
</table>
<p><span class="font7" style="font-weight:bold;">Figure 2.4 </span><span class="font50">♦ </span><span class="font5">Requirements of selected network applications</span></p>
<p><span class="font53">Internet, one of the first decisions you have to make is whether to use UDP or TCP. Each of these protocols offers a different set of services to the invoking applications. Figure 2.4 shows the service requirements for some selected applications.</span></p>
<p><span class="font22" style="font-weight:bold;">TCP Services</span></p>
<p><span class="font53">The TCP service model includes a connection-oriented service and a reliable data transfer service. When an application invokes TCP as its transport protocol, the application receives both of these services from TCP.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Connection-oriented service.</span><span class="font53"> TCP has the client and server exchange transportlayer control information with each other </span><span class="font53" style="font-style:italic;">before</span><span class="font53"> the application-level messages begin to flow. This so-called handshaking procedure alerts the client and server, allowing them to prepare for an onslaught of packets. After the handshaking phase, a </span><span class="font53" style="font-weight:bold;">TCP connection </span><span class="font53">is said to exist between the sockets of the two processes. The connection is a full-duplex connection in that the two processes can send messages to each other over the connection at the same time. When the application finishes sending messages, it must tear down the connection. In Chapter 3, we’ll discuss connection-oriented service in detail and examine how it is implemented.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Reliable data transfer service.</span><span class="font53"> The communicating processes can rely on TCP to deliver all data sent without error and in the proper order. When one side of the application passes a stream of bytes into a socket, it can count on TCP to deliver the same stream of bytes to the receiving socket, with no missing or duplicate bytes.</span></p></li></ul>
<p><span class="font53">TCP also includes a congestion-control mechanism, a service for the general welfare of the Internet rather than for the direct benefit of the communicating processes. The TCP congestion-control mechanism throttles a sending process (client or server) when the network is congested between sender and receiver. As we will see in Chapter 3, TCP congestion control also attempts to limit each TCP connection to its fair share of network bandwidth.</span></p>
<p><span class="font22" style="font-weight:bold;">UDP Services</span></p>
<p><span class="font53">UDP is a no-frills, lightweight transport protocol, providing minimal services. UDP is connectionless, so there is no handshaking before the two processes start to communicate. UDP provides an unreliable data transfer service—that is, when a process sends a message into a UDP socket, UDP provides </span><span class="font53" style="font-style:italic;">no</span><span class="font53"> guarantee that the message will ever reach the receiving process. Furthermore, messages that do arrive at the receiving process may arrive out of order.</span></p>
<div><img src="networking_files/networking-74.jpg" alt="" style="width:168pt;height:22pt;">
</div><br clear="all">
<div>
<p><span class="font23" style="font-weight:bold;">FOCUS ON SECURITY</span></p>
</div><br clear="all">
<p><span class="font4" style="font-weight:bold;">SECURING TCP</span></p>
<p><span class="font4">Neither TCP nor UDP provides any encryption — the data that the sending process passes into its socket is the same data that travels over the network to the destination process. So, for example, if the sending process sends a password in cleartext (i.e., unencrypted) into its socket, the cleartext password will travel over all the links between sender and receiver, potentially getting sniffed and discovered at any of the intervening links. Because privacy and other security issues have become critical for many applications, the Internet community has developed an enhancement for TCP, called </span><span class="font5" style="font-weight:bold;">Transport Layer Security </span><span class="font4">(TLS) [RFC 5246]. TCP-enhanced-with-TLS not only does everything that traditional TCP does but also provides critical process-to-process security services, including encryption, data integrity, and end-point authentication. We emphasize that TLS is not a third Internet transport protocol, on the same level as TCP and UDP, but instead is an enhancement of TCP, with the enhancements being implemented in the application layer. In particular, if an application wants to use the services of TLS, it needs to include TLS code (existing, highly optimized libraries and classes) in both the client and server sides of the application. TLS has its own socket API that is similar to the traditional TCP socket API. When an application uses TLS, the sending process passes cleartext data to the TLS socket; TLS in the sending host then encrypts the data and passes the encrypted data to the TCP socket. The encrypted data travels over the Internet to the TCP socket in the receiving process. The receiving socket passes the encrypted data to TLS, which decrypts the data. Finally, TLS passes the cleartext data through its TLS socket to the receiving process. We’ll cover TLS in some detail in Chapter 8.</span></p>
<p><span class="font53">UDP does not include a congestion-control mechanism, so the sending side of UDP can pump data into the layer below (the network layer) at any rate it pleases. (Note, however, that the actual end-to-end throughput may be less than this rate due to the limited transmission capacity of intervening links or due to congestion).</span></p>
<p><span class="font22" style="font-weight:bold;">Services Not Provided by Internet Transport Protocols</span></p>
<p><span class="font53">We have organized transport protocol services along four dimensions: reliable data transfer, throughput, timing, and security. Which of these services are provided by TCP and UDP? We have already noted that TCP provides reliable end-to-end data transfer. And we also know that TCP can be easily enhanced at the application layer with TLS to provide security services. But in our brief description of TCP and UDP, conspicuously missing was any mention of throughput or timing guarantees— services </span><span class="font53" style="font-style:italic;">not</span><span class="font53"> provided by today’s Internet transport protocols. Does this mean that timesensitive applications such as Internet telephony cannot run in today’s Internet? The answer is clearly no—the Internet has been hosting time-sensitive applications for many years. These applications often work fairly well because they have been designed to cope, to the greatest extent possible, with this lack of guarantee. Nevertheless, clever design has its limitations when delay is excessive, or the end-to-end throughput is limited. In summary, today’s Internet can often provide satisfactory service to timesensitive applications, but it cannot provide any timing or throughput guarantees.</span></p>
<p><span class="font53">Figure 2.5 indicates the transport protocols used by some popular Internet applications. We see that e-mail, remote terminal access, the Web, and file transfer all use TCP. These applications have chosen TCP primarily because TCP provides reliable data transfer, guaranteeing that all data will eventually get to its destination. Because Internet telephony applications (such as Skype) can often tolerate some loss but require a minimal rate to be effective, developers of Internet telephony applications</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Application</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Application-Layer Protocol</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Underlying Transport Protocol</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Electronic mail</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">SMTP [RFC 5321]</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">TCP</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Remote terminal access</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Telnet [RFC 854]</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">TCP</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Web</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">HTTP 1.1 [RFC 7230]</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">TCP</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">File transfer</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">FTP [RFC 959]</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">TCP</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Streaming multimedia</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">HTTP (e.g., YouTube), DASH</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">TCP</span></p></td></tr>
<tr><td>
<p><span class="font6">Internet telephony</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">SIP [RFC 3261], RTP [RFC 3550], or proprietary (e.g., Skype)</span></p></td><td>
<p><span class="font6">UDP or TCP</span></p></td></tr>
</table>
<p><span class="font7" style="font-weight:bold;">Figure 2.5 </span><span class="font50">♦ </span><span class="font5">Popular Internet applications, their application-layer protocols, and their underlying transport protocols </span><span class="font53">usually prefer to run their applications over UDP, thereby circumventing TCP’s congestion control mechanism and packet overheads. But because many firewalls are configured to block (most types of) UDP traffic, Internet telephony applications often are designed to use TCP as a backup if UDP communication fails.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">2.1.5 </span><span class="font23" style="font-weight:bold;">Application-Layer Protocols</span></p></li></ul>
<p><span class="font53">We have just learned that network processes communicate with each other by sending messages into sockets. But how are these messages structured? What are the meanings of the various fields in the messages? When do the processes send the messages? These questions bring us into the realm of application-layer protocols. An </span><span class="font53" style="font-weight:bold;">application-layer protocol </span><span class="font53">defines how an application’s processes, running on different end systems, pass messages to each other. In particular, an application-layer protocol defines:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;The types of messages exchanged, for example, request messages and response messages</span></p></li>
<li>
<p><span class="font53">• &nbsp;The syntax of the various message types, such as the fields in the message and how the fields are delineated</span></p></li>
<li>
<p><span class="font53">• &nbsp;The semantics of the fields, that is, the meaning of the information in the fields</span></p></li>
<li>
<p><span class="font53">• &nbsp;Rules for determining when and how a process sends messages and responds to messages</span></p></li></ul>
<p><span class="font53">Some application-layer protocols are specified in RFCs and are therefore in the public domain. For example, the Web’s application-layer protocol, HTTP (the HyperText Transfer Protocol [RFC 7230]), is available as an RFC. If a browser developer follows the rules of the HTTP RFC, the browser will be able to retrieve Web pages from any Web server that has also followed the rules of the HTTP RFC. Many other application-layer protocols are proprietary and intentionally not available in the public domain. For example, Skype uses proprietary application-layer protocols.</span></p>
<p><a name="bookmark293"></a><span class="font53">It is important to distinguish between network applications and application-layer protocols. An application-layer protocol is only one piece of a network application (albeit, a very important piece of the application from our point of view!). Let’s look at a couple of examples. The Web is a client-server application that allows users to obtain documents from Web servers on demand. The Web application consists of many components, including a standard for document formats (that is, HTML), Web browsers (for example, Chrome and Microsoft Internet Explorer), Web servers (for example, Apache and Microsoft servers), and an application-layer protocol. The Web’s application-layer protocol, HTTP, defines the format and sequence of messages exchanged between browser and Web server. Thus, HTTP is only one piece (albeit, an important piece) of the Web application. As another example, we’ll see in Section 2.6 that Netflix’s video service also has many components, including servers that store and transmit videos, other servers that manage billing and other client functions, clients (e.g., the Netflix app on your smartphone, tablet, or computer), and an application-level DASH protocol defines the format and sequence of messages exchanged between a Netflix server and client. Thus, DASH is only one piece (albeit, an important piece) of the Netflix application.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">2.1.6 </span><span class="font23" style="font-weight:bold;">Network Applications Covered in This Book</span></p></li></ul>
<p><span class="font53">New applications are being developed every day. Rather than covering a large number of Internet applications in an encyclopedic manner, we have chosen to focus on a small number of applications that are both pervasive and important. In this chapter, we discuss five important applications: the Web, electronic mail, directory service, video streaming, and P2P applications. We first discuss the Web, not only because it is an enormously popular application, but also because its application-layer protocol, HTTP, is straightforward and easy to understand. We then discuss electronic mail, the Internet’s first killer application. E-mail is more complex than the Web in the sense that it makes use of not one but several application-layer protocols. After e-mail, we cover DNS, which provides a directory service for the Internet. Most users do not interact with DNS directly; instead, users invoke DNS indirectly through other applications (including the Web, file transfer, and electronic mail). DNS illustrates nicely how a piece of core network functionality (network-name to network-address translation) can be implemented at the application layer in the Internet. We then discuss P2P file sharing applications, and complete our application study by discussing video streaming on demand, including distributing stored video over content distribution networks.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">2.2 </span><span class="font24" style="font-weight:bold;">The Web and HTTP</span></p></li></ul>
<p><span class="font53">Until the early 1990s, the Internet was used primarily by researchers, academics, and university students to log in to remote hosts, to transfer files from local hosts to remote hosts and vice versa, to receive and send news, and to receive and send electronic mail. Although these applications were (and continue to be) extremely useful, the Internet was essentially unknown outside of the academic and research communities. Then, in the early 1990s, a major new application arrived on the scene—the World Wide Web [Berners-Lee 1994]. The Web was the first Internet application that caught the general public’s eye. It dramatically changed how people interact inside and outside their work environments. It elevated the Internet from just one of many data networks to essentially the one and only data network.</span></p>
<p><a name="bookmark294"></a><span class="font53">Perhaps what appeals the most to users is that the Web operates </span><span class="font53" style="font-style:italic;">on demand. </span><span class="font53">Users receive what they want, when they want it. This is unlike traditional broadcast radio and television, which force users to tune in when the content provider makes the content available. In addition to being available on demand, the Web has many other wonderful features that people love and cherish. It is enormously easy for any individual to make information available over the Web—everyone can become a publisher at extremely low cost. Hyperlinks and search engines help us navigate through an ocean of information. Photos and videos stimulate our senses. Forms, JavaScript, video, and many other devices enable us to interact with pages and sites. And the Web and its protocols serve as a platform for YouTube, Web-based e-mail (such as Gmail), and most mobile Internet applications, including Instagram and Google Maps.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">2.2.1 </span><span class="font23" style="font-weight:bold;">Overview of HTTP</span></p></li></ul>
<p><span class="font53">The </span><span class="font53" style="font-weight:bold;">HyperText Transfer Protocol (HTTP)</span><span class="font53">, the Web’s application-layer protocol, is at the heart of the Web. It is defined in [RFC 1945], [RFC 7230] and [RFC 7540]. HTTP is implemented in two programs: a client program and a server program. The client program and server program, executing on different end systems, talk to each other by exchanging HTTP messages. HTTP defines the structure of these messages and how the client and server exchange the messages. Before explaining HTTP in detail, we should review some Web terminology.</span></p>
<p><span class="font53">A </span><span class="font53" style="font-weight:bold;">Web page </span><span class="font53">(also called a document) consists of objects. An </span><span class="font53" style="font-weight:bold;">object </span><span class="font53">is simply a file—such as an HTML file, a JPEG image, a Javascrpt file, a CCS style sheet file, or a video clip—that is addressable by a single URL. Most Web pages consist of a </span><span class="font53" style="font-weight:bold;">base HTML file </span><span class="font53">and several referenced objects. For example, if a Web page contains HTML text and five JPEG images, then the Web page has six objects: the base HTML file plus the five images. The base HTML file references the other objects in the page with the objects’ URLs. Each URL has two components: the hostname of the server that houses the object and the object’s path name. For example, the URL</span></p>
<p><a href="http://www.someSchool.edu/someDepartment/picture.gif"><span class="font36">http://www.someSchool.edu/someDepartment/picture.gif</span></a></p>
<p><span class="font53">has </span><a href="http://www.someSchool.edu"><span class="font36">www.someSchool.edu </span></a><span class="font53">for a hostname and </span><span class="font36">/someDepartment/picture. gif </span><span class="font53">for a path name. Because </span><span class="font53" style="font-weight:bold;">Web browsers </span><span class="font53">(such as Internet Explorer and Chrome) implement the client side of HTTP, in the context of the Web, we will use the words </span><span class="font53" style="font-style:italic;">browser</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">client</span><span class="font53"> interchangeably. </span><span class="font53" style="font-weight:bold;">Web servers</span><span class="font53">, which implement the server side of HTTP, house Web objects, each addressable by a URL. Popular Web servers include Apache and Microsoft Internet Information Server.</span></p>
<p><a name="bookmark52"></a><span class="font53">HTTP defines how Web clients request Web pages from Web servers and how servers transfer Web pages to clients. We discuss the interaction between client and server in detail later, but the general idea is illustrated in Figure 2.6. When a user requests a Web page (for example, clicks on a hyperlink), the browser sends</span></p>
<div>
<p><span class="font4">Server running Apache Web server</span></p><img src="networking_files/networking-75.jpg" alt="" style="width:165pt;height:119pt;">
<p><span class="font4">PC running Internet Explorer</span></p>
</div><br clear="all">
<p><span class="font4">Android smartphone running Google Chrome</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 2.6 </span><span class="font50">♦ </span><span class="font5">HTTP request-response behavior</span></p>
<p><span class="font53">HTTP request messages for the objects in the page to the server. The server receives the requests and responds with HTTP response messages that contain the objects.</span></p>
<p><span class="font53">HTTP uses TCP as its underlying transport protocol (rather than running on top of UDP). The HTTP client first initiates a TCP connection with the server. Once the connection is established, the browser and the server processes access TCP through their socket interfaces. As described in Section 2.1, on the client side the socket interface is the door between the client process and the TCP connection; on the server side it is the door between the server process and the TCP connection. The client sends HTTP request messages into its socket interface and receives HTTP response messages from its socket interface. Similarly, the HTTP server receives request messages from its socket interface and sends response messages into its socket interface. Once the client sends a message into its socket interface, the message is out of the client’s hands and is “in the hands” of TCP. Recall from Section 2.1 that TCP provides a reliable data transfer service to HTTP. This implies that each HTTP request message sent by a client process eventually arrives intact at the server; similarly, each HTTP response message sent by the server process eventually arrives intact at the client. Here we see one of the great advantages of a layered architecture—HTTP need not worry about lost data or the details of how TCP recovers from loss or reordering of data within the network. That is the job of TCP and the protocols in the lower layers of the protocol stack.</span></p>
<p><span class="font53">It is important to note that the server sends requested files to clients without storing any state information about the client. If a particular client asks for the same object twice in a period of a few seconds, the server does not respond by saying that it just served the object to the client; instead, the server resends the object, as it has completely forgotten what it did earlier. Because an HTTP server maintains no information about the clients, HTTP is said to be a </span><span class="font53" style="font-weight:bold;">stateless protocol</span><span class="font53">. We also remark that the Web uses the client-server application architecture, as described in Section 2.1. A Web server is always on, with a fixed IP address, and it services requests from potentially millions of different browsers.</span></p>
<p><span class="font53">The original version of HTTP is called HTTP/1.0 and dates back to the early 1990’s [RFC 1945]. As of 2020, the majority of HTTP transactions take place over HTTP/1.1 [RFC 7230]. However, increasingly browsers and Web servers also support a new version of HTTP called HTTP/2 [RFC 7540]. At the end of this section, we’ll provide an introduction to HTTP/2.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">2.2.2 </span><span class="font23" style="font-weight:bold;">Non-Persistent and Persistent Connections</span></p></li></ul>
<p><span class="font53">In many Internet applications, the client and server communicate for an extended period of time, with the client making a series of requests and the server responding to each of the requests. Depending on the application and on how the application is being used, the series of requests may be made back-to-back, periodically at regular intervals, or intermittently. When this client-server interaction is taking place over TCP, the application developer needs to make an important decision—should each request/response pair be sent over a </span><span class="font53" style="font-style:italic;">separate</span><span class="font53"> TCP connection, or should all of the requests and their corresponding responses be sent over the </span><span class="font53" style="font-style:italic;">same</span><span class="font53"> TCP connection? In the former approach, the application is said to use </span><span class="font53" style="font-weight:bold;">non-persistent connections</span><span class="font53">; and in the latter approach, </span><span class="font53" style="font-weight:bold;">persistent connections</span><span class="font53">. To gain a deep understanding of this design issue, let’s examine the advantages and disadvantages of persistent connections in the context of a specific application, namely, HTTP, which can use both non-persistent connections and persistent connections. Although HTTP uses persistent connections in its default mode, HTTP clients and servers can be configured to use non-persistent connections instead.</span></p>
<p><span class="font22" style="font-weight:bold;">HTTP with Non-Persistent Connections</span></p>
<p><span class="font53">Let’s walk through the steps of transferring a Web page from server to client for the case of non-persistent connections. Let’s suppose the page consists of a base HTML file and 10 JPEG images, and that all 11 of these objects reside on the same server. Further suppose the URL for the base HTML file is</span></p>
<p><a href="http://www.someSchool.edu/someDepartment/home.index"><span class="font36">http://www.someSchool.edu/someDepartment/home.index</span></a></p>
<p><span class="font53">Here is what happens:</span></p>
<ul style="list-style:none;"><li>
<p><a name="bookmark53"></a><span class="font53">1. The HTTP client process initiates a TCP connection to the server </span><a href="http://www.someSchool.edu"><span class="font36">www.someSchool.edu </span></a><span class="font53">on port number 80, which is the default port number for HTTP. Associated with the TCP connection, there will be a socket at the client and a socket at the server.</span></p></li>
<li>
<p><span class="font53">2. The HTTP client sends an HTTP request message to the server via its socket.</span></p></li></ul>
<p><span class="font53">The request message includes the path name </span><span class="font36">/someDepartment/home .index</span><span class="font53">. (We will discuss HTTP messages in some detail below.)</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">3. The HTTP server process receives the request message via its socket, retrieves the object </span><span class="font36">/someDepartment/home.index </span><span class="font53">from its storage (RAM or disk), encapsulates the object in an HTTP response message, and sends the response message to the client via its socket.</span></p></li>
<li>
<p><span class="font53">4. The HTTP server process tells TCP to close the TCP connection. (But TCP doesn’t actually terminate the connection until it knows for sure that the client has received the response message intact.)</span></p></li>
<li>
<p><span class="font53">5. The HTTP client receives the response message. The TCP connection terminates. The message indicates that the encapsulated object is an HTML file. The client extracts the file from the response message, examines the HTML file, and finds references to the 10 JPEG objects.</span></p></li>
<li>
<p><span class="font53">6. The first four steps are then repeated for each of the referenced JPEG objects.</span></p></li></ul>
<p><span class="font53">As the browser receives the Web page, it displays the page to the user. Two different browsers may interpret (that is, display to the user) a Web page in somewhat different ways. HTTP has nothing to do with how a Web page is interpreted by a client. The HTTP specifications ([RFC 1945] and [RFC 7540]) define only the communication protocol between the client HTTP program and the server HTTP program.</span></p>
<p><span class="font53">The steps above illustrate the use of non-persistent connections, where each TCP connection is closed after the server sends the object—the connection does not persist for other objects. HTTP/1.0 employes non-persistent TCP connections. Note that each non-persistent TCP connection transports exactly one request message and one response message. Thus, in this example, when a user requests the Web page, 11 TCP connections are generated.</span></p>
<p><span class="font53">In the steps described above, we were intentionally vague about whether the client obtains the 10 JPEGs over 10 serial TCP connections, or whether some of the JPEGs are obtained over parallel TCP connections. Indeed, users can configure some browsers to control the degree of parallelism. Browsers may open multiple TCP connections and request different parts of the Web page over the multiple connections. As we’ll see in the next chapter, the use of parallel connections shortens the response time.</span></p>
<p><span class="font53">Before continuing, let’s do a back-of-the-envelope calculation to estimate the amount of time that elapses from when a client requests the base HTML file until the entire file is received by the client. To this end, we define the </span><span class="font53" style="font-weight:bold;">round-trip time (RTT)</span><span class="font53">, which is the time it takes for a small packet to travel from client to server and then back to the client. The RTT includes packet-propagation delays, packetqueuing delays in intermediate routers and switches, and packet-processing delays. (These delays were discussed in Section 1.4.) Now consider what happens when a user clicks on a hyperlink. As shown in Figure 2.7, this causes the browser to initiate a TCP connection between the browser and the Web server; this involves</span></p>
<div><img src="networking_files/networking-76.jpg" alt="" style="width:34pt;height:37pt;">
</div><br clear="all">
<div><img src="networking_files/networking-77.jpg" alt="" style="width:20pt;height:39pt;">
</div><br clear="all">
<div>
<p><span class="font4">Initiate TCP</span></p><img src="networking_files/networking-78.jpg" alt="" style="width:252pt;height:174pt;">
<p><span class="font4">Time to transmit file</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Time at client</span></p>
</div><br clear="all">
<p><span class="font4">Time at server</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 2.7 </span><span class="font50">♦ </span><span class="font5">Back-of-the-envelope calculation for the time needed to request and receive an HTML file</span></p>
<p><span class="font53">a “three-way handshake”—the client sends a small TCP segment to the server, the server acknowledges and responds with a small TCP segment, and, finally, the client acknowledges back to the server. The first two parts of the three-way handshake take one RTT. After completing the first two parts of the handshake, the client sends the HTTP request message combined with the third part of the three-way handshake (the acknowledgment) into the TCP connection. Once the request message arrives at the server, the server sends the HTML file into the TCP connection. This HTTP request/response eats up another RTT. Thus, roughly, the total response time is two RTTs plus the transmission time at the server of the HTML file.</span></p>
<p><span class="font22" style="font-weight:bold;">HTTP with Persistent Connections</span></p>
<p><span class="font53">Non-persistent connections have some shortcomings. First, a brand-new connection must be established and maintained for </span><span class="font53" style="font-style:italic;">each requested object.</span><span class="font53"> For each of these connections, TCP buffers must be allocated and TCP variables must be kept in both the client and server. This can place a significant burden on the Web server, which may be serving requests from hundreds of different clients simultaneously. Second, as we just described, each object suffers a delivery delay of two RTTs—one RTT to establish the TCP connection and one RTT to request and receive an object.</span></p>
<p><span class="font53">With HTTP/1.1 persistent connections, the server leaves the TCP connection open after sending a response. Subsequent requests and responses between the same client and server can be sent over the same connection. In particular, an entire Web page (in the example above, the base HTML file and the 10 images) can be sent over a single persistent TCP connection. Moreover, multiple Web pages residing on the same server can be sent from the server to the same client over a single persistent TCP connection. These requests for objects can be made back-to-back, without waiting for replies to pending requests (pipelining). Typically, the HTTP server closes a connection when it isn’t used for a certain time (a configurable timeout interval). When the server receives the back-to-back requests, it sends the objects back-to-back. The default mode of HTTP uses persistent connections with pipelining. We’ll quantitatively compare the performance of non-persistent and persistent connections in the homework problems of Chapters 2 and 3. You are also encouraged to see [Heidemann 1997; Nielsen 1997; RFC 7540].</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">2.2.3 </span><span class="font23" style="font-weight:bold;">HTTP Message Format</span></p></li></ul>
<p><span class="font53">The HTTP specifications [RFC 1945; RFC 7230; RFC 7540] include the definitions of the HTTP message formats. There are two types of HTTP messages, request messages and response messages, both of which are discussed below.</span></p>
<p><span class="font22" style="font-weight:bold;">HTTP Request Message</span></p>
<p><span class="font53">Below we provide a typical HTTP request message:</span></p>
<p><span class="font36">GET /somedir/page.html HTTP/1.1</span></p>
<p><span class="font36">Host: </span><a href="http://www.someschool.edu"><span class="font36">www.someschool.edu</span></a></p>
<p><span class="font36">Connection: close</span></p>
<p><span class="font36">User-agent: Mozilla/5.0 Accept-language: fr</span></p>
<p><a name="bookmark54"></a><span class="font53">We can learn a lot by taking a close look at this simple request message. First of all, we see that the message is written in ordinary ASCII text, so that your ordinary computer-literate human being can read it. Second, we see that the message consists of five lines, each followed by a carriage return and a line feed. The last line is followed by an additional carriage return and line feed. Although this particular request message has five lines, a request message can have many more lines or as few as one line. The first line of an HTTP request message is called the </span><span class="font53" style="font-weight:bold;">request line</span><span class="font53">; the subsequent lines are called the </span><span class="font53" style="font-weight:bold;">header lines</span><span class="font53">. The request line has three fields: the method field, the URL field, and the HTTP version field. The method field can take on several different values, including </span><span class="font36">GET, POST, HEAD, PUT, </span><span class="font53">and </span><span class="font36">DELETE</span><span class="font53">.</span></p>
<p><span class="font53">The great majority of HTTP request messages use the </span><span class="font36">GET </span><span class="font53">method. The </span><span class="font36">GET </span><span class="font53">method is used when the browser requests an object, with the requested object identified in the URL field. In this example, the browser is requesting the object </span><span class="font36">/somedir/ page.html</span><span class="font53">. The version is self-explanatory; in this example, the browser implements version HTTP/1.1.</span></p>
<p><span class="font53">Now let’s look at the header lines in the example. The header line </span><span class="font36">Host: </span><a href="http://www.someschool.edu"><span class="font36">www.someschool.edu </span></a><span class="font53">specifies the host on which the object resides. You might think that this header line is unnecessary, as there is already a TCP connection in place to the host. But, as we’ll see in Section 2.2.5, the information provided by the host header line is required by Web proxy caches. By including the </span><span class="font36">Connection: close </span><span class="font53">header line, the browser is telling the server that it doesn’t want to bother with persistent connections; it wants the server to close the connection after sending the requested object. The </span><span class="font36">User-agent: </span><span class="font53">header line specifies the user agent, that is, the browser type that is making the request to the server. Here the user agent is Mozilla/5.0, a Firefox browser. This header line is useful because the server can actually send different versions of the same object to different types of user agents. (Each of the versions is addressed by the same URL.) Finally, the </span><span class="font36">Accept-language: </span><span class="font53">header indicates that the user prefers to receive a French version of the object, if such an object exists on the server; otherwise, the server should send its default version. The </span><span class="font36">Accept-language: </span><span class="font53">header is just one of many content negotiation headers available in HTTP.</span></p>
<p><span class="font53">Having looked at an example, let’s now look at the general format of a request message, as shown in Figure 2.8. We see that the general format closely follows our earlier example. You may have noticed, however, that after the header lines (and the additional carriage return and line feed) there is an “entity body.” The entity body is empty with the </span><span class="font36">GET </span><span class="font53">method, but is used with the </span><span class="font36">POST </span><span class="font53">method. An HTTP client often uses the </span><span class="font36">POST </span><span class="font53">method when the user fills out a form—for example, when a user provides search words to a search engine. With a </span><span class="font36">POST </span><span class="font53">message, the user is still requesting a Web page from the server, but the specific contents of the Web page depend on what the user entered into the form fields. If the value of the method field is </span><span class="font36">POST</span><span class="font53">, then the entity body contains what the user entered into the form fields.</span></p>
<div>
<p><span class="font4">Blank line</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Entity body</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Request line</span></p>
<p><span class="font4">Header lines</span></p><img src="networking_files/networking-79.jpg" alt="" style="width:232pt;height:143pt;">
<p><span class="font7" style="font-weight:bold;">Figure 2.8 </span><span class="font50">♦ </span><span class="font5">General format of an HTTP request message</span></p>
</div><br clear="all">
<p><span class="font53">We would be remiss if we didn’t mention that a request generated with a form does not necessarily have to use the </span><span class="font36">POST </span><span class="font53">method. Instead, HTML forms often use the </span><span class="font36">GET </span><span class="font53">method and include the inputted data (in the form fields) in the requested URL. For example, if a form uses the </span><span class="font36">GET </span><span class="font53">method, has two fields, and the inputs to the two fields are </span><span class="font36">monkeys </span><span class="font53">and </span><span class="font36">bananas</span><span class="font53">, then the URL will have the structure </span><a href="http://www.somesite.com/animalsearch?monkeys&amp;bananas"><span class="font36">www.somesite.com/animalsearch?monkeys&amp;bananas</span></a><span class="font53">. In your day-to-day Web surfing, you have probably noticed extended URLs of this sort.</span></p>
<p><span class="font53">The </span><span class="font36">HEAD </span><span class="font53">method is similar to the </span><span class="font36">GET </span><span class="font53">method. When a server receives a request with the </span><span class="font36">HEAD </span><span class="font53">method, it responds with an HTTP message but it leaves out the requested object. Application developers often use the </span><span class="font36">HEAD </span><span class="font53">method for debugging. The </span><span class="font36">PUT </span><span class="font53">method is often used in conjunction with Web publishing tools. It allows a user to upload an object to a specific path (directory) on a specific Web server. The </span><span class="font36">PUT </span><span class="font53">method is also used by applications that need to upload objects to Web servers. The </span><span class="font36">DELETE </span><span class="font53">method allows a user, or an application, to delete an object on a Web server.</span></p>
<p><span class="font22" style="font-weight:bold;">HTTP Response Message</span></p>
<p><span class="font53">Below we provide a typical HTTP response message. This response message could be the response to the example request message just discussed.</span></p>
<p><span class="font36">HTTP/1.1 200 OK</span></p>
<p><span class="font36">Connection: close</span></p>
<p><span class="font36">Date: Tue, 18 Aug 2015 15:44:04 GMT</span></p>
<p><span class="font36">Server: Apache/2.2.3 (CentOS)</span></p>
<p><span class="font36">Last-Modified: Tue, 18 Aug 2015 15:11:03 GMT Content-Length: 6821</span></p>
<p><span class="font36">Content-Type: text/html</span></p>
<p><span class="font36">(data data data data data ...)</span></p>
<p><span class="font53">Let’s take a careful look at this response message. It has three sections: an initial </span><span class="font53" style="font-weight:bold;">status line</span><span class="font53">, six </span><span class="font53" style="font-weight:bold;">header lines</span><span class="font53">, and then the </span><span class="font53" style="font-weight:bold;">entity body</span><span class="font53">. The entity body is the meat of the message—it contains the requested object itself (represented by </span><span class="font36">data data data data data ...</span><span class="font53">). The status line has three fields: the protocol version field, a status code, and a corresponding status message. In this example, the status line indicates that the server is using HTTP/1.1 and that everything is OK (that is, the server has found, and is sending, the requested object).</span></p>
<p><span class="font53">Now let’s look at the header lines. The server uses the </span><span class="font36">Connection: close </span><span class="font53">header line to tell the client that it is going to close the TCP connection after sending the message. The </span><span class="font36">Date: </span><span class="font53">header line indicates the time and date when the HTTP response was created and sent by the server. Note that this is not the time when the object was created or last modified; it is the time when the server retrieves the object from its file system, inserts the object into the response message, and sends the response message. The </span><span class="font36">Server: </span><span class="font53">header line indicates that the message was generated by an Apache Web server; it is analogous to the </span><span class="font36">User-agent: </span><span class="font53">header line in the HTTP request message. The </span><span class="font36">Last-Modified: </span><span class="font53">header line indicates the time and date when the object was created or last modified. The </span><span class="font36">Last-Modified: </span><span class="font53">header, which we will soon cover in more detail, is critical for object caching, both in the local client and in network cache servers (also known as proxy servers). The </span><span class="font36">Content-Length: </span><span class="font53">header line indicates the number of bytes in the object being sent. The </span><span class="font36">Content-Type: </span><span class="font53">header line indicates that the object in the entity body is HTML text. (The object type is officially indicated by the </span><span class="font36">Content-Type: </span><span class="font53">header and not by the file extension.)</span></p>
<p><span class="font53">Having looked at an example, let’s now examine the general format of a response message, which is shown in Figure 2.9. This general format of the response message matches the previous example of a response message. Let’s say a few additional words about status codes and their phrases. The status code and associated phrase indicate the result of the request. Some common status codes and associated phrases include:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font36">2 00 OK: </span><span class="font53">Request succeeded and the information is returned in the response.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font36">301 Moved Permanently: </span><span class="font53">Requested object has been permanently moved; the new URL is specified in </span><span class="font36">Location</span><span class="font53">: header of the response message. The client software will automatically retrieve the new URL.</span></p></li></ul><img src="networking_files/networking-80.jpg" alt="" style="width:295pt;height:143pt;">
<p><span class="font7" style="font-weight:bold;">Figure 2.9 </span><span class="font50">♦ </span><span class="font5">General format of an HTTP response message</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font36">400 Bad Request: </span><span class="font53">This is a generic error code indicating that the request could not be understood by the server.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font36">4 04 Not Found: </span><span class="font53">The requested document does not exist on this server.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font36">505 HTTP Version Not Supported: </span><span class="font53">The requested HTTP protocol version is not supported by the server.</span></p></li></ul>
<p><span class="font53">How would you like to see a real HTTP response message? This is highly recommended and very easy to do! First Telnet into your favorite Web server. Then type in a one-line request message for some object that is housed on the server. For example, if you have access to a command prompt, type:</span></p>
<div>
<p><span class="font16" style="font-weight:bold;">D</span></p>
<p><span class="font2" style="font-weight:bold;">VideoNote</span></p>
<p><span class="font1" style="font-weight:bold;">Using Wireshark to investigate the HTTP protocol</span></p>
</div><br clear="all">
<p><span class="font36">telnet </span><a href="http://gaia.cs.umass.edu"><span class="font36">gaia.cs.umass.edu </span></a><span class="font36">80</span></p>
<p><span class="font36">GET /kurose_ross/interactive/index.php HTTP/1.1</span></p>
<p><span class="font36">Host: </span><a href="http://gaia.cs.umass.edu"><span class="font36">gaia.cs.umass.edu</span></a></p>
<p><span class="font53">(Press the carriage return twice after typing the last line.) This opens a TCP connection to port 80 of the host </span><a href="http://gaia.cs.umass.edu"><span class="font36">gaia.cs.umass.edu </span></a><span class="font53">and then sends the HTTP request message. You should see a response message that includes the base HTML file for the interactive homework problems for this textbook. If you’d rather just see the HTTP message lines and not receive the object itself, replace </span><span class="font36">GET </span><span class="font53">with </span><span class="font36">HEAD</span><span class="font53">.</span></p>
<p><span class="font53">In this section, we discussed a number of header lines that can be used within HTTP request and response messages. The HTTP specification defines many, many more header lines that can be inserted by browsers, Web servers, and network cache servers. We have covered only a small number of the totality of header lines. We’ll cover a few more below and another small number when we discuss network Web caching in Section 2.2.5. A highly readable and comprehensive discussion of the HTTP protocol, including its headers and status codes, is given in [Krishnamurthy 2001].</span></p>
<p><span class="font53">How does a browser decide which header lines to include in a request message? How does a Web server decide which header lines to include in a response message? A browser will generate header lines as a function of the browser type and version, the user configuration of the browser and whether the browser currently has a cached, but possibly out-of-date, version of the object. Web servers behave similarly: There are different products, versions, and configurations, all of which influence which header lines are included in response messages.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">2.2.4 </span><span class="font23" style="font-weight:bold;">User-Server Interaction: Cookies</span></p></li></ul>
<p><a name="bookmark55"></a><span class="font53">We mentioned above that an HTTP server is stateless. This simplifies server design and has permitted engineers to develop high-performance Web servers that can handle thousands of simultaneous TCP connections. However, it is often desirable for a Web site to identify users, either because the server wishes to restrict user access or because it wants to serve content as a function of the user identity. For these purposes, HTTP uses cookies. Cookies, defined in [RFC 6265], allow sites to keep track of users. Most major commercial Web sites use cookies today.</span></p>
<p><span class="font53">As shown in Figure 2.10, cookie technology has four components: (1) a cookie header line in the HTTP response message; (2) a cookie header line in the HTTP request message; (3) a cookie file kept on the user’s end system and managed by the user’s browser; and (4) a back-end database at the Web site. Using Figure 2.10, let’s walk through an example of how cookies work. Suppose Susan, who always</span></p>
<div>
<p><span class="font4" style="font-weight:bold;">Client host</span></p>
<p><span class="font4" style="font-weight:bold;">Server host</span></p>
<p><span class="font4">ebay: 8734</span></p>
<p><span class="font4">One week later—</span></p><img src="networking_files/networking-81.jpg" alt="" style="width:223pt;height:306pt;">
<p><span class="font4">---Server creates</span></p>
<p><span class="font4">ID 1678 for user</span></p>
<p><span class="font4">access</span></p>
<p><span class="font4">---Cookie-specific ◄--------</span></p>
<p><span class="font4">action</span></p>
<p><span class="font4">amazon: 1678 ebay: 8734</span></p>
<p><span class="font4">Time</span></p>
<p><span class="font4">Time</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-82.jpg" alt="" style="width:23pt;height:25pt;">
</div><br clear="all">
<div>
<p><span class="font4">amazon: 1678 ebay: 8734</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-83.jpg" alt="" style="width:48pt;height:48pt;">
<p><span class="font4">entry in backend database</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Key:</span></p><img src="networking_files/networking-84.jpg" alt="" style="width:17pt;height:18pt;">
<p><span class="font41">Cookie file</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-85.jpg" alt="" style="width:160pt;height:83pt;">
<p><span class="font4">----Cookie-specific</span></p>
<p><span class="font4">action</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-86.jpg" alt="" style="width:75pt;height:107pt;">
<p><span class="font4">access</span></p>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 2.10 </span><span class="font50">♦ </span><span class="font5">Keeping user state with cookies</span></p>
<p><span class="font53">accesses the Web using Internet Explorer from her home PC, contacts </span><a href="http://Amazon.com"><span class="font53">Amazon.com</span></a><span class="font53"> for the first time. Let us suppose that in the past she has already visited the eBay site. When the request comes into the Amazon Web server, the server creates a unique identification number and creates an entry in its back-end database that is indexed by the identification number. The Amazon Web server then responds to Susan’s browser, including in the HTTP response a </span><span class="font36">Set-cookie: </span><span class="font53">header, which contains the identification number. For example, the header line might be:</span></p>
<p><span class="font36">Set-cookie: 1678</span></p>
<p><span class="font53">When Susan’s browser receives the HTTP response message, it sees the </span><span class="font36">Set-cookie: </span><span class="font53">header. The browser then appends a line to the special cookie file that it manages. This line includes the hostname of the server and the identification number in the </span><span class="font36">Set-cookie: </span><span class="font53">header. Note that the cookie file already has an entry for eBay, since Susan has visited that site in the past. As Susan continues to browse the Amazon site, each time she requests a Web page, her browser consults her cookie file, extracts her identification number for this site, and puts a cookie header line that includes the identification number in the HTTP request. Specifically, each of her HTTP requests to the Amazon server includes the header line:</span></p>
<p><span class="font36">Cookie: 1678</span></p>
<p><span class="font53">In this manner, the Amazon server is able to track Susan’s activity at the Amazon site. Although the Amazon Web site does not necessarily know Susan’s name, it knows exactly which pages user 1678 visited, in which order, and at what times! Amazon uses cookies to provide its shopping cart service—Amazon can maintain a list of all of Susan’s intended purchases, so that she can pay for them collectively at the end of the session.</span></p>
<p><span class="font53">If Susan returns to Amazon’s site, say, one week later, her browser will continue to put the header line </span><span class="font36">Cookie: 167 8 </span><span class="font53">in the request messages. Amazon also recommends products to Susan based on Web pages she has visited at Amazon in the past. If Susan also registers herself with Amazon—providing full name, e-mail address, postal address, and credit card information—Amazon can then include this information in its database, thereby associating Susan’s name with her identification number (and all of the pages she has visited at the site in the past!). This is how Amazon and other e-commerce sites provide “one-click shopping”—when Susan chooses to purchase an item during a subsequent visit, she doesn’t need to re-enter her name, credit card number, or address.</span></p>
<p><span class="font53">From this discussion, we see that cookies can be used to identify a user. The first time a user visits a site, the user can provide a user identification (possibly his or her name). During the subsequent sessions, the browser passes a cookie header to the server, thereby identifying the user to the server. Cookies can thus be used to create a user session layer on top of stateless HTTP. For example, when a user logs in to a Web-based e-mail application (such as Hotmail), the browser sends cookie information to the server, permitting the server to identify the user throughout the user’s session with the application.</span></p>
<p><span class="font53">Although cookies often simplify the Internet shopping experience for the user, they are controversial because they can also be considered as an invasion of privacy. As we just saw, using a combination of cookies and user-supplied account information, a Web site can learn a lot about a user and potentially sell this information to a third party.</span></p>
<p><span class="font56" style="font-weight:bold;">2.2.5 </span><span class="font23" style="font-weight:bold;">Web Caching</span></p>
<p><span class="font53">A </span><span class="font53" style="font-weight:bold;">Web cache—</span><span class="font53">also called a </span><span class="font53" style="font-weight:bold;">proxy server—</span><span class="font53">is a network entity that satisfies HTTP requests on the behalf of an origin Web server. The Web cache has its own disk storage and keeps copies of recently requested objects in this storage. As shown in Figure 2.11, a user’s browser can be configured so that all of the user’s HTTP requests are first directed to the Web cache [RFC 7234]. Once a browser is configured, each browser request for an object is first directed to the Web cache. As an example, suppose a browser is requesting the object</span><a href="http://www.someschool.edu/campus.gif"><span class="font53"> </span><span class="font36">http://www.someschool.edu/</span></a><span class="font36"> </span><a href="http://www.someschool.edu/campus.gif"><span class="font36">campus.gif</span></a><span class="font53">. Here is what happens:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">1. The browser establishes a TCP connection to the Web cache and sends an HTTP request for the object to the Web cache.</span></p></li>
<li>
<p><span class="font53">2. The Web cache checks to see if it has a copy of the object stored locally. If it does, the Web cache returns the object within an HTTP response message to the client browser.</span></p></li>
<li>
<p><span class="font53">3. If the Web cache does not have the object, the Web cache opens a TCP connection to the origin server, that is, to </span><a href="http://www.someschool.edu"><span class="font36">www.someschool.edu</span></a><span class="font53">. The Web cache</span></p></li></ul><img src="networking_files/networking-87.jpg" alt="" style="width:213pt;height:141pt;">
<p><span class="font4">server</span></p>
<p><a name="bookmark56"></a><span class="font7" style="font-weight:bold;">Figure 2.11 </span><span class="font50">♦ </span><span class="font5">Clients requesting objects through a Web cache</span></p>
<p><span class="font53">then sends an HTTP request for the object into the cache-to-server TCP connection. After receiving this request, the origin server sends the object within an HTTP response to the Web cache.</span></p>
<ul style="list-style:none;"><li>
<p class="font53">4. When the Web cache receives the object, it stores a copy in its local storage and sends a copy, within an HTTP response message, to the client browser (over the existing TCP connection between the client browser and the Web cache).</p></li></ul>
<p><span class="font53">Note that a cache is both a server and a client at the same time. When it receives requests from and sends responses to a browser, it is a server. When it sends requests to and receives responses from an origin server, it is a client.</span></p>
<p><span class="font53">Typically a Web cache is purchased and installed by an ISP. For example, a university might install a cache on its campus network and configure all of the campus browsers to point to the cache. Or a major residential ISP (such as Comcast) might install one or more caches in its network and preconfigure its shipped browsers to point to the installed caches.</span></p>
<p><span class="font53">Web caching has seen deployment in the Internet for two reasons. First, a Web cache can substantially reduce the response time for a client request, particularly if the bottleneck bandwidth between the client and the origin server is much less than the bottleneck bandwidth between the client and the cache. If there is a high-speed connection between the client and the cache, as there often is, and if the cache has the requested object, then the cache will be able to deliver the object rapidly to the client. Second, as we will soon illustrate with an example, Web caches can substantially reduce traffic on an institution’s access link to the Internet. By reducing traffic, the institution (for example, a company or a university) does not have to upgrade bandwidth as quickly, thereby reducing costs. Furthermore, Web caches can substantially reduce Web traffic in the Internet as a whole, thereby improving performance for all applications.</span></p>
<p><span class="font53">To gain a deeper understanding of the benefits of caches, let’s consider an example in the context of Figure 2.12. This figure shows two networks—the institutional network and the rest of the public Internet. The institutional network is a high-speed LAN. A router in the institutional network and a router in the Internet are connected by a 15 Mbps link. The origin servers are attached to the Internet but are located all over the globe. Suppose that the average object size is 1 Mbits and that the average request rate from the institution’s browsers to the origin servers is 15 requests per second. Suppose that the HTTP request messages are negligibly small and thus create no traffic in the networks or in the access link (from institutional router to Internet router). Also suppose that the amount of time it takes from when the router on the Internet side of the access link in Figure 2.12 forwards an HTTP request (within an IP datagram) until it receives the response (typically within many IP datagrams) is two seconds on average. Informally, we refer to this last delay as the “Internet delay.”</span></p>
<p><span class="font53">The total response time—that is, the time from the browser’s request of an object until its receipt of the object—is the sum of the LAN delay, the access delay (that is, the delay between the two routers), and the Internet delay. Let’s now do</span></p>
<p><span class="font4">Origin servers</span></p><img src="networking_files/networking-88.jpg" alt="" style="width:182pt;height:64pt;">
<p><span class="font4" style="font-weight:bold;">Public Internet</span></p><img src="networking_files/networking-89.jpg" alt="" style="width:28pt;height:22pt;">
<p><span class="font4">15 Mbps access link</span></p><img src="networking_files/networking-90.jpg" alt="" style="width:164pt;height:104pt;">
<p><span class="font4" style="font-weight:bold;">Institutional network</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 2.12 </span><span class="font50">♦ </span><span class="font5">Bottleneck between an institutional network and the Internet</span></p>
<p><span class="font53">a very crude calculation to estimate this delay. The traffic intensity on the LAN (see Section 1.4.2) is</span></p>
<p><span class="font53">(15 requests/sec) </span><span class="font60">• </span><span class="font53">(1 Mbits/request)/(100 Mbps) </span><span class="font54">= </span><span class="font53">0.15</span></p>
<p><span class="font53">whereas the traffic intensity on the access link (from the Internet router to institution router) is</span></p>
<p><span class="font53">(15 requests/sec) </span><span class="font12"><sup>•</sup> </span><span class="font53">(1 Mbits/request)/(15 Mbps) </span><span class="font54">= </span><span class="font53">1</span></p>
<p><span class="font53">A traffic intensity of 0.15 on a LAN typically results in, at most, tens of milliseconds of delay; hence, we can neglect the LAN delay. However, as discussed in Section 1.4.2, as the traffic intensity approaches 1 (as is the case of the access link in Figure 2.12), the delay on a link becomes very large and grows without bound. Thus, the average response time to satisfy requests is going to be on the order of minutes, if not more, which is unacceptable for the institution’s users. Clearly something must be done.</span></p>
<p><span class="font53">One possible solution is to increase the access rate from 15 Mbps to, say, 100 Mbps. This will lower the traffic intensity on the access link to 0.15, which translates to negligible delays between the two routers. In this case, the total response time will roughly be two seconds, that is, the Internet delay. But this solution also means that the institution must upgrade its access link from 15 Mbps to 100 Mbps, a costly proposition.</span></p>
<p><span class="font53">Now consider the alternative solution of not upgrading the access link but instead installing a Web cache in the institutional network. This solution is illustrated in Figure 2.13. Hit rates—the fraction of requests that are satisfied by a cache— typically range from 0.2 to 0.7 in practice. For illustrative purposes, let’s suppose that the cache provides a hit rate of 0.4 for this institution. Because the clients and the cache are connected to the same high-speed LAN, 40 percent of the requests will be satisfied almost immediately, say, within 10 milliseconds, by the cache. Nevertheless, the remaining 60 percent of the requests still need to be satisfied by the origin servers. But with only 60 percent of the requested objects passing through the access link, the traffic intensity on the access link is reduced from 1.0 to 0.6. Typically, a</span></p>
<p><span class="font4">Origin servers</span></p><img src="networking_files/networking-91.jpg" alt="" style="width:182pt;height:64pt;">
<p><span class="font4" style="font-weight:bold;">Public Internet</span></p><img src="networking_files/networking-92.jpg" alt="" style="width:28pt;height:22pt;">
<p><span class="font4">15 Mbps access link</span></p><img src="networking_files/networking-93.jpg" alt="" style="width:226pt;height:115pt;">
<p><span class="font4">Institutional</span></p>
<p><span class="font4" style="font-weight:bold;">Institutional network &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font4">cache</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 2.13 </span><span class="font50">♦ </span><span class="font5">Adding a cache to the institutional network</span></p>
<p><span class="font53">traffic intensity less than 0.8 corresponds to a small delay, say, tens of milliseconds, on a 15 Mbps link. This delay is negligible compared with the two-second Internet delay. Given these considerations, average delay therefore is</span></p>
<p><span class="font53">0.4 </span><span class="font60">• </span><span class="font53">(0.01 seconds) </span><span class="font55">+ </span><span class="font53">0.6 </span><span class="font60">• </span><span class="font53">(2.01 seconds)</span></p>
<p><span class="font53">which is just slightly greater than 1.2 seconds. Thus, this second solution provides an even lower response time than the first solution, and it doesn’t require the institution to upgrade its link to the Internet. The institution does, of course, have to purchase and install a Web cache. But this cost is low—many caches use public-domain software that runs on inexpensive PCs.</span></p>
<p><span class="font53">Through the use of </span><span class="font53" style="font-weight:bold;">Content Distribution Networks (CDNs)</span><span class="font53">, Web caches are increasingly playing an important role in the Internet. A CDN company installs many geographically distributed caches throughout the Internet, thereby localizing much of the traffic. There are shared CDNs (such as Akamai and Limelight) and dedicated CDNs (such as Google and Netflix). We will discuss CDNs in more detail in Section 2.6.</span></p>
<p><span class="font22" style="font-weight:bold;">The Conditional GET</span></p>
<p><span class="font53">Although caching can reduce user-perceived response times, it introduces a new problem—the copy of an object residing in the cache may be stale. In other words, the object housed in the Web server may have been modified since the copy was cached at the client. Fortunately, HTTP has a mechanism that allows a cache to verify that its objects are up to date. This mechanism is called the </span><span class="font53" style="font-weight:bold;">conditional GET </span><span class="font53">[RFC 7232]. An HTTP request message is a so-called conditional GET message if (1) the request message uses the </span><span class="font36">GET </span><span class="font53">method and (2) the request message includes an </span><span class="font36">If-Modified-Since: </span><span class="font53">header line.</span></p>
<p><span class="font53">To illustrate how the conditional GET operates, let’s walk through an example. First, on the behalf of a requesting browser, a proxy cache sends a request message to a Web server:</span></p>
<p><span class="font36">GET /fruit/kiwi.gif HTTP/1.1</span></p>
<p><span class="font36">Host:</span><a href="http://www.exotiquecuisine.com"><span class="font36"> www.exotiquecuisine.com</span></a></p>
<p><span class="font53">Second, the Web server sends a response message with the requested object to the cache:</span></p>
<p><span class="font36">HTTP/1.1 200 OK</span></p>
<p><span class="font36">Date: Sat, 3 Oct 2015 15:39:29</span></p>
<p><span class="font36">Server: Apache/1.3.0 (Unix)</span></p>
<p><span class="font36">Last-Modified: Wed, 9 Sep 2015 09:23:24</span></p>
<p><span class="font36">Content-Type: image/gif</span></p>
<p><span class="font36">(data data data data data ...)</span></p>
<p><span class="font53">The cache forwards the object to the requesting browser but also caches the object locally. Importantly, the cache also stores the last-modified date along with the object. Third, one week later, another browser requests the same object via the cache, and the object is still in the cache. Since this object may have been modified at the Web server in the past week, the cache performs an up-to-date check by issuing a conditional GET. Specifically, the cache sends:</span></p>
<p><span class="font36">GET /fruit/kiwi.gif HTTP/1.1</span></p>
<p><span class="font36">Host: </span><a href="http://www.exotiquecuisine.com"><span class="font36">www.exotiquecuisine.com</span></a></p>
<p><span class="font36">If-modified-since: Wed, 9 Sep 2015 09:23:24</span></p>
<p><span class="font53">Note that the value of the </span><span class="font36">If-modified-since: </span><span class="font53">header line is exactly equal to the value of the </span><span class="font36">Last-Modified: </span><span class="font53">header line that was sent by the server one week ago. This conditional GET is telling the server to send the object only if the object has been modified since the specified date. Suppose the object has not been modified since 9 Sep 2015 09:23:24. Then, fourth, the Web server sends a response message to the cache:</span></p>
<p><span class="font36">HTTP/1.1 304 Not Modified</span></p>
<p><span class="font36">Date: Sat, 10 Oct 2015 15:39:29</span></p>
<p><span class="font36">Server: Apache/1.3.0 (Unix)</span></p>
<p><span class="font36">(empty entity body)</span></p>
<p><span class="font53">We see that in response to the conditional GET, the Web server still sends a response message but does not include the requested object in the response message. Including the requested object would only waste bandwidth and increase user-perceived response time, particularly if the object is large. Note that this last response message has </span><span class="font36">304 Not Modified </span><span class="font53">in the status line, which tells the cache that it can go ahead and forward its (the proxy cache’s) cached copy of the object to the requesting browser.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">2.2.6 </span><span class="font23" style="font-weight:bold;">HTTP/2</span></p></li></ul>
<p><span class="font53">HTTP/2 [RFC 7540], standardized in 2015, was the first new version of HTTP since HTTP/1.1, which was standardized in 1997. Since standardization, HTTP/2 has taken off, with over 40% of the top 10 million websites supporting HTTP/2 in 2020 [W3Techs]. Most browsers—including Google Chrome, Internet Explorer, Safari, Opera, and Firefox—also support HTTP/2.</span></p>
<p><a name="bookmark57"></a><span class="font53">The primary goals for HTTP/2 are to reduce perceived latency by enabling request and response multiplexing over a </span><span class="font53" style="font-style:italic;">single</span><span class="font53"> TCP connection, provide request prioritization and server push, and provide efficient compression of HTTP header fields. HTTP/2 does not change HTTP methods, status codes, URLs, or header fields. Instead, HTTP/2 changes how the data is formatted and transported between the client and server.</span></p>
<p><span class="font53">To motivate the need for HTTP/2, recall that HTTP/1.1 uses persistent TCP connections, allowing a Web page to be sent from server to client over a single TCP connection. By having only one TCP connection per Web page, the number of sockets at the server is reduced and each transported Web page gets a fair share of the network bandwidth (as discussed below). But developers of Web browsers quickly discovered that sending all the objects in a Web page over a single TCP connection has a </span><span class="font53" style="font-weight:bold;">Head of Line (HOL) blocking </span><span class="font53">problem. To understand HOL blocking, consider a Web page that includes an HTML base page, a large video clip near the top of Web page, and many small objects below the video. Further suppose there is a low-to-medium speed bottleneck link (for example, a low-speed wireless link) on the path between server and client. Using a single TCP connection, the video clip will take a long time to pass through the bottleneck link, while the small objects are delayed as they wait behind the video clip; that is, the video clip at the head of the line blocks the small objects behind it. HTTP/1.1 browsers typically work around this problem by opening multiple parallel TCP connections, thereby having objects in the same web page sent in parallel to the browser. This way, the small objects can arrive at and be rendered in the browser much faster, thereby reducing user-perceived delay.</span></p>
<p><span class="font53">TCP congestion control, discussed in detail in Chapter 3, also provides browsers an unintended incentive to use multiple parallel TCP connections rather than a single persistent connection. Very roughly speaking, TCP congestion control aims to give each TCP connection sharing a bottleneck link an equal share of the available bandwidth of that link; so if there are </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> TCP connections operating over a bottleneck link, then each connection approximately gets </span><span class="font53" style="font-style:italic;">1/nth</span><span class="font53"> of the bandwidth. By opening multiple parallel TCP connections to transport a single Web page, the browser can “cheat” and grab a larger portion of the link bandwidth. Many HTTP/1.1 browsers open up to six parallel TCP connections not only to circumvent HOL blocking but also to obtain more bandwidth.</span></p>
<p><span class="font53">One of the primary goals of HTTP/2 is to get rid of (or at least reduce the number of) parallel TCP connections for transporting a single Web page. This not only reduces the number of sockets that need to be open and maintained at servers, but also allows TCP congestion control to operate as intended. But with only one TCP connection to transport a Web page, HTTP/2 requires carefully designed mechanisms to avoid HOL blocking.</span></p>
<p><span class="font22" style="font-weight:bold;">HTTP/2 Framing</span></p>
<p><span class="font53">The HTTP/2 solution for HOL blocking is to break each message into small frames, and interleave the request and response messages on the same TCP connection. To understand this, consider again the example of a Web page consisting of one large video clip and, say, 8 smaller objects. Thus the server will receive 9 concurrent requests from any browser wanting to see this Web page. For each of these requests, the server needs to send 9 competing HTTP response messages to the browser. Suppose all frames are of fixed length, the video clip consists of 1000 frames, and each of the smaller objects consists of two frames. With frame interleaving, after sending one frame from the video clip, the first frames of each of the small objects are sent. Then after sending the second frame of the video clip, the last frames of each of the small objects are sent. Thus, all of the smaller objects are sent after sending a total of 18 frames. If interleaving were not used, the smaller objects would be sent only after sending 1016 frames. Thus the HTTP/2 framing mechanism can significantly decrease user-perceived delay.</span></p>
<p><span class="font53">The ability to break down an HTTP message into independent frames, interleave them, and then reassemble them on the other end is the single most important enhancement of HTTP/2. The framing is done by the framing sub-layer of the HTTP/2 protocol. When a server wants to send an HTTP response, the response is processed by the framing sub-layer, where it is broken down into frames. The header field of the response becomes one frame, and the body of the message is broken down into one for more additional frames. The frames of the response are then interleaved by the framing sub-layer in the server with the frames of other responses and sent over the single persistent TCP connection. As the frames arrive at the client, they are first reassembled into the original response messages at the framing sub-layer and then processed by the browser as usual. Similarly, a client’s HTTP requests are broken into frames and interleaved.</span></p>
<p><span class="font53">In addition to breaking down each HTTP message into independent frames, the framing sublayer also binary encodes the frames. Binary protocols are more efficient to parse, lead to slightly smaller frames, and are less error-prone.</span></p>
<p><span class="font22" style="font-weight:bold;">Response Message Prioritization and Server Pushing</span></p>
<p><span class="font53">Message prioritization allows developers to customize the relative priority of requests to better optimize application performance. As we just learned, the framing sub-layer organizes messages into parallel streams of data destined to the same requestor. When a client sends concurrent requests to a server, it can prioritize the responses it is requesting by assigning a weight between 1 and 256 to each message. The higher number indicates higher priority. Using these weights, the server can send first the frames for the responses with the highest priority. In addition to this, the client also states each message’s dependency on other messages by specifying the ID of the message on which it depends.</span></p>
<p><span class="font53">Another feature of HTTP/2 is the ability for a server to send multiple responses for a single client request. That is, in addition to the response to the original request, the server can </span><span class="font53" style="font-style:italic;">push</span><span class="font53"> additional objects to the client, without the client having to request each one. This is possible since the HTML base page indicates the objects that will be needed to fully render the Web page. So instead of waiting for the HTTP requests for these objects, the server can analyze the HTML page, identify the objects that are needed, and send them to the client </span><span class="font53" style="font-style:italic;">before receiving explicit requests for these objects.</span><span class="font53"> Server push eliminates the extra latency due to waiting for the requests.</span></p>
<p><span class="font22" style="font-weight:bold;">HTTP/3</span></p>
<p><span class="font53">QUIC, discussed in Chapter 3, is a new “transport” protocol that is implemented in the application layer over the bare-bones UDP protocol. QUIC has several features that are desirable for HTTP, such as message multiplexing (interleaving), per-stream flow control, and low-latency connection establishment. HTTP/3 is yet a new HTTP protocol that is designed to operate over QUIC. As of 2020, HTTP/3 is described in Internet drafts and has not yet been fully standardized. Many of the HTTP/2 features (such as message interleaving) are subsumed by QUIC, allowing for a simpler, streamlined design for HTTP/3.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">2.3 </span><span class="font24" style="font-weight:bold;">Electronic Mail in the Internet</span></p></li></ul>
<p><span class="font53">Electronic mail has been around since the beginning of the Internet. It was the most popular application when the Internet was in its infancy [Segaller 1998], and has become more elaborate and powerful over the years. It remains one of the Internet’s most important and utilized applications.</span></p>
<p><span class="font53">As with ordinary postal mail, e-mail is an asynchronous communication medium—people send and read messages when it is convenient for them, without having to coordinate with other people’s schedules. In contrast with postal mail, electronic mail is fast, easy to distribute, and inexpensive. Modern e-mail has many powerful features, including messages with attachments, hyperlinks, HTML-formatted text, and embedded photos.</span></p>
<p><span class="font53">In this section, we examine the application-layer protocols that are at the heart of Internet e-mail. But before we jump into an in-depth discussion of these protocols, let’s take a high-level view of the Internet mail system and its key components.</span></p>
<p><span class="font53">Figure 2.14 presents a high-level view of the Internet mail system. We see from this diagram that it has three major components: </span><span class="font53" style="font-weight:bold;">user agents</span><span class="font53">, </span><span class="font53" style="font-weight:bold;">mail servers</span><span class="font53">, and the </span><span class="font53" style="font-weight:bold;">Simple Mail Transfer Protocol (SMTP)</span><span class="font53">. We now describe each of these components in the context of a sender, Alice, sending an e-mail message to a recipient, Bob. User agents allow users to read, reply to, forward, save, and compose messages. Examples of user agents for e-mail include Microsoft Outlook, Apple Mail, Webbased Gmail, the Gmail App running in a smartphone, and so on. When Alice is finished composing her message, her user agent sends the message to her mail server, where the message is placed in the mail server’s outgoing message queue. When Bob wants to read a message, his user agent retrieves the message from his mailbox in his mail server.</span></p>
<p><a name="bookmark58"></a><span class="font53">Mail servers form the core of the e-mail infrastructure. Each recipient, such as Bob, has a </span><span class="font53" style="font-weight:bold;">mailbox </span><span class="font53">located in one of the mail servers. Bob’s mailbox manages and maintains the messages that have been sent to him. A typical message starts its journey in the sender’s user agent, then travels to the sender’s mail server, and then</span></p>
<div><img src="networking_files/networking-94.jpg" alt="" style="width:356pt;height:268pt;">
<p><span class="font4">Key:</span></p>
</div><br clear="all">
<div>
<p><span class="font41">message queue</span></p>
</div><br clear="all">
<div>
<p><span class="font41">User mailbox</span></p>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 2.14 </span><span class="font50">♦ </span><span class="font5">A high-level view of the Internet e-mail system</span></p>
<p><span class="font53">travels to the recipient’s mail server, where it is deposited in the recipient’s mailbox. When Bob wants to access the messages in his mailbox, the mail server containing his mailbox authenticates Bob (with his username and password). Alice’s mail server must also deal with failures in Bob’s mail server. If Alice’s server cannot deliver mail to Bob’s server, Alice’s server holds the message in a </span><span class="font53" style="font-weight:bold;">message queue </span><span class="font53">and attempts to transfer the message later. Reattempts are often done every 30 minutes or so; if there is no success after several days, the server removes the message and notifies the sender (Alice) with an e-mail message.</span></p>
<p><span class="font53">SMTP is the principal application-layer protocol for Internet electronic mail. It uses the reliable data transfer service of TCP to transfer mail from the sender’s mail server to the recipient’s mail server. As with most application-layer protocols, SMTP has two sides: a client side, which executes on the sender’s mail server, and a server side, which executes on the recipient’s mail server. Both the client and server sides of</span></p>
<p><span class="font53">SMTP run on every mail server. When a mail server sends mail to other mail servers, it acts as an SMTP client. When a mail server receives mail from other mail servers, it acts as an SMTP server.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">2.3.1 </span><span class="font23" style="font-weight:bold;">SMTP</span></p></li></ul>
<p><span class="font53">SMTP, defined in RFC 5321, is at the heart of Internet electronic mail. As mentioned above, SMTP transfers messages from senders’ mail servers to the recipients’ mail servers. SMTP is much older than HTTP. (The original SMTP RFC dates back to 1982, and SMTP was around long before that.) Although SMTP has numerous wonderful qualities, as evidenced by its ubiquity in the Internet, it is nevertheless a legacy technology that possesses certain archaic characteristics. For example, it restricts the body (not just the headers) of all mail messages to simple 7-bit ASCII. This restriction made sense in the early 1980s when transmission capacity was scarce and no one was e-mailing large attachments or large image, audio, or video files. But today, in the multimedia era, the 7-bit ASCII restriction is a bit of a pain—it requires binary multimedia data to be encoded to ASCII before being sent over SMTP; and it requires the corresponding ASCII message to be decoded back to binary after SMTP transport. Recall from Section 2.2 that HTTP does not require multimedia data to be ASCII encoded before transfer.</span></p>
<p><span class="font53">To illustrate the basic operation of SMTP, let’s walk through a common scenario. Suppose Alice wants to send Bob a simple ASCII message.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">1. Alice invokes her user agent for e-mail, provides Bob’s e-mail address (for example, </span><a href="mailto:bob@someschool.edu"><span class="font36">bob@someschool.edu</span><span class="font53">)</span></a><span class="font53">, composes a message, and instructs the user agent to send the message.</span></p></li>
<li>
<p><span class="font53">2. Alice’s user agent sends the message to her mail server, where it is placed in a message queue.</span></p></li>
<li>
<p><span class="font53">3. The client side of SMTP, running on Alice’s mail server, sees the message in the message queue. It opens a TCP connection to an SMTP server, running on Bob’s mail server.</span></p></li>
<li>
<p><span class="font53">4. After some initial SMTP handshaking, the SMTP client sends Alice’s message into the TCP connection.</span></p></li>
<li>
<p><span class="font53">5. At Bob’s mail server, the server side of SMTP receives the message. Bob’s mail server then places the message in Bob’s mailbox.</span></p></li>
<li>
<p><span class="font53">6. Bob invokes his user agent to read the message at his convenience.</span></p></li></ul>
<p><span class="font53">The scenario is summarized in Figure 2.15.</span></p>
<p><a name="bookmark59"></a><span class="font53">It is important to observe that SMTP does not normally use intermediate mail servers for sending mail, even when the two mail servers are located at opposite ends of the world. If Alice’s server is in Hong Kong and Bob’s server is in St. Louis, the TCP connection is a direct connection between the Hong Kong and St. Louis servers. In</span></p>
<div><img src="networking_files/networking-95.jpg" alt="" style="width:64pt;height:56pt;">
</div><br clear="all">
<div><img src="networking_files/networking-96.jpg" alt="" style="width:15pt;height:27pt;">
<p><span class="font4">Alice's mail server</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Alice's agent</span></p><img src="networking_files/networking-97.jpg" alt="" style="width:90pt;height:44pt;">
</div><br clear="all">
<div><img src="networking_files/networking-98.jpg" alt="" style="width:184pt;height:75pt;">
</div><br clear="all">
<div><img src="networking_files/networking-99.jpg" alt="" style="width:28pt;height:38pt;">
</div><br clear="all">
<div>
<p><span class="font4">Key:</span></p>
</div><br clear="all">
<div>
<p><span class="font41">ueue</span></p>
</div><br clear="all">
<div>
<p><span class="font41">User mailbox</span></p>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 2.15 </span><span class="font50">♦ </span><span class="font5">Alice sends a message to Bob</span></p>
<p><span class="font53">particular, if Bob’s mail server is down, the message remains in Alice’s mail server and waits for a new attempt—the message does not get placed in some intermediate mail server.</span></p>
<p><span class="font53">Let’s now take a closer look at how SMTP transfers a message from a sending mail server to a receiving mail server. We will see that the SMTP protocol has many similarities with protocols that are used for face-to-face human interaction. First, the client SMTP (running on the sending mail server host) has TCP establish a connection to port 25 at the server SMTP (running on the receiving mail server host). If the server is down, the client tries again later. Once this connection is established, the server and client perform some applicationlayer handshaking—just as humans often introduce themselves before transferring information from one to another, SMTP clients and servers introduce themselves before transferring information. During this SMTP handshaking phase, the SMTP client indicates the e-mail address of the sender (the person who generated the message) and the e-mail address of the recipient. Once the SMTP client and server have introduced themselves to each other, the client sends the message. SMTP can count on the reliable data transfer service of TCP to get the message to the server without errors. The client then repeats this process over the same TCP connection if it has other messages to send to the server; otherwise, it instructs TCP to close the connection.</span></p>
<p><span class="font53">Let’s next take a look at an example transcript of messages exchanged between an SMTP client (C) and an SMTP server (S). The hostname of the client is </span><a href="http://crepes.fr"><span class="font36">crepes.fr</span></a><span class="font36"> </span><span class="font53">and the hostname of the server is </span><a href="http://hamburger.edu"><span class="font36">hamburger.edu</span></a><span class="font53">. The ASCII text lines prefaced with </span><span class="font36">C: </span><span class="font53">are exactly the lines the client sends into its TCP socket, and the ASCII text lines prefaced with </span><span class="font36">S: </span><span class="font53">are exactly the lines the server sends into its TCP socket. The following transcript begins as soon as the TCP connection is established.</span></p>
<p><span class="font36">S: &nbsp;220</span><a href="http://hamburger.edu"><span class="font36"> hamburger.edu</span></a></p>
<p><span class="font36">C: HELO</span><a href="http://crepes.fr"><span class="font36"> crepes.fr</span></a></p>
<p><span class="font36">S: &nbsp;250 Hello </span><a href="http://crepes.fr"><span class="font36">crepes.fr</span></a><span class="font36">, pleased to meet you</span></p>
<p><span class="font36">C: MAIL FROM: &lt;</span><a href="mailto:alice@crepes.fr"><span class="font36">alice@crepes.fr&gt;</span></a></p>
<p><span class="font36">S: &nbsp;250</span><a href="mailto:alice@crepes.fr"><span class="font36"> alice@crepes.fr </span></a><span class="font36">... Sender ok</span></p>
<p><span class="font36">C: RCPT TO: </span><a href="mailto:bob@hamburger.edu"><span class="font36">&lt;bob@hamburger.edu&gt;</span></a></p>
<p><span class="font36">S: &nbsp;250 </span><a href="mailto:bob@hamburger.edu"><span class="font36">bob@hamburger.edu </span></a><span class="font36">... Recipient ok</span></p>
<p><span class="font36">C: &nbsp;DATA</span></p>
<p><span class="font36">S: &nbsp;354 Enter mail, end with &quot;.&quot; on a line by itself</span></p>
<p><span class="font36">C: &nbsp;Do you like ketchup?</span></p>
<p><span class="font36">C: &nbsp;How about pickles?</span></p>
<p><span class="font36">C: &nbsp;&nbsp;&nbsp;.</span></p>
<p><span class="font36">S: &nbsp;250 Message accepted for delivery</span></p>
<p><span class="font36">C: QUIT</span></p>
<p><span class="font36">S: &nbsp;221</span><a href="http://hamburger.edu"><span class="font36"> hamburger.edu </span></a><span class="font36">closing connection</span></p>
<p><span class="font53">In the example above, the client sends a message (“</span><span class="font36">Do you like ketchup? How about pickles?</span><span class="font53">”) from mail server </span><a href="http://crepes.fr"><span class="font36">crepes.fr </span></a><span class="font53">to mail server </span><a href="http://hamburger.edu"><span class="font36">hamburger.edu</span></a><span class="font53">. As part of the dialogue, the client issued five commands: </span><span class="font36">HELO </span><span class="font53">(an abbreviation for HELLO), </span><span class="font36">MAIL FROM</span><span class="font53">, </span><span class="font36">RCPT TO</span><span class="font53">, </span><span class="font36">DATA</span><span class="font53">, and </span><span class="font36">QUIT</span><span class="font53">. These commands are self-explanatory. The client also sends a line consisting of a single period, which indicates the end of the message to the server. (In ASCII jargon, each message ends with </span><span class="font36">CRLF.CRLF</span><span class="font53">, where </span><span class="font36">CR </span><span class="font53">and </span><span class="font36">LF </span><span class="font53">stand for carriage return and line feed, respectively.) The server issues replies to each command, with each reply having a reply code and some (optional) English-language explanation. We mention here that SMTP uses persistent connections: If the sending mail server has several messages to send to the same receiving mail server, it can send all of the messages over the same TCP connection. For each message, the client begins the process with a new </span><span class="font36">MAIL FROM:</span><a href="http://crepes.fr"><span class="font36"> crepes.fr</span><span class="font53">,</span></a><span class="font53"> designates the end of message with an isolated period, and issues </span><span class="font36">QUIT </span><span class="font53">only after all messages have been sent.</span></p>
<p><span class="font53">It is highly recommended that you use Telnet to carry out a direct dialogue with an SMTP server. To do this, issue</span></p>
<p><span class="font36">telnet serverName 25</span></p>
<p><span class="font53">where </span><span class="font36">serverName </span><span class="font53">is the name of a local mail server. When you do this, you are simply establishing a TCP connection between your local host and the mail server. After typing this line, you should immediately receive the </span><span class="font36">220 </span><span class="font53">reply from the server. Then issue the SMTP commands </span><span class="font36">HELO</span><span class="font53">, </span><span class="font36">MAIL FROM</span><span class="font53">, </span><span class="font36">RCPT TO</span><span class="font53">, </span><span class="font36">DATA</span><span class="font53">, </span><span class="font36">CRLF.CRLF</span><span class="font53">, and </span><span class="font36">QUIT </span><span class="font53">at the appropriate times. It is also highly recommended that you do Programming Assignment 3 at the end of this chapter. In that assignment, you’ll build a simple user agent that implements the client side of SMTP. It will allow you to send an e-mail message to an arbitrary recipient via a local mail server.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">2.3.2 </span><span class="font23" style="font-weight:bold;">Mail Message Formats</span></p></li></ul>
<p><span class="font53">When Alice writes an ordinary snail-mail letter to Bob, she may include all kinds of peripheral header information at the top of the letter, such as Bob’s address, her own return address, and the date. Similarly, when an e-mail message is sent from one person to another, a header containing peripheral information precedes the body of the message itself. This peripheral information is contained in a series of header lines, which are defined in RFC 5322. The header lines and the body of the message are separated by a blank line (that is, by </span><span class="font36">CRLF</span><span class="font53">). RFC 5322 specifies the exact format for mail header lines as well as their semantic interpretations. As with HTTP, each header line contains readable text, consisting of a keyword followed by a colon followed by a value. Some of the keywords are required and others are optional. Every header must have a </span><span class="font36">From: </span><span class="font53">header line and a </span><span class="font36">To: </span><span class="font53">header line; a header may include a </span><span class="font36">Subject: </span><span class="font53">header line as well as other optional header lines. It is important to note that these header lines are </span><span class="font53" style="font-style:italic;">different</span><span class="font53"> from the SMTP commands we studied in Section 2.3.1 (even though they contain some common words such as </span><span class="font53" style="font-style:italic;">““from”</span><span class="font53"> and “</span><span class="font53" style="font-style:italic;">to</span><span class="font53">”). The commands in that section were part of the SMTP handshaking protocol; the header lines examined in this section are part of the mail message itself.</span></p>
<p><span class="font53">A typical message header looks like this:</span></p>
<p><span class="font36">From:</span><a href="mailto:alice@crepes.fr"><span class="font36"> alice@crepes.fr</span></a><span class="font36"> To: </span><a href="mailto:bob@hamburger.edu"><span class="font36">bob@hamburger.edu</span></a><span class="font36"> Subject: Searching for the meaning of life.</span></p>
<p><span class="font53">After the message header, a blank line follows; then the message body (in ASCII) follows. You should use Telnet to send a message to a mail server that contains some header lines, including the </span><span class="font36">Subject: </span><span class="font53">header line. To do this, issue </span><span class="font36">telnet serverName 25, </span><span class="font53">as discussed in Section 2.3.1.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">2.3.3 </span><span class="font23" style="font-weight:bold;">Mail Access Protocols</span></p></li></ul>
<p><a name="bookmark60"></a><span class="font53">Once SMTP delivers the message from Alice’s mail server to Bob’s mail server, the message is placed in Bob’s mailbox. Given that Bob (the recipient) executes his user agent on his local host (e.g., smartphone or PC), it is natural to consider placing a mail server on his local host as well. With this approach, Alice’s mail server would dialogue directly with Bob’s PC. There is a problem with this approach, however. Recall that a mail server manages mailboxes and runs the client and server sides of SMTP. If Bob’s mail server were to reside on his local host, then Bob’s host would have to remain always on, and connected to the Internet, in order to receive new mail, which can arrive at any time. This is impractical for many Internet users. Instead, a typical user runs a user agent on the local host but accesses its mailbox stored on an always-on shared mail server. This mail server is shared with other users.</span></p>
<div><img src="networking_files/networking-100.jpg" alt="" style="width:280pt;height:75pt;">
<p><span class="font4">HTTP or</span></p>
<p><span class="font4">IMAP</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 2.16 </span><span class="font50">♦ </span><span class="font5">E-mail protocols and their communicating entities</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-101.jpg" alt="" style="width:25pt;height:39pt;">
</div><br clear="all">
<div>
<p><span class="font4">Bob's agent</span></p><img src="networking_files/networking-102.jpg" alt="" style="width:28pt;height:38pt;">
</div><br clear="all">
<p><span class="font53">Now let’s consider the path an e-mail message takes when it is sent from Alice to Bob. We just learned that at some point along the path the e-mail message needs to be deposited in Bob’s mail server. This could be done simply by having Alice’s user agent send the message directly to Bob’s mail server. However, typically the sender’s user agent does not dialogue directly with the recipient’s mail server. Instead, as shown in Figure 2.16, Alice’s user agent uses SMTP or HTTP to deliver the e-mail message into her mail server, then Alice’s mail server uses SMTP (as an SMTP client) to relay the e-mail message to Bob’s mail server. Why the two-step procedure? Primarily because without relaying through Alice’s mail server, Alice’s user agent doesn’t have any recourse to an unreachable destination mail server. By having Alice first deposit the e-mail in her own mail server, Alice’s mail server can repeatedly try to send the message to Bob’s mail server, say every 30 minutes, until Bob’s mail server becomes operational. (And if Alice’s mail server is down, then she has the recourse of complaining to her system administrator!)</span></p>
<p><span class="font53">But there is still one missing piece to the puzzle! How does a recipient like Bob, running a user agent on his local host , obtain his messages, which are sitting in a mail server? Note that Bob’s user agent can’t use SMTP to obtain the messages because obtaining the messages is a pull operation, whereas SMTP is a push protocol.</span></p>
<p><span class="font53">Today, there are two common ways for Bob to retrieve his e-mail from a mail server. If Bob is using Web-based e-mail or a smartphone app (such as Gmail), then the user agent will use HTTP to retrieve Bob’s e-mail. This case requires Bob’s mail server to have an HTTP interface as well as an SMTP interface (to communicate with Alice’s mail server). The alternative method, typically used with mail clients such as Microsoft Outlook, is to use the </span><span class="font53" style="font-weight:bold;">Internet Mail Access Protocol (IMAP) </span><span class="font53">defined in RFC 3501. Both the HTTP and IMAP approaches allow Bob to manage folders, maintained in Bob’s mail server. Bob can move messages into the folders he creates, delete messages, mark messages as important, and so on.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">2.4 </span><span class="font24" style="font-weight:bold;">DNS—The Internet’s Directory Service</span></p></li></ul>
<p><a name="bookmark61"></a><span class="font53">We human beings can be identified in many ways. For example, we can be identified by the names that appear on our birth certificates. We can be identified by our social security numbers. We can be identified by our driver’s license numbers. Although each can be used to identify people, within a given context one identifier may be more appropriate than another. For example, the computers at the IRS (the infamous tax-collecting agency in the United States) prefer to use fixed-length social security numbers rather than birth certificate names. On the other hand, ordinary people prefer the more mnemonic birth certificate names rather than social security numbers. (Indeed, can you imagine saying, “Hi. My name is 132-67-9875. Please meet my husband, 178-87-1146.”)</span></p>
<p><span class="font53">Just as humans can be identified in many ways, so too can Internet hosts. One identifier for a host is its </span><span class="font53" style="font-weight:bold;">hostname</span><span class="font53">. Hostnames—such as </span><a href="http://www.facebook.com"><span class="font36">www.facebook.com</span></a><span class="font36">, </span><a href="http://www.google.com"><span class="font36">www.google.com</span></a><span class="font53">,</span><a href="http://gaia.cs.umass.edu"><span class="font36">gaia.cs.umass.edu—</span></a><span class="font53">are mnemonic and are therefore appreciated by humans. However, hostnames provide little, if any, information about the location within the Internet of the host. (A hostname such as </span><a href="http://www.eurecom.fr"><span class="font36">www.eurecom.</span></a><span class="font36"> </span><a href="http://www.eurecom.fr"><span class="font36">fr</span><span class="font53">,</span></a><span class="font53"> which ends with the country code </span><span class="font36">.fr</span><span class="font53">, tells us that the host is probably in France, but doesn’t say much more.) Furthermore, because hostnames can consist of variable-length alphanumeric characters, they would be difficult to process by routers. For these reasons, hosts are also identified by so-called </span><span class="font53" style="font-weight:bold;">IP addresses</span><span class="font53">.</span></p>
<p><span class="font53">We discuss IP addresses in some detail in Chapter 4, but it is useful to say a few brief words about them now. An IP address consists of four bytes and has a rigid hierarchical structure. An IP address looks like </span><span class="font36">121.7.106.83</span><span class="font53">, where each period separates one of the bytes expressed in decimal notation from 0 to 255. An IP address is hierarchical because as we scan the address from left to right, we obtain more and more specific information about where the host is located in the Internet (that is, within which network, in the network of networks). Similarly, when we scan a postal address from bottom to top, we obtain more and more specific information about where the addressee is located.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">2.4.1 </span><span class="font23" style="font-weight:bold;">Services Provided by DNS</span></p></li></ul>
<p><span class="font53">We have just seen that there are two ways to identify a host—by a hostname and by an IP address. People prefer the more mnemonic hostname identifier, while routers prefer fixed-length, hierarchically structured IP addresses. In order to reconcile these preferences, we need a directory service that translates hostnames to IP addresses. This is the main task of the Internet’s </span><span class="font53" style="font-weight:bold;">domain name system (DNS)</span><span class="font53">. The DNS is (1) a distributed database implemented in a hierarchy of </span><span class="font53" style="font-weight:bold;">DNS servers</span><span class="font53">, and (2) an application-layer protocol that allows hosts to query the distributed database. The DNS servers are often UNIX machines running the Berkeley Internet Name Domain (BIND) software [BIND 2020]. The DNS protocol runs over UDP and uses port 53.</span></p>
<p><a name="bookmark62"></a><span class="font53">DNS is commonly employed by other application-layer protocols, including HTTP and SMTP, to translate user-supplied hostnames to IP addresses. As an example, consider what happens when a browser (that is, an HTTP client), running on some user’s host, requests the URL </span><a href="http://www.someschool.edu/index.html"><span class="font36">www.someschool.edu/index.html</span></a><span class="font53">. In order for the user’s host to be able to send an HTTP request message to the Web server </span><a href="http://www.someschool.edu"><span class="font36">www.someschool.edu</span></a><span class="font53">, the user’s host must first obtain the IP address of </span><a href="http://www.someschool.edu"><span class="font36">www.someschool.edu</span></a><span class="font53">. This is done as follows.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">1. The same user machine runs the client side of the DNS application.</span></p></li>
<li>
<p><span class="font53">2. The browser extracts the hostname, </span><a href="http://www.someschool.edu"><span class="font36">www.someschool.edu</span></a><span class="font53">, from the URL and passes the hostname to the client side of the DNS application.</span></p></li>
<li>
<p><span class="font53">3. The DNS client sends a query containing the hostname to a DNS server.</span></p></li>
<li>
<p><span class="font53">4. The DNS client eventually receives a reply, which includes the IP address for the hostname.</span></p></li>
<li>
<p><span class="font53">5. Once the browser receives the IP address from DNS, it can initiate a TCP connection to the HTTP server process located at port 80 at that IP address.</span></p></li></ul>
<p><span class="font53">We see from this example that DNS adds an additional delay—sometimes substantial—to the Internet applications that use it. Fortunately, as we discuss below, the desired IP address is often cached in a “nearby” DNS server, which helps to reduce DNS network traffic as well as the average DNS delay.</span></p>
<p><span class="font53">DNS provides a few other important services in addition to translating hostnames to IP addresses:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-weight:bold;">Host aliasing. </span><span class="font53">A host with a complicated hostname can have one or more alias names. For example, a hostname such as</span><a href="http://relay1.west-coast.enterprise.com"><span class="font53"> </span><span class="font36">relayl.west-coast</span></a><span class="font36"> </span><a href="http://relay1.west-coast.enterprise.com"><span class="font36">.enterprise.com</span></a><span class="font36"> </span><span class="font53">could have, say, two aliases such as</span><a href="http://enterprise.com"><span class="font53"> </span><span class="font36">enterprise.com</span></a><span class="font36"> </span><span class="font53">and </span><a href="http://www.enterprise.com"><span class="font36">www.enterprise.com</span></a><span class="font53">. In this case, the hostname</span><a href="http://relay1.west-coast.enterprise.com"><span class="font53"> </span><span class="font36">relayl</span></a><span class="font36"> </span><a href="http://relay1.west-coast.enterprise.com"><span class="font36">.west-coast.enterprise.com</span></a><span class="font36"> </span><span class="font53">is said to be a </span><span class="font53" style="font-weight:bold;">canonical hostname</span><span class="font53">. Alias hostnames, when present, are typically more mnemonic than canonical hostnames. DNS can be invoked by an application to obtain the canonical hostname for a supplied alias hostname as well as the IP address of the host.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-weight:bold;">Mail server aliasing. </span><span class="font53">For obvious reasons, it is highly desirable that e-mail addresses be mnemonic. For example, if Bob has an account with Yahoo Mail, Bob’s e-mail address might be as simple as </span><a href="mailto:bob@yahoo.com"><span class="font36">bob@yahoo.com</span></a><span class="font53">. However, the hostname of the Yahoo mail server is more complicated and much less mnemonic than simply</span><a href="http://yahoo.com"><span class="font53"> </span><span class="font36">yahoo.com </span></a><span class="font53">(for example, the canonical hostname might be something like </span><a href="http://relay1.west-coast.yahoo.com"><span class="font36">relay1.west-coast.yahoo.com</span><span class="font53">)</span></a><span class="font53">. DNS can be invoked by a mail application to obtain the canonical hostname for a supplied alias hostname as well as the IP address of the host. In fact, the MX record (see below) permits a company’s mail server and Web server to have identical (aliased) hostnames; for example, a company’s Web server and mail server can both be called</span><a href="http://enterprise.com"><span class="font53"> </span><span class="font36">enter-</span></a><span class="font36">prise.com</span><span class="font53">.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-weight:bold;">Load distribution. </span><span class="font53">DNS is also used to perform load distribution among replicated servers, such as replicated Web servers. Busy sites, such as </span><a href="http://cnn.com"><span class="font36">cnn.com</span></a><span class="font53">, are replicated over multiple servers, with each server running on a different end system and each having a different IP address. For replicated Web servers, a </span><span class="font53" style="font-style:italic;">set</span><span class="font53"> of IP</span></p>
<div><img src="networking_files/networking-103.jpg" alt="" style="width:131pt;height:21pt;">
</div><br clear="all">
<div>
<p><span class="font23" style="font-weight:bold;">PRINCIPLES IN PRACTICE</span></p>
</div><br clear="all"></li></ul>
<p><span class="font4" style="font-weight:bold;">DNS: CRITICAL NETWORK FUNCTIONS VIA THE CLIENT-SERVER PARADIGM</span></p>
<p><span class="font4">Like HTTP, FTP, and SMTP, the DNS protocol is an application-layer protocol since it</span></p>
<ul style="list-style:none;"><li>
<p><span class="font4">(1) runs between communicating end systems using the client-server paradigm and</span></p></li>
<li>
<p><span class="font4">(2) relies on an underlying end-to-end transport protocol to transfer DNS messages between communicating end systems. In another sense, however, the role of the DNS is quite different from Web, file transfer, and e-mail applications. Unlike these applications, the DNS is not an application with which a user directly interacts. Instead, the DNS provides a core Internet function — namely, translating hostnames to their underlying IP addresses, for user applications and other software in the Internet. We noted in Section 1.2 that much of the complexity in the Internet architecture is located at the “edges” of the network. The DNS, which implements the critical name-to-address translation process using clients and servers located at the edge of the network, is yet another example of that design philosophy.</span></p></li></ul>
<p><span class="font53">addresses is thus associated with one alias hostname. The DNS database contains this set of IP addresses. When clients make a DNS query for a name mapped to a set of addresses, the server responds with the entire set of IP addresses, but rotates the ordering of the addresses within each reply. Because a client typically sends its HTTP request message to the IP address that is listed first in the set, DNS rotation distributes the traffic among the replicated servers. DNS rotation is also used for e-mail so that multiple mail servers can have the same alias name. Also, content distribution companies such as Akamai have used DNS in more sophisticated ways [Dilley 2002] to provide Web content distribution (see Section 2.6.3).</span></p>
<p><span class="font53">The DNS is specified in RFC 1034 and RFC 1035, and updated in several additional RFCs. It is a complex system, and we only touch upon key aspects of its operation here. The interested reader is referred to these RFCs and the book by Albitz and Liu [Albitz 1993]; see also the retrospective paper [Mockapetris 1988], which provides a nice description of the what and why of DNS, and [Mockapetris 2005].</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">2.4.2 </span><span class="font23" style="font-weight:bold;">Overview of How DNS Works</span></p></li></ul>
<p><span class="font53">We now present a high-level overview of how DNS works. Our discussion will focus on the hostname-to-IP-address translation service.</span></p>
<p><a name="bookmark63"></a><span class="font53">Suppose that some application (such as a Web browser or a mail client) running in a user’s host needs to translate a hostname to an IP address. The application will invoke the client side of DNS, specifying the hostname that needs to be translated. (On many UNIX-based machines, </span><span class="font36">gethostbyname() </span><span class="font53">is the function call that an application calls in order to perform the translation.) DNS in the user’s host then takes over, sending a query message into the network. All DNS query and reply messages are sent within UDP datagrams to port 53. After a delay, ranging from milliseconds to seconds, DNS in the user’s host receives a DNS reply message that provides the desired mapping. This mapping is then passed to the invoking application. Thus, from the perspective of the invoking application in the user’s host, DNS is a black box providing a simple, straightforward translation service. But in fact, the black box that implements the service is complex, consisting of a large number of DNS servers distributed around the globe, as well as an application-layer protocol that specifies how the DNS servers and querying hosts communicate.</span></p>
<p><span class="font53">A simple design for DNS would have one DNS server that contains all the mappings. In this centralized design, clients simply direct all queries to the single DNS server, and the DNS server responds directly to the querying clients. Although the simplicity of this design is attractive, it is inappropriate for today’s Internet, with its vast (and growing) number of hosts. The problems with a centralized design include:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-weight:bold;">A single point of failure. </span><span class="font53">If the DNS server crashes, so does the entire Internet!</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-weight:bold;">Traffic volume. </span><span class="font53">A single DNS server would have to handle all DNS queries (for all the HTTP requests and e-mail messages generated from hundreds of millions of hosts).</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-weight:bold;">Distant centralized database. </span><span class="font53">A single DNS server cannot be “close to” all the querying clients. If we put the single DNS server in New York City, then all queries from Australia must travel to the other side of the globe, perhaps over slow and congested links. This can lead to significant delays.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-weight:bold;">Maintenance. </span><span class="font53">The single DNS server would have to keep records for all Internet hosts. Not only would this centralized database be huge, but it would have to be updated frequently to account for every new host.</span></p></li></ul>
<p><span class="font53">In summary, a centralized database in a single DNS server simply </span><span class="font53" style="font-style:italic;">doesn’t scale. </span><span class="font53">Consequently, the DNS is distributed by design. In fact, the DNS is a wonderful example of how a distributed database can be implemented in the Internet.</span></p>
<p><span class="font22" style="font-weight:bold;">A Distributed, Hierarchical Database</span></p>
<p><span class="font53">In order to deal with the issue of scale, the DNS uses a large number of servers, organized in a hierarchical fashion and distributed around the world. No single DNS server has all of the mappings for all of the hosts in the Internet. Instead, the mappings are distributed across the DNS servers. To a first approximation, there are three classes of DNS servers—root DNS servers, top-level domain (TLD) DNS servers, and authoritative DNS servers—organized in a hierarchy as shown in Figure 2.17. To understand how these three classes of servers interact, suppose a DNS client wants to determine the IP address for the hostname </span><a href="http://www.amazon.com"><span class="font36">www.amazon.com</span></a><span class="font53">. To a first approximation, the following events will take place. The client first contacts one of</span></p><img src="networking_files/networking-104.jpg" alt="" style="width:335pt;height:122pt;">
<p><span class="font7" style="font-weight:bold;">Figure 2.17 </span><span class="font50">♦ </span><span class="font5">Portion of the hierarchy of DNS servers</span></p>
<p><span class="font53">the root servers, which returns IP addresses for TLD servers for the top-level domain </span><span class="font36">com</span><span class="font53">. The client then contacts one of these TLD servers, which returns the IP address of an authoritative server for </span><a href="http://amazon.com"><span class="font36">amazon.com</span></a><span class="font53">. Finally, the client contacts one of the authoritative servers for</span><a href="http://amazon.com"><span class="font53"> </span><span class="font36">amazon.com</span><span class="font53">,</span></a><span class="font53"> which returns the IP address for the hostname </span><a href="http://www.amazon.com"><span class="font36">www.amazon.com</span></a><span class="font53">. We’ll soon examine this DNS lookup process in more detail. But let’s first take a closer look at these three classes of DNS servers:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-weight:bold;">Root DNS servers. </span><span class="font53">There are more than 1000 root servers instances scattered all over the world, as shown in Figure 2.18. These root servers are copies of 13 different root servers, managed by 12 different organizations, and coordinated through the Internet Assigned Numbers Authority [IANA 2020]. The full list of root name servers, along with the organizations that manage them and their IP addresses can be found at [Root Servers 2020]. Root name servers provide the IP addresses of the TLD servers.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-weight:bold;">Top-level domain (TLD) servers. </span><span class="font53">For each of the top-level domains—top-level domains such as com, org, net, edu, and gov, and all of the country top-level domains such as uk, fr, ca, and jp—there is TLD server (or server cluster). The company Verisign Global Registry Services maintains the TLD servers for the </span><span class="font36">com </span><span class="font53">top-level domain, and the company Educause maintains the TLD servers for the </span><span class="font36">edu </span><span class="font53">top-level domain. The network infrastructure supporting a TLD can be large and complex; see [Osterweil 2012] for a nice overview of the Verisign network. See [TLD list 2020] for a list of all top-level domains. TLD servers provide the IP addresses for authoritative DNS servers.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-weight:bold;">Authoritative DNS servers. </span><span class="font53">Every organization with publicly accessible hosts (such as Web servers and mail servers) on the Internet must provide publicly accessible DNS records that map the names of those hosts to IP addresses. An organization’s authoritative DNS server houses these DNS records. An organization can choose to implement its own authoritative DNS server to hold these records; alternatively, the organization can pay to have these records stored in an</span></p></li></ul><img src="networking_files/networking-105.jpg" alt="" style="width:414pt;height:201pt;">
<p><span class="font4">Key:</span></p>
<p><span class="font42">3 0 Servers</span></p>
<p><span class="font42">O 1-10 Servers</span></p>
<p><span class="font42">O 11-20 Servers</span></p>
<p><span class="font42">■ 21+ Servers</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 2.18 </span><span class="font50">♦ </span><span class="font5">DNS root servers in 2020</span></p>
<p><span class="font53">authoritative DNS server of some service provider. Most universities and large companies implement and maintain their own primary and secondary (backup) authoritative DNS server.</span></p>
<p><span class="font53">The root, TLD, and authoritative DNS servers all belong to the hierarchy of DNS servers, as shown in Figure 2.17. There is another important type of DNS server called the </span><span class="font53" style="font-weight:bold;">local DNS server</span><span class="font53">. A local DNS server does not strictly belong to the hierarchy of servers but is nevertheless central to the DNS architecture. Each ISP—such as a residential ISP or an institutional ISP—has a local DNS server (also called a default name server). When a host connects to an ISP, the ISP provides the host with the IP addresses of one or more of its local DNS servers (typically through DHCP, which is discussed in Chapter 4). You can easily determine the IP address of your local DNS server by accessing network status windows in Windows or UNIX. A host’s local DNS server is typically “close to” the host. For an institutional ISP, the local DNS server may be on the same LAN as the host; for a residential ISP, it is typically separated from the host by no more than a few routers. When a host makes a DNS query, the query is sent to the local DNS server, which acts a proxy, forwarding the query into the DNS server hierarchy, as we’ll discuss in more detail below.</span></p>
<p><span class="font53">Let’s take a look at a simple example. Suppose the host </span><a href="http://cse.nyu.edu"><span class="font36">cse.nyu.edu </span></a><span class="font53">desires the IP address of </span><a href="http://gaia.cs.umass.edu"><span class="font36">gaia.cs.umass.edu</span></a><span class="font53">. Also suppose that NYU’s local DNS server for</span><a href="http://cse.nyu.edu"><span class="font53"> </span><span class="font36">cse.nyu.edu </span></a><span class="font53">is called </span><a href="http://dns.nyu.edu"><span class="font36">dns.nyu.edu </span></a><span class="font53">and that an authoritative DNS server for </span><a href="http://gaia.cs.umass.edu"><span class="font36">gaia.cs.umass.edu </span></a><span class="font53">is called</span><a href="http://dns.umass.edu"><span class="font53"> </span><span class="font36">dns.umass.edu</span></a><span class="font53">. As shown in</span></p>
<div><img src="networking_files/networking-106.jpg" alt="" style="width:3pt;height:111pt;">
</div><br clear="all">
<div><img src="networking_files/networking-107.jpg" alt="" style="width:126pt;height:120pt;">
<p><span class="font4">Local DNS server</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-108.jpg" alt="" style="width:28pt;height:111pt;">
</div><br clear="all">
<div><img src="networking_files/networking-109.jpg" alt="" style="width:142pt;height:71pt;">
</div><br clear="all">
<div>
<p><span class="font4">TLD DNS server</span></p><img src="networking_files/networking-110.jpg" alt="" style="width:153pt;height:102pt;">
<p><span class="font4">Requesting host</span></p>
<p><a href="http://cse.nyu.edu"><span class="font34">cse.nyu.edu</span></a></p>
</div><br clear="all">
<div>
<p><span class="font4">Authoritative DNS server</span></p>
<p><a href="http://dns.umass.edu"><span class="font34">dns.umass.edu</span></a></p>
</div><br clear="all">
<div><img src="networking_files/networking-111.jpg" alt="" style="width:37pt;height:40pt;">
</div><br clear="all">
<p><a href="http://gaia.cs.umass.edu"><span class="font34">gaia.cs.umass.edu</span></a></p>
<p><span class="font7" style="font-weight:bold;">Figure 2.19 </span><span class="font50">♦ </span><span class="font5">Interaction of the various DNS servers</span></p>
<p><span class="font53">Figure 2.19, the host</span><a href="http://cse.nyu.edu"><span class="font53"> </span><span class="font36">cse.nyu.edu </span></a><span class="font53">first sends a DNS query message to its local DNS server, </span><a href="http://dns.nyu.edu"><span class="font36">dns.nyu.edu</span></a><span class="font53">. The query message contains the hostname to be translated, namely,</span><a href="http://gaia.cs.umass.edu"><span class="font53"> </span><span class="font36">gaia.cs.umass.edu</span></a><span class="font53">. The local DNS server forwards the query message to a root DNS server. The root DNS server takes note of the edu suffix and returns to the local DNS server a list of IP addresses for TLD servers responsible for </span><span class="font36">edu</span><span class="font53">. The local DNS server then resends the query message to one of these TLD servers. The TLD server takes note of the </span><a href="http://umass.edu"><span class="font36">umass.edu </span></a><span class="font53">suffix and responds with the IP address of the authoritative DNS server for the University of Massachusetts, namely, </span><a href="http://dns.umass.edu"><span class="font36">dns.umass.edu</span></a><span class="font53">. Finally, the local DNS server resends the query message directly to </span><a href="http://dns.umass.edu"><span class="font36">dns.umass.edu</span></a><span class="font53">, which responds with the IP address of</span><a href="http://gaia.cs.umass.edu"><span class="font53"> </span><span class="font36">gaia</span></a><span class="font36"> </span><a href="http://gaia.cs.umass.edu"><span class="font36">.cs.umass.edu</span><span class="font53">.</span></a><span class="font53"> Note that in this example, in order to obtain the mapping for one hostname, eight DNS messages were sent: four query messages and four reply messages! We’ll soon see how DNS caching reduces this query traffic.</span></p>
<p><span class="font53">Our previous example assumed that the TLD server knows the authoritative DNS server for the hostname. In general, this is not always true. Instead, the TLD server may know only of an intermediate DNS server, which in turn knows the authoritative DNS server for the hostname. For example, suppose again that the University of Massachusetts has a DNS server for the university, called </span><a href="http://dns.umass.edu"><span class="font36">dns.umass.edu</span></a><span class="font53">. Also suppose that each of the departments at the University of Massachusetts has its own DNS server, and that each departmental DNS server is authoritative for all hosts in the department. In this case, when the intermediate DNS server,</span><a href="http://dns.umass.edu"><span class="font53"> </span><span class="font36">dns.umass.edu</span><span class="font53">,</span></a><span class="font53"> receives a query for a host with a hostname ending with </span><a href="http://cs.umass.edu"><span class="font36">cs.umass.edu</span><span class="font53">,</span></a><span class="font53"> it returns to </span><a href="http://dns.nyu.edu"><span class="font36">dns.nyu.edu </span></a><span class="font53">the IP address of</span><a href="http://dns.cs.umass.edu"><span class="font53"> </span><span class="font36">dns.cs.umass.edu</span></a><span class="font53">, which is authoritative for all hostnames ending with</span><a href="http://cs.umass.edu"><span class="font53"> </span><span class="font36">cs.umass.edu</span></a><span class="font53">. The local DNS server</span><a href="http://dns.nyu.edu"><span class="font53"> </span><span class="font36">dns.nyu</span></a><span class="font36"> </span><a href="http://dns.nyu.edu"><span class="font36">.edu </span></a><span class="font53">then sends the query to the authoritative DNS server, which returns the desired mapping to the local DNS server, which in turn returns the mapping to the requesting host. In this case, a total of 10 DNS messages are sent!</span></p>
<p><span class="font53">The example shown in Figure 2.19 makes use of both </span><span class="font53" style="font-weight:bold;">recursive queries </span><span class="font53">and </span><span class="font53" style="font-weight:bold;">iterative queries</span><span class="font53">. The query sent from </span><a href="http://cse.nyu.edu"><span class="font36">cse.nyu.edu </span></a><span class="font53">to</span><a href="http://dns.nyu.edu"><span class="font53"> </span><span class="font36">dns.nyu.edu </span></a><span class="font53">is a recursive query, since the query asks </span><a href="http://dns.nyu.edu"><span class="font36">dns.nyu.edu </span></a><span class="font53">to obtain the mapping on its behalf. However, the subsequent three queries are iterative since all of the replies are directly returned to</span><a href="http://dns.nyu.edu"><span class="font53"> </span><span class="font36">dns.nyu.edu</span></a><span class="font53">. In theory, any DNS query can be iterative or recursive. For example, Figure 2.20 shows a DNS query chain for which all of the queries are recursive. In practice, the queries typically follow the pattern in Figure 2.19: The query from the requesting host to the local DNS server is recursive, and the remaining queries are iterative.</span></p>
<p><span class="font22" style="font-weight:bold;">DNS Caching</span></p>
<p><span class="font53">Our discussion thus far has ignored </span><span class="font53" style="font-weight:bold;">DNS caching</span><span class="font53">, a critically important feature of the DNS system. In truth, DNS extensively exploits DNS caching in order to improve the delay performance and to reduce the number of DNS messages ricocheting around the Internet. The idea behind DNS caching is very simple. In a query chain, when a DNS server receives a DNS reply (containing, for example, a mapping from a hostname to an IP address), it can cache the mapping in its local memory. For example, in Figure 2.19, each time the local DNS server</span><a href="http://dns.nyu.edu"><span class="font53"> </span><span class="font36">dns.nyu.edu</span></a><span class="font36"> </span><span class="font53">receives a reply from some DNS server, it can cache any of the information contained in the reply. If a hostname/IP address pair is cached in a DNS server and another query arrives to the DNS server for the same hostname, the DNS server can provide the desired IP address, even if it is not authoritative for the hostname. Because hosts and mappings between hostnames and IP addresses are by no means permanent, DNS servers discard cached information after a period of time (often set to two days).</span></p>
<p><span class="font53">As an example, suppose that a host </span><a href="http://apricot.nyu.edu"><span class="font36">apricot.nyu.edu </span></a><span class="font53">queries</span><a href="http://dns.nyu.edu"><span class="font53"> </span><span class="font36">dns.nyu.edu</span></a><span class="font36"> </span><span class="font53">for the IP address for the hostname </span><a href="http://cnn.com"><span class="font36">cnn.com</span><span class="font53">.</span></a><span class="font53"> Furthermore, suppose that a few hours later, another NYU host, say, </span><a href="http://kiwi.nyu.edu"><span class="font36">kiwi.nyu.edu</span></a><span class="font53">, also queries </span><a href="http://dns.nyu.edu"><span class="font36">dns.nyu.edu</span></a><span class="font36"> </span><span class="font53">with the same hostname. Because of caching, the local DNS server will be able to immediately return the IP address of </span><a href="http://cnn.com"><span class="font36">cnn.com </span></a><span class="font53">to this second requesting host without having to query any other DNS servers. A local DNS server can</span></p>
<div>
<p><span class="font4">Root DNS server</span></p><img src="networking_files/networking-112.jpg" alt="" style="width:154pt;height:108pt;">
<p><span class="font4">Local DNS server &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TLD DNS server</span></p>
<p><a href="http://dns.nyu.edu"><span class="font34">dns.nyu.edu</span></a></p>
</div><br clear="all">
<div><img src="networking_files/networking-113.jpg" alt="" style="width:26pt;height:60pt;">
</div><br clear="all">
<div><img src="networking_files/networking-114.jpg" alt="" style="width:35pt;height:37pt;">
</div><br clear="all">
<div><img src="networking_files/networking-115.jpg" alt="" style="width:26pt;height:104pt;">
</div><br clear="all">
<div>
<p><span class="font4">Requesting host</span></p>
<p><a href="http://cse.nyu.edu"><span class="font34">cse.nyu.edu</span></a></p>
</div><br clear="all">
<div>
<p><span class="font4">Authoritative DNS server</span></p>
<p><a href="http://dns.umass.edu"><span class="font34">dns.umass.edu</span></a></p>
</div><br clear="all">
<div><img src="networking_files/networking-116.jpg" alt="" style="width:34pt;height:37pt;">
</div><br clear="all">
<div>
<p><a href="http://gaia.cs.umass.edu"><span class="font34">gaia.cs.umass.edu</span></a></p>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 2.20 </span><span class="font50">♦ </span><span class="font5">Recursive queries in DNS</span></p>
<p><span class="font53">also cache the IP addresses of TLD servers, thereby allowing the local DNS server to bypass the root DNS servers in a query chain. In fact, because of caching, root servers are bypassed for all but a very small fraction of DNS queries.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">2.4.3 </span><span class="font23" style="font-weight:bold;">DNS Records and Messages</span></p></li></ul>
<p><a name="bookmark64"></a><span class="font53">The DNS servers that together implement the DNS distributed database store </span><span class="font53" style="font-weight:bold;">resource records (RRs)</span><span class="font53">, including RRs that provide hostname-to-IP address mappings. Each DNS reply message carries one or more resource records. In this and the following subsection, we provide a brief overview of DNS resource records and messages; more details can be found in [Albitz 1993] or in the DNS RFCs [RFC 1034; RFC 1035].</span></p>
<p><span class="font53">A resource record is a four-tuple that contains the following fields:</span></p>
<p><span class="font36">(Name, Value, Type, TTL)</span></p>
<p><span class="font36">TTL </span><span class="font53">is the time to live of the resource record; it determines when a resource should be removed from a cache. In the example records given below, we ignore the </span><span class="font36">TTL </span><span class="font53">field. The meaning of </span><span class="font36">Name </span><span class="font53">and </span><span class="font36">Value </span><span class="font53">depend on </span><span class="font36">Type</span><span class="font53">:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;If </span><span class="font36">Type=A</span><span class="font53">, then </span><span class="font36">Name </span><span class="font53">is a hostname and </span><span class="font36">Value </span><span class="font53">is the IP address for the hostname. Thus, a Type A record provides the standard hostname-to-IP address mapping. As an example, </span><span class="font36">(</span><a href="http://relay1.bar.foo.com"><span class="font36">relay1.bar.foo.com</span></a><span class="font36">, 145.37.93.12 6, A) </span><span class="font53">is a Type A record.</span></p></li>
<li>
<p><span class="font53">• &nbsp;If </span><span class="font36">Type=NS</span><span class="font53">, then </span><span class="font36">Name </span><span class="font53">is a domain (such as </span><a href="http://foo.com"><span class="font36">foo.com</span><span class="font53">)</span></a><span class="font53"> and </span><span class="font36">Value </span><span class="font53">is the hostname of an authoritative DNS server that knows how to obtain the IP addresses for hosts in the domain. This record is used to route DNS queries further along in the query chain. As an example, </span><span class="font36">(</span><a href="http://foo.com"><span class="font36">foo.com</span></a><span class="font36">,</span><a href="http://dns.foo.com"><span class="font36"> dns.foo.com</span></a><span class="font36">, NS) </span><span class="font53">is a Type NS record.</span></p></li>
<li>
<p><span class="font53">• &nbsp;If </span><span class="font36">Type=CNAME</span><span class="font53">, then </span><span class="font36">Value </span><span class="font53">is a canonical hostname for the alias hostname </span><span class="font36">Name</span><span class="font53">. This record can provide querying hosts the canonical name for a hostname. As an example, </span><span class="font36">(</span><a href="http://foo.com"><span class="font36">foo.com</span></a><span class="font36">, </span><a href="http://relay1.bar.foo.com"><span class="font36">relay1.bar.foo.com</span></a><span class="font36">, CNAME) </span><span class="font53">is a CNAME record.</span></p></li>
<li>
<p><span class="font53">• &nbsp;If </span><span class="font36">Type=MX</span><span class="font53">, then </span><span class="font36">Value </span><span class="font53">is the canonical name of a mail server that has an alias hostname </span><span class="font36">Name</span><span class="font53">. As an example, </span><span class="font36">(</span><a href="http://foo.com"><span class="font36">foo.com</span></a><span class="font36">,</span><a href="http://mail.bar.foo.com"><span class="font36"> mail.bar.foo.com</span></a><span class="font36">, MX) </span><span class="font53">is an MX record. MX records allow the hostnames of mail servers to have simple aliases. Note that by using the MX record, a company can have the same aliased name for its mail server and for one of its other servers (such as its Web server). To obtain the canonical name for the mail server, a DNS client would query for an MX record; to obtain the canonical name for the other server, the DNS client would query for the CNAME record.</span></p></li></ul>
<p><span class="font53">If a DNS server is authoritative for a particular hostname, then the DNS server will contain a Type A record for the hostname. (Even if the DNS server is not authoritative, it may contain a Type A record in its cache.) If a server is not authoritative for a hostname, then the server will contain a Type NS record for the domain that includes the hostname; it will also contain a Type A record that provides the IP address of the DNS server in the </span><span class="font36">Value </span><span class="font53">field of the NS record. As an example, suppose an edu TLD server is not authoritative for the host</span><a href="http://gaia.cs.umass.edu"><span class="font53"> </span><span class="font36">gaia.cs.umass.edu</span></a><span class="font53">. Then this server will contain a record for a domain that includes the host </span><a href="http://gaia.cs.umass.edu"><span class="font36">gaia.cs.umass</span></a><span class="font36"> </span><a href="http://gaia.cs.umass.edu"><span class="font36">.edu</span></a><span class="font53">, for example, </span><span class="font36">(</span><a href="http://umass.edu"><span class="font36">umass.edu</span></a><span class="font36">, </span><a href="http://dns.umass.edu"><span class="font36">dns.umass.edu</span></a><span class="font36">, NS)</span><span class="font53">. The edu TLD server would also contain a Type A record, which maps the DNS server </span><a href="http://dns.umass.edu"><span class="font36">dns.umass.edu </span></a><span class="font53">to an IP address, for example, </span><span class="font36">(</span><a href="http://dns.umass.edu"><span class="font36">dns.umass.edu</span></a><span class="font36">, 128.119.40.111, A)</span><span class="font53">.</span></p>
<p><span class="font22" style="font-weight:bold;">DNS Messages</span></p>
<p><span class="font53">Earlier in this section, we referred to DNS query and reply messages. These are the only two kinds of DNS messages. Furthermore, both query and reply messages have the same format, as shown in Figure 2.21.The semantics of the various fields in a DNS message are as follows:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;The first 12 bytes is the </span><span class="font53" style="font-style:italic;">header section,</span><span class="font53"> which has a number of fields. The first field is a 16-bit number that identifies the query. This identifier is copied into the reply message to a query, allowing the client to match received replies with sent queries. There are a number of flags in the flag field. A 1-bit query/reply flag indicates whether the message is a query (0) or a reply (1). A 1-bit authoritative flag is set in a reply message when a DNS server is an authoritative server for a queried name. A 1-bit recursion-desired flag is set when a client (host or DNS server) desires that the DNS server perform recursion when it doesn’t have the record. A 1-bit recursion-available field is set in a reply if the DNS server supports recursion. In the header, there are also four number-of fields. These fields indicate the number of occurrences of the four types of data sections that follow the header.</span></p></li>
<li>
<p><span class="font53">• &nbsp;The </span><span class="font53" style="font-style:italic;">question section</span><span class="font53"> contains information about the query that is being made. This section includes (1) a name field that contains the name that is being queried, and (2) a type field that indicates the type of question being asked about the name—for example, a host address associated with a name (Type A) or the mail server for a name (Type MX).</span></p></li></ul><img src="networking_files/networking-117.jpg" alt="" style="width:336pt;height:200pt;">
<p><span class="font7" style="font-weight:bold;">Figure 2.21 </span><span class="font50">♦ </span><span class="font5">DNS message format</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;In a reply from a DNS server, the </span><span class="font53" style="font-style:italic;">answer section</span><span class="font53"> contains the resource records for the name that was originally queried. Recall that in each resource record there is the </span><span class="font36">Type </span><span class="font53">(for example, A, NS, CNAME, and MX), the </span><span class="font36">Value</span><span class="font53">, and the </span><span class="font36">TTL</span><span class="font53">. A reply can return multiple RRs in the answer, since a hostname can have multiple IP addresses (for example, for replicated Web servers, as discussed earlier in this section).</span></p></li>
<li>
<p><span class="font53">• &nbsp;The </span><span class="font53" style="font-style:italic;">authority section</span><span class="font53"> contains records of other authoritative servers.</span></p></li>
<li>
<p><span class="font53">• &nbsp;The </span><span class="font53" style="font-style:italic;">additional section</span><span class="font53"> contains other helpful records. For example, the answer field in a reply to an MX query contains a resource record providing the canonical hostname of a mail server. The additional section contains a Type A record providing the IP address for the canonical hostname of the mail server.</span></p></li></ul>
<p><span class="font53">How would you like to send a DNS query message directly from the host you’re working on to some DNS server? This can easily be done with the </span><span class="font53" style="font-weight:bold;">nslookup program</span><span class="font53">, which is available from most Windows and UNIX platforms. For example, from a Windows host, open the Command Prompt and invoke the nslookup program by simply typing “nslookup.” After invoking nslookup, you can send a DNS query to any DNS server (root, TLD, or authoritative). After receiving the reply message from the DNS server, nslookup will display the records included in the reply (in a human-readable format). As an alternative to running nslookup from your own host, you can visit one of many Web sites that allow you to remotely employ nslookup. (Just type “nslookup” into a search engine and you’ll be brought to one of these sites.) The DNS Wireshark lab at the end of this chapter will allow you to explore the DNS in much more detail.</span></p>
<p><span class="font22" style="font-weight:bold;">Inserting Records into the DNS Database</span></p>
<p><span class="font53">The discussion above focused on how records are retrieved from the DNS database. You might be wondering how records get into the database in the first place. Let’s look at how this is done in the context of a specific example. Suppose you have just created an exciting new startup company called Network Utopia. The first thing you’ll surely want to do is register the domain name </span><a href="http://networkutopia.com"><span class="font36">networkutopia.com </span></a><span class="font53">at a registrar. A </span><span class="font53" style="font-weight:bold;">registrar </span><span class="font53">is a commercial entity that verifies the uniqueness of the domain name, enters the domain name into the DNS database (as discussed below), and collects a small fee from you for its services. Prior to 1999, a single registrar, Network Solutions, had a monopoly on domain name registration for </span><span class="font36">com</span><span class="font53">, </span><span class="font36">net</span><span class="font53">, and </span><span class="font36">org </span><span class="font53">domains. But now there are many registrars competing for customers, and the Internet Corporation for Assigned Names and Numbers (ICANN) accredits the various registrars. A complete list of accredited registrars is available at</span><a href="http://www.internic.net"><span class="font53"> </span><span class="font36">http://www.internic.net</span></a><span class="font53">.</span></p>
<p><span class="font53">When you register the domain name </span><a href="http://networkutopia.com"><span class="font36">networkutopia.com </span></a><span class="font53">with some registrar, you also need to provide the registrar with the names and IP addresses of your primary and secondary authoritative DNS servers. Suppose the names and IP addresses are</span><a href="http://dns1.networkutopia.com"><span class="font53"> </span><span class="font36">dns1.networkutopia.com</span></a><span class="font53">, </span><a href="http://dns2.networkutopia.com"><span class="font36">dns2.networkutopia.com</span></a><span class="font53">, </span><span class="font36">212.2.212.1, </span><span class="font53">and </span><span class="font36">212.212.212.2. </span><span class="font53">For each of these two authoritative DNS</span></p>
<div><img src="networking_files/networking-118.jpg" alt="" style="width:167pt;height:21pt;">
</div><br clear="all">
<div>
<p><span class="font23" style="font-weight:bold;">FOCUS ON SECURITY</span></p>
</div><br clear="all">
<p><span class="font4" style="font-weight:bold;">DNS VULNERABILITIES</span></p>
<p><span class="font4">We have seen that DNS is a critical component of the Internet infrastructure, with many important services—including the Web and e-mail — simply incapable of functioning without it. We therefore naturally ask, how can DNS be attacked? Is DNS a sitting duck, waiting to be knocked out of service, while taking most Internet applications down with it?</span></p>
<p><span class="font4">The first type of attack that comes to mind is a DDoS bandwidth-flooding attack (see Section 1.6) against DNS servers. For example, an attacker could attempt to send to each DNS root server a deluge of packets, so many that the majority of legitimate DNS queries never get answered. Such a large-scale DDoS attack against DNS root servers actually took place on October 21,2002. In this attack, the attackers leveraged a botnet to send truck loads of ICMP ping messages to each of the 13 DNS root IP addresses. (ICMP messages are discussed in Section 5.6. For now, it suffices to know that ICMP packets are special types of IP datagrams.) Fortunately, this large-scale attack caused minimal damage, having little or no impact on users’ Internet experience. The attackers did succeed at directing a deluge of packets at the root servers. But many of the DNS root servers were protected by packet filters, configured to always block all ICMP ping messages directed at the root servers. These protected servers were thus spared and functioned as normal. Furthermore, most local DNS servers cache the IP addresses of top-level-domain servers, allowing the query process to often bypass the DNS root servers.</span></p>
<p><span class="font4">A potentially more effective DDoS attack against DNS is send a deluge of DNS queries to top-level-domain servers, for example, to top-level-domain servers that handle the .com domain. It is harder to filter DNS queries directed to DNS servers; and top-level-domain servers are not as easily bypassed as are root servers. Such an attack took place against the top-level-domain service provider Dyn on October 21, 2016. This DDoS attack was accomplished through a large number of DNS lookup requests from a botnet consisting of about one hundred thousand IoT devices such as printers, IP cameras, residential gateways and baby monitors that had been infected with Mirai malware. For almost a full day, Amazon, Twitter, Netflix, Github and Spotify were disturbed.</span></p>
<p><span class="font4">DNS could potentially be attacked in other ways. In a man-in-the-middle attack, the attacker intercepts queries from hosts and returns bogus replies. In the DNS poisoning attack, the attacker sends bogus replies to a DNS server, tricking the server into accepting bogus records into its cache. Either of these attacks could be used, for example, to redirect an unsuspecting Web user to the attacker’s Web site. The DNS Security Extensions (DNSSEC [Gieben 2004; RFC 4033] have been designed and deployed to protect against such exploits. DNSSEC, a secured version of DNS, addresses many of these possible attacks and is gaining popularity in the Internet. </span><span class="font53">servers, the registrar would then make sure that a Type NS and a Type A record are entered into the TLD com servers. Specifically, for the primary authoritative server for</span><a href="http://networkutopia.com"><span class="font53"> </span><span class="font36">networkutopia.com</span><span class="font53">,</span></a><span class="font53"> the registrar would insert the following two resource records into the DNS system:</span></p>
<p><span class="font36">(</span><a href="http://networkutopia.com"><span class="font36">networkutopia.com</span></a><span class="font36">,</span><a href="http://dns1.networkutopia.com"><span class="font36"> dns1.networkutopia.com</span></a><span class="font36">, NS) (</span><a href="http://dns1.networkutopia.com"><span class="font36">dns1.networkutopia.com</span></a><span class="font36">, 212.212.212.1, A)</span></p>
<p><span class="font53">You’ll also have to make sure that the Type A resource record for your Web server </span><a href="http://www.networkutopia.com"><span class="font36">www.networkutopia.com </span></a><span class="font53">and the Type MX resource record for your mail server</span><a href="http://mail.networkutopia.com"><span class="font53"> </span><span class="font36">mail.networkutopia.com </span></a><span class="font53">are entered into your authoritative DNS servers. (Until recently, the contents of each DNS server were configured statically, for example, from a configuration file created by a system manager. More recently, an UPDATE option has been added to the DNS protocol to allow data to be dynamically added or deleted from the database via DNS messages. [RFC 2136] and [RFC 3007] specify DNS dynamic updates.)</span></p>
<p><span class="font53">Once all of these steps are completed, people will be able to visit your Web site and send e-mail to the employees at your company. Let’s conclude our discussion of DNS by verifying that this statement is true. This verification also helps to solidify what we have learned about DNS. Suppose Alice in Australia wants to view the Web page </span><a href="http://www.networkutopia.com"><span class="font36">www.networkutopia.com</span></a><span class="font53">. As discussed earlier, her host will first send a DNS query to her local DNS server. The local DNS server will then contact a TLD </span><span class="font36">com </span><span class="font53">server. (The local DNS server will also have to contact a root DNS server if the address of a TLD </span><span class="font36">com </span><span class="font53">server is not cached.) This TLD server contains the Type NS and Type A resource records listed above, because the registrar had these resource records inserted into all of the TLD com servers. The TLD com server sends a reply to Alice’s local DNS server, with the reply containing the two resource records. The local DNS server then sends a DNS query to </span><span class="font36">212.212.212.1</span><span class="font53">, asking for the Type A record corresponding to </span><a href="http://www.networkutopia.com"><span class="font36">www.networkutopia.com</span></a><span class="font53">. This record provides the IP address of the desired Web server, say, </span><span class="font36">212.212.71.4</span><span class="font53">, which the local DNS server passes back to Alice’s host. Alice’s browser can now initiate a TCP connection to the host </span><span class="font36">212.212.71.4 </span><span class="font53">and send an HTTP request over the connection. Whew! There’s a lot more going on than what meets the eye when one surfs the Web!</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">2.5 </span><span class="font24" style="font-weight:bold;">Peer-to-Peer File Distribution</span></p></li></ul>
<p><a name="bookmark65"></a><span class="font53">The applications described in this chapter thus far—including the Web, e-mail, and DNS—all employ client-server architectures with significant reliance on always-on infrastructure servers. Recall from Section 2.1.1 that with a P2P architecture, there is minimal (or no) reliance on always-on infrastructure servers. Instead, pairs of intermittently connected hosts, called peers, communicate directly with each other. The peers are not owned by a service provider, but are instead PCs, laptops, and smartpones controlled by users.</span></p>
<p><span class="font53">In this section, we consider a very natural P2P application, namely, distributing a large file from a single server to a large number of hosts (called peers). The file might be a new version of the Linux operating system, a software patch for an existing operating system or an MPEG video file. In client-server file distribution, the server must send a copy of the file to each of the peers—placing an enormous burden on the server and consuming a large amount of server bandwidth. In P2P file distribution, each peer can redistribute any portion of the file it has received to any other peers, thereby assisting the server in the distribution process. As of 2020, the most popular P2P file distribution protocol is BitTorrent. Originally developed by Bram Cohen, there are now many different independent BitTorrent clients conforming to the BitTorrent protocol, just as there are a number of Web browser clients that conform to the HTTP protocol. In this subsection, we first examine the self-scalability of P2P architectures in the context of file distribution. We then describe BitTorrent in some detail, highlighting its most important characteristics and features.</span></p>
<p><span class="font22" style="font-weight:bold;">Scalability of P2P Architectures</span></p>
<p><span class="font53">To compare client-server architectures with peer-to-peer architectures, and illustrate the inherent self-scalability of P2P, we now consider a simple quantitative model for distributing a file to a fixed set of peers for both architecture types. As shown in Figure 2.22, the server and the peers are connected to the Internet with access</span></p>
<div>
<p><span class="font4">File: F</span></p><img src="networking_files/networking-119.jpg" alt="" style="width:20pt;height:27pt;">
</div><br clear="all">
<div>
<p><span class="font4">Server</span></p><img src="networking_files/networking-120.jpg" alt="" style="width:48pt;height:46pt;">
</div><br clear="all">
<div>
<p><span class="font9">•W</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-121.jpg" alt="" style="width:39pt;height:37pt;">
<p><span class="font50" style="font-style:italic;text-decoration:underline;"><sup>d</sup>N</span></p>
<p><span class="font11" style="font-style:italic;font-variant:small-caps;">•</span><span class="font4" style="font-style:italic;font-variant:small-caps;">n</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Internet</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-122.jpg" alt="" style="width:43pt;height:43pt;">
</div><br clear="all">
<div><img src="networking_files/networking-123.jpg" alt="" style="width:35pt;height:37pt;">
</div><br clear="all">
<div><img src="networking_files/networking-124.jpg" alt="" style="width:62pt;height:85pt;">
</div><br clear="all">
<div><img src="networking_files/networking-125.jpg" alt="" style="width:78pt;height:101pt;">
</div><br clear="all">
<div><img src="networking_files/networking-126.jpg" alt="" style="width:34pt;height:37pt;">
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 2.22 </span><span class="font50">♦ </span><span class="font5">An illustrative file distribution problem</span></p>
<p><span class="font53">links. Denote the upload rate of the server’s access link by </span><span class="font53" style="font-style:italic;">u<sub>s</sub>,</span><span class="font53"> the upload rate of the </span><span class="font53" style="font-style:italic;">i</span><span class="font53">th peer’s access link by </span><span class="font53" style="font-style:italic;">u<sub>{</sub>,</span><span class="font53"> and the download rate of the </span><span class="font53" style="font-style:italic;">i</span><span class="font53">th peer’s access link by </span><span class="font53" style="font-style:italic;">d<sub>t</sub>.</span><span class="font53"> Also denote the size of the file to be distributed (in bits) by </span><span class="font53" style="font-style:italic;">F</span><span class="font53"> and the number of peers that want to obtain a copy of the file by </span><span class="font53" style="font-style:italic;">N.</span><span class="font53"> The </span><span class="font53" style="font-weight:bold;">distribution time </span><span class="font53">is the time it takes to get a copy of the file to all </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> peers. In our analysis of the distribution time below, for both client-server and P2P architectures, we make the simplifying (and generally accurate [Akella 2003]) assumption that the Internet core has abundant bandwidth, implying that all of the bottlenecks are in access networks. We also suppose that the server and clients are not participating in any other network applications, so that all of their upload and download access bandwidth can be fully devoted to distributing this file.</span></p>
<p><span class="font53">Let’s first determine the distribution time for the client-server architecture, which we denote by </span><span class="font53" style="font-style:italic;">D<sub>cs</sub>.</span><span class="font53"> In the client-server architecture, none of the peers aids in distributing the file. We make the following observations:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;The server must transmit one copy of the file to each of the </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> peers. Thus, the server must transmit </span><span class="font53" style="font-style:italic;">NF</span><span class="font53"> bits. Since the server’s upload rate is </span><span class="font53" style="font-style:italic;">u<sub>s</sub>,</span><span class="font53"> the time to distribute the file must be at least </span><span class="font53" style="font-style:italic;">NF/u<sub>s</sub>.</span></p></li>
<li>
<p><span class="font53">• &nbsp;Let </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>min</sub> denote the download rate of the peer with the lowest download rate, that is, </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>min</sub> </span><span class="font54">= </span><span class="font53">min { </span><span class="font53" style="font-style:italic;">d<sub>1</sub>, d<sub>p</sub>,</span><span class="font53"> . . . , </span><span class="font53" style="font-style:italic;">d<sub>N</sub></span><span class="font53">}. The peer with the lowest download rate cannot obtain all </span><span class="font53" style="font-style:italic;">F</span><span class="font53"> bits of the file in less than </span><span class="font53" style="font-style:italic;">F</span><span class="font53">/</span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>min</sub> seconds. Thus, the minimum distribution time is at least </span><span class="font53" style="font-style:italic;">F</span><span class="font53">/</span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>min</sub>.</span></p></li></ul>
<p><span class="font53">Putting these two observations together, we obtain</span></p>
<p><span class="font53" style="font-style:italic;">NF F</span></p>
<p><span class="font50" style="font-style:italic;"><sup>D</sup>cs</span><span class="font55"> ' </span><span class="font59"><sup>maX</sup> </span><span class="font53" style="font-variant:small-caps;">b</span><span class="font50" style="font-style:italic;"> &nbsp;&nbsp;’ d-</span><span class="font67"> <sup>R</sup> </span><span class="font53">.</span></p>
<p><span class="font53">This provides a lower bound on the minimum distribution time for the client-server architecture. In the homework problems, you will be asked to show that the server can schedule its transmissions so that the lower bound is actually achieved. So let’s take this lower bound provided above as the actual distribution time, that is,</span></p>
<p><span class="font53" style="font-style:italic;">D</span><span class="font50" style="font-style:italic;">cs </span><span class="font53" style="font-style:italic;">=</span><span class="font53"> max </span><span class="font53" style="font-variant:small-caps;">b </span><span class="font53" style="font-style:italic;"><sup>NF</sup></span><span class="font53">, </span><span class="font53" style="font-style:italic;">f</span><span class="font53"> R </span><span class="font53" style="font-style:italic;"><sup>u</sup></span><span class="font50" style="font-style:italic;">s </span><span class="font53" style="font-style:italic;"><sup>d</sup></span><span class="font50">min</span></p>
<div>
<p><span class="font53">(2.1)</span></p>
</div><br clear="all">
<p><span class="font53">We see from Equation 2.1 that for </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> large enough, the client-server distribution time is given by </span><span class="font53" style="font-style:italic;">NF/u<sub>s</sub>.</span><span class="font53"> Thus, the distribution time increases linearly with the number of peers </span><span class="font53" style="font-style:italic;">N</span><span class="font53">. So, for example, if the number of peers from one week to the next increases a thousand-fold from a thousand to a million, the time required to distribute the file to all peers increases by 1,000.</span></p>
<p><span class="font53">Let’s now go through a similar analysis for the P2P architecture, where each peer can assist the server in distributing the file. In particular, when a peer receives some file data, it can use its own upload capacity to redistribute the data to other peers. Calculating the distribution time for the P2P architecture is somewhat more complicated than for the client-server architecture, since the distribution time depends on how each peer distributes portions of the file to the other peers. Nevertheless, a simple expression for the minimal distribution time can be obtained [Kumar 2006]. To this end, we first make the following observations:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;At the beginning of the distribution, only the server has the file. To get this file into the community of peers, the server must send each bit of the file at least once into its access link. Thus, the minimum distribution time is at least </span><span class="font53" style="font-style:italic;">F/u<sub>s</sub>.</span><span class="font53"> (Unlike the client-server scheme, a bit sent once by the server may not have to be sent by the server again, as the peers may redistribute the bit among themselves.)</span></p></li>
<li>
<p><span class="font53">• &nbsp;As with the client-server architecture, the peer with the lowest download rate cannot obtain all </span><span class="font53" style="font-style:italic;">F</span><span class="font53"> bits of the file in less than </span><span class="font53" style="font-style:italic;">F</span><span class="font53">/</span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>min</sub> seconds. Thus, the minimum distribution time is at least </span><span class="font53" style="font-style:italic;">F</span><span class="font53">/</span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>min</sub>.</span></p></li>
<li>
<p><span class="font53">• &nbsp;Finally, observe that the total upload capacity of the system as a whole is equal to the upload rate of the server plus the upload rates of each of the individual peers, that is, </span><span class="font53" style="font-style:italic;">u</span><span class="font53"><sub>total</sub> </span><span class="font54">= </span><span class="font53" style="font-style:italic;">u<sub>s</sub></span><span class="font55"> + </span><span class="font53" style="font-style:italic;">u-</span><span class="font49" style="font-style:italic;">1</span><span class="font55"> + </span><span class="font53">• </span><span class="font53" style="font-style:italic;">• </span><span class="font55">■ + </span><span class="font53" style="font-style:italic;">u<sub>N</sub>.</span><span class="font53"> The system must deliver (upload) </span><span class="font53" style="font-style:italic;">F </span><span class="font53">bits to each of the </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> peers, thus delivering a total of </span><span class="font53" style="font-style:italic;">NF</span><span class="font53"> bits. This cannot be done at a rate faster than </span><span class="font53" style="font-style:italic;">u</span><span class="font53"><sub>total</sub>. Thus, the minimum distribution time is also at least </span><span class="font53" style="font-style:italic;">NF/(u<sub>s</sub></span><span class="font55"> + </span><span class="font53" style="font-style:italic;">u</span><span class="font50">i </span><span class="font55">+ </span><span class="font53">• </span><span class="font53" style="font-style:italic;">• </span><span class="font55">• + </span><span class="font53" style="font-style:italic;">u</span><span class="font50" style="font-style:italic;">N</span><span class="font53" style="font-style:italic;">).</span></p></li></ul>
<p><span class="font53">Putting these three observations together, we obtain the minimum distribution time for P2P, denoted by </span><span class="font53" style="font-style:italic;">D<sub>p2p</sub>.</span></p>
<div>
<p><span class="font65" style="font-style:italic;">{</span><span class="font53" style="font-style:italic;">F </span><span class="font53" style="font-style:italic;text-decoration:underline;">F</span><span class="font53" style="font-style:italic;">__NF</span></p>
<p><span class="font53" style="font-weight:bold;font-style:italic;"><sup>u</sup>S </span><span class="font53" style="font-style:italic;">d </span><span class="font53" style="font-weight:bold;font-style:italic;">' <sub>u</sub></span><span class="font55"> + </span><span class="font53" style="font-weight:bold;font-style:italic;">y^<sub>u</sub> </span><span class="font66" style="font-variant:small-caps;"><sup>s</sup></span></p>
</div><br clear="all">
<div>
<p><span class="font53">(2.2)</span></p>
</div><br clear="all">
<p><span class="font53">Equation 2.2 provides a lower bound for the minimum distribution time for the P2P architecture. It turns out that if we imagine that each peer can redistribute a bit as soon as it receives the bit, then there is a redistribution scheme that actually achieves this lower bound [Kumar 2006]. (We will prove a special case of this result in the homework.) In reality, where chunks of the file are redistributed rather than individual bits, Equation 2.2 serves as a good approximation of the actual minimum distribution time. Thus, let’s take the lower bound provided by Equation 2.2 as the actual minimum distribution time, that is,</span></p>
<div>
<p><span class="font65" style="font-style:italic;">{</span><span class="font53" style="font-style:italic;">F </span><span class="font53" style="font-style:italic;text-decoration:underline;">F</span><span class="font53" style="font-style:italic;">__NF</span></p>
<p><span class="font53" style="font-style:italic;"><sup>u</sup></span><span class="font50" style="font-style:italic;">S </span><span class="font53" style="font-style:italic;"><sup>d</sup></span><span class="font49" style="font-style:italic;">mn </span><span class="font53" style="font-weight:bold;font-style:italic;"><sub>u</sub></span><span class="font56" style="font-weight:bold;"><sub> +</sub> ^</span><span class="font53" style="font-weight:bold;font-style:italic;"><sub>u</sub> </span><span class="font66" style="font-variant:small-caps;"><sup>s</sup></span></p>
</div><br clear="all">
<div>
<p><span class="font53">(2.3)</span></p>
</div><br clear="all"><img src="networking_files/networking-127.jpg" alt="" style="width:274pt;height:180pt;">
<p><span class="font7" style="font-weight:bold;">Figure 2.23 </span><span class="font50">♦ </span><span class="font5">Distribution time for P2P and client-server architectures</span></p>
<p><span class="font53">Figure 2.23 compares the minimum distribution time for the client-server and P2P architectures assuming that all peers have the same upload rate </span><span class="font53" style="font-style:italic;">u.</span><span class="font53"> In Figure 2.23, we have set </span><span class="font53" style="font-style:italic;">F/u =</span><span class="font53"> 1 hour, </span><span class="font53" style="font-style:italic;">u<sub>s</sub> =</span><span class="font53"> 10</span><span class="font53" style="font-style:italic;">u</span><span class="font53">, and </span><span class="font53" style="font-style:italic;">d<sub>min</sub></span><span class="font55"> &gt;&nbsp;</span><span class="font53" style="font-style:italic;">u<sub>s</sub>.</span><span class="font53"> Thus, a peer can transmit the entire file in one hour, the server transmission rate is 10 times the peer upload rate, and (for simplicity) the peer download rates are set large enough so as not to have an effect. We see from Figure 2.23 that for the client-server architecture, the distribution time increases linearly and without bound as the number of peers increases. However, for the P2P architecture, the minimal distribution time is not only always less than the distribution time of the client-server architecture; it is also less than one hour for </span><span class="font53" style="font-style:italic;">any</span><span class="font53"> number of peers </span><span class="font53" style="font-style:italic;">N.</span><span class="font53"> Thus, applications with the P2P architecture can be self-scaling. This scalability is a direct consequence of peers being redistributors as well as consumers of bits.</span></p>
<p><span class="font22" style="font-weight:bold;">BitTorrent</span></p>
<p><span class="font53">BitTorrent is a popular P2P protocol for file distribution [Chao 2011]. In BitTorrent lingo, the collection of all peers participating in the distribution of a particular file is called a </span><span class="font53" style="font-style:italic;">torrent.</span><span class="font53"> Peers in a torrent download equal-size </span><span class="font53" style="font-style:italic;">chunks</span><span class="font53"> of the file from one another, with a typical chunk size of 256 KBytes. When a peer first joins a torrent, it has no chunks. Over time it accumulates more and more chunks. While it downloads chunks it also uploads chunks to other peers. Once a peer has acquired the entire file, it may (selfishly) leave the torrent, or (altruistically) remain in the torrent and continue to upload chunks to other peers. Also, any peer may leave the torrent at any time with only a subset of chunks, and later rejoin the torrent.</span></p>
<p><span class="font4">Tracker</span></p>
<p><span class="font4">Peer</span></p>
<p><span class="font4">Obtain list of peers</span></p><img src="networking_files/networking-128.jpg" alt="" style="width:335pt;height:246pt;">
<p><span class="font4">Trading chunks</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 2.24 </span><span class="font50">♦ </span><span class="font5">File distribution with BitTorrent</span></p>
<p><span class="font53">Let’s now take a closer look at how BitTorrent operates. Since BitTorrent is a rather complicated protocol and system, we’ll only describe its most important mechanisms, sweeping some of the details under the rug; this will allow us to see the forest through the trees. Each torrent has an infrastructure node called a </span><span class="font53" style="font-style:italic;">tracker. </span><span class="font53">When a peer joins a torrent, it registers itself with the tracker and periodically informs the tracker that it is still in the torrent. In this manner, the tracker keeps track of the peers that are participating in the torrent. A given torrent may have fewer than ten or more than a thousand peers participating at any instant of time.</span></p>
<p><span class="font53">As shown in Figure 2.24, when a new peer, Alice, joins the torrent, the tracker randomly selects a subset of peers (for concreteness, say 50) from the set of participating peers, and sends the IP addresses of these 50 peers to Alice. Possessing this list of peers, Alice attempts to establish concurrent TCP connections with all the peers on this list. Let’s call all the peers with which Alice succeeds in establishing a TCP connection “neighboring peers.” (In Figure 2.24, Alice is shown to have only three neighboring peers. Normally, she would have many more.) As time evolves, some of these peers may leave and other peers (outside the initial 50) may attempt to establish TCP connections with Alice. So a peer’s neighboring peers will fluctuate over time.</span></p>
<p><span class="font53">At any given time, each peer will have a subset of chunks from the file, with different peers having different subsets. Periodically, Alice will ask each of her neighboring peers (over the TCP connections) for the list of the chunks they have. If Alice has </span><span class="font53" style="font-style:italic;">L</span><span class="font53"> different neighbors, she will obtain </span><span class="font53" style="font-style:italic;">L</span><span class="font53"> lists of chunks. With this knowledge, Alice will issue requests (again over the TCP connections) for chunks she currently does not have.</span></p>
<p><span class="font53">So at any given instant of time, Alice will have a subset of chunks and will know which chunks her neighbors have. With this information, Alice will have two important decisions to make. First, which chunks should she request first from her neighbors? And second, to which of her neighbors should she send requested chunks? In deciding which chunks to request, Alice uses a technique called </span><span class="font53" style="font-weight:bold;">rarest first</span><span class="font53">. The idea is to determine, from among the chunks she does not have, the chunks that are the rarest among her neighbors (that is, the chunks that have the fewest repeated copies among her neighbors) and then request those rarest chunks first. In this manner, the rarest chunks get more quickly redistributed, aiming to (roughly) equalize the numbers of copies of each chunk in the torrent.</span></p>
<p><span class="font53">To determine which requests she responds to, BitTorrent uses a clever trading algorithm. The basic idea is that Alice gives priority to the neighbors that are currently supplying her data </span><span class="font53" style="font-style:italic;">at the highest rate.</span><span class="font53"> Specifically, for each of her neighbors, Alice continually measures the rate at which she receives bits and determines the four peers that are feeding her bits at the highest rate. She then reciprocates by sending chunks to these same four peers. Every 10 seconds, she recalculates the rates and possibly modifies the set of four peers. In BitTorrent lingo, these four peers are said to be </span><span class="font53" style="font-weight:bold;">unchoked</span><span class="font53">. Importantly, every 30 seconds, she also picks one additional neighbor at random and sends it chunks. Let’s call the randomly chosen peer Bob. In BitTorrent lingo, Bob is said to be </span><span class="font53" style="font-weight:bold;">optimistically unchoked</span><span class="font53">. Because Alice is sending data to Bob, she may become one of Bob’s top four uploaders, in which case Bob would start to send data to Alice. If the rate at which Bob sends data to Alice is high enough, Bob could then, in turn, become one of Alice’s top four uploaders. In other words, every 30 seconds, Alice will randomly choose a new trading partner and initiate trading with that partner. If the two peers are satisfied with the trading, they will put each other in their top four lists and continue trading with each other until one of the peers finds a better partner. The effect is that peers capable of uploading at compatible rates tend to find each other. The random neighbor selection also allows new peers to get chunks, so that they can have something to trade. All other neighboring peers besides these five peers (four “top” peers and one probing peer) are “choked,” that is, they do not receive any chunks from Alice. BitTorrent has a number of interesting mechanisms that are not discussed here, including pieces (mini-chunks), pipelining, random first selection, endgame mode, and anti-snubbing [Cohen 2003].</span></p>
<p><span class="font53">The incentive mechanism for trading just described is often referred to as tit-for-tat [Cohen 2003]. It has been shown that this incentive scheme can be circumvented [Liogkas 2006; Locher 2006; Piatek 2008]. Nevertheless, the BitTorrent ecosystem is wildly successful, with millions of simultaneous peers actively sharing files in</span></p>
<p><span class="font53">hundreds of thousands of torrents. If BitTorrent had been designed without tit-for-tat (or a variant), but otherwise exactly the same, BitTorrent would likely not even exist now, as the majority of the users would have been freeriders [Saroiu 2002].</span></p>
<div>
<p><span class="font16" style="font-weight:bold;">D</span></p>
<p><span class="font2" style="font-weight:bold;">VideoNote </span><span class="font1" style="font-weight:bold;">Walking though distributed hash tables</span></p>
</div><br clear="all">
<p><span class="font53">We close our discussion on P2P by briefly mentioning another application of P2P, namely, Distributed Hast Table (DHT). A distributed hash table is a simple database, with the database records being distributed over the peers in a P2P system. DHTs have been widely implemented (e.g., in BitTorrent) and have been the subject of extensive research. An overview is provided in a Video Note in the Companion Website.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">2.6 </span><span class="font24" style="font-weight:bold;">Video Streaming and Content Distribution Networks</span></p></li></ul>
<p><span class="font53">By many estimates, streaming video—including Netflix, YouTube and Amazon Prime—account for about 80% of Internet traffic in 2020 [Cisco 2020]. This section we will provide an overview of how popular video streaming services are implemented in today’s Internet. We will see they are implemented using application-level protocols and servers that function in some ways like a cache.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">2.6.1 </span><span class="font23" style="font-weight:bold;">Internet Video</span></p></li></ul>
<p><span class="font53">In streaming stored video applications, the underlying medium is prerecorded video, such as a movie, a television show, a prerecorded sporting event, or a prerecorded user-generated video (such as those commonly seen on YouTube). These prerecorded videos are placed on servers, and users send requests to the servers to view the videos </span><span class="font53" style="font-style:italic;">on demand.</span><span class="font53"> Many Internet companies today provide streaming video, including, Netflix, YouTube (Google), Amazon, and TikTok.</span></p>
<p><span class="font53">But before launching into a discussion of video streaming, we should first get a quick feel for the video medium itself. A video is a sequence of images, typically being displayed at a constant rate, for example, at 24 or 30 images per second. An uncompressed, digitally encoded image consists of an array of pixels, with each pixel encoded into a number of bits to represent luminance and color. An important characteristic of video is that it can be compressed, thereby trading off video quality with bit rate. Today’s off-the-shelf compression algorithms can compress a video to essentially any bit rate desired. Of course, the higher the bit rate, the better the image quality and the better the overall user viewing experience.</span></p>
<p><a name="bookmark66"></a><span class="font53">From a networking perspective, perhaps the most salient characteristic of video is its high bit rate. Compressed Internet video typically ranges from 100 kbps for low-quality video to over 4 Mbps for streaming high-definition movies; 4K streaming envisions a bitrate of more than 10 Mbps. This can translate to huge amount of traffic and storage, particularly for high-end video. For example, a single 2 Mbps video with a duration of 67 minutes will consume 1 gigabyte of storage and traffic. By far, the most important performance measure for streaming video is average end-to-end throughput. In order to provide continuous playout, the network must provide an average throughput to the streaming application that is at least as large as the bit rate of the compressed video.</span></p>
<p><span class="font53">We can also use compression to create multiple versions of the same video, each at a different quality level. For example, we can use compression to create, say, three versions of the same video, at rates of 300 kbps, 1 Mbps, and 3 Mbps. Users can then decide which version they want to watch as a function of their current available bandwidth. Users with high-speed Internet connections might choose the 3 Mbps version; users watching the video over 3G with a smartphone might choose the 300 kbps version.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">2.6.2 </span><span class="font23" style="font-weight:bold;">HTTP Streaming and DASH</span></p></li></ul>
<p><span class="font53">In HTTP streaming, the video is simply stored at an HTTP server as an ordinary file with a specific URL. When a user wants to see the video, the client establishes a TCP connection with the server and issues an HTTP </span><span class="font36">GET </span><span class="font53">request for that URL. The server then sends the video file, within an HTTP response message, as quickly as the underlying network protocols and traffic conditions will allow. On the client side, the bytes are collected in a client application buffer. Once the number of bytes in this buffer exceeds a predetermined threshold, the client application begins play-back—specifically, the streaming video application periodically grabs video frames from the client application buffer, decompresses the frames, and displays them on the user’s screen. Thus, the video streaming application is displaying video as it is receiving and buffering frames corresponding to latter parts of the video.</span></p>
<p><span class="font53">Although HTTP streaming, as described in the previous paragraph, has been extensively deployed in practice (for example, by YouTube since its inception), it has a major shortcoming: All clients receive the same encoding of the video, despite the large variations in the amount of bandwidth available to a client, both across different clients and also over time for the same client. This has led to the development of a new type of HTTP-based streaming, often referred to as </span><span class="font53" style="font-weight:bold;">Dynamic Adaptive Streaming over HTTP (DASH)</span><span class="font53">. In DASH, the video is encoded into several different versions, with each version having a different bit rate and, correspondingly, a different quality level. The client dynamically requests chunks of video segments of a few seconds in length. When the amount of available bandwidth is high, the client naturally selects chunks from a high-rate version; and when the available bandwidth is low, it naturally selects from a low-rate version. The client selects different chunks one at a time with HTTP GET request messages [Akhshabi 2011].</span></p>
<p><a name="bookmark67"></a><span class="font53">DASH allows clients with different Internet access rates to stream in video at different encoding rates. Clients with low-speed 3G connections can receive a low bit-rate (and low-quality) version, and clients with fiber connections can receive a high-quality version. DASH also allows a client to adapt to the available bandwidth if the available end-to-end bandwidth changes during the session. This feature is particularly important for mobile users, who typically see their bandwidth availability fluctuate as they move with respect to the base stations.</span></p>
<p><span class="font53">With DASH, each video version is stored in the HTTP server, each with a different URL. The HTTP server also has a </span><span class="font53" style="font-weight:bold;">manifest file</span><span class="font53">, which provides a URL for each version along with its bit rate. The client first requests the manifest file and learns about the various versions. The client then selects one chunk at a time by specifying a URL and a byte range in an HTTP GET request message for each chunk. While downloading chunks, the client also measures the received bandwidth and runs a rate determination algorithm to select the chunk to request next. Naturally, if the client has a lot of video buffered and if the measured receive bandwidth is high, it will choose a chunk from a high-bitrate version. And naturally if the client has little video buffered and the measured received bandwidth is low, it will choose a chunk from a low-bitrate version. DASH therefore allows the client to freely switch among different quality levels.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">2.6.3 </span><span class="font23" style="font-weight:bold;">Content Distribution Networks</span></p></li></ul>
<p><span class="font53">Today, many Internet video companies are distributing on-demand multi-Mbps streams to millions of users on a daily basis. YouTube, for example, with a library of hundreds of millions of videos, distributes hundreds of millions of video streams to users around the world every day. Streaming all this traffic to locations all over the world while providing continuous playout and high interactivity is clearly a challenging task.</span></p>
<p><span class="font53">For an Internet video company, perhaps the most straightforward approach to providing streaming video service is to build a single massive data center, store all of its videos in the data center, and stream the videos directly from the data center to clients worldwide. But there are three major problems with this approach. First, if the client is far from the data center, server-to-client packets will cross many communication links and likely pass through many ISPs, with some of the ISPs possibly located on different continents. If one of these links provides a throughput that is less than the video consumption rate, the end-to-end throughput will also be below the consumption rate, resulting in annoying freezing delays for the user. (Recall from Chapter 1 that the end-to-end throughput of a stream is governed by the throughput at the bottleneck link.) The likelihood of this happening increases as the number of links in the end-to-end path increases. A second drawback is that a popular video will likely be sent many times over the same communication links. Not only does this waste network bandwidth, but the Internet video company itself will be paying its provider ISP (connected to the data center) for sending the </span><span class="font53" style="font-style:italic;">same</span><span class="font53"> bytes into the Internet over and over again. A third problem with this solution is that a single data center represents a single point of failure—if the data center or its links to the Internet goes down, it would not be able to distribute </span><span class="font53" style="font-style:italic;">any</span><span class="font53"> video streams.</span></p>
<p><a name="bookmark68"></a><span class="font53">In order to meet the challenge of distributing massive amounts of video data to users distributed around the world, almost all major video-streaming companies make use of </span><span class="font53" style="font-weight:bold;">Content Distribution Networks (CDNs)</span><span class="font53">. A CDN manages servers in multiple geographically distributed locations, stores copies of the videos (and other types of Web content, including documents, images, and audio) in its servers, and attempts to direct each user request to a CDN location that will provide the best user experience. The CDN may be a </span><span class="font53" style="font-weight:bold;">private CDN</span><span class="font53">, that is, owned by the content provider itself; for example, Google’s CDN distributes YouTube videos and other types of content. The CDN may alternatively be a </span><span class="font53" style="font-weight:bold;">third-party CDN </span><span class="font53">that distributes content on behalf of multiple content providers; Akamai, Limelight and Level-3 all operate third-party CDNs. A very readable overview of modern CDNs is [Leighton 2009; Nygren 2010].</span></p>
<p><span class="font53">CDNs typically adopt one of two different server placement philosophies [Huang 2008]:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-weight:bold;">Enter Deep. </span><span class="font53">One philosophy, pioneered by Akamai, is to </span><span class="font53" style="font-style:italic;">enter deep</span><span class="font53"> into the access networks of Internet Service Providers, by deploying server clusters in access ISPs all over the world. (Access networks are described in Section 1.3.) Akamai takes this approach with clusters in thousands of locations. The goal is to get close to end users, thereby improving user-perceived delay and throughput by decreasing the number of links and routers between the end user and the CDN server from which it receives content. Because of this highly distributed design, the task of maintaining and managing the clusters becomes challenging.</span></p></li>
<li>
<p><span class="font53">• </span><span class="font53" style="font-weight:bold;">Bring Home. </span><span class="font53">A second design philosophy, taken by Limelight and many other CDN companies, is to </span><span class="font53" style="font-style:italic;">bring the ISPs home</span><span class="font53"> by building large clusters at a smaller number (for example, tens) of sites. Instead of getting inside the access ISPs, these CDNs typically place their clusters in Internet Exchange Points (IXPs) (see Section 1.3). Compared with the enter-deep design philosophy, the bring-home design typically results in lower maintenance and management overhead, possibly at the expense of higher delay and lower throughput to end users.</span></p></li></ul>
<p><span class="font53">Once its clusters are in place, the CDN replicates content across its clusters. The CDN may not want to place a copy of every video in each cluster, since some videos are rarely viewed or are only popular in some countries. In fact, many CDNs do not push videos to their clusters but instead use a simple pull strategy: If a client requests a video from a cluster that is not storing the video, then the cluster retrieves the video (from a central repository or from another cluster) and stores a copy locally while streaming the video to the client at the same time. Similar Web caching (see Section 2.2.5), when a cluster’s storage becomes full, it removes videos that are not frequently requested.</span></p>
<p><span class="font22" style="font-weight:bold;">CDN Operation</span></p>
<p><span class="font53">Having identified the two major approaches toward deploying a CDN, let’s now dive down into the nuts and bolts of how a CDN operates. When a browser in a user’s</span></p>
<p><span class="font62" style="font-weight:bold;font-variant:small-caps;"><sup>case study</sup></span></p>
<p><span class="font4" style="font-weight:bold;">GOOGLE’S NETWORK INFRASTRUCTURE</span></p>
<p><span class="font4">To support its vast array of services—including search, Gmail, calendar, YouTube video, maps, documents, and social networks—Google has deployed an extensive private network and CDN infrastructure. Google’s CDN infrastructure has three tiers of server clusters:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font4">Nineteen “mega data centers” in North America, Europe, and Asia [Google Locations 2020], with each data center having on the order of 100,000 servers. These mega data centers are responsible for serving dynamic (and often personalized) content, including search results and Gmail messages.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font4">With about 90 clusters in IXPs scattered throughout the world, with each cluster consisting of hundreds of servers servers [Adhikari 2011a] [Google CDN 2020]. These clusters are responsible for serving static content, including YouTube videos.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font4">Many hundreds of “enter-deep” clusters located within an access ISP. Here a cluster typically consists of tens of servers within a single rack. These enter-deep servers perform TCP splitting (see Section 3.7) and serve static content [Chen 2011], including the static portions of Web pages that embody search results.</span></p></li></ul>
<p><span class="font4">All of these data centers and cluster locations are networked together with Google’s own private network. When a user makes a search query, often the query is first sent over the local ISP to a nearby enter-deep cache, from where the static content is retrieved; while providing the static content to the client, the nearby cache also forwards the query over Google’s private network to one of the mega data centers, from where the personalized search results are retrieved. For a YouTube video, the video itself may come from one of the bring-home caches, whereas portions of the Web page surrounding the video may come from the nearby enter-deep cache, and the advertisements surrounding the video come from the data centers. In summary, except for the local ISPs, the Google cloud services are largely provided by a network infrastructure that is independent of the public Internet.</span></p>
<p><span class="font53">host is instructed to retrieve a specific video (identified by a URL), the CDN must intercept the request so that it can (1) determine a suitable CDN server cluster for that client at that time, and (2) redirect the client’s request to a server in that cluster. We’ll shortly discuss how a CDN can determine a suitable cluster. But first let’s examine the mechanics behind intercepting and redirecting a request.</span></p>
<p><span class="font53">Most CDNs take advantage of DNS to intercept and redirect requests; an interesting discussion of such a use of the DNS is [Vixie 2009]. Let’s consider a simple example to illustrate how the DNS is typically involved. Suppose a content provider, NetCinema, employs the third-party CDN company, KingCDN, to distribute its videos to its customers. On the NetCinema Web pages, each of its videos is assigned a URL that includes the string “video” and a unique identifier for the video itself; for example, </span><span class="font53" style="font-style:italic;">Transformers 7</span><span class="font53"> might be assigned</span><a href="http://video.netcinema.com/6Y7B23V"><span class="font53"> http://video.netcinema.com/6Y7B23V</span></a><span class="font53">. Six steps then occur, as shown in Figure 2.25:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">1. The user visits the Web page at NetCinema.</span></p></li>
<li>
<p><span class="font53">2. When the user clicks on the link </span><a href="http://video.netcinema.com/6Y7B23V"><span class="font53">http://video.netcinema.com/6Y7B23V</span></a><span class="font53">, the user’s host sends a DNS query for </span><a href="http://video.netcinema.com"><span class="font53">video.netcinema.com</span></a><span class="font53">.</span></p></li>
<li>
<p><span class="font53">3. The user’s Local DNS Server (LDNS) relays the DNS query to an authoritative DNS server for NetCinema, which observes the string “video” in the hostname</span><a href="http://video.netcinema.com"><span class="font53"> video.netcinema.com</span></a><span class="font53">. To “hand over” the DNS query to KingCDN, instead of returning an IP address, the NetCinema authoritative DNS server returns to the LDNS a hostname in the KingCDN’s domain, for example, </span><a href="http://a1105.kingcdn.com"><span class="font53">a1105.kingcdn.com</span></a><span class="font53">.</span></p></li>
<li>
<p><span class="font53">4. From this point on, the DNS query enters into KingCDN’s private DNS infrastructure. The user’s LDNS then sends a second query, now for</span><a href="http://a1105.kingcdn.com"><span class="font53"> a1105.kingcdn.</span></a><span class="font53"> </span><a href="http://a1105.kingcdn.com"><span class="font53">com</span></a><span class="font53">, and KingCDN’s DNS system eventually returns the IP addresses of a KingCDN content server to the LDNS. It is thus here, within the KingCDN’s DNS system, that the CDN server from which the client will receive its content is specified.</span></p></li></ul><img src="networking_files/networking-129.jpg" alt="" style="width:267pt;height:185pt;">
<p><span class="font4">KingCDN content</span></p>
<p><span class="font4">distribution server</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 2.25 </span><span class="font50">♦ </span><span class="font5">DNS redirects a user's request to a CDN server</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">5. The LDNS forwards the IP address of the content-serving CDN node to the user’s host.</span></p></li>
<li>
<p><span class="font53">6. Once the client receives the IP address for a KingCDN content server, it establishes a direct TCP connection with the server at that IP address and issues an HTTP GET request for the video. If DASH is used, the server will first send to the client a manifest file with a list of URLs, one for each version of the video, and the client will dynamically select chunks from the different versions.</span></p></li></ul>
<p><span class="font22" style="font-weight:bold;">Cluster Selection Strategies</span></p>
<p><span class="font53">At the core of any CDN deployment is a </span><span class="font53" style="font-weight:bold;">cluster selection strategy</span><span class="font53">, that is, a mechanism for dynamically directing clients to a server cluster or a data center within the CDN. As we just saw, the CDN learns the IP address of the client’s LDNS server via the client’s DNS lookup. After learning this IP address, the CDN needs to select an appropriate cluster based on this IP address. CDNs generally employ proprietary cluster selection strategies. We now briefly survey a few approaches, each of which has its own advantages and disadvantages.</span></p>
<p><span class="font53">One simple strategy is to assign the client to the cluster that is </span><span class="font53" style="font-weight:bold;">geographically closest</span><span class="font53">. Using commercial geo-location databases (such as Quova [Quova 2020] and MaxMind [MaxMind 2020]), each LDNS IP address is mapped to a geographic location. When a DNS request is received from a particular LDNS, the CDN chooses the geographically closest cluster, that is, the cluster that is the fewest kilometers from the LDNS “as the bird flies.” Such a solution can work reasonably well for a large fraction of the clients [Agarwal 2009]. However, for some clients, the solution may perform poorly, since the geographically closest cluster may not be the closest cluster in terms of the length or number of hops of the network path. Furthermore, a problem inherent with all DNSbased approaches is that some end-users are configured to use remotely located LDNSs [Shaikh 2001; Mao 2002], in which case the LDNS location may be far from the client’s location. Moreover, this simple strategy ignores the variation in delay and available bandwidth over time of Internet paths, always assigning the same cluster to a particular client.</span></p>
<p><span class="font53">In order to determine the best cluster for a client based on the </span><span class="font53" style="font-style:italic;">current</span><span class="font53"> traffic conditions, CDNs can instead perform periodic </span><span class="font53" style="font-weight:bold;">real-time measurements </span><span class="font53">of delay and loss performance between their clusters and clients. For instance, a CDN can have each of its clusters periodically send probes (for example, ping messages or DNS queries) to all of the LDNSs around the world. One drawback of this approach is that many LDNSs are configured to not respond to such probes.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">2.6.4 </span><span class="font23" style="font-weight:bold;">Case Studies: Netflix and YouTube</span></p></li></ul>
<p><a name="bookmark69"></a><span class="font53">We conclude our discussion of streaming stored video by taking a look at two highly successful large-scale deployments: Netflix and YouTube. We’ll see that each of these systems take a very different approach, yet employ many of the underlying principles discussed in this section.</span></p>
<p><span class="font22" style="font-weight:bold;">Netflix</span></p>
<p><span class="font53">As of 2020, Netflix is the leading service provider for online movies and TV series in North America. As we discuss below, Netflix video distribution has two major components: the Amazon cloud and its own private CDN infrastructure.</span></p>
<p><span class="font53">Netflix has a Web site that handles numerous functions, including user registration and login, billing, movie catalogue for browsing and searching, and a movie recommendation system. As shown in Figure 2.26, this Web site (and its associated backend databases) run entirely on Amazon servers in the Amazon cloud. Additionally, the Amazon cloud handles the following critical functions:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-weight:bold;font-style:italic;">Content ingestion.</span><span class="font53"> Before Netflix can distribute a movie to its customers, it must first ingest and process the movie. Netflix receives studio master versions of movies and uploads them to hosts in the Amazon cloud.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-weight:bold;font-style:italic;">Content processing.</span><span class="font53"> The machines in the Amazon cloud create many different formats for each movie, suitable for a diverse array of client video players running on desktop computers, smartphones, and game consoles connected to televisions. A different version is created for each of these formats and at multiple bit rates, allowing for adaptive streaming over HTTP using DASH.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-weight:bold;font-style:italic;">Uploading versions to its CDN.</span><span class="font53"> Once all of the versions of a movie have been created, the hosts in the Amazon cloud upload the versions to its CDN.</span></p></li></ul><img src="networking_files/networking-130.jpg" alt="" style="width:224pt;height:190pt;">
<p><span class="font7" style="font-weight:bold;">Figure 2.26 </span><span class="font50">♦ </span><span class="font5">Netflix video streaming platform</span></p>
<p><span class="font53">When Netflix first rolled out its video streaming service in 2007, it employed three third-party CDN companies to distribute its video content. Netflix has since created its own private CDN, from which it now streams all of its videos. To create its own CDN, Netflix has installed server racks both in IXPs and within residential ISPs themselves. Netflix currently has server racks in over 200 IXP locations; see [Bottger 2018] [Netflix Open Connect 2020] for a current list of IXPs housing Netflix racks. There are also hundreds of ISP locations housing Netflix racks; also see [Netflix Open Connect 2020], where Netflix provides to potential ISP partners instructions about installing a (free) Netflix rack for their networks. Each server in the rack has several 10 Gbps Ethernet ports and over 100 terabytes of storage. The number of servers in a rack varies: IXP installations often have tens of servers and contain the entire Netflix streaming video library, including multiple versions of the videos to support DASH. Netflix does not use pull-caching (Section 2.2.5) to populate its CDN servers in the IXPs and ISPs. Instead, Netflix distributes by pushing the videos to its CDN servers during off-peak hours. For those locations that cannot hold the entire library, Netflix pushes only the most popular videos, which are determined on a day-to-day basis. The Netflix CDN design is described in some detail in the YouTube videos [Netflix Video 1] and [Netflix Video 2]; see also [Bottger 2018].</span></p>
<p><span class="font53">Having described the components of the Netflix architecture, let’s take a closer look at the interaction between the client and the various servers that are involved in movie delivery. As indicated earlier, the Web pages for browsing the Netflix video library are served from servers in the Amazon cloud. When a user selects a movie to play, the Netflix software, running in the Amazon cloud, first determines which of its CDN servers have copies of the movie. Among the servers that have the movie, the software then determines the “best” server for that client request. If the client is using a residential ISP that has a Netflix CDN server rack installed in that ISP, and this rack has a copy of the requested movie, then a server in this rack is typically selected. If not, a server at a nearby IXP is typically selected.</span></p>
<p><span class="font53">Once Netflix determines the CDN server that is to deliver the content, it sends the client the IP address of the specific server as well as a manifest file, which has the URLs for the different versions of the requested movie. The client and that CDN server then directly interact using a proprietary version of DASH. Specifically, as described in Section 2.6.2, the client uses the byte-range header in HTTP GET request messages, to request chunks from the different versions of the movie. Netflix uses chunks that are approximately four-seconds long [Adhikari 2012]. While the chunks are being downloaded, the client measures the received throughput and runs a rate-determination algorithm to determine the quality of the next chunk to request.</span></p>
<p><span class="font53">Netflix embodies many of the key principles discussed earlier in this section, including adaptive streaming and CDN distribution. However, because Netflix uses its own private CDN, which distributes only video (and not Web pages), Netflix has been able to simplify and tailor its CDN design. In particular, Netflix does not need to employ DNS redirect, as discussed in Section 2.6.3, to connect a particular client to a CDN server; instead, the Netflix software (running in the Amazon cloud) directly tells the client to use a particular CDN server. Furthermore, the Netflix CDN uses push caching rather than pull caching (Section 2.2.5): content is pushed into the servers at scheduled times at off-peak hours, rather than dynamically during cache misses.</span></p>
<p><span class="font22" style="font-weight:bold;">YouTube</span></p>
<p><span class="font53">With hundreds of hours of video uploaded to YouTube every minute and several billion video views per day, YouTube is indisputably the world’s largest videosharing site. YouTube began its service in April 2005 and was acquired by Google in November 2006. Although the Google/YouTube design and protocols are proprietary, through several independent measurement efforts we can gain a basic understanding about how YouTube operates [Zink 2009; Torres 2011; Adhikari 2011a]. As with Netflix, YouTube makes extensive use of CDN technology to distribute its videos [Torres 2011]. Similar to Netflix, Google uses its own private CDN to distribute YouTube videos, and has installed server clusters in many hundreds of different IXP and ISP locations. From these locations and directly from its huge data centers, Google distributes YouTube videos [Adhikari 2011a]. Unlike Netflix, however, Google uses pull caching, as described in Section 2.2.5, and DNS redirect, as described in Section 2.6.3. Most of the time, Google’s cluster-selection strategy directs the client to the cluster for which the RTT between client and cluster is the lowest; however, in order to balance the load across clusters, sometimes the client is directed (via DNS) to a more distant cluster [Torres 2011].</span></p>
<p><span class="font53">YouTube employs HTTP streaming, often making a small number of different versions available for a video, each with a different bit rate and corresponding quality level. YouTube does not employ adaptive streaming (such as DASH), but instead requires the user to manually select a version. In order to save bandwidth and server resources that would be wasted by repositioning or early termination, YouTube uses the HTTP byte range request to limit the flow of transmitted data after a target amount of video is prefetched.</span></p>
<p><span class="font53">Several million videos are uploaded to YouTube every day. Not only are YouTube videos streamed from server to client over HTTP, but YouTube uploaders also upload their videos from client to server over HTTP. YouTube processes each video it receives, converting it to a YouTube video format and creating multiple versions at different bit rates. This processing takes place entirely within Google data centers. (See the case study on Google’s network infrastructure in Section 2.6.3.)</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">2.7 </span><span class="font24" style="font-weight:bold;">Socket Programming: Creating Network Applications</span></p></li></ul>
<p><a name="bookmark70"></a><span class="font53">Now that we’ve looked at a number of important network applications, let’s explore how network application programs are actually created. Recall from Section 2.1 that a typical network application consists of a pair of programs—a client program and a server program—residing in two different end systems. When these two programs are executed, a client process and a server process are created, and these processes communicate with each other by reading from, and writing to, sockets. When creating a network application, the developer’s main task is therefore to write the code for both the client and server programs.</span></p>
<p><span class="font53">There are two types of network applications. One type is an implementation whose operation is specified in a protocol standard, such as an RFC or some other standards document; such an application is sometimes referred to as “open,” since the rules specifying its operation are known to all. For such an implementation, the client and server programs must conform to the rules dictated by the RFC. For example, the client program could be an implementation of the client side of the HTTP protocol, described in Section 2.2 and precisely defined in RFC 2616; similarly, the server program could be an implementation of the HTTP server protocol, also precisely defined in RFC 2616. If one developer writes code for the client program and another developer writes code for the server program, and both developers carefully follow the rules of the RFC, then the two programs will be able to interoperate. Indeed, many of today’s network applications involve communication between client and server programs that have been created by independent developers—for example, a Google Chrome browser communicating with an Apache Web server, or a BitTorrent client communicating with BitTorrent tracker.</span></p>
<p><span class="font53">The other type of network application is a proprietary network application. In this case, the client and server programs employ an application-layer protocol that has </span><span class="font53" style="font-style:italic;">not</span><span class="font53"> been openly published in an RFC or elsewhere. A single developer (or development team) creates both the client and server programs, and the developer has complete control over what goes in the code. But because the code does not implement an open protocol, other independent developers will not be able to develop code that interoperates with the application.</span></p>
<p><span class="font53">In this section, we’ll examine the key issues in developing a client-server application, and we’ll “get our hands dirty” by looking at code that implements a very simple client-server application. During the development phase, one of the first decisions the developer must make is whether the application is to run over TCP or over UDP. Recall that TCP is connection oriented and provides a reliable byte-stream channel through which data flows between two end systems. UDP is connectionless and sends independent packets of data from one end system to the other, without any guarantees about delivery. Recall also that when a client or server program implements a protocol defined by an RFC, it should use the well-known port number associated with the protocol; conversely, when developing a proprietary application, the developer must be careful to avoid using such well-known port numbers. (Port numbers were briefly discussed in Section 2.1. They are covered in more detail in Chapter 3.)</span></p>
<p><span class="font53">We introduce UDP and TCP socket programming by way of a simple UDP application and a simple TCP application. We present the simple UDP and TCP applications in Python 3. We could have written the code in Java, C, or C++, but we chose Python mostly because Python clearly exposes the key socket concepts. With Python there are fewer lines of code, and each line can be explained to the novice programmer without difficulty. But there’s no need to be frightened if you are not familiar with Python. You should be able to easily follow the code if you have experience programming in Java, C, or C++.</span></p>
<p><span class="font53">If you are interested in client-server programming with Java, you are encouraged to see the Companion Website for this textbook; in fact, you can find there all the examples in this section (and associated labs) in Java. For readers who are interested in client-server programming in C, there are several good references available [Donahoo 2001; Stevens 1997; Frost 1994]; our Python examples below have a similar look and feel to C.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">2.7.1 </span><span class="font23" style="font-weight:bold;">Socket Programming with UDP</span></p></li></ul>
<p><span class="font53">In this subsection, we’ll write simple client-server programs that use UDP; in the following section, we’ll write similar programs that use TCP.</span></p>
<p><span class="font53">Recall from Section 2.1 that processes running on different machines communicate with each other by sending messages into sockets. We said that each process is analogous to a house and the process’s socket is analogous to a door. The application resides on one side of the door in the house; the transport-layer protocol resides on the other side of the door in the outside world. The application developer has control of everything on the application-layer side of the socket; however, it has little control of the transport-layer side.</span></p>
<p><span class="font53">Now let’s take a closer look at the interaction between two communicating processes that use UDP sockets. Before the sending process can push a packet of data out the socket door, when using UDP, it must first attach a destination address to the packet. After the packet passes through the sender’s socket, the Internet will use this destination address to route the packet through the Internet to the socket in the receiving process. When the packet arrives at the receiving socket, the receiving process will retrieve the packet through the socket, and then inspect the packet’s contents and take appropriate action.</span></p>
<p><a name="bookmark71"></a><span class="font53">So you may be now wondering, what goes into the destination address that is attached to the packet? As you might expect, the destination host’s IP address is part of the destination address. By including the destination IP address in the packet, the routers in the Internet will be able to route the packet through the Internet to the destination host. But because a host may be running many network application processes, each with one or more sockets, it is also necessary to identify the particular socket in the destination host. When a socket is created, an identifier, called a </span><span class="font53" style="font-weight:bold;">port number</span><span class="font53">, is assigned to it. So, as you might expect, the packet’s destination address also includes the socket’s port number. In summary, the sending process attaches to the packet a destination address, which consists of the destination host’s IP address and the destination socket’s port number. Moreover, as we shall soon see, the sender’s source address—consisting of the IP address of the source host and the port number of the source socket—are also attached to the packet. However, attaching the source address to the packet is typically </span><span class="font53" style="font-style:italic;">not</span><span class="font53"> done by the UDP application code; instead it is automatically done by the underlying operating system.</span></p>
<p><span class="font53">We’ll use the following simple client-server application to demonstrate socket programming for both UDP and TCP:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">1. The client reads a line of characters (data) from its keyboard and sends the data to the server.</span></p></li>
<li>
<p><span class="font53">2. The server receives the data and converts the characters to uppercase.</span></p></li>
<li>
<p><span class="font53">3. The server sends the modified data to the client.</span></p></li>
<li>
<p><span class="font53">4. The client receives the modified data and displays the line on its screen.</span></p></li></ul>
<p><span class="font53">Figure 2.27 highlights the main socket-related activity of the client and server that communicate over the UDP transport service.</span></p>
<p><span class="font4" style="font-weight:bold;">Server &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Client</span></p>
<p><span class="font4">(Running on serverIP)</span></p><img src="networking_files/networking-131.jpg" alt="" style="width:337pt;height:256pt;">
<p><span class="font7" style="font-weight:bold;">Figure 2.27 </span><span class="font50">♦ </span><span class="font5">The client-server application using UDP</span></p>
<p><span class="font53">Now let’s get our hands dirty and take a look at the client-server program pair for a UDP implementation of this simple application. We also provide a detailed, line-by-line analysis after each program. We’ll begin with the UDP client, which will send a simple application-level message to the server. In order for the server to be able to receive and reply to the client’s message, it must be ready and running—that is, it must be running as a process before the client sends its message.</span></p>
<p><span class="font53">The client program is called UDPClient.py, and the server program is called UDPServer.py. In order to emphasize the key issues, we intentionally provide code that is minimal. “Good code” would certainly have a few more auxiliary lines, in particular for handling error cases. For this application, we have arbitrarily chosen 12000 for the server port number.</span></p>
<p><span class="font22" style="font-weight:bold;">UDPClient.py</span></p>
<p><span class="font53">Here is the code for the client side of the application:</span></p>
<p><span class="font36">from socket import * serverName = 'hostname' serverPort = 12000 clientsocket = socket(AF_INET, SOCK_DGRAM) message = input('Input lowercase sentence:') clientSocket.sendto(message.encode(),(serverName, serverPort)) modifiedMessage, serverAddress = clientSocket.recvfrom(2048) print(modifiedMessage.decode()) clientSocket.close()</span></p>
<p><span class="font53">Now let’s take a look at the various lines of code in UDPClient.py.</span></p>
<p><span class="font36">from socket import *</span></p>
<p><span class="font53">The </span><span class="font36">socket </span><span class="font53">module forms the basis of all network communications in Python. By including this line, we will be able to create sockets within our program.</span></p>
<p><span class="font36">serverName = 'hostname' serverPort = 12000</span></p>
<p><span class="font53">The first line sets the variable </span><span class="font36">serverName </span><span class="font53">to the string ‘hostname’. Here, we provide a string containing either the IP address of the server (e.g., “128.138.32.126”) or the hostname of the server (e.g., “</span><a href="http://cis.poly.edu"><span class="font53">cis.poly.edu</span></a><span class="font53">”). If we use the hostname, then a DNS lookup will automatically be performed to get the IP address.) The second line sets the integer variable </span><span class="font36">serverPort </span><span class="font53">to 12000.</span></p>
<p><span class="font36">clientsocket = socket(AF_INET, SOCK_DGRAM)</span></p>
<p><span class="font53">This line creates the client’s socket, called </span><span class="font36">clientsocket</span><span class="font53">. The first parameter indicates the address family; in particular, </span><span class="font36">AF_INET </span><span class="font53">indicates that the underlying network is using IPv4. (Do not worry about this now—we will discuss IPv4 in Chapter 4.) The second parameter indicates that the socket is of type </span><span class="font36">SOCK_DGRAM</span><span class="font53">, which means it is a UDP socket (rather than a TCP socket). Note that we are not specifying the port number of the client socket when we create it; we are instead letting the operating system do this for us. Now that the client process’s door has been created, we will want to create a message to send through the door.</span></p>
<p><span class="font36">message = input(’Input lowercase sentence:’)</span></p>
<p><span class="font36">input() </span><span class="font53">is a built-in function in Python. When this command is executed, the user at the client is prompted with the words “Input lowercase sentence:” The user then uses her keyboard to input a line, which is put into the variable </span><span class="font36">message</span><span class="font53">. Now that we have a socket and a message, we will want to send the message through the socket to the destination host.</span></p>
<p><span class="font36">clientSocket.sendto(message.encode(), (serverName, serverPort))</span></p>
<p><span class="font53">In the above line, we first convert the message from string type to byte type, as we need to send bytes into a socket; this is done with the </span><span class="font36">encode() </span><span class="font53">method. The method </span><span class="font36">sendto() </span><span class="font53">attaches the destination address (</span><span class="font36">serverName, serverPort</span><span class="font53">) to the message and sends the resulting packet into the process’s socket, </span><span class="font36">clientsocket</span><span class="font53">. (As mentioned earlier, the source address is also attached to the packet, although this is done automatically rather than explicitly by the code.) Sending a client-to-server message via a UDP socket is that simple! After sending the packet, the client waits to receive data from the server.</span></p>
<p><span class="font36">modifiedMessage, serverAddress = clientSocket.recvfrom(2048)</span></p>
<p><span class="font53">With the above line, when a packet arrives from the Internet at the client’s socket, the packet’s data is put into the variable </span><span class="font36">modifiedMessage </span><span class="font53">and the packet’s source address is put into the variable </span><span class="font36">serverAddress</span><span class="font53">. The variable </span><span class="font36">serverAddress </span><span class="font53">contains both the server’s IP address and the server’s port number. The program UDPClient doesn’t actually need this server address information, since it already knows the server address from the outset; but this line of Python provides the server address nevertheless. The method </span><span class="font36">recvfrom </span><span class="font53">also takes the buffer size 2048 as input. (This buffer size works for most purposes.)</span></p>
<p><span class="font36">print(modifiedMessage.decode())</span></p>
<p><span class="font53">This line prints out modifiedMessage on the user’s display, after converting the message from bytes to string. It should be the original line that the user typed, but now capitalized.</span></p>
<p><span class="font36">clientSocket.close()</span></p>
<p><span class="font53">This line closes the socket. The process then terminates.</span></p>
<p><span class="font22" style="font-weight:bold;">UDPServer.py</span></p>
<p><span class="font53">Let’s now take a look at the server side of the application:</span></p>
<p><span class="font36">from socket import * serverPort = 12000 serverSocket = socket(AF_INET, SOCK_DGRAM) serverSocket.bind(('', serverPort)) print(&quot;The server is ready to receive&quot;) while True:</span></p>
<p><span class="font36">message, clientAddress = serverSocket.recvfrom(2048) modifiedMessage = message.decode().upper() serverSocket.sendto(modifiedMessage.encode(), clientAddress)</span></p>
<p><span class="font53">Note that the beginning of UDPServer is similar to UDPClient. It also imports the socket module, also sets the integer variable </span><span class="font36">serverPort </span><span class="font53">to 12000, and also creates a socket of type </span><span class="font36">SOCK_DGRAM </span><span class="font53">(a UDP socket). The first line of code that is significantly different from UDPClient is:</span></p>
<p><span class="font36">serverSocket.bind(('', serverPort))</span></p>
<p><span class="font53">The above line binds (that is, assigns) the port number 12000 to the server’s socket. Thus, in UDPServer, the code (written by the application developer) is explicitly assigning a port number to the socket. In this manner, when anyone sends a packet to port 12000 at the IP address of the server, that packet will be directed to this socket. UDPServer then enters a while loop; the while loop will allow UDPServer to receive and process packets from clients indefinitely. In the while loop, UDPServer waits for a packet to arrive.</span></p>
<p><span class="font36">message, clientAddress = serverSocket.recvfrom(2048)</span></p>
<p><span class="font53">This line of code is similar to what we saw in UDPClient. When a packet arrives at the server’s socket, the packet’s data is put into the variable </span><span class="font36">message </span><span class="font53">and the packet’s source address is put into the variable </span><span class="font36">clientAddress</span><span class="font53">. The variable clientAddress contains both the client’s IP address and the client’s port number. Here, UDPServer </span><span class="font53" style="font-style:italic;">will</span><span class="font53"> make use of this address information, as it provides a return address, similar to the return address with ordinary postal mail. With this source address information, the server now knows to where it should direct its reply.</span></p>
<p><span class="font36">modifiedMessage = message.decode().upper()</span></p>
<p><span class="font53">This line is the heart of our simple application. It takes the line sent by the client and, after converting the message to a string, uses the method </span><span class="font36">upper() </span><span class="font53">to capitalize it.</span></p>
<p><span class="font36">serverSocket.sendto(modifiedMessage.encode(), clientAddress)</span></p>
<p><span class="font53">This last line attaches the client’s address (IP address and port number) to the capitalized message (after converting the string to bytes), and sends the resulting packet into the server’s socket. (As mentioned earlier, the server address is also attached to the packet, although this is done automatically rather than explicitly by the code.) The Internet will then deliver the packet to this client address. After the server sends the packet, it remains in the while loop, waiting for another UDP packet to arrive (from any client running on any host).</span></p>
<p><span class="font53">To test the pair of programs, you run UDPClient.py on one host and UDPS-erver.py on another host. Be sure to include the proper hostname or IP address of the server in UDPClient.py. Next, you execute UDPServer.py, the compiled server program, in the server host. This creates a process in the server that idles until it is contacted by some client. Then you execute UDPClient.py, the compiled client program, in the client. This creates a process in the client. Finally, to use the application at the client, you type a sentence followed by a carriage return.</span></p>
<p><span class="font53">To develop your own UDP client-server application, you can begin by slightly modifying the client or server programs. For example, instead of converting all the letters to uppercase, the server could count the number of times the letter </span><span class="font53" style="font-style:italic;">5</span><span class="font53"> appears and return this number. Or you can modify the client so that after receiving a capitalized sentence, the user can continue to send more sentences to the server.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">2.7.2 </span><span class="font23" style="font-weight:bold;">Socket Programming with TCP</span></p></li></ul>
<p><a name="bookmark72"></a><span class="font53">Unlike UDP, TCP is a connection-oriented protocol. This means that before the client and server can start to send data to each other, they first need to handshake and establish a TCP connection. One end of the TCP connection is attached to the client socket and the other end is attached to a server socket. When creating the TCP connection, we associate with it the client socket address (IP address and port number) and the server socket address (IP address and port number). With the TCP connection established, when one side wants to send data to the other side, it just drops the data into the TCP connection via its socket. This is different from UDP, for which the server must attach a destination address to the packet before dropping it into the socket.</span></p>
<p><span class="font53">Now let’s take a closer look at the interaction of client and server programs in TCP. The client has the job of initiating contact with the server. In order for the server to be able to react to the client’s initial contact, the server has to be ready. This implies two things. First, as in the case of UDP, the TCP server must be running as a process before the client attempts to initiate contact. Second, the server program must have a special door—more precisely, a special socket—that welcomes some initial contact from a client process running on an arbitrary host. Using our house/ door analogy for a process/socket, we will sometimes refer to the client’s initial contact as “knocking on the welcoming door.”</span></p>
<p><span class="font53">With the server process running, the client process can initiate a TCP connection to the server. This is done in the client program by creating a TCP socket. When the client creates its TCP socket, it specifies the address of the welcoming socket in the server, namely, the IP address of the server host and the port number of the socket. After creating its socket, the client initiates a three-way handshake and establishes a TCP connection with the server. The three-way handshake, which takes place within the transport layer, is completely invisible to the client and server programs.</span></p>
<p><span class="font53">During the three-way handshake, the client process knocks on the welcoming door of the server process. When the server “hears” the knocking, it creates a new door—more precisely, a </span><span class="font53" style="font-style:italic;">new</span><span class="font53"> socket that is dedicated to that particular client. In our example below, the welcoming door is a TCP socket object that we call </span><span class="font36">serverSocket</span><span class="font53">; the newly created socket dedicated to the client making the connection is called </span><span class="font36">connectionsocket</span><span class="font53">. Students who are encountering TCP sockets for the first time sometimes confuse the welcoming socket (which is the initial point of contact for all clients wanting to communicate with the server), and each newly created server-side connection socket that is subsequently created for communicating with each client.</span></p>
<p><span class="font53">From the application’s perspective, the client’s socket and the server’s connection socket are directly connected by a pipe. As shown in Figure 2.28, the client process can send arbitrary bytes into its socket, and TCP guarantees that the server process will receive (through the connection socket) each byte in the order sent. TCP thus provides a reliable service between the client and server processes. Furthermore, just as people can go in and out the same door, the client process not only sends bytes into but also receives bytes from its socket; similarly, the server process not only receives bytes from but also sends bytes into its connection socket.</span></p>
<p><span class="font53">We use the same simple client-server application to demonstrate socket programming with TCP: The client sends one line of data to the server, the server capitalizes the line and sends it back to the client. Figure 2.29 highlights the main socket-related activity of the client and server that communicate over the TCP transport service.</span></p><img src="networking_files/networking-132.jpg" alt="" style="width:188pt;height:39pt;"><img src="networking_files/networking-133.jpg" alt="" style="width:239pt;height:173pt;">
<p><span class="font7" style="font-weight:bold;">Figure 2.28 </span><span class="font50">♦ </span><span class="font5">The TCPServer process has two sockets</span></p>
<p><span class="font22" style="font-weight:bold;">TCPClient.py</span></p>
<p><span class="font53">Here is the code for the client side of the application:</span></p>
<p><span class="font36">from socket import * serverName = 'servername' serverPort = 12000 clientsocket = socket(AF_INET, SOCK_STREAM) clientSocket.connect((serverName,serverPort)) sentence = input('Input lowercase sentence:') clientSocket.send(sentence.encode()) modifiedSentence = clientSocket.recv(1024) print('From Server: ', modifiedSentence.decode()) clientSocket.close()</span></p>
<p><span class="font53">Let’s now take a look at the various lines in the code that differ significantly from the UDP implementation. The first such line is the creation of the client socket.</span></p>
<p><span class="font36">clientSocket = socket(AF_INET, SOCK_STREAM)</span></p>
<p><span class="font53">This line creates the client’s socket, called </span><span class="font36">clientSocket</span><span class="font53">. The first parameter again indicates that the underlying network is using IPv4. The second parameter</span></p>
<p><span class="font4" style="font-weight:bold;">Server &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Client</span></p>
<p><span class="font4">(Running on serverIP)</span></p><img src="networking_files/networking-134.jpg" alt="" style="width:335pt;height:318pt;">
<p><span class="font7" style="font-weight:bold;">Figure 2.29 </span><span class="font50">♦ </span><span class="font5">The client-server application using TCP</span></p>
<p><span class="font53">indicates that the socket is of type </span><span class="font36">SOCK_STREAM</span><span class="font53">, which means it is a TCP socket (rather than a UDP socket). Note that we are again not specifying the port number of the client socket when we create it; we are instead letting the operating system do this for us. Now the next line of code is very different from what we saw in UDPClient:</span></p>
<p><span class="font36">clientSocket.connect((serverName,serverPort))</span></p>
<p><span class="font53">Recall that before the client can send data to the server (or vice versa) using a TCP socket, a TCP connection must first be established between the client and server. The above line initiates the TCP connection between the client and server. The parameter of the </span><span class="font36">connect)) </span><span class="font53">method is the address of the server side of the connection. After this line of code is executed, the three-way handshake is performed and a TCP connection is established between the client and server.</span></p>
<p><span class="font36">sentence = input(’Input lowercase sentence:’)</span></p>
<p><span class="font53">As with UDPClient, the above obtains a sentence from the user. The string </span><span class="font36">sentence </span><span class="font53">continues to gather characters until the user ends the line by typing a carriage return. The next line of code is also very different from UDPClient:</span></p>
<p><span class="font36">clientSocket.send(sentence.encode())</span></p>
<p><span class="font53">The above line sends the </span><span class="font36">sentence </span><span class="font53">through the client’s socket and into the TCP connection. Note that the program does </span><span class="font53" style="font-style:italic;">not</span><span class="font53"> explicitly create a packet and attach the destination address to the packet, as was the case with UDP sockets. Instead the client program simply drops the bytes in the string </span><span class="font36">sentence </span><span class="font53">into the TCP connection. The client then waits to receive bytes from the server.</span></p>
<p><span class="font36">modifiedSentence = clientSocket.recv(2048)</span></p>
<p><span class="font53">When characters arrive from the server, they get placed into the string </span><span class="font36">modifiedSentence</span><span class="font53">. Characters continue to accumulate in </span><span class="font36">modifiedSen-tence </span><span class="font53">until the line ends with a carriage return character. After printing the capitalized sentence, we close the client’s socket:</span></p>
<p><span class="font36">clientSocket.close()</span></p>
<p><span class="font53">This last line closes the socket and, hence, closes the TCP connection between the client and the server. It causes TCP in the client to send a TCP message to TCP in the server (see Section 3.5).</span></p>
<p><span class="font22" style="font-weight:bold;">TCPServer.py</span></p>
<p><span class="font53">Now let’s take a look at the server program.</span></p>
<p><span class="font36">from socket import * serverPort = 12000 serversocket = socket(AF_INET,SOCK_STREAM) serverSocket.bind((’’,serverPort)) serverSocket.listen(l) print(’The server is ready to receive’)</span></p>
<p><span class="font36">while True:</span></p>
<p><span class="font36">connectionsocket, addr = serverSocket.accept() sentence = connectionSocket.recv(1024).decode() capitalizedSentence = sentence.upper() connectionSocket.send(capitalizedSentence.encode()) connectionSocket.close()</span></p>
<p><span class="font53">Let’s now take a look at the lines that differ significantly from UDPServer and TCP-Client. As with TCPClient, the server creates a TCP socket with:</span></p>
<p><span class="font36">serverSocket=socket(AF_INET,SOCK_STREAM)</span></p>
<p><span class="font53">Similar to UDPServer, we associate the server port number, </span><span class="font36">serverPort</span><span class="font53">, with this socket:</span></p>
<p><span class="font36">serverSocket.bind(('',serverPort))</span></p>
<p><span class="font53">But with TCP, </span><span class="font36">serverSocket </span><span class="font53">will be our welcoming socket. After establishing this welcoming door, we will wait and listen for some client to knock on the door:</span></p>
<p><span class="font36">serverSocket.listen(1)</span></p>
<p><span class="font53">This line has the server listen for TCP connection requests from the client. The parameter specifies the maximum number of queued connections (at least 1).</span></p>
<p><span class="font36">connectionSocket, addr = serverSocket.accept()</span></p>
<p><span class="font53">When a client knocks on this door, the program invokes the </span><span class="font36">accept() </span><span class="font53">method for serverSocket, which creates a new socket in the server, called </span><span class="font36">connectionSocket</span><span class="font53">, dedicated to this particular client. The client and server then complete the handshaking, creating a TCP connection between the client’s </span><span class="font36">clientSocket </span><span class="font53">and the server’s </span><span class="font36">connectionSocket</span><span class="font53">. With the TCP connection established, the client and server can now send bytes to each other over the connection. With TCP, all bytes sent from one side are only guaranteed to arrive at the other side but also guaranteed to arrive in order.</span></p>
<p><span class="font36">connectionSocket.close()</span></p>
<p><span class="font53">In this program, after sending the modified sentence to the client, we close the connection socket. But since </span><span class="font36">serverSocket </span><span class="font53">remains open, another client can now knock on the door and send the server a sentence to modify.</span></p>
<p><span class="font53">This completes our discussion of socket programming in TCP. You are encouraged to run the two programs in two separate hosts, and also to modify them to achieve slightly different goals. You should compare the UDP program pair with the TCP program pair and see how they differ. You should also do many of the socket programming assignments described at the ends of Chapter 2 and 5. Finally, we hope someday, after mastering these and more advanced socket programs, you will write your own popular network application, become very rich and famous, and remember the authors of this textbook!</span></p>
<p><span class="font59" style="font-weight:bold;">2.8 </span><span class="font24" style="font-weight:bold;">Summary</span></p>
<p><span class="font53">In this chapter, we’ve studied the conceptual and the implementation aspects of network applications. We’ve learned about the ubiquitous client-server architecture adopted by many Internet applications and seen its use in the HTTP, SMTP, and DNS protocols. We’ve studied these important application-level protocols, and their corresponding associated applications (the Web, file transfer, e-mail, and DNS) in some detail. We’ve learned about the P2P architecture and contrasted it with the client-server architecture. We’ve also learned about streaming video, and how modern video distribution systems leverage CDNs. We’ve examined how the socket API can be used to build network applications. We’ve walked through the use of sockets for connection-oriented (TCP) and connectionless (UDP) end-to-end transport services. The first step in our journey down the layered network architecture is now complete!</span></p>
<p><span class="font53">At the very beginning of this book, in Section 1.1, we gave a rather vague, bare-bones definition of a protocol: “the format and the order of messages exchanged between two or more communicating entities, as well as the actions taken on the transmission and/or receipt of a message or other event.” The material in this chapter, and in particular our detailed study of the HTTP, SMTP, and DNS protocols, has now added considerable substance to this definition. Protocols are a key concept in networking; our study of application protocols has now given us the opportunity to develop a more intuitive feel for what protocols are all about.</span></p>
<p><span class="font53">In Section 2.1, we described the service models that TCP and UDP offer to applications that invoke them. We took an even closer look at these service models when we developed simple applications that run over TCP and UDP in Section 2.7. However, we have said little about how TCP and UDP provide these service models. For example, we know that TCP provides a reliable data service, but we haven’t said yet how it does so. In the next chapter, we’ll take a careful look at not only the what, but also the how and why of transport protocols.</span></p>
<p><a name="bookmark73"></a><span class="font53">Equipped with knowledge about Internet application structure and applicationlevel protocols, we’re now ready to head further down the protocol stack and examine the transport layer in Chapter 3.</span></p>
<p><span class="font24" style="font-weight:bold;">Homework Problems and Questions</span></p>
<p><span class="font23" style="font-weight:bold;">Chapter 2 Review Questions</span></p>
<p><span class="font43" style="font-weight:bold;">SECTION 2.1</span></p>
<p><span class="font53">R1. List five nonproprietary Internet applications and the application-layer protocols that they use.</span></p>
<p><span class="font53">R2. What is the difference between network architecture and application architecture?</span></p>
<p><span class="font53">R3. For a communication session between a pair of processes, which process is the client and which is the server?</span></p>
<p><span class="font53">R4. Why are the terms client and server still used in peer-to-peer applications?</span></p>
<p><span class="font53">R5. What information is used by a process running on one host to identify a process running on another host?</span></p>
<p><span class="font53">R6. What is the role of HTTP in a network application? What other components are needed to complete a Web application?</span></p>
<p><span class="font53">R7. Referring to Figure 2.4, we see that none of the applications listed in Figure 2.4 requires both no data loss and timing. Can you conceive of an application that requires no data loss and that is also highly time-sensitive?</span></p>
<p><span class="font53">R8. List the four broad classes of services that a transport protocol can provide. For each of the service classes, indicate if either UDP or TCP (or both) provides such a service.</span></p>
<p><span class="font53">R9. Recall that TCP can be enhanced with TLS to provide process-to-process security services, including encryption. Does TLS operate at the transport layer or the application layer? If the application developer wants TCP to be enhanced with TLS, what does the developer have to do?</span></p>
<p><span class="font43" style="font-weight:bold;">SECTIONS 2.2-2.5</span></p>
<p><span class="font53">R10. What is meant by a handshaking protocol?</span></p>
<p><span class="font53">R11. What does a stateless protocol mean? Is IMAP stateless? What about SMTP?</span></p>
<p><span class="font53">R12. How can websites keep track of users? Do they always need to use cookies?</span></p>
<p><span class="font53">R13. Describe how Web caching can reduce the delay in receiving a requested object. Will Web caching reduce the delay for all objects requested by a user or for only some of the objects? Why?</span></p>
<p><span class="font53">R14. Telnet into a Web server and send a multiline request message. Include in the request message the </span><span class="font36">If-modified-since: </span><span class="font53">header line to force a response message with the </span><span class="font36">304 Not Modified </span><span class="font53">status code.</span></p>
<p><a name="bookmark74"></a><span class="font53">R15. Are there any constraints on the format of the HTTP body? What about the email message body sent with SMTP? How can arbitrary data be transmitted over SMTP?</span></p>
<p><span class="font53">R16. Suppose Alice, with a Web-based e-mail account (such as Hotmail or Gmail), sends a message to Bob, who accesses his mail from his mail server using IMAP. Discuss how the message gets from Alice’s host to Bob’s host. Be sure to list the series of application-layer protocols that are used to move the message between the two hosts.</span></p>
<p><span class="font53">R17. Print out the header of an e-mail message you have recently received. How many </span><span class="font36">Received: </span><span class="font53">header lines are there? Analyze each of the header lines in the message.</span></p>
<p><span class="font53">R18. What is the HOL blocking issue in HTTP/1.1? How does HTTP/2 attempt to solve it?</span></p>
<p><span class="font53">R19. Why are MX records needed? Would it not be enough to use a CNAME record? (Assume the email client looks up email addresses through a Type A query and that the target host only runs an email server.)</span></p>
<p><span class="font53">R20. What is the difference between recursive and iterative DNS queries?</span></p>
<p><span class="font43" style="font-weight:bold;">SECTION 2.5</span></p>
<p><span class="font53">R21. Under what circumstances is file downloading through P2P much faster than through a centralized client-server approach? Justify your answer using Equation 2.2.</span></p>
<p><span class="font53">R22. Consider a new peer Alice that joins BitTorrent without possessing any chunks. Without any chunks, she cannot become a top-four uploader for any of the other peers, since she has nothing to upload. How then will Alice get her first chunk?</span></p>
<p><span class="font53">R23. Assume a BitTorrent tracker suddenly becomes unavailable. What are its consequences? Can files still be downloaded?</span></p>
<p><span class="font43" style="font-weight:bold;">SECTION 2.6</span></p>
<p><span class="font53">R24. CDNs typically adopt one of two different server placement philosophies. Name and briefly describe them.</span></p>
<p><span class="font53">R25. Besides network-related considerations such as delay, loss, and bandwidth performance, there are other important factors that go into designing a CDN server selection strategy. What are they?</span></p>
<p><span class="font43" style="font-weight:bold;">SECTION 2.7</span></p>
<p><span class="font53">R26. In Section 2.7, the UDP server described needed only one socket, whereas the TCP server needed two sockets. Why? If the TCP server were to support </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> simultaneous connections, each from a different client host, how many sockets would the TCP server need?</span></p>
<p><span class="font53">R27. For the client-server application over TCP described in Section 2.7, why must the server program be executed before the client program? For the client-server application over UDP, why may the client program be executed before the server program?</span></p>
<p><span class="font24" style="font-weight:bold;">Problems</span></p>
<p><span class="font53">P1. True or false?</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. A user requests a Web page that consists of some text and three images. For this page, the client will send one request message and receive four response messages.</span></p></li>
<li>
<p><span class="font53">b. Two distinct Web pages (for example, </span><a href="http://www.mit.edu/research.html"><span class="font36">www.mit.edu/research</span></a><span class="font36"> </span><a href="http://www.mit.edu/research.html"><span class="font36">.html</span></a><span class="font36"> </span><span class="font53">and </span><a href="http://www.mit.edu/students.html"><span class="font36">www.mit.edu/students.html</span></a><span class="font53">) can be sent over the same persistent connection.</span></p></li>
<li>
<p><span class="font53">c. With nonpersistent connections between browser and origin server, it is possible for a single TCP segment to carry two distinct HTTP request messages.</span></p></li>
<li>
<p><span class="font53">d. The </span><span class="font36">Date: </span><span class="font53">header in the HTTP response message indicates when the object in the response was last modified.</span></p></li>
<li>
<p><span class="font53">e. HTTP response messages never have an empty message body.</span></p></li></ul>
<p><span class="font53">P2. SMS, iMessage, Wechat, and WhatsApp are all smartphone real-time messaging systems. After doing some research on the Internet, for each of these systems write one paragraph about the protocols they use. Then write a paragraph explaining how they differ.</span></p>
<p><span class="font53">P3. Assume you open a browser and enter</span><a href="http://yourbusiness.com/about.html"><span class="font53"> </span><span class="font36">http://yourbusiness.com/</span></a><span class="font36"> </span><a href="http://yourbusiness.com/about.html"><span class="font36">about.html</span></a><span class="font36"> </span><span class="font53">in the address bar. What happens until the webpage is displayed? Provide details about the protocol(s) used and a high-level description of the messages exchanged.</span></p>
<p><span class="font53">P4. Consider the following string of ASCII characters that were captured by Wireshark when the browser sent an HTTP GET message (i.e., this is the actual content of an HTTP GET message). The characters </span><span class="font53" style="font-style:italic;">&lt;cr&gt;&lt;lf&gt;</span><span class="font53"> are carriage return and line-feed characters (that is, the italized character string </span><span class="font53" style="font-style:italic;">&lt;cr&gt;</span><span class="font53"> in the text below represents the single carriage-return character that was contained at that point in the HTTP header). Answer the following questions, indicating where in the HTTP GET message below you find the answer.</span></p>
<p class="font36">GET /cs453/index.html HTTP/1.1<span class="font36" style="font-style:italic;">&lt;cr&gt;&lt;!b&gt;</span><span class="font36">Host: </span><a href="http://gaia.cs.umass.edu"><span class="font36">gai</span></a></p>
<ul style="list-style:none;"><li>
<p><a href="http://gaia.cs.umass.edu"><span class="font36">a.cs.umass.edu</span></a><span class="font36" style="font-style:italic;">&lt;cr&gt;&lt;!b&gt;</span><span class="font36">User-Agent: Mozilla/5.0 ( Windows;U; Windows NT 5.1; en-US; rv:1.7.2) Gec ko/20040804 Netscape/7.2 (ax) </span><span class="font36" style="font-style:italic;">&lt;cr&gt;&lt;!b&gt;</span><span class="font36">Accept:ex t/xml, application/xml, application/xhtml+xml, text /html;q=0.9, text/plain;q=0.8,image/png,*/*;q=0.5</span></p></li></ul>
<p><span class="font36" style="font-style:italic;">&lt;cr&gt;&lt;lf&gt;</span><span class="font36">Accept-Language: en-us,en;q=0.5</span><span class="font36" style="font-style:italic;">&lt;cr&gt;&lt;lf&gt;</span><span class="font36">Accept-Encoding: zip,deflate</span><span class="font36" style="font-style:italic;">&lt;cr&gt;&lt;lf&gt;</span><span class="font36">Accept-Charset: ISO -8859-1,utf-8;q=0.7,*;q=0.7 </span><span class="font36" style="font-style:italic;">&lt;cr&gt;&lt;lf&gt;</span><span class="font36">Keep-Alive: 300</span><span class="font36" style="font-style:italic;">&lt;cr&gt; &lt;lf&gt;Connection:keep-alive&lt;cr&gt;&lt;lf&gt;&lt;cr&gt;&lt;lf&gt;</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. What is the URL of the document requested by the browser?</span></p></li>
<li>
<p><span class="font53">b. What version of HTTP is the browser running?</span></p></li>
<li>
<p><span class="font53">c. Does the browser request a non-persistent or a persistent connection?</span></p></li>
<li>
<p><span class="font53">d. What is the IP address of the host on which the browser is running?</span></p></li>
<li>
<p><span class="font53">e. What type of browser initiates this message? Why is the browser type needed in an HTTP request message?</span></p></li></ul>
<p><span class="font53">P5. The text below shows the reply sent from the server in response to the HTTP GET message in the question above. Answer the following questions, indicating where in the message below you find the answer.</span></p>
<p><span class="font36">HTTP/1.1 200 OK</span><span class="font36" style="font-style:italic;">&lt;cr&gt;&lt;lf&gt;</span><span class="font36">Date: Tue, 07 Mar 2008 12:39:45GMT</span><span class="font36" style="font-style:italic;">&lt;cr&gt;&lt;lf&gt;</span><span class="font36">Server: Apache/2.0.52 (Fedora) </span><span class="font36" style="font-style:italic;">&lt;cr&gt;&lt;lf&gt;</span><span class="font36">Last-Modified: Sat, 10 Dec2005 18:27:46 GMT</span><span class="font36" style="font-style:italic;">&lt;cr&gt;&lt;lf&gt;</span><span class="font36">ETag: &quot;526c3-f22-a88a4c80&quot;</span><span class="font36" style="font-style:italic;">&lt;cr&gt;&lt;lf&gt;</span><span class="font36">Accept-Ranges: bytes</span><span class="font36" style="font-style:italic;">&lt;cr&gt;&lt;lf&gt;</span><span class="font36">Content-Length: </span><span class="font36" style="font-style:italic;">3874&lt;cr&gt;&lt;lf&gt; </span><span class="font36">Keep-Alive: timeout=max=100</span><span class="font36" style="font-style:italic;">&lt;cr&gt;&lt;lf&gt;</span><span class="font36">Connection: Keep-Alive</span><span class="font36" style="font-style:italic;">&lt;cr&gt;&lt;lf&gt;</span><span class="font36">Content-Type: text/html; charset= ISO-8859-1</span><span class="font36" style="font-style:italic;">&lt;cr&gt;&lt;lf&gt;&lt;cr&gt;&lt;lf&gt;</span><span class="font36">&lt;!doctype html public &quot;-//w3c//dtd html 4.0transitional//en&quot;&gt;</span><span class="font36" style="font-style:italic;">&lt;lf&gt;</span><span class="font36">&lt;html&gt;</span><span class="font36" style="font-style:italic;">&lt;lf&gt; </span><span class="font36">&lt;head&gt;</span><span class="font36" style="font-style:italic;">&lt;lf&gt;</span><span class="font36"> &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=iso-8859-1&quot;&gt;</span><span class="font36" style="font-style:italic;">&lt;lf&gt;</span><span class="font36"> &lt;meta name=&quot;GENERATOR&quot; content=&quot;Mozilla/4.79 [en] (Windows NT 5.0; U) Netscape]&quot;&gt;</span><span class="font36" style="font-style:italic;">&lt;lf&gt;</span><span class="font36"> &lt;title&gt;CMPSCI 453 / 591 / NTU-ST550ASpring 2005 homepage&lt;/title&gt;</span><span class="font36" style="font-style:italic;">&lt;lf&gt;</span><span class="font36">&lt;/head&gt;</span><span class="font36" style="font-style:italic;">&lt;lf&gt; &lt;much more document text following here (not shown)&gt;</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Was the server able to successfully find the document or not? What time was the document reply provided?</span></p></li>
<li>
<p><span class="font53">b. When was the document last modified?</span></p></li>
<li>
<p><span class="font53">c. How many bytes are there in the document being returned?</span></p></li>
<li>
<p><span class="font53">d. What are the first 5 bytes of the document being returned? Did the server agree to a persistent connection?</span></p></li></ul>
<p><span class="font53">P6. Obtain the HTTP/1.1 specification (RFC 2616). Answer the following questions:</span></p>
<ul style="list-style:none;"><li>
<p class="font53">a. Explain the mechanism used for signaling between the client and server to indicate that a persistent connection is being closed. Can the client, the server, or both signal the close of a connection?</p></li>
<li>
<p><span class="font53">b. What encryption services are provided by HTTP?</span></p></li>
<li>
<p><span class="font53">c. Can a client open three or more simultaneous connections with a given server?</span></p></li>
<li>
<p><span class="font53">d. Either a server or a client may close a transport connection between them if either one detects the connection has been idle for some time. Is it possible that one side starts closing a connection while the other side is transmitting data via this connection? Explain.</span></p></li></ul>
<p><span class="font53">P7. Suppose within your Web browser, you click on a link to obtain a Web page. The IP address for the associated URL is not cached in your local host, so a DNS lookup is necessary to obtain the IP address. Suppose that </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> DNS servers are visited before your host receives the IP address from DNS; the successive visits incur an RTT of </span><span class="font53" style="font-style:italic;">RTT</span><span class="font49" style="font-style:italic;">1</span><span class="font53" style="font-style:italic;">,</span><span class="font53"> . . . , </span><span class="font53" style="font-style:italic;">RTT<sub>n</sub>.</span><span class="font53"> Further suppose that the Web page associated with the link contains exactly one object, consisting of a large amount of HTML text. Let </span><span class="font53" style="font-style:italic;">RTT<sub>0</sub></span><span class="font53"> denote the RTT between the local host and the server containing the object. Assuming transmission duration of 0.002 </span><span class="font55">X </span><span class="font53" style="font-style:italic;">RTT<sub>0</sub></span><span class="font53"> of the object, how much time elapses from when the client clicks on the link until the client receives the object?</span></p>
<p><span class="font53">P8. Consider Problem P7 again and assume </span><span class="font53" style="font-style:italic;">RTT<sub>0</sub> = RTT<sub>1</sub> = RTT</span><span class="font49" style="font-style:italic;">2 </span><span class="font53" style="font-style:italic;">=</span><span class="font53"> . . .</span></p>
<p><span class="font53" style="font-style:italic;">RTT<sub>n</sub> = RTT,</span><span class="font53"> Furthermore, assume a new HTML file, small enough to have negligible transmission time, which references nine equally small objects on the same server. How much time elapses with</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. non-persistent HTTP with no parallel TCP connections?</span></p></li>
<li>
<p><span class="font53">b. non-persistent HTTP with the browser configured for 6 parallel connections?</span></p></li>
<li>
<p><span class="font53">c. persistent HTTP?</span></p></li></ul>
<p><span class="font53">P9. Consider Figure 2.12, for which there is an institutional network connected to the Internet. Moreover, assume the access link has been upgraded to 54 Mbps, and the institutional LAN is upgraded to 10 Gbps. Suppose that the average object size is 1,600,000 bits and that the average request rate from the institution’s browsers to the origin servers is 24 requests per second. Also suppose that the amount of time it takes from when the router on the Internet side of the access link forwards an HTTP request until it receives the response is three seconds on average (see Section 2.2.5). Model the total average response time as the sum of the average access delay (that is, the delay from Internet router to institution router) and the average Internet delay. For the average access delay, use </span><span class="font54">A</span><span class="font53">/(1 </span><span class="font55">— </span><span class="font54">A</span><span class="font12">b</span><span class="font53">), where </span><span class="font54">A </span><span class="font53">is the average time required to send an object over the access link and </span><span class="font12">b </span><span class="font53">is the arrival rate of objects to the access link.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Find the total average response time.</span></p></li>
<li>
<p><span class="font53">b. Now suppose a cache is installed in the institutional LAN. Suppose the miss rate is 0.3. Find the total response time.</span></p></li></ul>
<p><span class="font53">P10. Consider a 30-meter link, over which a sender can transmit at a rate of 300 bits/sec in both directions. Suppose that packets containing data are 100,000 bits long, and packets containing only control (e.g., ACK or handshaking) are 200 bits long. Assume that </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> parallel connections each get </span><span class="font53" style="font-style:italic;">1/N</span><span class="font53"> of the link bandwidth. Now, consider the HTTP protocol and suppose that each downloaded object is 100 Kbits long, and that the initial downloaded object contains 10 referenced objects from the same sender. Would parallel downloads via parallel instances of non-persistent HTTP make sense in this case? Now consider persistent HTTP. Do you expect significant gains over the non-persistent case? Justify and explain your answer.</span></p>
<p><span class="font53">P11. Consider the scenario introduced in the previous problem. Now, suppose that the link is shared by Alice with Bob. Alice does not use parallel instances of non-persistent HTTP while Bob uses non-persistent HTTP with five parallel downloads each.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Does Alice have any advantage over Bob? Why or why not?</span></p></li>
<li>
<p><span class="font53">b. If Alice opens five parallel instances of non-persistent HTTP, then would her parallel connections be beneficial? Why or why not?</span></p></li></ul>
<p><span class="font53">P12. Write a simple TCP program for a server that accepts lines of input from a client and prints the lines onto the server’s standard output. (You can do this by modifying the TCPServer.py program in the text.) Compile and execute your program. On any other machine that contains a Web browser, set the proxy server in the browser to the host that is running your server program; also configure the port number appropriately. Your browser should now send its GET request messages to your server, and your server should display the messages on its standard output. Use this platform to determine whether your browser generates conditional GET messages for objects that are locally cached.</span></p>
<p><span class="font53">P13. Consider sending over HTTP/2 a Web page that consists of one video file and three images. Suppose that the video clip is transported as 5000 frames, and each image captures four frames.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. If all the video frames are sent first without interleaving, how many “frame times” are needed until all images are sent?</span></p></li>
<li>
<p><span class="font53">b. If frames are interleaved, how many frame times are needed until all three images are sent?</span></p></li></ul>
<p><span class="font53">P14. Consider the Web page in problem 13. Now HTTP/2 prioritization is employed. Suppose all the images are given priority over the video clip, and that the first image is given priority over the second image, the second image over the third image, and so on. How many frame times will be needed until the second image is sent?</span></p>
<p><span class="font53">P15. What is the difference between </span><span class="font36">MAIL FROM</span><span class="font53">: in SMTP and </span><span class="font36">From</span><span class="font53">: in the mail message itself?</span></p>
<p><span class="font53">P16. How does SMTP mark the end of a message body? How about HTTP? Can HTTP use the same method as SMTP to mark the end of a message body? Explain.</span></p>
<p><span class="font53">P17. Read RFC 5321 for SMTP. What does MTA stand for? Consider the following received spam e-mail (modified from a real spam e-mail). Assuming only the originator of this spam e-mail is malicious and all other hosts are honest, identify the malacious host that has generated this spam e-mail.</span></p>
<p><span class="font36">From - Fri Nov 07 13:41:30 2008 Return-Path: &lt;</span><a href="mailto:tennis5@pp33head.com"><span class="font36">tennis5@pp33head.com&gt;</span></a><span class="font36"> Received: from</span><a href="http://barmail.cs.umass.edu"><span class="font36"> barmail.cs.umass.edu </span></a><span class="font36">(</span><a href="http://barmail.cs.umass.edu"><span class="font36">barmail.cs.umass.</span></a><span class="font36"> </span><a href="http://barmail.cs.umass.edu"><span class="font36">edu</span></a><span class="font36"> [128.119.240.3]) by</span><a href="http://cs.umass.edu"><span class="font36"> cs.umass.edu </span></a><span class="font36">(8.13.1/8.12.6) for &lt;</span><a href="mailto:hg@cs.umass.edu"><span class="font36">hg@cs.umass.edu&gt;</span></a><span class="font36">; Fri, 7 Nov 2008 13:27:10 -0500 Received: from asusus-4b96 (localhost [127.0.0.1]) by </span><a href="http://barmail.cs.umass.edu"><span class="font36">barmail.cs.umass.edu </span></a><span class="font36">(Spam Firewall) for &lt;</span><a href="mailto:hg@cs.umass.edu"><span class="font36">hg@cs.umass.</span></a><span class="font36"> </span><a href="mailto:hg@cs.umass.edu"><span class="font36">edu&gt;</span></a><span class="font36">; Fri, 7 Nov 2008 13:27:07 -0500 (EST) Received: from asusus-4b96 ([58.88.21.177]) by </span><a href="http://barmail.cs.umass.edu"><span class="font36">barmail.</span></a><span class="font36"> </span><a href="http://barmail.cs.umass.edu"><span class="font36">cs.umass.edu</span></a><span class="font36"> for &lt;</span><a href="mailto:hg@cs.umass.edu"><span class="font36">hg@cs.umass.edu&gt;</span></a><span class="font36">; Fri, 07 Nov 2008 13:27:07 -0500 (EST) Received: from [58.88.21.177] by</span><a href="http://inbnd55.exchangeddd.com"><span class="font36"> inbnd55.exchangeddd.</span></a><span class="font36"> </span><a href="http://inbnd55.exchangeddd.com"><span class="font36">com</span></a><span class="font36">; Sat, 8 Nov 2008 01:27:07 +0700</span></p>
<p><span class="font36">From: &quot;Jonny&quot; &lt;</span><a href="mailto:tennis5@pp33head.com"><span class="font36">tennis5@pp33head.com&gt;</span></a><span class="font36"> To: &lt;</span><a href="mailto:hg@cs.umass.edu"><span class="font36">hg@cs.umass.edu&gt;</span></a></p>
<p><span class="font36">Subject: How to secure your savings</span></p>
<p><span class="font53">P18. a. What is a </span><span class="font53" style="font-style:italic;">whois</span><span class="font53"> database?</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">b. Use various whois databases on the Internet to obtain the names of two DNS servers. Indicate which whois databases you used.</span></p></li>
<li>
<p><span class="font53">c. Use nslookup on your local host to send DNS queries to three DNS servers: your local DNS server and the two DNS servers you found in part (b). Try querying for Type A, NS, and MX reports. Summarize your findings.</span></p></li>
<li>
<p><span class="font53">d. Use nslookup to find a Web server that has multiple IP addresses. Does the Web server of your institution (school or company) have multiple IP addresses?</span></p></li>
<li>
<p><span class="font53">e. Use the ARIN whois database to determine the IP address range used by your university.</span></p></li>
<li>
<p><span class="font53">f. Describe how an attacker can use whois databases and the nslookup tool to perform reconnaissance on an institution before launching an attack.</span></p></li>
<li>
<p><span class="font53">g. Discuss why whois databases should be publicly available.</span></p></li></ul>
<p><span class="font53">P19. In this problem, we use the useful </span><span class="font53" style="font-style:italic;">dig</span><span class="font53"> tool available on Unix and Linux hosts to explore the hierarchy of DNS servers. Recall that in Figure 2.19, a DNS server in the DNS hierarchy delegates a DNS query to a DNS server lower in the hierarchy, by sending back to the DNS client the name of that lower-level DNS server. First read the man page for </span><span class="font53" style="font-style:italic;">dig</span><span class="font53">, and then answer the following questions.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Starting with a root DNS server (from one of the root servers [a-m]. </span><a href="http://root-servers.net"><span class="font53">root-servers.net</span></a><span class="font53">), initiate a sequence of queries for the IP address for your department’s Web server by using </span><span class="font53" style="font-style:italic;">dig.</span><span class="font53"> Show the list of the names of DNS servers in the delegation chain in answering your query.</span></p></li>
<li>
<p><span class="font53">b. Repeat part (a) for several popular Web sites, such as</span><a href="http://google.com"><span class="font53"> google.com</span></a><span class="font53">,</span><a href="http://yahoo.com"><span class="font53"> yahoo</span></a><span class="font53"> </span><a href="http://yahoo.com"><span class="font53">.com</span></a><span class="font53">, or</span><a href="http://amazon.com"><span class="font53"> amazon.com</span></a><span class="font53">.</span></p></li></ul>
<p><span class="font53">P20. Consider the scenarios illustrated in Figures 2.12 and 2.13. Assume the rate of the institutional network is </span><span class="font53" style="font-style:italic;">R<sub>l</sub></span><span class="font53"> and that of the bottleneck link is </span><span class="font53" style="font-style:italic;">R<sub>b</sub>.</span><span class="font53"> Suppose there are </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> clients requesting a file of size </span><span class="font53" style="font-style:italic;">L</span><span class="font53"> with HTTP at the same time. For what values of </span><span class="font53" style="font-style:italic;">R<sub>l</sub></span><span class="font53"> would the file transfer takes less time when a proxy is installed at the institutional network? (Assume the RTT between a client and any other host in the institutional network is negligible.)</span></p>
<p><span class="font53">P21. Suppose that your department has a local DNS server for all computers in the department. You are an ordinary user (i.e., not a network/system administrator). Can you determine if an external Web site was likely accessed from a computer in your department a couple of seconds ago? Explain.</span></p>
<p><span class="font53">P22. Consider distributing a file of </span><span class="font53" style="font-style:italic;">F =</span><span class="font53"> 10 Gbits to </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> peers. The server has an upload rate of </span><span class="font53" style="font-style:italic;">u<sub>s</sub> =</span><span class="font53"> 1 Gbps, and each peer has a download rate of </span><span class="font53" style="font-style:italic;">d<sub>i</sub> =</span><span class="font53"> 200 Mbps and an upload rate of </span><span class="font53" style="font-style:italic;">u</span><span class="font53">. For </span><span class="font53" style="font-style:italic;">N =</span><span class="font53"> 10, 100, and 1,000 and </span><span class="font53" style="font-style:italic;">u =</span><span class="font53"> 2 Mbps, 10 Mbps, and 100 Mbps, prepare a table giving the minimum distribution time in seconds for each of the combinations of </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">u</span><span class="font53"> for both client-server distribution and P2P distribution.</span></p>
<p><span class="font53">P23. Consider distributing a file of </span><span class="font53" style="font-style:italic;">F</span><span class="font53"> bits to </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> peers using a client-server architecture. Assume a fluid model where the server can simultaneously transmit to multiple peers, transmitting to each peer at different rates, as long as the combined rate does not exceed </span><span class="font53" style="font-style:italic;">u<sub>s</sub>.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Suppose that </span><span class="font53" style="font-style:italic;">u<sub>s</sub>/N</span><span class="font55"> &lt;&nbsp;</span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>min</sub>. Specify a distribution scheme that has a distribution time of </span><span class="font53" style="font-style:italic;">NF/u<sub>s</sub>.</span></p></li>
<li>
<p><span class="font53">b. Suppose that </span><span class="font53" style="font-style:italic;">u<sub>s</sub>/N</span><span class="font55"> &gt;&nbsp;</span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>min</sub>. Specify a distribution scheme that has a distribution time of </span><span class="font53" style="font-style:italic;">F</span><span class="font53">/</span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>min</sub>.</span></p></li>
<li>
<p><span class="font53">c. Conclude that the minimum distribution time is in general given by max { </span><span class="font53" style="font-style:italic;">NF/u<sub>s</sub>, F/d<sub>mn</sub></span><span class="font53"> }.</span></p></li></ul>
<p><span class="font53">P24. Consider distributing a file of </span><span class="font53" style="font-style:italic;">F</span><span class="font53"> bits to </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> peers using a P2P architecture. Assume a fluid model. For simplicity assume that </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>min</sub> is very large, so that peer download bandwidth is never a bottleneck.</span></p>
<p><span class="font53">a. Suppose that </span><span class="font53" style="font-style:italic;">u<sub>s</sub></span><span class="font55"> &lt;&nbsp;</span><span class="font53" style="font-style:italic;">(u<sub>s</sub></span><span class="font55"> + </span><span class="font53" style="font-style:italic;">u</span><span class="font53"><sub>1</sub> </span><span class="font55">+ </span><span class="font53">. . . </span><span class="font55">+ </span><span class="font53" style="font-style:italic;">u<sub>N</sub></span><span class="font53">)/</span><span class="font53" style="font-style:italic;">N</span><span class="font53">. Specify a distribution scheme that has a distribution time of </span><span class="font53" style="font-style:italic;">F/u<sub>s</sub>.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">b. Suppose that </span><span class="font53" style="font-style:italic;">u<sub>s</sub></span><span class="font55"> &gt;&nbsp;</span><span class="font53" style="font-style:italic;">(u<sub>s</sub></span><span class="font55"> + </span><span class="font53" style="font-style:italic;">u</span><span class="font49" style="font-style:italic;">1</span><span class="font55"> + </span><span class="font53">. . . </span><span class="font55">+ </span><span class="font53" style="font-style:italic;">u<sub>N</sub>)/N.</span><span class="font53"> Specify a distribution scheme that has a distribution time of </span><span class="font53" style="font-style:italic;">NF/(u<sub>s</sub></span><span class="font55"> + </span><span class="font53" style="font-style:italic;">u-</span><span class="font49" style="font-style:italic;">1</span><span class="font55"> + </span><span class="font53">. . . </span><span class="font55">+ </span><span class="font53" style="font-style:italic;">u<sub>N</sub></span><span class="font53">).</span></p></li>
<li>
<p><span class="font53">c. Conclude that the minimum distribution time is in general given by max {</span><span class="font53" style="font-style:italic;">F/u<sub>s</sub>, NF/(u<sub>s</sub></span><span class="font55"> + </span><span class="font53" style="font-style:italic;">u</span><span class="font49" style="font-style:italic;">1</span><span class="font55"> + </span><span class="font53">. . . </span><span class="font55">+ </span><span class="font53" style="font-style:italic;">u<sub>N</sub>)</span><span class="font53">}.</span></p></li></ul>
<p><span class="font53">P25. Consider an overlay network with </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> active peers, with each pair of peers having an active TCP connection. Additionally, suppose that the TCP connections pass through a total of </span><span class="font53" style="font-style:italic;">M</span><span class="font53"> routers. How many nodes and edges are there in the corresponding overlay network?</span></p>
<p><span class="font53">P26. Suppose Bob joins a BitTorrent torrent, but he does not want to upload any data to any other peers (he wants to be a so-called free-rider).</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Alice who has been using BitTorrent tells Bob that he cannot receive a complete copy of the file that is shared by the swarm. Is Alice correct or not? Why?</span></p></li>
<li>
<p><span class="font53">b. Charlie claims that Alice is wrong and that he has even been using a collection of multiple computers (with distinct IP addresses) in the computer lab in his department to make his downloads faster, using some additional coordination scripting. What could his script have done?</span></p></li></ul>
<p><span class="font53">P27. Consider a DASH system for which there are </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> video versions (at </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> different rates and qualities) and </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> audio versions (at </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> different rates and qualities). Suppose we want to allow the player to choose at any time any of the </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> video versions and any of the </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> audio versions.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. If we create files so that the audio is mixed in with the video, so server sends only one media stream at given time, how many files will the server need to store (each a different URL)?</span></p></li>
<li>
<p><span class="font53">b. If the server instead sends the audio and video streams separately and has the client synchronize the streams, how many files will the server need to store?</span></p></li></ul>
<p><span class="font53">P28. Install the Python programs TCPClient and UDPClient on one host and TCPServer and UDPServer on another host.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Suppose you run TCPServer and you try to connect using UDPClient. What happens? Why?</span></p></li>
<li>
<p><span class="font53">b. Suppose you run UDPClient before you run UDPServer. What happens? Why?</span></p></li>
<li>
<p><span class="font53">c. What happens if you hardwire in the python client and server programs different port numbers for the client and server sides in either a TCP or UDP client-server pair?</span></p></li></ul>
<p><span class="font53">P29. Suppose that in UDPClient.py, after we create the socket, we add the line:</span></p>
<p><span class="font36">clientSocket.bind(('', 5432))</span></p>
<p><span class="font53">Will it become necessary to change UDPServer.py? What are the port numbers for the sockets in UDPClient and UDPServer? What were they before making this change?</span></p>
<p><span class="font53">P30. Can you configure your browser to open multiple simultaneous connections to a Web site? What are the advantages and disadvantages of having a large number of simultaneous TCP connections?</span></p>
<p><span class="font53">P31. We have seen that Internet TCP sockets treat the data being sent as a byte stream but UDP sockets recognize message boundaries. What are one advantage and one disadvantage of byte-oriented API versus having the API explicitly recognize and preserve application-defined message boundaries?</span></p>
<p><span class="font53">P32. What is the Apache Web server? How much does it cost? What functionality does it currently have? You may want to look at Wikipedia to answer this question.</span></p>
<p><span class="font24" style="font-weight:bold;">Socket Programming Assignments</span></p>
<p><span class="font53">The Companion Website includes six socket programming assignments. The first four assignments are summarized below. The fifth assignment makes use of the ICMP protocol and is summarized at the end of Chapter 5. It is highly recommended that students complete several, if not all, of these assignments. Students can find full details of these assignments, as well as important snippets of the Python code, at the Web site </span><a href="http://www.pearsonglobaleditions.com"><span class="font53">www.pearsonglobaleditions.com</span></a><span class="font53">.</span></p>
<p><span class="font23" style="font-weight:bold;">Assignment 1: Web Server</span></p>
<p><span class="font53">In this assignment, you will develop a simple Web server in Python that is capable of processing only one request. Specifically, your Web server will (i) create a connection socket when contacted by a client (browser); (ii) receive the HTTP request from this connection; (iii) parse the request to determine the specific file being requested; (iv) get the requested file from the server’s file system; (v) create an HTTP response message consisting of the requested file preceded by header lines; and (vi) send the response over the TCP connection to the requesting browser. If a browser requests a file that is not present in your server, your server should return a “404 Not Found” error message.</span></p>
<p><span class="font53">In the Companion Website, we provide the skeleton code for your server. Your job is to complete the code, run your server, and then test your server by sending requests from browsers running on different hosts. If you run your server on a host that already has a Web server running on it, then you should use a different port than port 80 for your Web server.</span></p>
<p><span class="font23" style="font-weight:bold;">Assignment 2: UDP Pinger</span></p>
<p><a name="bookmark75"></a><span class="font53">In this programming assignment, you will write a client ping program in Python. Your client will send a simple ping message to a server, receive a corresponding pong message back from the server, and determine the delay between when the client sent the ping message and received the pong message. This delay is called the Round Trip Time (RTT). The functionality provided by the client and server is similar to the functionality provided by standard ping program available in modern operating systems. However, standard ping programs use the Internet Control Message Protocol (ICMP) (which we will study in Chapter 5). Here we will create a nonstandard (but simple!) UDP-based ping program.</span></p>
<p><span class="font53">Your ping program is to send 10 ping messages to the target server over UDP. For each message, your client is to determine and print the RTT when the corresponding pong message is returned. Because UDP is an unreliable protocol, a packet sent by the client or server may be lost. For this reason, the client cannot wait indefinitely for a reply to a ping message. You should have the client wait up to one second for a reply from the server; if no reply is received, the client should assume that the packet was lost and print a message accordingly.</span></p>
<p><span class="font53">In this assignment, you will be given the complete code for the server (available in the Companion Website). Your job is to write the client code, which will be very similar to the server code. It is recommended that you first study carefully the server code. You can then write your client code, liberally cutting and pasting lines from the server code.</span></p>
<p><span class="font23" style="font-weight:bold;">Assignment 3: Mail Client</span></p>
<p><span class="font53">The goal of this programming assignment is to create a simple mail client that sends e-mail to any recipient. Your client will need to establish a TCP connection with a mail server (e.g., a Google mail server), dialogue with the mail server using the SMTP protocol, send an e-mail message to a recipient (e.g., your friend) via the mail server, and finally close the TCP connection with the mail server.</span></p>
<p><span class="font53">For this assignment, the Companion Website provides the skeleton code for your client. Your job is to complete the code and test your client by sending e-mail to different user accounts. You may also try sending through different servers (for example, through a Google mail server and through your university mail server).</span></p>
<p><span class="font23" style="font-weight:bold;">Assignment 4: Web Proxy</span></p>
<p><span class="font53">In this assignment, you will develop a Web proxy. When your proxy receives an HTTP request for an object from a browser, it generates a new HTTP request for the same object and sends it to the origin server. When the proxy receives the corresponding HTTP response with the object from the origin server, it creates a new HTTP response, including the object, and sends it to the client.</span></p>
<p><span class="font53">For this assignment, the Companion Website provides the skeleton code for the proxy server. Your job is to complete the code, and then test it by having different browsers request Web objects via your proxy.</span></p>
<p><span class="font24" style="font-weight:bold;">Wireshark Lab: HTTP</span></p>
<p><span class="font53">Having gotten our feet wet with the Wireshark packet sniffer in Lab 1, we’re now ready to use Wireshark to investigate protocols in operation. In this lab, we’ll explore several aspects of the HTTP protocol: the basic GET/reply interaction, HTTP message formats, retrieving large HTML files, retrieving HTML files with embedded URLs, persistent and non-persistent connections, and HTTP authentication and security.</span></p>
<p><span class="font53">As is the case with all Wireshark labs, the full description of this lab is available at this book’s Web site, </span><a href="http://www.pearsonglobaleditions.com"><span class="font53">www.pearsonglobaleditions.com</span></a><span class="font53">.</span></p>
<p><span class="font24" style="font-weight:bold;">Wireshark Lab: DNS</span></p>
<p><span class="font53">In this lab, we take a closer look at the client side of the DNS, the protocol that translates Internet hostnames to IP addresses. Recall from Section 2.5 that the client’s role in the DNS is relatively simple—a client sends a query to its local DNS server and receives a response back. Much can go on under the covers, invisible to the DNS clients, as the hierarchical DNS servers communicate with each other to either recursively or iteratively resolve the client’s DNS query. From the DNS client’s standpoint, however, the protocol is quite simple—a query is formulated to the local DNS server and a response is received from that server. We observe DNS in action in this lab.</span></p>
<p><a name="bookmark76"></a><span class="font53">As is the case with all Wireshark labs, the full description of this lab is available at this book’s Web site, </span><a href="http://www.pearsonglobaleditions.com"><span class="font53">www.pearsonglobaleditions.com</span></a><span class="font53">.</span></p>
<p><span class="font23" style="font-weight:bold;">AN INTERVIEW WITH...</span></p>
<p><span class="font13" style="font-weight:bold;">Tim Berners-Lee</span></p>
<div><img src="networking_files/networking-135.jpg" alt="" style="width:98pt;height:146pt;">
<p><span class="font3">Courtesy of Tim Berners-Lee</span></p>
</div><br clear="all">
<p><span class="font46">Sir Tim Berners-Lee is known as the inventor of the World Wide Web. In 1989, while working as a fellow at CERN, he proposed an Internet-based distributed information management system including the original version of the HTTP protocol. In the same year he successfully implemented his design on a client and server. He received the 2016 Turing award for “inventing the World Wide Web, the first Web browser, and the fundamental protocols and algorithms allowing the Web to scale.” He is the Co-Founder of the World Wide Web Foundation, and currently is a Professorial Fellow of Computer Science at the University of Oxford and a professor at CSAIL at MIT.</span></p>
<p><span class="font4" style="font-weight:bold;">You originally studied physics. How is networking similar to physics?</span></p>
<p><span class="font52">When you study physics, you imagine what rules of behavior on the very small scale could possibly give rise to the large-scale world as we see it. When you design a global system like the Web, you try to invent rules of behavior of Web pages and links and things that could in the large create a large-scale world as we would like it. One is analysis and the other synthesis, but they are very similar.</span></p>
<p><span class="font4" style="font-weight:bold;">What influenced you to specialize in networking?</span></p>
<p><span class="font52">After my physics degree, the telecommunications research companies seemed to be the most interesting places. The microprocessor had just come out, and telecommunications was switching very fast from hardwired logic to microprocessor-based systems. It was very exciting.</span></p>
<p><span class="font4" style="font-weight:bold;">What is the most challenging part of your job?</span></p>
<p><span class="font52">When two groups disagree strongly about something, but want in the end to achieve a common goal, finding exactly what they each mean and where the misunderstandings are can be very demanding. The chair of any working group knows that. However, this is what it takes to make progress toward consensus on a large scale.</span></p>
<p><span class="font4" style="font-weight:bold;">What people have inspired you professionally?</span></p>
<p><span class="font52">My parents, who were involved in the early days of computing, gave me a fascination with the whole subject. Mike Sendall and Peggie Rimmer, for whom I worked at various times at CERN are among the people who taught me and encouraged me. I later learned to admire the people, including Vanevar Bush, Doug Englebart, and Ted Nelson, who had had similar dreams in their time but had not had the benefit of the existence for PCs and the Internet to be able to realize it.</span></p>
<p><span class="font70" style="font-style:italic;">This page is intentionally left blank</span></p><img src="networking_files/networking-136.jpg" alt="" style="width:531pt;height:153pt;">
<h1><a name="bookmark295"></a><span class="font27" style="font-weight:bold;">Transport Layer</span></h1>
<p><span class="font53">Residing between the application and network layers, the transport layer is a central piece of the layered network architecture. It has the critical role of providing communication services directly to the application processes running on different hosts. The pedagogic approach we take in this chapter is to alternate between discussions of transport-layer principles and discussions of how these principles are implemented in existing protocols; as usual, particular emphasis will be given to Internet protocols, in particular the TCP and UDP transport-layer protocols.</span></p>
<p><span class="font53">We’ll begin by discussing the relationship between the transport and network layers. This sets the stage for examining the first critical function of the transport layer—extending the network layer’s delivery service between two end systems to a delivery service between two application-layer processes running on the end systems. We’ll illustrate this function in our coverage of the Internet’s connectionless transport protocol, UDP.</span></p>
<p><span class="font53">We’ll then return to principles and confront one of the most fundamental problems in computer networking—how two entities can communicate reliably over a medium that may lose and corrupt data. Through a series of increasingly complicated (and realistic!) scenarios, we’ll build up an array of techniques that transport protocols use to solve this problem. We’ll then show how these principles are embodied in TCP, the Internet’s connection-oriented transport protocol.</span></p>
<p><a name="bookmark296"></a><span class="font53">We’ll next move on to a second fundamentally important problem in networking—controlling the transmission rate of transport-layer entities in order to avoid, or recover from, congestion within the network. We’ll consider the causes and consequences of congestion, as well as commonly used congestion-control techniques. After obtaining a solid understanding of the issues behind congestion control, we’ll study TCP’s approach to congestion control.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">3.1 </span><span class="font24" style="font-weight:bold;">Introduction and Transport-Layer Services</span></p></li></ul>
<p><span class="font53">In the previous two chapters, we touched on the role of the transport layer and the services that it provides. Let’s quickly review what we have already learned about the transport layer.</span></p>
<p><span class="font53">A transport-layer protocol provides for </span><span class="font53" style="font-weight:bold;">logical communication </span><span class="font53">between application processes running on different hosts. By </span><span class="font53" style="font-style:italic;">logical communication,</span><span class="font53"> we mean that from an application’s perspective, it is as if the hosts running the processes were directly connected; in reality, the hosts may be on opposite sides of the planet, connected via numerous routers and a wide range of link types. Application processes use the logical communication provided by the transport layer to send messages to each other, free from the worry of the details of the physical infrastructure used to carry these messages. Figure 3.1 illustrates the notion of logical communication.</span></p>
<p><span class="font53">As shown in Figure 3.1, transport-layer protocols are implemented in the end systems but not in network routers. On the sending side, the transport layer converts the application-layer messages it receives from a sending application process into transport-layer packets, known as transport-layer </span><span class="font53" style="font-weight:bold;">segments </span><span class="font53">in Internet terminology. This is done by (possibly) breaking the application messages into smaller chunks and adding a transport-layer header to each chunk to create the transport-layer segment. The transport layer then passes the segment to the network layer at the sending end system, where the segment is encapsulated within a network-layer packet (a datagram) and sent to the destination. It’s important to note that network routers act only on the network-layer fields of the datagram; that is, they do not examine the fields of the transport-layer segment encapsulated with the datagram. On the receiving side, the network layer extracts the transport-layer segment from the datagram and passes the segment up to the transport layer. The transport layer then processes the received segment, making the data in the segment available to the receiving application.</span></p>
<p><span class="font53">More than one transport-layer protocol may be available to network applications. For example, the Internet has two protocols—TCP and UDP. Each of these protocols provides a different set of transport-layer services to the invoking application.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">3.1.1 </span><span class="font23" style="font-weight:bold;">Relationship Between Transport and Network Layers</span></p></li></ul>
<p><a name="bookmark297"></a><span class="font53">Recall that the transport layer lies just above the network layer in the protocol stack. Whereas a transport-layer protocol provides logical communication between</span></p>
<div>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font4">Application</span></p></td><td></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4" style="font-weight:bold;">Transport</span></p></td><td></td></tr>
<tr><td>
<p><span class="font4">Network</span></p></td><td></td></tr>
<tr><td>
<p><span class="font4">Link</span></p></td><td></td></tr>
<tr><td>
<p><span class="font4">Physical</span></p></td><td></td></tr>
</table>
</div><br clear="all">
<div>
<p><span class="font4">Link</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Datacenter Network</span></p>
<p><span class="font4" style="font-weight:bold;">National or Global ISP</span></p><img src="networking_files/networking-137.jpg" alt="" style="width:319pt;height:226pt;">
<p><span class="font4" style="font-weight:bold;">Mobile Network</span></p>
<p><span class="font4">Link</span></p>
<p><span class="font4" style="font-weight:bold;">.ocal or \aional ISP</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Network</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Datacenter Network</span></p><img src="networking_files/networking-138.jpg" alt="" style="width:56pt;height:47pt;">
</div><br clear="all">
<div>
<p><span class="font4">hysical</span></p>
<table border="1">
<tr><td></td><td style="vertical-align:middle;">
<p><span class="font4">Network</span></p></td></tr>
<tr><td></td><td>
<p><span class="font4">Link</span></p></td></tr>
<tr><td></td><td>
<p><span class="font4">Physical</span></p></td></tr>
</table>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Home Network</span></p>
<p><span class="font4" style="font-weight:bold;">Content Provider Network</span></p>
<p><span class="font4">Network</span></p>
<p><span class="font4">Network</span></p>
<p><span class="font4">Physical</span></p><img src="networking_files/networking-139.jpg" alt="" style="width:300pt;height:154pt;">
<p><span class="font4">Link</span></p>
<p><span class="font4">Network</span></p>
<p><span class="font4">Link</span></p>
<p><span class="font4">Physical</span></p>
<p><span class="font4" style="font-weight:bold;">Transport</span></p>
<p><span class="font4">Network</span></p>
<p><span class="font4" style="font-weight:bold;">Enterprise Network</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Application</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Link</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Physical</span></p>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 3.1 </span><span class="font50">♦ </span><span class="font5">The transport layer provides logical rather than physical communication between application processes </span><span class="font53" style="font-style:italic;">processes</span><span class="font53"> running on different hosts, a network-layer protocol provides logical-communication between </span><span class="font53" style="font-style:italic;">hosts.</span><span class="font53"> This distinction is subtle but important. Let’s examine this distinction with the aid of a household analogy.</span></p>
<p><span class="font53">Consider two houses, one on the East Coast and the other on the West Coast, with each house being home to a dozen kids. The kids in the East Coast household are cousins of the kids in the West Coast household. The kids in the two households love to write to each other—each kid writes each cousin every week, with each letter delivered by the traditional postal service in a separate envelope. Thus, each household sends 144 letters to the other household every week. (These kids would save a lot of money if they had e-mail!) In each of the households, there is one kid—Ann in the West Coast house and Bill in the East Coast house—responsible for mail collection and mail distribution. Each week Ann visits all her brothers and sisters, collects the mail, and gives the mail to a postal-service mail carrier, who makes daily visits to the house. When letters arrive at the West Coast house, Ann also has the job of distributing the mail to her brothers and sisters. Bill has a similar job on the East Coast.</span></p>
<p><span class="font53">In this example, the postal service provides logical communication between the two houses—the postal service moves mail from house to house, not from person to person. On the other hand, Ann and Bill provide logical communication among the cousins—Ann and Bill pick up mail from, and deliver mail to, their brothers and sisters. Note that from the cousins’ perspective, Ann and Bill </span><span class="font53" style="font-style:italic;">are</span><span class="font53"> the mail service, even though Ann and Bill are only a part (the end-system part) of the end-to-end delivery process. This household example serves as a nice analogy for explaining how the transport layer relates to the network layer:</span></p>
<p><span class="font53">application messages </span><span class="font54">= </span><span class="font53">letters in envelopes</span></p>
<p><span class="font53">processes </span><span class="font54">= </span><span class="font53">cousins</span></p>
<p><span class="font53">hosts (also called end systems) </span><span class="font54">= </span><span class="font53">houses</span></p>
<p><span class="font53">transport-layer protocol </span><span class="font54">= </span><span class="font53">Ann and Bill</span></p>
<p><span class="font53">network-layer protocol </span><span class="font54">= </span><span class="font53">postal service (including mail carriers)</span></p>
<p><span class="font53">Continuing with this analogy, note that Ann and Bill do all their work within their respective homes; they are not involved, for example, in sorting mail in any intermediate mail center or in moving mail from one mail center to another. Similarly, transport-layer protocols live in the end systems. Within an end system, a transport protocol moves messages from application processes to the network edge (that is, the network layer) and vice versa, but it doesn’t have any say about how the messages are moved within the network core. In fact, as illustrated in Figure 3.1, intermediate routers neither act on, nor recognize, any information that the transport layer may have added to the application messages.</span></p>
<p><span class="font53">Continuing with our family saga, suppose now that when Ann and Bill go on vacation, another cousin pair—say, Susan and Harvey—substitute for them and provide the household-internal collection and delivery of mail. Unfortunately for the two families, Susan and Harvey do not do the collection and delivery in exactly the same way as Ann and Bill. Being younger kids, Susan and Harvey pick up and drop off the mail less frequently and occasionally lose letters (which are sometimes chewed up by the family dog). Thus, the cousin-pair Susan and Harvey do not provide the same set of services (that is, the same service model) as Ann and Bill. In an analogous manner, a computer network may make available multiple transport protocols, with each protocol offering a different service model to applications.</span></p>
<p><span class="font53">The possible services that Ann and Bill can provide are clearly constrained by the possible services that the postal service provides. For example, if the postal service doesn’t provide a maximum bound on how long it can take to deliver mail between the two houses (for example, three days), then there is no way that Ann and Bill can guarantee a maximum delay for mail delivery between any of the cousin pairs. In a similar manner, the services that a transport protocol can provide are often constrained by the service model of the underlying network-layer protocol. If the network-layer protocol cannot provide delay or bandwidth guarantees for transportlayer segments sent between hosts, then the transport-layer protocol cannot provide delay or bandwidth guarantees for application messages sent between processes.</span></p>
<p><span class="font53">Nevertheless, certain services </span><span class="font53" style="font-style:italic;">can</span><span class="font53"> be offered by a transport protocol even when the underlying network protocol doesn’t offer the corresponding service at the network layer. For example, as we’ll see in this chapter, a transport protocol can offer reliable data transfer service to an application even when the underlying network protocol is unreliable, that is, even when the network protocol loses, garbles, or duplicates packets. As another example (which we’ll explore in Chapter 8 when we discuss network security), a transport protocol can use encryption to guarantee that application messages are not read by intruders, even when the network layer cannot guarantee the confidentiality of transport-layer segments.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">3.1.2 </span><span class="font23" style="font-weight:bold;">Overview of the Transport Layer in the Internet</span></p></li></ul>
<p><span class="font53">Recall that the Internet makes two distinct transport-layer protocols available to the application layer. One of these protocols is </span><span class="font53" style="font-weight:bold;">UDP </span><span class="font53">(User Datagram Protocol), which provides an unreliable, connectionless service to the invoking application. The second of these protocols is </span><span class="font53" style="font-weight:bold;">TCP </span><span class="font53">(Transmission Control Protocol), which provides a reliable, connection-oriented service to the invoking application. When designing a network application, the application developer must specify one of these two transport protocols. As we saw in Section 2.7, the application developer selects between UDP and TCP when creating sockets.</span></p>
<p><a name="bookmark298"></a><span class="font53">To simplify terminology, we refer to the transport-layer packet as a </span><span class="font53" style="font-style:italic;">segment.</span><span class="font53"> We mention, however, that the Internet literature (for example, the RFCs) also refers to the transport-layer packet for TCP as a segment but often refers to the packet for UDP as a datagram. However, this same Internet literature also uses the term </span><span class="font53" style="font-style:italic;">datagram</span><span class="font53"> for the network-layer packet! For an introductory book on computer networking such as this, we believe that it is less confusing to refer to both TCP and UDP packets as segments, and reserve the term </span><span class="font53" style="font-style:italic;">datagram</span><span class="font53"> for the network-layer packet.</span></p>
<p><span class="font53">Before proceeding with our brief introduction of UDP and TCP, it will be useful to say a few words about the Internet’s network layer. (We’ll learn about the network layer in detail in Chapters 4 and 5.) The Internet’s network-layer protocol has a name—IP, for Internet Protocol. IP provides logical communication between hosts. The IP service model is a </span><span class="font53" style="font-weight:bold;">best-effort delivery service</span><span class="font53">. This means that IP makes its “best effort” to deliver segments between communicating hosts, </span><span class="font53" style="font-style:italic;">but it makes no guarantees.</span><span class="font53"> In particular, it does not guarantee segment delivery, it does not guarantee orderly delivery of segments, and it does not guarantee the integrity of the data in the segments. For these reasons, IP is said to be an </span><span class="font53" style="font-weight:bold;">unreliable service</span><span class="font53">. We also mention here that every host has at least one network-layer address, a so-called IP address. We’ll examine IP addressing in detail in Chapter 4; for this chapter we need only keep in mind that </span><span class="font53" style="font-style:italic;">each host has an IP address.</span></p>
<p><span class="font53">Having taken a glimpse at the IP service model, let’s now summarize the service models provided by UDP and TCP. The most fundamental responsibility of UDP and TCP is to extend IP’s delivery service between two end systems to a delivery service between two processes running on the end systems. Extending host-to-host delivery to process-to-process delivery is called </span><span class="font53" style="font-weight:bold;">transport-layer multiplexing </span><span class="font53">and </span><span class="font53" style="font-weight:bold;">demultiplexing</span><span class="font53">. We’ll discuss transport-layer multiplexing and demultiplexing in the next section. UDP and TCP also provide integrity checking by including errordetection fields in their segments’ headers. These two minimal transport-layer services—process-to-process data delivery and error checking—are the only two services that UDP provides! In particular, like IP, UDP is an unreliable service—it does not guarantee that data sent by one process will arrive intact (or at all!) to the destination process. UDP is discussed in detail in Section 3.3.</span></p>
<p><span class="font53">TCP, on the other hand, offers several additional services to applications. First and foremost, it provides </span><span class="font53" style="font-weight:bold;">reliable data transfer</span><span class="font53">. Using flow control, sequence numbers, acknowledgments, and timers (techniques we’ll explore in detail in this chapter), TCP ensures that data is delivered from sending process to receiving process, correctly and in order. TCP thus converts IP’s unreliable service between end systems into a reliable data transport service between processes. TCP also provides </span><span class="font53" style="font-weight:bold;">congestion control</span><span class="font53">. Congestion control is not so much a service provided to the invoking application as it is a service for the Internet as a whole, a service for the general good. Loosely speaking, TCP congestion control prevents any one TCP connection from swamping the links and routers between communicating hosts with an excessive amount of traffic. TCP strives to give each connection traversing a congested link an equal share of the link bandwidth. This is done by regulating the rate at which the sending sides of TCP connections can send traffic into the network. UDP traffic, on the other hand, is unregulated. An application using UDP transport can send at any rate it pleases, for as long as it pleases.</span></p>
<p><span class="font53">A protocol that provides reliable data transfer and congestion control is necessarily complex. We’ll need several sections to cover the principles of reliable data transfer and congestion control, and additional sections to cover the TCP protocol itself. These topics are investigated in Sections 3.4 through 3.7. The approach taken in this chapter is to alternate between basic principles and the TCP protocol. For example, we’ll first discuss reliable data transfer in a general setting and then discuss how TCP specifically provides reliable data transfer. Similarly, we’ll first discuss congestion control in a general setting and then discuss how TCP performs congestion control. But before getting into all this good stuff, let’s first look at transportlayer multiplexing and demultiplexing.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">3.2 </span><span class="font24" style="font-weight:bold;">Multiplexing and Demultiplexing</span></p></li></ul>
<p><span class="font53">In this section, we discuss transport-layer multiplexing and demultiplexing, that is, extending the host-to-host delivery service provided by the network layer to a process-to-process delivery service for applications running on the hosts. In order to keep the discussion concrete, we’ll discuss this basic transport-layer service in the context of the Internet. We emphasize, however, that a multiplexing/demultiplexing service is needed for all computer networks.</span></p>
<p><span class="font53">At the destination host, the transport layer receives segments from the network layer just below. The transport layer has the responsibility of delivering the data in these segments to the appropriate application process running in the host. Let’s take a look at an example. Suppose you are sitting in front of your computer, and you are downloading Web pages while running one FTP session and two Telnet sessions. You therefore have four network application processes running—two Telnet processes, one FTP process, and one HTTP process. When the transport layer in your computer receives data from the network layer below, it needs to direct the received data to one of these four processes. Let’s now examine how this is done.</span></p>
<p><span class="font53">First recall from Section 2.7 that a process (as part of a network application) can have one or more </span><span class="font53" style="font-weight:bold;">sockets</span><span class="font53">, doors through which data passes from the network to the process and through which data passes from the process to the network. Thus, as shown in Figure 3.2, the transport layer in the receiving host does not actually deliver data directly to a process, but instead to an intermediary socket. Because at any given time there can be more than one socket in the receiving host, each socket has a unique identifier. The format of the identifier depends on whether the socket is a UDP or a TCP socket, as we’ll discuss shortly.</span></p>
<p><a name="bookmark299"></a><span class="font53">Now let’s consider how a receiving host directs an incoming transport-layer segment to the appropriate socket. Each transport-layer segment has a set of fields in the segment for this purpose. At the receiving end, the transport layer examines these fields to identify the receiving socket and then directs the segment to that socket. This job of delivering the data in a transport-layer segment to the correct socket is called </span><span class="font53" style="font-weight:bold;">demultiplexing</span><span class="font53">. The job of gathering data chunks at the source host from different sockets, encapsulating each data chunk with header information (that will later be used in demultiplexing) to create segments, and passing the segments to the network layer is called </span><span class="font53" style="font-weight:bold;">multiplexing</span><span class="font53">. Note that the transport layer in the middle host</span></p>
<div><img src="networking_files/networking-140.jpg" alt="" style="width:35pt;height:73pt;">
</div><br clear="all">
<div>
<p><span class="font4">Key:</span></p><img src="networking_files/networking-141.jpg" alt="" style="width:25pt;height:12pt;">
</div><br clear="all">
<div><img src="networking_files/networking-142.jpg" alt="" style="width:207pt;height:143pt;">
<p><span class="font41" style="text-decoration:underline;">I I</span><span class="font41"> Socket</span></p>
</div><br clear="all">
<div>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font4">Application</span></p></td><td rowspan="2"></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4" style="font-weight:bold;">Transport</span></p></td></tr>
<tr><td>
<p><span class="font4">Network</span></p></td><td></td></tr>
<tr><td>
<p><span class="font4">Data link</span></p></td><td></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">Physical</span></p></td><td></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font17">—</span></p></td><td></td></tr>
</table>
</div><br clear="all">
<div>
<table border="1">
<tr><td></td><td style="vertical-align:bottom;">
<p><span class="font4" style="font-weight:bold;">Transport</span></p></td><td></td></tr>
<tr><td></td><td>
<p><span class="font4">Network</span></p></td><td></td></tr>
<tr><td></td><td>
<p><span class="font4">Data link</span></p></td><td></td></tr>
<tr><td></td><td style="vertical-align:bottom;">
<p><span class="font4">Physical</span></p></td><td></td></tr>
<tr><td></td><td></td><td></td></tr>
</table>
</div><br clear="all">
<div><img src="networking_files/networking-143.jpg" alt="" style="width:37pt;height:62pt;">
</div><br clear="all">
<div>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font4">P</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Application</span></p></td></tr>
<tr><td></td><td style="vertical-align:bottom;">
<p><span class="font4" style="font-weight:bold;">Transport</span></p></td></tr>
<tr><td></td><td>
<p><span class="font4">Network</span></p></td></tr>
<tr><td></td><td>
<p><span class="font4">Data link</span></p></td></tr>
<tr><td></td><td style="vertical-align:bottom;">
<p><span class="font4">Physical</span></p></td></tr>
</table>
</div><br clear="all">
<div><img src="networking_files/networking-144.jpg" alt="" style="width:29pt;height:42pt;">
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 3.2 </span><span class="font50">♦ </span><span class="font5">Transport-layer multiplexing and demultiplexing</span></p>
<p><span class="font53">in Figure 3.2 must demultiplex segments arriving from the network layer below to either process P</span><span class="font50">1 </span><span class="font53">or P<sub>2</sub> above; this is done by directing the arriving segment’s data to the corresponding process’s socket. The transport layer in the middle host must also gather outgoing data from these sockets, form transport-layer segments, and pass these segments down to the network layer. Although we have introduced multiplexing and demultiplexing in the context of the Internet transport protocols, it’s important to realize that they are concerns whenever a single protocol at one layer (at the transport layer or elsewhere) is used by multiple protocols at the next higher layer.</span></p>
<p><span class="font53">To illustrate the demultiplexing job, recall the household analogy in the previous section. Each of the kids is identified by his or her name. When Bill receives a batch of mail from the mail carrier, he performs a demultiplexing operation by observing to whom the letters are addressed and then hand delivering the mail to his brothers and sisters. Ann performs a multiplexing operation when she collects letters from her brothers and sisters and gives the collected mail to the mail person.</span></p>
<p><span class="font53">Now that we understand the roles of transport-layer multiplexing and demultiplexing, let us examine how it is actually done in a host. From the discussion above, we know that transport-layer multiplexing requires (1) that sockets have unique identifiers, and (2) that each segment have special fields that indicate the socket to which the segment is to be delivered. These special fields, illustrated in Figure 3.3, are the </span><span class="font53" style="font-weight:bold;">source port number field </span><span class="font53">and the </span><span class="font53" style="font-weight:bold;">destination port number field</span><span class="font53">. (The UDP and TCP segments have other fields as well, as discussed in the subsequent sections of this chapter.) Each port number is a 16-bit number, ranging from 0 to 65535. The port numbers ranging from 0 to 1023 are called </span><span class="font53" style="font-weight:bold;">well-known port numbers </span><span class="font53">and are restricted, which means that they are reserved for use by well-known</span></p>
<p><span class="font4">32 bits</span></p>
<p><span class="font4">Source port # Dest. port #</span></p>
<p><span class="font4">Other header fields</span></p>
<p><span class="font4">Application data (message)</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 3.3 </span><span class="font50">♦ </span><span class="font5">Source and destination port-number fields in a transport-layer segment</span></p>
<p><span class="font53">application protocols such as HTTP (which uses port number 80) and FTP (which uses port number 21). The list of well-known port numbers is given in RFC 1700 and is updated at </span><a href="http://www.iana.org"><span class="font53">http://www.iana.org </span></a><span class="font53">[RFC 3232]. When we develop a new application (such as the simple application developed in Section 2.7), we must assign the application a port number.</span></p>
<p><span class="font53">It should now be clear how the transport layer </span><span class="font53" style="font-style:italic;">could</span><span class="font53"> implement the demultiplexing service: Each socket in the host could be assigned a port number, and when a segment arrives at the host, the transport layer examines the destination port number in the segment and directs the segment to the corresponding socket. The segment’s data then passes through the socket into the attached process. As we’ll see, this is basically how UDP does it. However, we’ll also see that multiplexing/ demultiplexing in TCP is yet more subtle.</span></p>
<p><span class="font22" style="font-weight:bold;">Connectionless Multiplexing and Demultiplexing</span></p>
<p><span class="font53">Recall from Section 2.7.1 that the Python program running in a host can create a UDP socket with the line</span></p>
<p><span class="font36">clientsocket = socket(AF_INET, SOCK_DGRAM)</span></p>
<p><span class="font53">When a UDP socket is created in this manner, the transport layer automatically assigns a port number to the socket. In particular, the transport layer assigns a port number in the range 1024 to 65535 that is currently not being used by any other UDP port in the host. Alternatively, we can add a line into our Python program after we create the socket to associate a specific port number (say, 19157) to this UDP socket via the socket </span><span class="font53" style="font-weight:bold;">bind() </span><span class="font53">method:</span></p>
<p><span class="font36">clientSocket.bind(('', 19157))</span></p>
<p><span class="font53">If the application developer writing the code were implementing the server side of a “well-known protocol,” then the developer would have to assign the corresponding well-known port number. Typically, the client side of the application lets the transport layer automatically (and transparently) assign the port number, whereas the server side of the application assigns a specific port number.</span></p>
<p><span class="font53">With port numbers assigned to UDP sockets, we can now precisely describe UDP multiplexing/demultiplexing. Suppose a process in Host A, with UDP port 19157, wants to send a chunk of application data to a process with UDP port 46428 in Host B. The transport layer in Host A creates a transport-layer segment that includes the application data, the source port number (19157), the destination port number (46428), and two other values (which will be discussed later, but are unimportant for the current discussion). The transport layer then passes the resulting segment to the network layer. The network layer encapsulates the segment in an IP datagram and makes a best-effort attempt to deliver the segment to the receiving host. If the segment arrives at the receiving Host B, the transport layer at the receiving host examines the destination port number in the segment (46428) and delivers the segment to its socket identified by port 46428. Note that Host B could be running multiple processes, each with its own UDP socket and associated port number. As UDP segments arrive from the network, Host B directs (demultiplexes) each segment to the appropriate socket by examining the segment’s destination port number.</span></p>
<p><span class="font53">It is important to note that a UDP socket is fully identified by a two-tuple consisting of a destination IP address and a destination port number. As a consequence, if two UDP segments have different source IP addresses and/or source port numbers, but have the same </span><span class="font53" style="font-style:italic;">destination</span><span class="font53"> IP address and </span><span class="font53" style="font-style:italic;">destination</span><span class="font53"> port number, then the two segments will be directed to the same destination process via the same destination socket.</span></p>
<p><span class="font53">You may be wondering now, what is the purpose of the source port number? As shown in Figure 3.4, in the A-to-B segment the source port number serves as part of a “return address”—when B wants to send a segment back to A, the destination port in the B-to-A segment will take its value from the source port value of the A-to-B segment. (The complete return address is A’s IP address and the source port number.) As an example, recall the UDP server program studied in Section 2.7. In </span><span class="font36">UDPServer.py</span><span class="font53">, the server uses the </span><span class="font36">recvfrom() </span><span class="font53">method to extract the clientside (source) port number from the segment it receives from the client; it then sends a new segment to the client, with the extracted source port number serving as the destination port number in this new segment.</span></p>
<p><span class="font22" style="font-weight:bold;">Connection-Oriented Multiplexing and Demultiplexing</span></p>
<p><span class="font53">In order to understand TCP demultiplexing, we have to take a close look at TCP sockets and TCP connection establishment. One subtle difference between a TCP socket and a UDP socket is that a TCP socket is identified by a four-tuple: (source IP address, source port number, destination IP address, destination port number). Thus, when a TCP segment arrives from the network to a host, the host uses all four values to direct (demultiplex) the segment to the appropriate socket.</span></p>
<div>
<p><span class="font4">Host A</span></p><img src="networking_files/networking-145.jpg" alt="" style="width:35pt;height:37pt;">
</div><br clear="all">
<div><img src="networking_files/networking-146.jpg" alt="" style="width:295pt;height:191pt;">
<p><span class="font7" style="font-weight:bold;">Figure 3.4 </span><span class="font50">♦ </span><span class="font5">The inversion of source and destination port numbers</span></p>
</div><br clear="all">
<p><span class="font53">In particular, and in contrast with UDP, two arriving TCP segments with different source IP addresses or source port numbers will (with the exception of a TCP segment carrying the original connection-establishment request) be directed to two different sockets. To gain further insight, let’s reconsider the TCP client-server programming example in Section 2.7.2:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;The TCP server application has a “welcoming socket,” that waits for connectionestablishment requests from TCP clients (see Figure 2.29) on port number 12000.</span></p></li>
<li>
<p><span class="font53">• &nbsp;The TCP client creates a socket and sends a connection establishment request segment with the lines:</span></p></li></ul>
<p><span class="font36">clientsocket = socket(AF_INET, SOCK_STREAM) clientsocket.connect((serverName, 12000) )</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;A connection-establishment request is nothing more than a TCP segment with destination port number 12000 and a special connection-establishment bit set in the TCP header (discussed in Section 3.5). The segment also includes a source port number that was chosen by the client.</span></p></li>
<li>
<p><span class="font53">• &nbsp;When the host operating system of the computer running the server process receives the incoming connection-request segment with destination port 12000, it locates the server process that is waiting to accept a connection on port number 12000. The server process then creates a new socket:</span></p></li></ul>
<p><span class="font36">connectionSocket, addr = serverSocket.accept()</span></p>
<p><span class="font53">• Also, the transport layer at the server notes the following four values in the connection-request segment: (1) the source port number in the segment, (2) the IP address of the source host, (3) the destination port number in the segment, and (4) its own IP address. The newly created connection socket is identified by these four values; all subsequently arriving segments whose source port, source IP address, destination port, and destination IP address match these four values will be demultiplexed to this socket. With the TCP connection now in place, the client and server can now send data to each other.</span></p>
<p><span class="font53">The server host may support many simultaneous TCP connection sockets, with each socket attached to a process, and with each socket identified by its own fourtuple. When a TCP segment arrives at the host, all four fields (source IP address, source port, destination IP address, destination port) are used to direct (demultiplex) the segment to the appropriate socket.</span></p>
<div><img src="networking_files/networking-147.jpg" alt="" style="width:168pt;height:23pt;">
</div><br clear="all">
<div>
<p><span class="font23" style="font-weight:bold;">FOCUS ON SECURITY</span></p>
</div><br clear="all">
<p><span class="font4" style="font-weight:bold;">PORT SCANNING</span></p>
<p><span class="font4">We’ve seen that a server process waits patiently on an open port for contact by a remote client. Some ports are reserved for well-known applications (e.g., Web, FTP, DNS, and SMTP servers); other ports are used by convention by popular applications (e.g., the Microsoft Windows SQL server listens for requests on UDP port 1434). Thus, if we determine that a port is open on a host, we may be able to map that port to a specific application running on the host. This is very useful for system administrators, who are often interested in knowing which network applications are running on the hosts in their networks. But attackers, in order to “case the joint,” also want to know which ports are open on target hosts. If a host is found to be running an application with a known security flaw (e.g., a SQL server listening on port 1434 was subject to a buffer overflow, allowing a remote user to execute arbitrary code on the vulnerable host, a flaw exploited by the Slammer worm [CERT 2003-04]), then that host is ripe for attack.</span></p>
<p><span class="font4">Determining which applications are listening on which ports is a relatively easy task. Indeed there are a number of public domain programs, called port scanners, that do just that. Perhaps the most widely used of these is nmap, freely available at </span><a href="http://nmap.org"><span class="font4">http://nmap.org</span></a><span class="font4"> and included in most Linux distributions. For TCP, nmap sequentially scans ports, looking for ports that are accepting TCP connections. For UDP, nmap again sequentially scans ports, looking for UDP ports that respond to transmitted UDP segments. In both cases, nmap returns a list of open, closed, or unreachable ports. A host running nmap can attempt to scan any target host </span><span class="font4" style="font-style:italic;">anywhere</span><span class="font4"> in the Internet. We’ll revisit nmap in Section 3.5.6, when we discuss TCP connection management.</span></p>
<div style="border:solid;">
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font3">source port:</span></p>
<p><span class="font3">7532</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">dest. port:</span></p>
<p><span class="font3">80</span></p></td></tr>
<tr><td>
<p><span class="font3">source IP:</span></p>
<p><span class="font3">C</span></p></td><td>
<p><span class="font3">dest. IP: B</span></p></td></tr>
<tr><td></td><td></td></tr>
<tr><td colspan="2"></td></tr>
</table>
</div><br clear="all">
<div>
<p><span class="font4">Web client host A</span></p><img src="networking_files/networking-148.jpg" alt="" style="width:53pt;height:37pt;">
</div><br clear="all">
<div>
<p><span class="font4">Web server B</span></p>
<p><span class="font4">Web client host C</span></p><img src="networking_files/networking-149.jpg" alt="" style="width:262pt;height:190pt;">
<p><span class="font4">Per-connection</span></p>
<p><span class="font4">HTTP processes</span></p>
</div><br clear="all">
<div>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font3">source port:</span></p>
<p><span class="font3">26145</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">dest. port:</span></p>
<p><span class="font3">80</span></p></td></tr>
<tr><td>
<p><span class="font3">source IP:</span></p>
<p><span class="font3">C</span></p></td><td>
<p><span class="font3">dest. IP: B</span></p></td></tr>
<tr><td></td><td></td></tr>
<tr><td colspan="2"></td></tr>
</table>
</div><br clear="all">
<div>
<p><span class="font4">7 -I—Transportlayer demultiplexing</span></p>
</div><br clear="all">
<div style="border:solid;">
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font3">source port:</span></p>
<p><span class="font3">26145</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">dest. port:</span></p>
<p><span class="font3">80</span></p></td></tr>
<tr><td>
<p><span class="font3">source IP: A</span></p></td><td>
<p><span class="font3">dest. IP: B</span></p></td></tr>
<tr><td></td><td></td></tr>
<tr><td colspan="2"></td></tr>
</table>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 3.5 </span><span class="font50">♦ </span><span class="font5">Two clients, using the same destination port number (80) to communicate with the same Web server application</span></p>
<p><span class="font53">The situation is illustrated in Figure 3.5, in which Host C initiates two HTTP sessions to server B, and Host A initiates one HTTP session to B. Hosts A and C and server B each have their own unique IP address—A, C, and B, respectively. Host C assigns two different source port numbers (26145 and 7532) to its two HTTP connections. Because Host A is choosing source port numbers independently of C, it might also assign a source port of 26145 to its HTTP connection. But this is not a problem—server B will still be able to correctly demultiplex the two connections having the same source port number, since the two connections have different source IP addresses.</span></p>
<p><span class="font22" style="font-weight:bold;">Web Servers and TCP</span></p>
<p><span class="font53">Before closing this discussion, it’s instructive to say a few additional words about Web servers and how they use port numbers. Consider a host running a Web server, such as an Apache Web server, on port 80. When clients (for example, browsers) send segments to the server, </span><span class="font53" style="font-style:italic;">all</span><span class="font53"> segments will have destination port 80. In particular, both the initial connection-establishment segments and the segments carrying HTTP request messages will have destination port 80. As we have just described, the server distinguishes the segments from the different clients using source IP addresses and source port numbers.</span></p>
<p><span class="font53">Figure 3.5 shows a Web server that spawns a new process for each connection. As shown in Figure 3.5, each of these processes has its own connection socket through which HTTP requests arrive and HTTP responses are sent. We mention, however, that there is not always a one-to-one correspondence between connection sockets and processes. In fact, today’s high-performing Web servers often use only one process, and create a new thread with a new connection socket for each new client connection. (A thread can be viewed as a lightweight subprocess.) If you did the first programming assignment in Chapter 2, you built a Web server that does just this. For such a server, at any given time there may be many connection sockets (with different identifiers) attached to the same process.</span></p>
<p><span class="font53">If the client and server are using persistent HTTP, then throughout the duration of the persistent connection the client and server exchange HTTP messages via the same server socket. However, if the client and server use non-persistent HTTP, then a new TCP connection is created and closed for every request/response, and hence a new socket is created and later closed for every request/response. This frequent creating and closing of sockets can severely impact the performance of a busy Web server (although a number of operating system tricks can be used to mitigate the problem). Readers interested in the operating system issues surrounding persistent and non-persistent HTTP are encouraged to see [Nielsen 1997; Nahum 2002].</span></p>
<p><span class="font53">Now that we’ve discussed transport-layer multiplexing and demultiplexing, let’s move on and discuss one of the Internet’s transport protocols, UDP. In the next section, we’ll see that UDP adds little more to the network-layer protocol than a multi-plexing/demultiplexing service.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">3.3 </span><span class="font24" style="font-weight:bold;">Connectionless Transport: UDP</span></p></li></ul>
<p><span class="font53">In this section, we’ll take a close look at UDP, how it works, and what it does. We encourage you to refer back to Section 2.1, which includes an overview of the UDP service model, and to Section 2.7.1, which discusses socket programming using UDP.</span></p>
<p><a name="bookmark300"></a><span class="font53">To motivate our discussion about UDP, suppose you were interested in designing a no-frills, bare-bones transport protocol. How might you go about doing this? You might first consider using a vacuous transport protocol. In particular, on the sending side, you might consider taking the messages from the application process and passing them directly to the network layer; and on the receiving side, you might consider taking the messages arriving from the network layer and passing them directly to the application process. But as we learned in the previous section, we have to do a little more than nothing! At the very least, the transport layer has to provide a multiplexing/demultiplexing service in order to pass data between the network layer and the correct application-level process.</span></p>
<p><span class="font53">UDP, defined in [RFC 768], does just about as little as a transport protocol can do. Aside from the multiplexing/demultiplexing function and some light error checking, it adds nothing to IP. In fact, if the application developer chooses UDP instead of TCP, then the application is almost directly talking with IP. UDP takes messages from the application process, attaches source and destination port number fields for the multi-plexing/demultiplexing service, adds two other small fields, and passes the resulting segment to the network layer. The network layer encapsulates the transport-layer segment into an IP datagram and then makes a best-effort attempt to deliver the segment to the receiving host. If the segment arrives at the receiving host, UDP uses the destination port number to deliver the segment’s data to the correct application process. Note that with UDP there is no handshaking between sending and receiving transport-layer entities before sending a segment. For this reason, UDP is said to be </span><span class="font53" style="font-style:italic;">connectionless.</span></p>
<p><span class="font53">DNS is an example of an application-layer protocol that typically uses UDP. When the DNS application in a host wants to make a query, it constructs a DNS query message and passes the message to UDP. Without performing any handshaking with the UDP entity running on the destination end system, the host-side UDP adds header fields to the message and passes the resulting segment to the network layer. The network layer encapsulates the UDP segment into a datagram and sends the datagram to a name server. The DNS application at the querying host then waits for a reply to its query. If it doesn’t receive a reply (possibly because the underlying network lost the query or the reply), it might try resending the query, try sending the query to another name server, or inform the invoking application that it can’t get a reply.</span></p>
<p><span class="font53">Now you might be wondering why an application developer would ever choose to build an application over UDP rather than over TCP. Isn’t TCP always preferable, since TCP provides a reliable data transfer service, while UDP does not? The answer is no, as some applications are better suited for UDP for the following reasons:</span></p>
<p><span class="font53">• </span><span class="font53" style="font-style:italic;">Finer application-level control over what data is sent, and when.</span><span class="font53"> Under UDP, as soon as an application process passes data to UDP, UDP will package the data inside a UDP segment and immediately pass the segment to the network layer. TCP, on the other hand, has a congestion-control mechanism that throttles the transport-layer TCP sender when one or more links between the source and destination hosts become excessively congested. TCP will also continue to resend a segment until the receipt of the segment has been acknowledged by the destination, regardless of how long reliable delivery takes. Since real-time applications often require a minimum sending rate, do not want to overly delay segment transmission, and can tolerate some data loss, TCP’s service model is not particularly well matched to these applications’ needs. As discussed below, these applications can use UDP and implement, as part of the application, any additional functionality that is needed beyond UDP’s no-frills segment-delivery service.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">No connection establishment.</span><span class="font53"> As we’ll discuss later, TCP uses a three-way handshake before it starts to transfer data. UDP just blasts away without any formal preliminaries. Thus UDP does not introduce any delay to establish a connection. This is probably the principal reason why DNS runs over UDP rather than TCP— DNS would be much slower if it ran over TCP. HTTP uses TCP rather than UDP, since reliability is critical for Web pages with text. But, as we briefly discussed in Section 2.2, the TCP connection-establishment delay in HTTP is an important contributor to the delays associated with downloading Web documents. Indeed, the QUIC protocol (Quick UDP Internet Connection, [IETF QUIC 2020]), used in Google’s Chrome browser, uses UDP as its underlying transport protocol and implements reliability in an application-layer protocol on top of UDP. We’ll take a closer look at QUIC in Section 3.8.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">No connection state.</span><span class="font53"> TCP maintains connection state in the end systems. This connection state includes receive and send buffers, congestion-control parameters, and sequence and acknowledgment number parameters. We will see in Section 3.5 that this state information is needed to implement TCP’s reliable data transfer service and to provide congestion control. UDP, on the other hand, does not maintain connection state and does not track any of these parameters. For this reason, a server devoted to a particular application can typically support many more active clients when the application runs over UDP rather than TCP.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Small packet header overhead.</span><span class="font53"> The TCP segment has 20 bytes of header overhead in every segment, whereas UDP has only 8 bytes of overhead.</span></p></li></ul>
<p><span class="font53">Figure 3.6 lists popular Internet applications and the transport protocols that they use. As we expect, e-mail, remote terminal access, and file transfer run over TCP—all these applications need the reliable data transfer service of TCP. We learned in Chapter 2 that early versions of HTTP ran over TCP but that more recent versions of HTTP run over UDP, providing their own error control and congestion control (among other services) at the application layer. Nevertheless, many important applications run over UDP rather than TCP. For example, UDP is used to carry network management (SNMP; see Section 5.7) data. UDP is preferred to TCP in this case, since network management applications must often run when the network is in a stressed state—precisely when reliable, congestion-controlled data transfer is difficult to achieve. Also, as we mentioned earlier, DNS runs over UDP, thereby avoiding TCP’s connection-establishment delays.</span></p>
<p><span class="font53">As shown in Figure 3.6, both UDP and TCP are sometimes used today with multimedia applications, such as Internet phone, real-time video conferencing, and streaming of stored audio and video. We just mention now that all of these applications can tolerate a small amount of packet loss, so that reliable data transfer is not absolutely critical for the application’s success. Furthermore, real-time applications, like Internet phone and video conferencing, react very poorly to TCP’s congestion control. For these reasons, developers of multimedia applications may choose to run their applications over UDP instead of TCP. When packet loss rates are low, and</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Application</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Application-Layer Protocol</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Underlying Transport Protocol</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font6">Electronic mail</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">SMTP</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">TCP</span></p></td></tr>
<tr><td>
<p><span class="font6">Remote terminal access</span></p></td><td>
<p><span class="font6">Telnet</span></p></td><td>
<p><span class="font6">TCP</span></p></td></tr>
<tr><td>
<p><span class="font6">Secure remote terminal access</span></p></td><td>
<p><span class="font6">SSH</span></p></td><td>
<p><span class="font6">TCP</span></p></td></tr>
<tr><td>
<p><span class="font6">Web</span></p></td><td>
<p><span class="font6">HTTP, HTTP/3</span></p></td><td>
<p><span class="font6">TCP (for HTTP), UDP (for HTTP/3)</span></p></td></tr>
<tr><td>
<p><span class="font6">File transfer</span></p></td><td>
<p><span class="font6">FTP</span></p></td><td>
<p><span class="font6">TCP</span></p></td></tr>
<tr><td>
<p><span class="font6">Remote file server</span></p></td><td>
<p><span class="font6">NFS</span></p></td><td>
<p><span class="font6">Typically UDP</span></p></td></tr>
<tr><td>
<p><span class="font6">Streaming multimedia</span></p></td><td>
<p><span class="font6">DASH</span></p></td><td>
<p><span class="font6">TCP</span></p></td></tr>
<tr><td>
<p><span class="font6">Internet telephony</span></p></td><td>
<p><span class="font6">typically proprietary</span></p></td><td>
<p><span class="font6">UDP or TCP</span></p></td></tr>
<tr><td>
<p><span class="font6">Network management</span></p></td><td>
<p><span class="font6">SNMP</span></p></td><td>
<p><span class="font6">Typically UDP</span></p></td></tr>
<tr><td>
<p><span class="font6">Name translation</span></p></td><td>
<p><span class="font6">DNS</span></p></td><td>
<p><span class="font6">Typically UDP</span></p></td></tr>
</table>
<p><span class="font7" style="font-weight:bold;">Figure 3.6 </span><span class="font50">♦ </span><span class="font5">Popular Internet applications and their underlying transport protocols</span></p>
<p><span class="font53">with some organizations blocking UDP traffic for security reasons (see Chapter 8), TCP becomes an increasingly attractive protocol for streaming media transport.</span></p>
<p><span class="font53">Although commonly done today, running multimedia applications over UDP needs to be done with care. As we mentioned above, UDP has no congestion control. But congestion control is needed to prevent the network from entering a congested state in which very little useful work is done. If everyone were to start streaming high-bit-rate video without using any congestion control, there would be so much packet overflow at routers that very few UDP packets would successfully traverse the source-to-destination path. Moreover, the high loss rates induced by the uncontrolled UDP senders would cause the TCP senders (which, as we’ll see, </span><span class="font53" style="font-style:italic;">do</span><span class="font53"> decrease their sending rates in the face of congestion) to dramatically decrease their rates. Thus, the lack of congestion control in UDP can result in high loss rates between a UDP sender and receiver, and the crowding out of TCP sessions. Many researchers have proposed new mechanisms to force all sources, including UDP sources, to perform adaptive congestion control [Mahdavi 1997; Floyd 2000; Kohler 2006: RFC 4340].</span></p>
<p><span class="font53">Before discussing the UDP segment structure, we mention that it </span><span class="font53" style="font-style:italic;">is</span><span class="font53"> possible for an application to have reliable data transfer when using UDP. This can be done if reliability is built into the application itself (for example, by adding acknowledgment and retransmission mechanisms, such as those we’ll study in the next section). We mentioned earlier that the QUIC protocol implements reliability in an application-layer protocol on top of UDP. But this is a nontrivial task that would keep an application developer busy debugging for a long time. Nevertheless, building reliability directly into the application allows the application to “have its cake and eat it too.” That is, application processes can communicate reliably without being subjected to the transmission-rate constraints imposed by TCP’s congestion-control mechanism.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">3.3.1 </span><span class="font23" style="font-weight:bold;">UDP Segment Structure</span></p></li></ul>
<p><span class="font53">The UDP segment structure, shown in Figure 3.7, is defined in RFC 768. The application data occupies the data field of the UDP segment. For example, for DNS, the data field contains either a query message or a response message. For a streaming audio application, audio samples fill the data field. The UDP header has only four fields, each consisting of two bytes. As discussed in the previous section, the port numbers allow the destination host to pass the application data to the correct process running on the destination end system (that is, to perform the demultiplexing function). The length field specifies the number of bytes in the UDP segment (header plus data). An explicit length value is needed since the size of the data field may differ from one UDP segment to the next. The checksum is used by the receiving host to check whether errors have been introduced into the segment. In truth, the checksum is also calculated over a few of the fields in the IP header in addition to the UDP segment. But we ignore this detail in order to see the forest through the trees. We’ll discuss the checksum calculation below. Basic principles of error detection are described in Section 6.2. The length field specifies the length of the UDP segment, including the header, in bytes.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">3.3.2 </span><span class="font23" style="font-weight:bold;">UDP Checksum</span></p></li></ul>
<p><span class="font53">The UDP checksum provides for error detection. That is, the checksum is used to determine whether bits within the UDP segment have been altered (for example, by noise in the links or while stored in a router) as it moved from source to destination.</span></p>
<p><span class="font4">32 bits</span></p>
<p><span class="font4">Source port # Dest. port #</span></p>
<p><span class="font4">Length &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Checksum</span></p>
<p><span class="font4">Application data (message)</span></p>
<p><a name="bookmark301"></a><span class="font7" style="font-weight:bold;">Figure 3.7 </span><span class="font50">♦ </span><span class="font5">UDP segment structure</span></p>
<p><span class="font53">UDP at the sender side performs the 1s complement of the sum of all the 16-bit words in the segment, with any overflow encountered during the sum being wrapped around. This result is put in the checksum field of the UDP segment. Here we give a simple example of the checksum calculation. You can find details about efficient implementation of the calculation in RFC 1071 and performance over real data in [Stone 1998; Stone 2000]. As an example, suppose that we have the following three 16-bit words:</span></p>
<p><span class="font53">0110011001100000</span></p>
<p><span class="font53">0101010101010101</span></p>
<p><span class="font53">1000111100001100</span></p>
<p><span class="font53">The sum of first two of these 16-bit words is</span></p>
<p><span class="font53">0110011001100000</span></p>
<p><span class="font53" style="text-decoration:underline;">0101010101010101</span></p>
<p><span class="font53">1011101110110101</span></p>
<p><span class="font53">Adding the third word to the above sum gives</span></p>
<p><span class="font53">1011101110110101</span></p>
<p><span class="font53" style="text-decoration:underline;">1000111100001100</span></p>
<p><span class="font53">0100101011000010</span></p>
<p><span class="font53">Note that this last addition had overflow, which was wrapped around. The 1s complement is obtained by converting all the 0s to 1s and converting all the 1s to 0s. Thus, the 1s complement of the sum 0100101011000010 is 1011010100111101, which becomes the checksum. At the receiver, all four 16-bit words are added, including the checksum. If no errors are introduced into the packet, then clearly the sum at the receiver will be 1111111111111111. If one of the bits is a 0, then we know that errors have been introduced into the packet.</span></p>
<p><span class="font53">You may wonder why UDP provides a checksum in the first place, as many link-layer protocols (including the popular Ethernet protocol) also provide error checking. The reason is that there is no guarantee that all the links between source and destination provide error checking; that is, one of the links may use a link-layer protocol that does not provide error checking. Furthermore, even if segments are correctly transferred across a link, it’s possible that bit errors could be introduced when a segment is stored in a router’s memory. Given that neither link-by-link reliability nor in-memory error detection is guaranteed, UDP must provide error detection at the transport layer, </span><span class="font53" style="font-style:italic;">on an end-end basis,</span><span class="font53"> if the end-end data transfer service is to provide error detection. This is an example of the celebrated </span><span class="font53" style="font-weight:bold;">end-end principle </span><span class="font53">in system design [Saltzer 1984], which states that since certain functionality (error detection, in this case) must be implemented on an end-end basis: “functions placed at the lower levels may be redundant or of little value when compared to the cost of providing them at the higher level.”</span></p>
<p><span class="font53">Because IP is supposed to run over just about any layer-2 protocol, it is useful for the transport layer to provide error checking as a safety measure. Although UDP provides error checking, it does not do anything to recover from an error. Some implementations of UDP simply discard the damaged segment; others pass the damaged segment to the application with a warning.</span></p>
<p><span class="font53">That wraps up our discussion of UDP. We will soon see that TCP offers reliable data transfer to its applications as well as other services that UDP doesn’t offer. Naturally, TCP is also more complex than UDP. Before discussing TCP, however, it will be useful to step back and first discuss the underlying principles of reliable data transfer.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">3.4 </span><span class="font24" style="font-weight:bold;">Principles of Reliable Data Transfer</span></p></li></ul>
<p><span class="font53">In this section, we consider the problem of reliable data transfer in a general context. This is appropriate since the problem of implementing reliable data transfer occurs not only at the transport layer, but also at the link layer and the application layer as well. The general problem is thus of central importance to networking. Indeed, if one had to identify a “top-ten” list of fundamentally important problems in all of networking, this would be a candidate to lead the list. In the next section, we’ll examine TCP and show, in particular, that TCP exploits many of the principles that we are about to describe.</span></p>
<p><span class="font53">Figure 3.8 illustrates the framework for our study of reliable data transfer. The service abstraction provided to the upper-layer entities is that of a reliable channel through which data can be transferred. With a reliable channel, no transferred data bits are corrupted (flipped from 0 to 1, or vice versa) or lost, and all are delivered in the order in which they were sent. This is precisely the service model offered by TCP to the Internet applications that invoke it.</span></p>
<p><span class="font53">It is the responsibility of a </span><span class="font53" style="font-weight:bold;">reliable data transfer protocol </span><span class="font53">to implement this service abstraction. This task is made difficult by the fact that the layer </span><span class="font53" style="font-style:italic;">below</span><span class="font53"> the reliable data transfer protocol may be unreliable. For example, TCP is a reliable data transfer protocol that is implemented on top of an unreliable (IP) end-to-end network layer. More generally, the layer beneath the two reliably communicating end points might consist of a single physical link (as in the case of a link-level data transfer protocol) or a global internetwork (as in the case of a transport-level protocol). For our purposes, however, we can view this lower layer simply as an unreliable point-to-point channel.</span></p>
<p><a name="bookmark302"></a><span class="font53">In this section, we will incrementally develop the sender and receiver sides of a reliable data transfer protocol, considering increasingly complex models of the underlying channel. For example, we’ll consider what protocol mechanisms are</span></p>
<div>
<p><span class="font4">Network layer</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Key:</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-150.jpg" alt="" style="width:24pt;height:26pt;">
</div><br clear="all">
<div><img src="networking_files/networking-151.jpg" alt="" style="width:24pt;height:26pt;">
</div><br clear="all">
<div><img src="networking_files/networking-152.jpg" alt="" style="width:24pt;height:26pt;">
</div><br clear="all">
<div><img src="networking_files/networking-153.jpg" alt="" style="width:24pt;height:26pt;">
</div><br clear="all">
<div>
<p><span class="font4">Application layer</span></p>
<p><span class="font4">Transport layer</span></p><img src="networking_files/networking-154.jpg" alt="" style="width:370pt;height:179pt;">
<p><span class="font42">Unreliable channel</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-155.jpg" alt="" style="width:148pt;height:16pt;">
<p><span class="font4" style="font-weight:bold;">a. Provided service</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">b. Service implementation</span></p>
</div><br clear="all">
<div>
<p><span class="font41">Data</span></p>
</div><br clear="all">
<p><span class="font41">Packet</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 3.8 </span><span class="font50">♦ </span><span class="font5">Reliable data transfer: Service model and service implementation</span></p>
<p><span class="font53">needed when the underlying channel can corrupt bits or lose entire packets. One assumption we’ll adopt throughout our discussion here is that packets will be delivered in the order in which they were sent, with some packets possibly being lost; that is, the underlying channel will not reorder packets. Figure 3.8(b) illustrates the interfaces for our data transfer protocol. The sending side of the data transfer protocol will be invoked from above by a call to </span><span class="font36">rdt_send()</span><span class="font53">. It will pass the data to be delivered to the upper layer at the receiving side. (Here </span><span class="font36">rdt </span><span class="font53">stands for </span><span class="font53" style="font-style:italic;">reliable data transfer</span><span class="font53"> protocol and </span><span class="font36">_send </span><span class="font53">indicates that the sending side of </span><span class="font36">rdt </span><span class="font53">is being called. The first step in developing any protocol is to choose a good name!) On the receiving side, </span><span class="font36">rdt_rcv() </span><span class="font53">will be called when a packet arrives from the receiving side of the channel. When the </span><span class="font36">rdt </span><span class="font53">protocol wants to deliver data to the upper layer, it will do so by calling </span><span class="font36">deliver_data()</span><span class="font53">. In the following, we use the terminology “packet” rather than transport-layer “segment.” Because the theory developed in this section applies to computer networks in general and not just to the Internet transport layer, the generic term “packet” is perhaps more appropriate here.</span></p>
<p><span class="font53">In this section, we consider only the case of </span><span class="font53" style="font-weight:bold;">unidirectional data transfer</span><span class="font53">, that is, data transfer from the sending to the receiving side. The case of reliable </span><span class="font53" style="font-weight:bold;">bidirectional </span><span class="font53">(that is, full-duplex) </span><span class="font53" style="font-weight:bold;">data transfer </span><span class="font53">is conceptually no more difficult but considerably more tedious to explain. Although we consider only unidirectional data transfer, it is important to note that the sending and receiving sides of our protocol will nonetheless need to transmit packets in </span><span class="font53" style="font-style:italic;">both</span><span class="font53"> directions, as indicated in Figure 3.8. We will see shortly that, in addition to exchanging packets containing the data to be transferred, the sending and receiving sides of </span><span class="font36">rdt </span><span class="font53">will also need to exchange control packets back and forth. Both the send and receive sides of </span><span class="font36">rdt </span><span class="font53">send packets to the other side by a call to </span><span class="font36">udt_send() </span><span class="font53">(where udt stands for </span><span class="font53" style="font-style:italic;">unreliable data transfer).</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">3.4.1 </span><span class="font23" style="font-weight:bold;">Building a Reliable Data Transfer Protocol</span></p></li></ul>
<p><span class="font53">We now step through a series of protocols, each one becoming more complex, arriving at a flawless, reliable data transfer protocol.</span></p>
<p><span class="font22" style="font-weight:bold;">Reliable Data Transfer over a Perfectly Reliable Channel: </span><span class="font37" style="font-weight:bold;">rdt1.0</span></p>
<p><span class="font53">We first consider the simplest case, in which the underlying channel is completely reliable. The protocol itself, which we’ll call </span><span class="font36">rdt1.0</span><span class="font53">, is trivial. The </span><span class="font53" style="font-weight:bold;">finite-state machine (FSM) </span><span class="font53">definitions for the </span><span class="font36">rdt1.0 </span><span class="font53">sender and receiver are shown in Figure 3.9. The FSM in Figure 3.9(a) defines the operation of the sender, while the FSM in Figure 3.9(b) defines the operation of the receiver. It is important to note that there are </span><span class="font53" style="font-style:italic;">separate</span><span class="font53"> FSMs for the sender and for the receiver. The sender and receiver FSMs in Figure 3.9 each have just one state. The arrows in the FSM description indicate the transition of the protocol from one state to another. (Since each FSM in Figure 3.9 has just one state, a transition is necessarily from the one state back to itself; we’ll see more complicated state diagrams shortly.) The event causing the transition is shown above the horizontal line labeling the transition, and the actions taken when the event occurs are shown below the horizontal line. When no action is taken on an event, or no event occurs and an action is taken, we’ll use the symbol </span><span class="font54">A </span><span class="font53">below or above the horizontal, respectively, to explicitly denote the lack of an action or event. The initial state of the FSM is indicated by the dashed arrow. Although the FSMs in Figure 3.9 have but one state, the FSMs we will see shortly have multiple states, so it will be important to identify the initial state of each FSM.</span></p>
<p><a name="bookmark303"></a><span class="font53">The sending side of </span><span class="font36">rdt </span><span class="font53">simply accepts data from the upper layer via the </span><span class="font36">rdt_send(data) </span><span class="font53">event, creates a packet containing the data (via the action </span><span class="font36">make_pkt(data)</span><span class="font53">) and sends the packet into the channel. In practice, the </span><span class="font36">rdt_send(data) </span><span class="font53">event would result from a procedure call (for example, to </span><span class="font36">rdt_send()</span><span class="font53">) by the upper-layer application.</span></p><img src="networking_files/networking-156.jpg" alt="" style="width:105pt;height:62pt;">
<p><span class="font33">rdt_send(data)</span></p>
<p><span class="font33">packet=make_pkt(data)</span></p>
<p><span class="font33">udt_send(packet)</span></p>
<p><span class="font4" style="font-weight:bold;">a. rdt1.0: sending side</span></p><img src="networking_files/networking-157.jpg" alt="" style="width:84pt;height:52pt;">
<p><span class="font33">rdt_rcv(packet)</span></p>
<p><span class="font33">extract(packet,data) deliver_data(data)</span></p>
<p><span class="font4" style="font-weight:bold;">b. rdt1.0: receiving side</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 3.9 </span><span class="font50">♦ </span><span class="font36">rdt1.0—</span><span class="font5">A protocol for a completely reliable channel</span></p>
<p><span class="font53">On the receiving side, rdt receives a packet from the underlying channel via the </span><span class="font36">rdt_rcv(packet) </span><span class="font53">event, removes the data from the packet (via the action </span><span class="font36">extract (packet, data)</span><span class="font53">) and passes the data up to the upper layer (via the action </span><span class="font36">deliver_data(data)</span><span class="font53">). In practice, the </span><span class="font36">rdt_rcv(packet) </span><span class="font53">event would result from a procedure call (for example, to </span><span class="font36">rdt_rcv()</span><span class="font53">) from the lower-layer protocol.</span></p>
<p><span class="font53">In this simple protocol, there is no difference between a unit of data and a packet. Also, all packet flow is from the sender to receiver; with a perfectly reliable channel there is no need for the receiver side to provide any feedback to the sender since nothing can go wrong! Note that we have also assumed that the receiver is able to receive data as fast as the sender happens to send data. Thus, there is no need for the receiver to ask the sender to slow down!</span></p>
<p><span class="font22" style="font-weight:bold;">Reliable Data Transfer over a Channel with Bit Errors: </span><span class="font37" style="font-weight:bold;">rdt2.0</span></p>
<p><span class="font53">A more realistic model of the underlying channel is one in which bits in a packet may be corrupted. Such bit errors typically occur in the physical components of a network as a packet is transmitted, propagates, or is buffered. We’ll continue to assume for the moment that all transmitted packets are received (although their bits may be corrupted) in the order in which they were sent.</span></p>
<p><span class="font53">Before developing a protocol for reliably communicating over such a channel, first consider how people might deal with such a situation. Consider how you yourself might dictate a long message over the phone. In a typical scenario, the message taker might say “OK” after each sentence has been heard, understood, and recorded. If the message taker hears a garbled sentence, you’re asked to repeat the garbled sentence. This message-dictation protocol uses both </span><span class="font53" style="font-weight:bold;">positive acknowledgments </span><span class="font53">(“OK”) and </span><span class="font53" style="font-weight:bold;">negative acknowledgments </span><span class="font53">(“Please repeat that.”). These control messages allow the receiver to let the sender know what has been received correctly, and what has been received in error and thus requires repeating. In a computer network setting, reliable data transfer protocols based on such retransmission are known as </span><span class="font53" style="font-weight:bold;">ARQ (Automatic Repeat reQuest) protocols</span><span class="font53">.</span></p>
<p><span class="font53">Fundamentally, three additional protocol capabilities are required in ARQ protocols to handle the presence of bit errors:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Error detection.</span><span class="font53"> First, a mechanism is needed to allow the receiver to detect when bit errors have occurred. Recall from the previous section that UDP uses the Internet checksum field for exactly this purpose. In Chapter 6, we’ll examine errordetection and -correction techniques in greater detail; these techniques allow the receiver to detect and possibly correct packet bit errors. For now, we need only know that these techniques require that extra bits (beyond the bits of original data to be transferred) be sent from the sender to the receiver; these bits will be gathered into the packet checksum field of the </span><span class="font36">rdt2.0 </span><span class="font53">data packet.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Receiver feedback.</span><span class="font53"> Since the sender and receiver are typically executing on different end systems, possibly separated by thousands of miles, the only way for the sender to learn of the receiver’s view of the world (in this case, whether or not a packet was received correctly) is for the receiver to provide explicit feedback to the sender. The positive (ACK) and negative (NAK) acknowledgment replies in the message-dictation scenario are examples of such feedback. Our </span><span class="font36">rdt2.0 </span><span class="font53">protocol will similarly send ACK and NAK packets back from the receiver to the sender. In principle, these packets need only be one bit long; for example, a 0 value could indicate a NAK and a value of 1 could indicate an ACK.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Retransmission.</span><span class="font53"> A packet that is received in error at the receiver will be retransmitted by the sender.</span></p></li></ul>
<p><span class="font53">Figure 3.10 shows the FSM representation of </span><span class="font36">rdt2.0</span><span class="font53">, a data transfer protocol employing error detection, positive acknowledgments, and negative acknowledgments.</span></p>
<p><span class="font53">The send side of </span><span class="font36">rdt2.0 </span><span class="font53">has two states. In the leftmost state, the send-side protocol is waiting for data to be passed down from the upper layer. When the </span><span class="font36">rdt_send(data) </span><span class="font53">event occurs, the sender will create a packet (</span><span class="font36">sndpkt</span><span class="font53">) containing the data to be sent, along with a packet checksum (for example, as discussed in Section 3.3.2 for the case of a UDP segment), and then send the packet via the </span><span class="font36">udt_send(sndpkt) </span><span class="font53">operation. In the rightmost state, the sender protocol is waiting for an ACK or a NAK packet from the receiver. If an ACK packet is received</span></p>
<p><span class="font33">rdt_send(data) sndpkt=make_pkt(data,checksum)</span></p>
<p><span class="font33">udt_send(sndpkt)</span></p>
<div><img src="networking_files/networking-158.jpg" alt="" style="width:35pt;height:17pt;">
</div><br clear="all">
<div><img src="networking_files/networking-159.jpg" alt="" style="width:95pt;height:62pt;">
<p><span class="font33">rdt_rcv(rcvpkt) &amp;&amp;isNAK(rcvpkt)</span></p>
<p><span class="font33">udt_send(sndpkt)</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Wait for call from above</span></p><img src="networking_files/networking-160.jpg" alt="" style="width:128pt;height:21pt;">
<p><span class="font33">rdt_rcv(rcvpkt) &amp;&amp;isACK(rcvpkt)</span></p>
</div><br clear="all">
<p><span class="font4" style="font-weight:bold;">a. rdt2.0: sending side</span></p>
<p><span class="font33">rdt_rcv(rcvpkt) &amp;&amp;&nbsp;corrupt(rcvpkt)</span></p>
<div><img src="networking_files/networking-161.jpg" alt="" style="width:76pt;height:29pt;">
<p><span class="font33">sndpkt=make_pkt(NAK)</span></p>
<p><span class="font33">udt_send(sndpkt)</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Wait for call from below</span></p><img src="networking_files/networking-162.jpg" alt="" style="width:42pt;height:26pt;">
</div><br clear="all">
<p><span class="font33" style="text-decoration:underline;">rdt_rcv(rcvpkt) &amp;&amp;&nbsp;notcorrupt(rcvpkt)</span></p>
<p><span class="font33">extract(rcvpkt,data)</span></p>
<p><span class="font33">deliver_data(data)</span></p>
<p><span class="font33">sndpkt=make_pkt(ACK)</span></p>
<p><span class="font33">udt_send(sndpkt)</span></p>
<ul style="list-style:none;"><li>
<p><span class="font4" style="font-weight:bold;">b. rdt2.0: receiving side</span></p></li></ul>
<p><span class="font7" style="font-weight:bold;">Figure 3.10 </span><span class="font50">♦ </span><span class="font36">rdt2.0—</span><span class="font5">A protocol for a channel with bit errors</span></p>
<p><span class="font53">(the notation </span><span class="font36">rdt_rcv (rcvpkt) &amp;&amp;&nbsp;isACK (rcvpkt) </span><span class="font53">in Figure 3.10 corresponds to this event), the sender knows that the most recently transmitted packet has been received correctly and thus the protocol returns to the state of waiting for data from the upper layer. If a NAK is received, the protocol retransmits the last packet and waits for an ACK or NAK to be returned by the receiver in response to the retransmitted data packet. It is important to note that when the sender is in the wait-for-ACK-or-NAK state, it </span><span class="font53" style="font-style:italic;">cannot</span><span class="font53"> get more data from the upper layer; that is, the </span><span class="font36">rdt_send() </span><span class="font53">event can not occur; that will happen only after the sender receives an ACK and leaves this state. Thus, the sender will not send a new piece of data until it is sure that the receiver has correctly received the current packet. Because of this behavior, protocols such as </span><span class="font36">rdt2.0 </span><span class="font53">are known as </span><span class="font53" style="font-weight:bold;">stop-and-wait </span><span class="font53">protocols.</span></p>
<p><span class="font53">The receiver-side FSM for </span><span class="font36">rdt2.0 </span><span class="font53">still has a single state. On packet arrival, the receiver replies with either an ACK or a NAK, depending on whether or not the received packet is corrupted. In Figure 3.10, the notation </span><span class="font36">rdt_rcv(rcvpkt) &amp;&amp;&nbsp;corrupt(rcvpkt) </span><span class="font53">corresponds to the event in which a packet is received and is found to be in error.</span></p>
<p><span class="font53">Protocol </span><span class="font36">rdt2.0 </span><span class="font53">may look as if it works but, unfortunately, it has a fatal flaw. In particular, we haven’t accounted for the possibility that the ACK or NAK packet could be corrupted! (Before proceeding on, you should think about how this problem may be fixed.) Unfortunately, our slight oversight is not as innocuous as it may seem. Minimally, we will need to add checksum bits to ACK/NAK packets in order to detect such errors. The more difficult question is how the protocol should recover from errors in ACK or NAK packets. The difficulty here is that if an ACK or NAK is corrupted, the sender has no way of knowing whether or not the receiver has correctly received the last piece of transmitted data.</span></p>
<p><span class="font53">Consider three possibilities for handling corrupted ACKs or NAKs:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;For the first possibility, consider what a human might do in the message-dictation scenario. If the speaker didn’t understand the “OK” or “Please repeat that” reply from the receiver, the speaker would probably ask, “What did you say?” (thus introducing a new type of sender-to-receiver packet to our protocol). The receiver would then repeat the reply. But what if the speaker’s “What did you say?” is corrupted? The receiver, having no idea whether the garbled sentence was part of the dictation or a request to repeat the last reply, would probably then respond with “What did </span><span class="font53" style="font-style:italic;">you</span><span class="font53"> say?” And then, of course, that response might be garbled. Clearly, we’re heading down a difficult path.</span></p></li>
<li>
<p><span class="font53">• &nbsp;A second alternative is to add enough checksum bits to allow the sender not only to detect, but also to recover from, bit errors. This solves the immediate problem for a channel that can corrupt packets but not lose them.</span></p></li>
<li>
<p><span class="font53">• &nbsp;A third approach is for the sender simply to resend the current data packet when it receives a garbled ACK or NAK packet. This approach, however, introduces </span><span class="font53" style="font-weight:bold;">duplicate packets </span><span class="font53">into the sender-to-receiver channel. The fundamental difficulty with duplicate packets is that the receiver doesn’t know whether the ACK or NAK </span><span class="font53" style="font-style:italic;">it</span><span class="font53"> last sent was received correctly at the sender. Thus, it cannot know </span><span class="font53" style="font-style:italic;">a priori</span><span class="font53"> whether an arriving packet contains new data or is a retransmission!</span></p></li></ul>
<p><span class="font53">A simple solution to this new problem (and one adopted in almost all existing data transfer protocols, including TCP) is to add a new field to the data packet and have the sender number its data packets by putting a </span><span class="font53" style="font-weight:bold;">sequence number </span><span class="font53">into this field. The receiver then need only check this sequence number to determine whether or not the received packet is a retransmission. For this simple case of a stop-and-wait protocol, a 1-bit sequence number will suffice, since it will allow the receiver to know whether the sender is resending the previously transmitted packet (the sequence number of the received packet has the same sequence number as the most recently received packet) or a new packet (the sequence number changes, moving “forward” in modulo-2 arithmetic). Since we are currently assuming a channel that does not lose packets, ACK and NAK packets do not themselves need to indicate the sequence number of the packet they are acknowledging. The sender knows that a received ACK or NAK packet (whether garbled or not) was generated in response to its most recently transmitted data packet.</span></p>
<p><span class="font53">Figures 3.11 and 3.12 show the FSM description for </span><span class="font36">rdt2.1</span><span class="font53">, our fixed version of </span><span class="font36">rdt2.0</span><span class="font53">. The </span><span class="font36">rdt2.1 </span><span class="font53">sender and receiver FSMs each now have twice as many states as before. This is because the protocol state must now reflect whether the packet currently being sent (by the sender) or expected (at the receiver) should have a sequence number of 0 or 1. Note that the actions in those states where a 0-numbered packet is being sent or expected are mirror images of those where a 1-numbered packet is being sent or expected; the only differences have to do with the handling of the sequence number.</span></p>
<p><span class="font53">Protocol </span><span class="font36">rdt2.1 </span><span class="font53">uses both positive and negative acknowledgments from the receiver to the sender. When an out-of-order packet is received, the receiver sends a positive acknowledgment for the packet it has received. When a corrupted packet</span></p>
<div>
<p><span class="font33">rdt_send(data)</span></p>
<p><span class="font33">sndpkt=make_pkt(0,data,checksum)</span></p>
<p><span class="font33">udt_send(sndpkt)</span></p><img src="networking_files/networking-163.jpg" alt="" style="width:160pt;height:33pt;">
<p><span class="font4">Wait for call 0 from above</span></p>
</div><br clear="all">
<div>
<p><span class="font33">rdt_rcv(rcvpkt)&amp;&amp;</span></p>
<p><span class="font33">(corrupt(rcvpkt)||</span></p>
<p><span class="font33">isNAK(rcvpkt))</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Wait for</span></p>
<p><span class="font4">ACK or</span></p>
<p><span class="font4">NAK 0</span></p>
</div><br clear="all">
<div>
<p><span class="font33">udt_send(sndpkt)</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-164.jpg" alt="" style="width:28pt;height:63pt;">
</div><br clear="all">
<div>
<p><span class="font33">rdt_rcv(rcvpkt)</span></p>
<p><span class="font33" style="font-style:italic;">&amp;&amp;</span><span class="font33"> notcorrupt(rcvpkt)</span></p>
<p><span class="font33">&amp;&amp; isACK(rcvpkt)</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-165.jpg" alt="" style="width:28pt;height:64pt;">
<p><span class="font33">rdt_rcv(rcvpkt)</span></p>
<p><span class="font33" style="font-style:italic;">&amp;&amp;</span><span class="font33">notcorrupt(rcvpkt)</span></p>
<p><span class="font33">&amp;&amp; isACK(rcvpkt)</span></p>
</div><br clear="all">
<div>
<p><span class="font51">L</span></p><img src="networking_files/networking-166.jpg" alt="" style="width:251pt;height:72pt;">
<p><span class="font33">sndpkt=make_pkt(1,data,checksum)</span></p>
<p><span class="font33">udt_send(sndpkt)</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 3.11 </span><span class="font50">♦ </span><span class="font36">rdt2.1 </span><span class="font5">sender</span></p>
</div><br clear="all">
<p><span class="font33">rdt_rcv(rcvpkt)&amp;&amp; notcorrupt(rcvpkt)</span></p>
<p><span class="font33" style="font-style:italic;">&amp;&amp;</span><span class="font33"> has_seq0(rcvpkt)</span></p>
<div>
<p><span class="font33">rdt_rcv(rcvpkt)</span></p>
<p><span class="font33" style="font-style:italic;">&amp;&amp;</span><span class="font33"> corrupt(rcvpkt)</span></p>
</div><br clear="all">
<div>
<p><span class="font33">sndpkt=make_pkt(NAK,checksum)</span></p>
<p><span class="font33">udt_send(sndpkt)</span></p>
</div><br clear="all">
<div>
<p><span class="font33">sndpkt=make_pkt(ACK,checksum)</span></p>
<p><span class="font33">udt_send(sndpkt)</span></p>
</div><br clear="all">
<div>
<p><span class="font33">extract(rcvpkt,data)</span></p>
<p><span class="font33">deliver_data(data)</span></p>
<p><span class="font33">sndpkt=make_pkt(ACK,checksum)</span></p>
<p><span class="font33">udt_send(sndpkt)</span></p>
<p><span class="font33">rdt_rcv(rcvpkt)&amp;&amp; notcorrupt</span></p>
<p><span class="font33">(rcvpkt)&amp;&amp; has_seq1(rcvpkt)</span></p><img src="networking_files/networking-167.jpg" alt="" style="width:144pt;height:93pt;">
</div><br clear="all">
<div>
<p><span class="font4">Wait for 0 from below</span></p>
</div><br clear="all">
<div>
<p><span class="font33">rdt_rcv(rcvpkt) &amp;&amp;&nbsp;corrupt(rcvpkt)</span></p>
</div><br clear="all">
<div>
<p><span class="font33">sndpkt=make_pkt(NAK,checksum)</span></p>
<p><span class="font33">udt_send(sndpkt)</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-168.jpg" alt="" style="width:143pt;height:79pt;">
<p><span class="font33">rdt_rcv(rcvpkt)&amp;&amp; notcorrupt</span></p>
<p><span class="font33">(rcvpkt)&amp;&amp; has_seq0(rcvpkt)</span></p>
<p><span class="font33">sndpkt=make_pkt(ACK,checksum)</span></p>
<p><span class="font33">udt_send(sndpkt)</span></p>
<p><span class="font33">rdt_rcv(rcvpkt) &amp;&amp;&nbsp;notcorrupt(rcvpkt)</span></p>
<p><span class="font33" style="font-style:italic;">&amp;&amp;</span><span class="font33"> has_seq1(rcvpkt)</span></p>
<p><span class="font33">extract(rcvpkt,data)</span></p>
<p><span class="font33">deliver_data(data)</span></p>
<p><span class="font33">sndpkt=make_pkt(ACK,checksum)</span></p>
<p><span class="font33">udt_send(sndpkt)</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Wait for</span></p>
<p><span class="font4">1 from below</span></p>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 3.12 </span><span class="font50">♦ </span><span class="font36">rdt2.1 </span><span class="font5">receiver</span></p>
<p><span class="font53">is received, the receiver sends a negative acknowledgment. We can accomplish the same effect as a NAK if, instead of sending a NAK, we send an ACK for the last correctly received packet. A sender that receives two ACKs for the same packet (that is, receives </span><span class="font53" style="font-weight:bold;">duplicate ACKs</span><span class="font53">) knows that the receiver did not correctly receive the packet following the packet that is being ACKed twice. Our NAK-free reliable data transfer protocol for a channel with bit errors is </span><span class="font36">rdt2.2</span><span class="font53">, shown in Figures 3.13 and 3.14. One subtle change between </span><span class="font36">rtdt2.1 </span><span class="font53">and </span><span class="font36">rdt2.2 </span><span class="font53">is that the receiver must now include the sequence number of the packet being acknowledged by an ACK message (this is done by including the </span><span class="font36">ACK</span><span class="font53">, </span><span class="font36">0 </span><span class="font53">or </span><span class="font36">ACK</span><span class="font53">, </span><span class="font36">1 </span><span class="font53">argument in </span><span class="font36">make_pkt() </span><span class="font53">in the receiver FSM), and the sender must now check the sequence number of the packet being acknowledged by a received ACK message (this is done by including the </span><span class="font36">0 </span><span class="font53">or </span><span class="font36">1 </span><span class="font53">argument in </span><span class="font36">isACK() </span><span class="font53">in the sender FSM).</span></p>
<p><span class="font22" style="font-weight:bold;">Reliable Data Transfer over a Lossy Channel with Bit Errors: </span><span class="font37">rdt3.0</span></p>
<p><span class="font53">Suppose now that in addition to corrupting bits, the underlying channel can </span><span class="font53" style="font-style:italic;">lose </span><span class="font53">packets as well, a not-uncommon event in today’s computer networks (including the Internet). Two additional concerns must now be addressed by the protocol: how to detect packet loss and what to do when packet loss occurs. The use of checksumming, sequence numbers, ACK packets, and retransmissions—the techniques</span></p>
<p><span class="font33">rdt_send(data)</span></p>
<p><span class="font33">sndpkt=make_pkt(0,data,checksum)</span></p><img src="networking_files/networking-169.jpg" alt="" style="width:357pt;height:198pt;">
<p><span class="font33">udt_send(sndpkt) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rdt<sup> </sup>sen<sup>d(</sup>data<sup>)</sup></span></p>
<p><span class="font33">sndpkt=make_pkt(1,data,checksum)</span></p>
<p><span class="font33">udt_send(sndpkt)</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 3.13 </span><span class="font50">♦ </span><span class="font36">rdt2.2 </span><span class="font5">sender</span></p>
<p><span class="font53">already developed in </span><span class="font36">rdt2.2—</span><span class="font53">will allow us to answer the latter concern. Handling the first concern will require adding a new protocol mechanism.</span></p>
<p><span class="font53">There are many possible approaches toward dealing with packet loss (several more of which are explored in the exercises at the end of the chapter). Here, we’ll put the burden of detecting and recovering from lost packets on the sender. Suppose that the sender transmits a data packet and either that packet, or the receiver’s ACK of that packet, gets lost. In either case, no reply is forthcoming at the sender from the receiver. If the sender is willing to wait long enough so that it is </span><span class="font53" style="font-style:italic;">certain</span><span class="font53"> that a packet has been lost, it can simply retransmit the data packet. You should convince yourself that this protocol does indeed work.</span></p>
<p><span class="font53">But how long must the sender wait to be certain that something has been lost? The sender must clearly wait at least as long as a round-trip delay between the sender and receiver (which may include buffering at intermediate routers) plus whatever amount of time is needed to process a packet at the receiver. In many networks, this worst-case maximum delay is very difficult even to estimate, much less know with certainty. Moreover, the protocol should ideally recover from packet loss as soon as possible; waiting for a worst-case delay could mean a long wait until error recovery </span><span class="font33">rdt_rcv(rcvpkt) &amp;&amp;&nbsp;notcorrupt(rcvpkt)</span></p>
<p><span class="font33" style="font-style:italic;">&amp;&amp;</span><span class="font33"> has_seq0(rcvpkt)</span></p>
<p><span class="font33">extract(rcvpkt,data)</span></p>
<div>
<p><span class="font33">deliver_data(data)</span></p>
</div><br clear="all">
<div>
<p><span class="font33">sndpkt=make_pkt(ACK,0,checksum)</span></p>
</div><br clear="all">
<div>
<p><span class="font33">udt_send(sndpkt)</span></p><img src="networking_files/networking-170.jpg" alt="" style="width:43pt;height:18pt;">
</div><br clear="all">
<div><img src="networking_files/networking-171.jpg" alt="" style="width:39pt;height:18pt;">
</div><br clear="all">
<div>
<p><span class="font33">rdt_rcv(rcvpkt) &amp;&amp;</span></p>
<p><span class="font33">(corrupt(rcvpkt)||</span></p>
<p><span class="font33">has_seq0(rcvpkt))</span></p>
<p><span class="font33">sndpkt=make_pkt(ACK,0,checksum)</span></p>
<p><span class="font33">udt_send(sndpkt)</span></p>
</div><br clear="all">
<div>
<p><span class="font33">rdt_rcv(rcvpkt) &amp;&amp;</span></p>
<p><span class="font33">(corrupt(rcvpkt)||</span></p>
<p><span class="font33">has_seq1(rcvpkt))</span></p>
</div><br clear="all">
<div>
<p><span class="font68">C</span><span class="font4">Wait for 0 from below</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Wait for</span></p>
<p><span class="font4">1 from below</span></p><img src="networking_files/networking-172.jpg" alt="" style="width:30pt;height:36pt;">
</div><br clear="all">
<p><span class="font33">sndpkt=make_pkt(ACK,1,checksum)</span></p>
<p><span class="font33">udt_send(sndpkt)</span></p>
<div><img src="networking_files/networking-173.jpg" alt="" style="width:38pt;height:18pt;">
</div><br clear="all">
<div><img src="networking_files/networking-174.jpg" alt="" style="width:36pt;height:18pt;">
</div><br clear="all">
<p><span class="font33">rdt_rcv(rcvpkt) &amp;&amp;&nbsp;notcorrupt(rcvpkt)</span></p>
<p><span class="font33" style="font-style:italic;">&amp;&amp;</span><span class="font33"> has_seq1(rcvpkt) extract(rcvpkt,data)</span></p>
<p><span class="font33">deliver_data(data)</span></p>
<p><span class="font33">sndpkt=make_pkt(ACK,1,checksum)</span></p>
<p><span class="font33">udt_send(sndpkt)</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 3.14 </span><span class="font50">♦ </span><span class="font36">rdt2.2 </span><span class="font5">receiver</span></p>
<p><span class="font53">is initiated. The approach thus adopted in practice is for the sender to judiciously choose a time value such that packet loss is likely, although not guaranteed, to have happened. If an ACK is not received within this time, the packet is retransmitted. Note that if a packet experiences a particularly large delay, the sender may retransmit the packet even though neither the data packet nor its ACK have been lost. This introduces the possibility of </span><span class="font53" style="font-weight:bold;">duplicate data packets </span><span class="font53">in the sender-to-receiver channel. Happily, protocol </span><span class="font36">rdt2.2 </span><span class="font53">already has enough functionality (that is, sequence numbers) to handle the case of duplicate packets.</span></p>
<p><span class="font53">From the sender’s viewpoint, retransmission is a panacea. The sender does not know whether a data packet was lost, an ACK was lost, or if the packet or ACK was simply overly delayed. In all cases, the action is the same: retransmit. Implementing a time-based retransmission mechanism requires a </span><span class="font53" style="font-weight:bold;">countdown timer </span><span class="font53">that can interrupt the sender after a given amount of time has expired. The sender will thus need to be able to (1) start the timer each time a packet (either a first-time packet or a retransmission) is sent, (2) respond to a timer interrupt (taking appropriate actions), and (3) stop the timer.</span></p>
<p><span class="font53">Figure 3.15 shows the sender FSM for </span><span class="font36">rdt3.0</span><span class="font53">, a protocol that reliably transfers data over a channel that can corrupt or lose packets; in the homework problems, you’ll be asked to provide the receiver FSM for </span><span class="font36">rdt3.0</span><span class="font53">. Figure 3.16 shows how the protocol operates with no lost or delayed packets and how it handles lost data packets. In Figure 3.16, time moves forward from the top of the diagram toward the bottom of the</span></p>
<div>
<p><span class="font33">rdt_send(data)</span></p>
</div><br clear="all">
<p><span class="font33">rdt_rcv(rcvpkt) &amp;&amp;</span></p>
<p><span class="font33">(corrupt(rcvpkt)||</span></p>
<p><span class="font33">isACK(rcvpkt,1))</span></p>
<div>
<p><span class="font33">sndpkt=make_pkt(0,data,checksum)</span></p>
<p><span class="font33">udt_send(sndpkt)</span></p>
<p><span class="font33">start_timer</span></p>
<p><span class="font33">rdt_rcv(rcvpkt)</span></p><img src="networking_files/networking-175.jpg" alt="" style="width:221pt;height:127pt;">
<p><span class="font51">L</span></p>
<p><span class="font33">timeout</span></p>
<p><span class="font33">stop_timer</span></p>
<p><span class="font33">rdt_rcv(rcvpkt)</span></p>
<p><span class="font33" style="font-style:italic;">&amp;&amp;</span><span class="font33">notcorrupt(rcvpkt)</span></p>
<p><span class="font33">&amp;&amp; isACK(rcvpkt,0)</span></p>
<p><span class="font33">udt_send(sndpkt) start_timer</span></p>
<p><span class="font4">Wait for call 0 from above</span></p>
<p><span class="font4">Wait for</span></p>
<p><span class="font4">ACK 0</span></p>
</div><br clear="all">
<div style="border-top:solid;">
<p><span class="font33">rdt_rcv(rcvpkt)</span></p>
<p><span class="font33" style="font-style:italic;">&amp;&amp;</span><span class="font33"> notcorrupt(rcvpkt)</span></p>
<p><span class="font33">&amp;&amp; isACK(rcvpkt,1)</span></p><img src="networking_files/networking-176.jpg" alt="" style="width:42pt;height:65pt;">
</div><br clear="all">
<div>
<p><span class="font33">stop_timer</span></p><img src="networking_files/networking-177.jpg" alt="" style="width:283pt;height:87pt;">
<p><span class="font33">rdt_rcv(rcvpkt)</span></p>
<p><span class="font33">udt_send(sndpkt) start_timer</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 3.15 </span><span class="font50">♦ </span><span class="font36">rdt3.0 </span><span class="font5">sender</span></p>
</div><br clear="all">
<p><span class="font53">diagram; note that a receive time for a packet is necessarily later than the send time for a packet as a result of transmission and propagation delays. In Figures 3.16(b)-(d), the send-side brackets indicate the times at which a timer is set and later times out. Several of the more subtle aspects of this protocol are explored in the exercises at the end of this chapter. Because packet sequence numbers alternate between 0 and 1, protocol </span><span class="font36">rdt3.0 </span><span class="font53">is sometimes known as the </span><span class="font53" style="font-weight:bold;">alternating-bit protocol</span><span class="font53">.</span></p>
<p><span class="font53">We have now assembled the key elements of a data transfer protocol. Checksums, sequence numbers, timers, and positive and negative acknowledgment packets each play a crucial and necessary role in the operation of the protocol. We now have a working reliable data transfer protocol!</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">3.4.2 </span><span class="font23" style="font-weight:bold;">Pipelined Reliable Data Transfer Protocols</span></p></li></ul>
<p><a name="bookmark304"></a><span class="font53">Protocol </span><span class="font36">rdt3.0 </span><span class="font53">is a functionally correct protocol, but it is unlikely that anyone would be happy with its performance, particularly in today’s high-speed networks. At the heart of </span><span class="font36">rdt3.0</span><span class="font53">’s performance problem is the fact that it is a stop-and-wait protocol.</span></p>
<div>
<p><span class="font4" style="font-weight:bold;">Sender &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Receiver</span></p>
</div><br clear="all">
<div>
<p><span class="font34">send pkt0</span></p>
<p><span class="font34">rcv ACK0</span></p>
<p><span class="font34">send pktl</span></p>
<p><span class="font34">rcv ACK1</span></p>
<p><span class="font34">send pkt0</span></p><img src="networking_files/networking-178.jpg" alt="" style="width:66pt;height:166pt;">
<p><span class="font34">rcv pkt0 send ACK0</span></p>
<p><span class="font34">rcv pkt1 send ACK1</span></p>
<p><span class="font34">rcv pkt0 send ACK0</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">a. Operation with no loss</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-179.jpg" alt="" style="width:130pt;height:229pt;">
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Receiver</span></p>
</div><br clear="all">
<div>
<p><span class="font34">rcv pkt0 send ACK0</span></p>
</div><br clear="all">
<div>
<p><span class="font34">rcv pkt1 send ACK1</span></p>
</div><br clear="all">
<div>
<p><span class="font34">rcv pkt1</span></p>
<p><span class="font34">(detect duplicate) send ACK1</span></p>
<p><span class="font34">rcv pkt0 send ACK0</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-180.jpg" alt="" style="width:126pt;height:210pt;">
<p><span class="font4" style="font-weight:bold;">Receiver</span></p>
<p><span class="font34">rcv pkt1 send ACK1</span></p>
<p><span class="font34">rcv pkt0 send ACK0</span></p>
<p><span class="font34">rcv pkt0 send ACK0</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-181.jpg" alt="" style="width:131pt;height:229pt;">
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Receiver</span></p>
</div><br clear="all">
<div>
<p><span class="font34">rcv pkt0 send ACK0</span></p>
</div><br clear="all">
<div>
<p><span class="font34">rcv pkt1</span></p>
<p><span class="font34">send ACK1</span></p>
<p><span class="font34">rcv pkt 1</span></p>
<p><span class="font34">(detect duplicate) send ACK1</span></p>
<p><span class="font34">rcv pkt0</span></p>
<p><span class="font34">send ACK0</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-182.jpg" alt="" style="width:181pt;height:110pt;">
<p><span class="font4" style="font-weight:bold;">a. A stop-and-wait protocol in operation</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 3.17 </span><span class="font50">♦ </span><span class="font5">Stop-and-wait versus pipelined protocol</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Data packets</span></p>
<table border="1">
<tr><td colspan="2" style="vertical-align:bottom;">
<p><span class="font5" style="font-weight:bold;">--|| tTf| tffr WTT WWW</span></p></td><td rowspan="2"></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font59">S</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">ACK packets</span></p></td></tr>
<tr><td></td><td>
<p><span class="font47" style="font-weight:bold;">◄— &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;WITr</span></p></td><td></td></tr>
</table>
</div><br clear="all">
<p><span class="font4" style="font-weight:bold;">b. A pipelined protocol in operation</span></p>
<p><span class="font53">To appreciate the performance impact of this stop-and-wait behavior, consider an idealized case of two hosts, one located on the West Coast of the United States and the other located on the East Coast, as shown in Figure 3.17. The speed-of-light round-trip propagation delay between these two end systems, RTT, is approximately 30 milliseconds. Suppose that they are connected by a channel with a transmission rate, </span><span class="font53" style="font-style:italic;">R,</span><span class="font53"> of 1 Gbps (10</span><span class="font50">9 </span><span class="font53">bits per second). With a packet size, </span><span class="font53" style="font-style:italic;">L,</span><span class="font53"> of 1,000 bytes (8,000 bits) per packet, including both header fields and data, the time needed to actually transmit the packet into the 1 Gbps link is</span></p>
<p><span class="font53" style="font-style:italic;">L</span><span class="font53"> 8000 bits „ .</span></p>
<p><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>trans</sub> = ~ </span><span class="font54">= </span><span class="font53" style="font-variant:small-caps;text-decoration:line-through;">q9 &nbsp;&nbsp;/</span><span class="font53">— = 8 microseconds</span></p>
<p><span class="font53">Figure 3.18(a) shows that with our stop-and-wait protocol, if the sender begins sending the packet at </span><span class="font53" style="font-style:italic;">t =</span><span class="font53"> 0, then at </span><span class="font53" style="font-style:italic;">t = L/R =</span><span class="font53"> 8 microseconds, the last bit enters the channel at the sender side. The packet then makes its 15-msec cross-country journey, with the last bit of the packet emerging at the receiver at </span><span class="font53" style="font-style:italic;">t =</span><span class="font53"> RTT/2 </span><span class="font55">+ </span><span class="font53" style="font-style:italic;">L/R = </span><span class="font53">15.008 msec. Assuming for simplicity that ACK packets are extremely small (so that we can ignore their transmission time) and that the receiver can send an ACK as soon as the last bit of a data packet is received, the ACK emerges back at the sender at </span><span class="font53" style="font-style:italic;">t =</span><span class="font53"> RTT </span><span class="font55">+ </span><span class="font53" style="font-style:italic;">L/R =</span><span class="font53"> 30.008 msec. At this point, the sender can now transmit the next message. Thus, in 30.008 msec, the sender was sending for only 0.008 msec. If we define the </span><span class="font53" style="font-weight:bold;">utilization </span><span class="font53">of the sender (or the channel) as the fraction of time the sender is actually busy sending bits into the channel, the analysis in Figure 3.18(a) shows that the stop-and-wait protocol has a rather dismal sender utilization, </span><span class="font53" style="font-style:italic;">U</span><span class="font53"><sub>sender</sub>, of</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font53" style="font-style:italic;"><sup>U</sup></span><span class="font50">sender</span></p></td><td>
<p><span class="font53" style="font-style:italic;">L</span><span class="font9" style="font-style:italic;">/</span><span class="font53" style="font-style:italic;">R</span><span class="font53"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.008</span></p>
<p><span class="font53">=--------— = -----= 0.00027</span></p>
<p><span class="font53" style="font-style:italic;">RTT</span><span class="font55"> + </span><span class="font53" style="font-style:italic;">L </span><span class="font9" style="font-style:italic;">/ </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> &nbsp;&nbsp;30.008</span></p></td></tr>
</table>
<div>
<p><span class="font4" style="font-weight:bold;">Receiver</span></p>
</div><br clear="all">
<div>
<p><span class="font4">First bit of first packet &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\3</span></p>
<p><span class="font4">transmitted, t = 0----------------</span></p>
<p><span class="font4">Last bit of first packet------------</span></p>
<p><span class="font4">transmitted, t = </span><span class="font4" style="font-style:italic;">L/R</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Sender</span></p><img src="networking_files/networking-183.jpg" alt="" style="width:34pt;height:36pt;">
</div><br clear="all">
<div><img src="networking_files/networking-184.jpg" alt="" style="width:34pt;height:37pt;">
</div><br clear="all">
<div>
<p><span class="font4" style="font-style:italic;">RTT-</span></p>
<p><span class="font4">ACK arrives, send next packet,—— t = </span><span class="font4" style="font-style:italic;">RTT</span><span class="font4"> + </span><span class="font4" style="font-style:italic;">L/R</span></p><img src="networking_files/networking-185.jpg" alt="" style="width:111pt;height:113pt;">
</div><br clear="all">
<div>
<p><span class="font4"><sup>1</sup> — First bit of first packet arrives</span></p>
<p><span class="font4">■ — Last bit of first packet arrives, send ACK</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">a. Stop-and-wait operation</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Receiver</span></p>
</div><br clear="all">
<div>
<p><span class="font4">First bit of first packet</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Sender</span></p><img src="networking_files/networking-186.jpg" alt="" style="width:34pt;height:36pt;">
</div><br clear="all">
<div><img src="networking_files/networking-187.jpg" alt="" style="width:34pt;height:36pt;">
</div><br clear="all">
<div>
<p><span class="font4">transmitted, t = 0</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Last bit of first packet transmitted, t = </span><span class="font4" style="font-style:italic;">L/R</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-188.jpg" alt="" style="width:133pt;height:40pt;">
</div><br clear="all">
<div>
<p><span class="font4" style="font-style:italic;">RTT</span></p>
<p><span class="font4">ACK arrives, send next packet,—-t = </span><span class="font4" style="font-style:italic;">RTT</span><span class="font4"> + </span><span class="font4" style="font-style:italic;">L/R &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;____</span></p><img src="networking_files/networking-189.jpg" alt="" style="width:111pt;height:113pt;">
<p><span class="font4">— First bit of first packet arrives</span></p>
</div><br clear="all">
<div>
<ul style="list-style:none;"><li>
<p><span class="font4">— Last bit of first packet arrives, send ACK</span></p></li>
<li>
<p><span class="font4">— Last bit of 2nd packet arrives, send ACK</span></p></li></ul>
<p><span class="font4">■ — Last bit of 3rd packet arrives, send ACK</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">b. Pipelined operation</span></p>
</div><br clear="all">
<p><span class="font53">That is, the sender was busy only 2.7 hundredths of one percent of the time! Viewed another way, the sender was able to send only 1,000 bytes in 30.008 milliseconds, an effective throughput of only 267 kbps—even though a 1 Gbps link was available! Imagine the unhappy network manager who just paid a fortune for a gigabit capacity link but manages to get a throughput of only 267 kilobits per second! This is a graphic example of how network protocols can limit the capabilities provided by the underlying network hardware. Also, we have neglected lower-layer protocol-processing times at the sender and receiver, as well as the processing and queuing delays that would occur at any intermediate routers between the sender and receiver. Including these effects would serve only to further increase the delay and further accentuate the poor performance.</span></p>
<p><span class="font53">The solution to this particular performance problem is simple: Rather than operate in a stop-and-wait manner, the sender is allowed to send multiple packets without waiting for acknowledgments, as illustrated in Figure 3.17(b). Figure 3.18(b) shows that if the sender is allowed to transmit three packets before having to wait for acknowledgments, the utilization of the sender is essentially tripled. Since the many in-transit sender-to-receiver packets can be visualized as filling a pipeline, this technique is known as </span><span class="font53" style="font-weight:bold;">pipelining</span><span class="font53">. Pipelining has the following consequences for reliable data transfer protocols:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;The range of sequence numbers must be increased, since each in-transit packet (not counting retransmissions) must have a unique sequence number and there may be multiple, in-transit, unacknowledged packets.</span></p></li>
<li>
<p><span class="font53">• &nbsp;The sender and receiver sides of the protocols may have to buffer more than one packet. Minimally, the sender will have to buffer packets that have been transmitted but not yet acknowledged. Buffering of correctly received packets may also be needed at the receiver, as discussed below.</span></p></li>
<li>
<p><span class="font53">• &nbsp;The range of sequence numbers needed and the buffering requirements will depend on the manner in which a data transfer protocol responds to lost, corrupted, and overly delayed packets. Two basic approaches toward pipelined error recovery can be identified: </span><span class="font53" style="font-weight:bold;">Go-Back-N </span><span class="font53">and </span><span class="font53" style="font-weight:bold;">selective repeat</span><span class="font53">.</span></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">3.4.3 </span><span class="font23" style="font-weight:bold;">Go-Back-N (GBN)</span></p></li></ul>
<p><span class="font53">In a </span><span class="font53" style="font-weight:bold;">Go-Back-N (GBN) protocol</span><span class="font53">, the sender is allowed to transmit multiple packets (when available) without waiting for an acknowledgment, but is constrained to have no more than some maximum allowable number, </span><span class="font53" style="font-style:italic;">N,</span><span class="font53"> of unacknowledged packets in the pipeline. We describe the GBN protocol in some detail in this section. But before reading on, you are encouraged to play with the GBN animation (an awesome interactive animation) at the Companion Website.</span></p>
<p><a name="bookmark305"></a><span class="font53">Figure 3.19 shows the sender’s view of the range of sequence numbers in a GBN protocol. If we define </span><span class="font36">base </span><span class="font53">to be the sequence number of the oldest unacknowledged</span></p>
<p><span class="font34">base &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;nextseqnum</span></p>
<div>
<p><span class="font4">Key:</span></p>
<p><span class="font65">□</span><span class="font41"> Already</span></p>
<p><span class="font41">ACK’d</span></p>
<p><span class="font65">□</span><span class="font41"> Sent, not yet ACK’d</span></p>
</div><br clear="all">
<div>
<p><span class="font41">Usable, not yet sent</span></p>
<p><span class="font41">Not usable</span></p>
</div><br clear="all">
<p><span class="font17">iiiiiin-nnrrnnn-nnrn</span></p>
<p><span class="font34">I__________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________,_____________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________I</span></p>
<p><span class="font4">Window size</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 3.19 </span><span class="font50">♦ </span><span class="font5">Sender's view of sequence numbers in Go-Back-N</span></p>
<p><span class="font53">packet and </span><span class="font36">nextseqnum </span><span class="font53">to be the smallest unused sequence number (that is, the sequence number of the next packet to be sent), then four intervals in the range of sequence numbers can be identified. Sequence numbers in the interval [</span><span class="font36">0,base-1</span><span class="font53">] correspond to packets that have already been transmitted and acknowledged. The interval </span><span class="font36">[base,nextseqnum-1] </span><span class="font53">corresponds to packets that have been sent but not yet acknowledged. Sequence numbers in the interval </span><span class="font36">[nextseqnum,base+N-1] </span><span class="font53">can be used for packets that can be sent immediately, should data arrive from the upper layer. Finally, sequence numbers greater than or equal to </span><span class="font36">base+N </span><span class="font53">cannot be used until an unacknowledged packet currently in the pipeline (specifically, the packet with sequence number </span><span class="font36">base</span><span class="font53">) has been acknowledged.</span></p>
<p><span class="font53">As suggested by Figure 3.19, the range of permissible sequence numbers for transmitted but not yet acknowledged packets can be viewed as a window of size </span><span class="font53" style="font-style:italic;">N </span><span class="font53">over the range of sequence numbers. As the protocol operates, this window slides forward over the sequence number space. For this reason, </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> is often referred to as the </span><span class="font53" style="font-weight:bold;">window size </span><span class="font53">and the GBN protocol itself as a </span><span class="font53" style="font-weight:bold;">sliding-window protocol</span><span class="font53">. You might be wondering why we would even limit the number of outstanding, unacknowledged packets to a value of </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> in the first place. Why not allow an unlimited number of such packets? We’ll see in Section 3.5 that flow control is one reason to impose a limit on the sender. We’ll examine another reason to do so in Section 3.7, when we study TCP congestion control.</span></p>
<p><span class="font53">In practice, a packet’s sequence number is carried in a fixed-length field in the packet header. If </span><span class="font53" style="font-style:italic;">k</span><span class="font53"> is the number of bits in the packet sequence number field, the range of sequence numbers is thus [0,2</span><span class="font53" style="font-style:italic;"><sup>k</sup></span><span class="font55"> — </span><span class="font53">1]. With a finite range of sequence numbers, all arithmetic involving sequence numbers must then be done using modulo 2</span><span class="font53" style="font-style:italic;"><sup>k </sup></span><span class="font53">arithmetic. (That is, the sequence number space can be thought of as a ring of size 2</span><span class="font53" style="font-style:italic;"><sup>k</sup></span><span class="font53">, where sequence number 2</span><span class="font53" style="font-style:italic;"><sup>k</sup></span><span class="font55"> — </span><span class="font53">1 is immediately followed by sequence number 0.) Recall that </span><span class="font36">rdt3.0 </span><span class="font53">had a 1-bit sequence number and a range of sequence numbers of [0,1]. Several of the problems at the end of this chapter explore the consequences of a finite range of sequence numbers. We will see in Section 3.5 that TCP has a 32-bit sequence number field, where TCP sequence numbers count bytes in the byte stream rather than packets.</span></p>
<p><span class="font53">Figures 3.20 and 3.21 give an extended FSM description of the sender and receiver sides of an ACK-based, NAK-free, GBN protocol. We refer to this FSM</span></p>
<p><span class="font33">rdt_send(data) if(nextseqnum&lt;base+N){</span></p>
<p><span class="font33">sndpkt[nextseqnum]=make_pkt(nextseqnum,data,checksum) udt_send(sndpkt[nextseqnum])</span></p>
<p><span class="font33">if(base==nextseqnum)</span></p>
<p><span class="font33">start_timer</span></p>
<p><span class="font33">nextseqnum++</span></p>
<p><span class="font33">}</span></p>
<div>
<p><span class="font33">refuse data(data)</span></p><img src="networking_files/networking-190.jpg" alt="" style="width:219pt;height:128pt;">
<p><span class="font4">Wait</span></p>
<p><span class="font33">timeout</span></p>
<p><span class="font33">udt_send(sndpkt[nextseqnum-1])</span></p>
<p><span class="font33">start_timer</span></p>
<p><span class="font33">udt_send(sndpkt[base])</span></p>
<p><span class="font33">udt_send(sndpkt[base+1])</span></p>
<p><span class="font33">nextseqnum=1</span></p>
<p><span class="font33">rdt_rcv(rcvpkt) &amp;&amp;&nbsp;corrupt(rcvpkt)</span></p>
<p><span class="font51">L</span></p>
</div><br clear="all">
<p><span class="font33">else </span><span class="font33" style="text-decoration:underline;">rdt_rcv(rcvpkt) &amp;&amp;&nbsp;notcorrupt(rcvpkt)</span><span class="font33"> base=getacknum(rcvpkt)+1</span></p>
<p><span class="font33">If(base==nextseqnum)</span></p>
<p><span class="font33">stop_timer</span></p>
<p><span class="font33">else</span></p>
<p><span class="font33">start_timer</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 3.20 </span><span class="font50">♦ </span><span class="font5">Extended FSM description of the GBN sender</span></p>
<p><span class="font33">rdt_rcv(rcvpkt)</span></p>
<p><span class="font33" style="font-style:italic;">&amp;&amp;</span><span class="font33"> notcorrupt(rcvpkt)</span></p>
<p><span class="font33" style="font-style:italic;">&amp;&amp;</span><span class="font33"> hasseqnum(rcvpkt,expectedseqnum)</span></p>
<p><span class="font33">extract(rcvpkt,data)</span></p>
<p><span class="font33">deliver_data(data)</span></p>
<p><span class="font33">sndpkt=make_pkt(expectedseqnum,ACK,checksum)</span></p>
<p><span class="font33">udt_send(sndpkt)</span></p>
<p><span class="font33">expectedseqnum++</span></p>
<div>
<p><span class="font51">L</span></p>
<p><span class="font33">expectedseqnum=1</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-191.jpg" alt="" style="width:76pt;height:61pt;">
<p><span class="font33">default</span></p>
<p><span class="font33">udt_send(sndpkt)</span></p>
</div><br clear="all">
<p><span class="font33">sndpkt=make_pkt(0,ACK,checksum)</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 3.21 </span><span class="font50">♦ </span><span class="font5">Extended FSM description of the GBN receiver </span><span class="font53">description as an </span><span class="font53" style="font-style:italic;">extended FSM</span><span class="font53"> because we have added variables (similar to programming-language variables) for </span><span class="font36">base </span><span class="font53">and </span><span class="font36">nextseqnum</span><span class="font53">, and added operations on these variables and conditional actions involving these variables. Note that the extended FSM specification is now beginning to look somewhat like a programming-language specification. [Bochman 1984] provides an excellent survey of additional extensions to FSM techniques as well as other programming-language-based techniques for specifying protocols.</span></p>
<p><span class="font53">The GBN sender must respond to three types of events:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Invocation from above.</span><span class="font53"> When </span><span class="font36">rdt_send() </span><span class="font53">is called from above, the sender first checks to see if the window is full, that is, whether there are </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> outstanding, unacknowledged packets. If the window is not full, a packet is created and sent, and variables are appropriately updated. If the window is full, the sender simply returns the data back to the upper layer, an implicit indication that the window is full. The upper layer would presumably then have to try again later. In a real implementation, the sender would more likely have either buffered (but not immediately sent) this data, or would have a synchronization mechanism (for example, a semaphore or a flag) that would allow the upper layer to call </span><span class="font36">rdt_send() </span><span class="font53">only when the window is not full.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Receipt of an ACK.</span><span class="font53"> In our GBN protocol, an acknowledgment for a packet with sequence number </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> will be taken to be a </span><span class="font53" style="font-weight:bold;">cumulative acknowledgment</span><span class="font53">, indicating that all packets with a sequence number up to and including </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> have been correctly received at the receiver. We’ll come back to this issue shortly when we examine the receiver side of GBN.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">A timeout event.</span><span class="font53"> The protocol’s name, “Go-Back-N,” is derived from the sender’s behavior in the presence of lost or overly delayed packets. As in the stop-and-wait protocol, a timer will again be used to recover from lost data or acknowledgment packets. If a timeout occurs, the sender resends </span><span class="font53" style="font-style:italic;">all</span><span class="font53"> packets that have been previously sent but that have not yet been acknowledged. Our sender in Figure 3.20 uses only a single timer, which can be thought of as a timer for the oldest transmitted but not yet acknowledged packet. If an ACK is received but there are still additional transmitted but not yet acknowledged packets, the timer is restarted. If there are no outstanding, unacknowledged packets, the timer is stopped.</span></p></li></ul>
<p><span class="font53">The receiver’s actions in GBN are also simple. If a packet with sequence number </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> is received correctly and is in order (that is, the data last delivered to the upper layer came from a packet with sequence number </span><span class="font53" style="font-style:italic;">n —</span><span class="font53"> 1), the receiver sends an ACK for packet </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> and delivers the data portion of the packet to the upper layer. In all other cases, the receiver discards the packet and resends an ACK for the most recently received in-order packet. Note that since packets are delivered one at a time to the upper layer, if packet </span><span class="font53" style="font-style:italic;">k</span><span class="font53"> has been received and delivered, then all packets with a sequence number lower than </span><span class="font53" style="font-style:italic;">k</span><span class="font53"> have also been delivered. Thus, the use of cumulative acknowledgments is a natural choice for GBN.</span></p>
<p><span class="font53">In our GBN protocol, the receiver discards out-of-order packets. Although it may seem silly and wasteful to discard a correctly received (but out-of-order) packet, there is some justification for doing so. Recall that the receiver must deliver data in order to the upper layer. Suppose now that packet </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> is expected, but packet </span><span class="font53" style="font-style:italic;">n</span><span class="font55"> + </span><span class="font53">1 arrives. Because data must be delivered in order, the receiver </span><span class="font53" style="font-style:italic;">could </span><span class="font53">buffer (save) packet </span><span class="font53" style="font-style:italic;">n</span><span class="font55"> + </span><span class="font53">1 and then deliver this packet to the upper layer after it had later received and delivered packet </span><span class="font53" style="font-style:italic;">n</span><span class="font53">. However, if packet </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> is lost, both it and packet </span><span class="font53" style="font-style:italic;">n</span><span class="font55"> + </span><span class="font53">1 will eventually be retransmitted as a result of the GBN retransmission rule at the sender. Thus, the receiver can simply discard packet </span><span class="font53" style="font-style:italic;">n</span><span class="font55"> + </span><span class="font53">1. The advantage of this approach is the simplicity of receiver buffering—the receiver need not buffer </span><span class="font53" style="font-style:italic;">any</span><span class="font53"> out-of-order packets. Thus, while the sender must maintain the upper and lower bounds of its window and the position of </span><span class="font36">nextseqnum </span><span class="font53">within this window, the only piece of information the receiver need maintain is the sequence number of the next in-order packet. This value is held in the variable </span><span class="font36">expectedseqnum</span><span class="font53">, shown in the receiver FSM in Figure 3.21. Of course, the disadvantage of throwing away a correctly received packet is that the subsequent retransmission of that packet might be lost or garbled and thus even more retransmissions would be required.</span></p>
<p><span class="font53">Figure 3.22 shows the operation of the GBN protocol for the case of a window size of four packets. Because of this window size limitation, the sender sends packets 0 through 3 but then must wait for one or more of these packets to be acknowledged before proceeding. As each successive ACK (for example, </span><span class="font36">ACK0 </span><span class="font53">and </span><span class="font36">ACK1</span><span class="font53">) is received, the window slides forward and the sender can transmit one new packet (pkt4 and pkt5, respectively). On the receiver side, packet 2 is lost and thus packets 3, 4, and 5 are found to be out of order and are discarded.</span></p>
<p><span class="font53">Before closing our discussion of GBN, it is worth noting that an implementation of this protocol in a protocol stack would likely have a structure similar to that of the extended FSM in Figure 3.20. The implementation would also likely be in the form of various procedures that implement the actions to be taken in response to the various events that can occur. In such </span><span class="font53" style="font-weight:bold;">event-based programming</span><span class="font53">, the various procedures are called (invoked) either by other procedures in the protocol stack, or as the result of an interrupt. In the sender, these events would be (1) a call from the upper-layer entity to invoke </span><span class="font36">rdt_send()</span><span class="font53">, (2) a timer interrupt, and (3) a call from the lower layer to invoke </span><span class="font36">rdt_rcv() </span><span class="font53">when a packet arrives. The programming exercises at the end of this chapter will give you a chance to actually implement these routines in a simulated, but realistic, network setting.</span></p>
<p><span class="font53">We note here that the GBN protocol incorporates almost all of the techniques that we will encounter when we study the reliable data transfer components of TCP in Section 3.5. These techniques include the use of sequence numbers, cumulative acknowledgments, checksums, and a timeout/retransmit operation.</span></p>
<p><span class="font4" style="font-weight:bold;">Sender</span></p>
<p><span class="font4" style="font-weight:bold;">Receiver</span></p><img src="networking_files/networking-192.jpg" alt="" style="width:235pt;height:341pt;">
<p><span class="font34">discard</span></p>
<p><span class="font34">discard</span></p>
<p><span class="font34">discard</span></p>
<p><span class="font34">deliver</span></p>
<p><span class="font34">deliver</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 3.22 </span><span class="font50">♦ </span><span class="font5">Go-Back-N in operation</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">3.4.4 </span><span class="font23" style="font-weight:bold;">Selective Repeat (SR)</span></p></li></ul>
<p><a name="bookmark306"></a><span class="font53">The GBN protocol allows the sender to potentially “fill the pipeline” in Figure 3.17 with packets, thus avoiding the channel utilization problems we noted with stop-and-wait protocols. There are, however, scenarios in which GBN itself suffers from performance problems. In particular, when the window size and bandwidth-delay product are both large, many packets can be in the pipeline. A single packet error can thus cause GBN to retransmit a large number of packets, many unnecessarily. As the probability of channel errors increases, the pipeline can become filled with these unnecessary retransmissions. Imagine, in our message-dictation scenario, that if every time a word was garbled, the surrounding 1,000 words (for example, a window size of 1,000 words) had to be repeated. The dictation would be slowed by all of the reiterated words.</span></p>
<p><span class="font53">As the name suggests, selective-repeat protocols avoid unnecessary retransmissions by having the sender retransmit only those packets that it suspects were received in error (that is, were lost or corrupted) at the receiver. This individual, as-needed, retransmission will require that the receiver </span><span class="font53" style="font-style:italic;">individually</span><span class="font53"> acknowledge correctly received packets. A window size of </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> will again be used to limit the number of outstanding, unacknowledged packets in the pipeline. However, unlike GBN, the sender will have already received ACKs for some of the packets in the window. Figure 3.23 shows the SR sender’s view of the sequence number space. Figure 3.24 details the various actions taken by the SR sender.</span></p>
<p><span class="font53">The SR receiver will acknowledge a correctly received packet whether or not it is in order. Out-of-order packets are buffered until any missing packets (that is, packets with lower sequence numbers) are received, at which point a batch of packets can be delivered in order to the upper layer. Figure 3.25 itemizes the various actions taken by the SR receiver. Figure 3.26 shows an example of SR operation in the presence of lost packets. Note that in Figure 3.26, the receiver initially buffers packets 3, 4, and 5, and delivers them together with packet 2 to the upper layer when packet 2 is finally received.</span></p>
<div>
<p><span class="font34">send_base &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;nextseqnum</span></p><img src="networking_files/networking-193.jpg" alt="" style="width:259pt;height:45pt;">
<p><span class="font4">| Window size</span></p>
<p><span class="font52" style="font-style:italic;">N</span></p>
<p><span class="font4" style="font-weight:bold;">a. Sender view of sequence numbers</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Key:</span></p>
<p><span class="font65">□</span><span class="font41"> Already</span></p>
<p><span class="font41">ACK'd</span></p>
<p><span class="font65">□</span><span class="font41"> Sent, not yet ACK'd</span></p>
</div><br clear="all">
<div>
<p><span class="font41">Usable, not yet sent</span></p>
<p><span class="font41">Not usable</span></p>
</div><br clear="all">
<div>
<p><span class="font34">rcv_base</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-194.jpg" alt="" style="width:10pt;height:12pt;">
</div><br clear="all">
<div>
<p><span class="font4">Window size</span></p>
<p><span class="font52" style="font-style:italic;">N</span></p>
<p><span class="font4" style="font-weight:bold;">b. Receiver view of sequence numbers</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Key:</span></p>
<p><span class="font65">□</span><span class="font41"> Out of order</span></p>
<p><span class="font41">(buffered) but</span></p>
<p><span class="font41">already ACK'd</span></p>
<p><span class="font65">n</span><span class="font41"> Expected, not yet received</span></p>
</div><br clear="all">
<div>
<p><span class="font41">Acceptable (within window)</span></p>
<p><span class="font41">Not usable</span></p>
</div><br clear="all">
<div>
<p><span class="font7" style="font-weight:bold;">Figure 3.23 </span><span class="font50">♦ </span><span class="font5">Selective-repeat (SR) sender and receiver views of sequence-number space</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<p><span class="font53">1. </span><span class="font53" style="font-style:italic;">Data received from above.</span><span class="font53"> When data is received from above, the SR sender checks the next available sequence number for the packet. If the sequence number is within the sender’s window, the data is packetized and sent; otherwise it is either buffered or returned to the upper layer for later transmission, as in GBN.</span></p></li>
<li>
<p><span class="font53">2. </span><span class="font53" style="font-style:italic;">Timeout.</span><span class="font53"> Timers are again used to protect against lost packets. However, each packet must now have its own logical timer, since only a single packet will be transmitted on timeout. A single hardware timer can be used to mimic the operation of multiple logical timers [Varghese 1997].</span></p></li>
<li>
<p><span class="font53">3. </span><span class="font53" style="font-style:italic;">ACK received.</span><span class="font53"> If an ACK is received, the SR sender marks that packet as having been received, provided it is in the window. If the packet’s sequence number is equal to </span><span class="font36">send_base</span><span class="font53">, the window base is moved forward to the unacknowledged packet with the smallest sequence number. If the window moves and there are untransmitted packets with sequence numbers that now fall within the window, these packets are transmitted.</span></p></li></ul>
<p><span class="font7" style="font-weight:bold;">Figure 3.24 </span><span class="font50">♦ </span><span class="font5">SR sender events and actions</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">1. </span><span class="font53" style="font-style:italic;">Packet with sequence number in</span><span class="font36"> [rcv_base, rcv_base+N-1] </span><span class="font53" style="font-style:italic;">is correctly received.</span><span class="font53"> In this case, the received packet falls within the receiver’s window and a selective ACK packet is returned to the sender. If the packet was not previously received, it is buffered. If this packet has a scx.|iicnccnuinbcrcqual to the base of the receive window (</span><span class="font36">rcv_base </span><span class="font53">in Figure 3.22), then this packet, and any previously buffered and consecutively numbered (beginning with </span><span class="font36">rcv_base</span><span class="font53">) packets are delivered to the upper layer. The receive window is then moved forward by the number of packets delivered to the upper layer. As an example, consider Figure 3.26. When a packet with a sequence number of </span><span class="font36">rcv_base=2 </span><span class="font53">is received, it and packets 3, 4, and 5 can be- delivered tothc upper layer.</span></p></li>
<li>
<p><span class="font53">2. </span><span class="font53" style="font-style:italic;">Packet with sequence number in</span><span class="font36"> [rcv_base-N, rcv_base-1] </span><span class="font53" style="font-style:italic;">is correctly received.</span><span class="font53"> In this case, an ACK must be generated, even though this is a packet that the receiver has previously acknowledged.</span></p></li>
<li>
<p><span class="font53">3. </span><span class="font53" style="font-style:italic;">Otherwise.</span><span class="font53"> Ignore the packet.</span></p></li></ul>
<p><span class="font7" style="font-weight:bold;">Figure 3.25 </span><span class="font50">♦ </span><span class="font5">SR receiver events and actions</span></p>
<p><span class="font53">It is important to note that in Step 2 in Figure 3.25, the receiver reacknowledges (rather than ignores) already received packets with certain sequence numbers </span><span class="font53" style="font-style:italic;">below </span><span class="font53">the current window base. You should convince yourself that this reacknowledgment is indeed needed. Given the sender and receiver sequence number spaces in Figure 3.23, for example, if there is no ACK for packet </span><span class="font36">send_base </span><span class="font53">propagating from</span></p>
<div><img src="networking_files/networking-195.jpg" alt="" style="width:240pt;height:371pt;">
<p><span class="font7" style="font-weight:bold;">Figure 3.26 </span><span class="font50">♦ </span><span class="font5">SR operation</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Receiver</span></p>
</div><br clear="all">
<p><span class="font34">pkt0</span><span class="font34" style="text-decoration:underline;"> </span><span class="font34">rcvd, delivered, ACK0 sent 0 1</span><span class="font34" style="text-decoration:underline;"> </span><span class="font34">2</span><span class="font34" style="text-decoration:underline;"> </span><span class="font34">3</span><span class="font34" style="text-decoration:underline;"> </span><span class="font34">4 5 6 7 8 9</span></p>
<p><span class="font34">pktl rcvd, delivered, ACK1 sent 0 1 2</span><span class="font34" style="text-decoration:underline;"> </span><span class="font34">3</span><span class="font34" style="text-decoration:underline;"> </span><span class="font34">4</span><span class="font34" style="text-decoration:underline;"> </span><span class="font34">5 6 7 8 9</span></p>
<div>
<table border="1">
<tr><td>
<p><span class="font34">pkt3 rcvd, buffered, 0 1 2 3 4 5 6 7 8 9</span></p></td><td>
<p><span class="font34">ACK3 sent</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font34">pkt4 rcvd, buffered, 0 1 2 3 4 5 6 7 8 9</span></p></td><td style="vertical-align:middle;">
<p><span class="font34">ACK4 sent</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font34">pkt5 rcvd; buffered, 0 1 2 3 4 5 6 7 8 9</span></p></td><td style="vertical-align:middle;">
<p><span class="font34">ACK5 sent</span></p></td></tr>
</table>
<p><span class="font34">pkt2 rcvd, pkt2,pkt3,pkt4,pkt5 delivered, ACK2 sent</span></p>
<p><span class="font34">0 1 2 3 4 5 6 7 8 9</span></p>
</div><br clear="all">
<p><span class="font53">the receiver to the sender, the sender will eventually retransmit packet </span><span class="font36">send_base</span><span class="font53">, even though it is clear (to us, not the sender!) that the receiver has already received that packet. If the receiver were not to acknowledge this packet, the sender’s window would never move forward! This example illustrates an important aspect of SR protocols (and many other protocols as well). The sender and receiver will not always have an identical view of what has been received correctly and what has not. For SR protocols, this means that the sender and receiver windows will not always coincide.</span></p>
<p><span class="font53">The lack of synchronization between sender and receiver windows has important consequences when we are faced with the reality of a finite range of sequence numbers. Consider what could happen, for example, with a finite range of four packet sequence numbers, 0, 1, 2, 3, and a window size of three. Suppose packets 0 through 2 are transmitted and correctly received and acknowledged at the receiver. At this point, the receiver’s window is over the fourth, fifth, and sixth packets, which have sequence numbers 3, 0, and 1, respectively. Now consider two scenarios. In the first scenario, shown in Figure 3.27(a), the ACKs for the first three packets are lost and the sender retransmits these packets. The receiver thus next receives a packet with sequence number 0—a copy of the first packet sent.</span></p>
<p><span class="font53">In the second scenario, shown in Figure 3.27(b), the ACKs for the first three packets are all delivered correctly. The sender thus moves its window forward and sends the fourth, fifth, and sixth packets, with sequence numbers 3, 0, and 1, respectively. The packet with sequence number 3 is lost, but the packet with sequence number 0 arrives—a packet containing </span><span class="font53" style="font-style:italic;">new</span><span class="font53"> data.</span></p>
<p><span class="font53">Now consider the receiver’s viewpoint in Figure 3.27, which has a figurative curtain between the sender and the receiver, since the receiver cannot “see” the actions taken by the sender. All the receiver observes is the sequence of messages it receives from the channel and sends into the channel. As far as it is concerned, the two scenarios in Figure 3.27 are </span><span class="font53" style="font-style:italic;">identical.</span><span class="font53"> There is no way of distinguishing the retransmission of the first packet from an original transmission of the fifth packet. Clearly, a window size that is 1 less than the size of the sequence number space won’t work. But how small must the window size be? A problem at the end of the chapter asks you to show that the window size must be less than or equal to half the size of the sequence number space for SR protocols.</span></p>
<p><span class="font53">At the Companion Website, you will find an animation that illustrates the operation of the SR protocol. Try performing the same experiments that you did with the GBN animation. Do the results agree with what you expect?</span></p>
<p><span class="font53">This completes our discussion of reliable data transfer protocols. We’ve covered a </span><span class="font53" style="font-style:italic;">lot</span><span class="font53"> of ground and introduced numerous mechanisms that together provide for reliable data transfer. Table 3.1 summarizes these mechanisms. Now that we have seen all of these mechanisms in operation and can see the “big picture,” we encourage you to review this section again to see how these mechanisms were incrementally added to cover increasingly complex (and realistic) models of the channel connecting the sender and receiver, or to improve the performance of the protocols.</span></p>
<p><span class="font53">Let’s conclude our discussion of reliable data transfer protocols by considering one remaining assumption in our underlying channel model. Recall that we have assumed that packets cannot be reordered within the channel between the sender and receiver. This is generally a reasonable assumption when the sender and receiver are connected by a single physical wire. However, when the “channel” connecting the two is a network, packet reordering can occur. One manifestation of packet reordering is that old copies of a packet with a sequence or acknowledgment</span></p>
<div><img src="networking_files/networking-196.jpg" alt="" style="width:202pt;height:204pt;">
<p><span class="font4" style="font-weight:bold;">Receiver window </span><span class="font4">(after receipt)</span></p>
<p><span class="font34">ACK0 &nbsp;&nbsp;0 1</span><span class="font34" style="text-decoration:underline;"> </span><span class="font34">2</span><span class="font34" style="text-decoration:underline;"> </span><span class="font34">3 0 1 2</span></p>
<p><span class="font34">ACK1 &nbsp;&nbsp;0 1 2</span><span class="font34" style="text-decoration:underline;"> </span><span class="font34">3</span><span class="font34" style="text-decoration:underline;"> </span><span class="font34">0 1 2</span></p>
<p><span class="font34">ACK2 &nbsp;&nbsp;0 1 2 3</span><span class="font34" style="text-decoration:underline;"> </span><span class="font34">0</span><span class="font34" style="text-decoration:underline;"> </span><span class="font34">1 2</span></p>
<p><span class="font34">receive packet</span></p>
<p><span class="font34">with seq number 0</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Sender window</span></p>
</div><br clear="all">
<div style="border-right:solid;">
<p><span class="font4">(after receipt)</span></p>
<p><a href="#bookmark307"><span class="font34">0</span><span class="font34" style="text-decoration:underline;"> &nbsp;</span><span class="font34">1</span><span class="font34" style="text-decoration:underline;"> </span><span class="font34">2 &nbsp;3 0 &nbsp;1</span></a></p>
<p><a href="#bookmark308"><span class="font34">0 &nbsp;1 2 &nbsp;3 0 &nbsp;1</span></a></p>
<p><a href="#bookmark309"><span class="font34">0</span><span class="font34" style="text-decoration:underline;"> &nbsp;</span><span class="font34">1</span><span class="font34" style="text-decoration:underline;"> </span><span class="font34">2 &nbsp;3 0 &nbsp;1</span></a></p>
<p><a href="#bookmark310"><span class="font34">0 &nbsp;1</span><span class="font34" style="text-decoration:underline;"> </span><span class="font34">2</span><span class="font34" style="text-decoration:underline;"> &nbsp;</span><span class="font34">3 0 &nbsp;1</span></a></p>
<p><a href="#bookmark311"><span class="font34">0 &nbsp;1 2 &nbsp;3 0 &nbsp;1</span></a></p>
<p><span class="font4" style="font-weight:bold;">b.</span></p>
</div><br clear="all">
<div style="border-right:solid;"><img src="networking_files/networking-197.jpg" alt="" style="width:114pt;height:176pt;">
</div><br clear="all">
<p><span class="font4" style="font-weight:bold;">Receiver window </span><span class="font4">(after receipt)</span></p>
<p><a href="#bookmark312"><span class="font34">ACK0 &nbsp;&nbsp;0 1</span><span class="font34" style="text-decoration:underline;"> </span><span class="font34">2</span><span class="font34" style="text-decoration:underline;"> </span><span class="font34">3 0 1</span></a></p>
<p><a href="#bookmark313"><span class="font34">ACK1 &nbsp;&nbsp;0 1 2</span><span class="font34" style="text-decoration:underline;"> </span><span class="font34">3</span><span class="font34" style="text-decoration:underline;"> </span><span class="font34">0 1</span></a></p>
<p><a href="#bookmark314"><span class="font34">ACK2 &nbsp;&nbsp;0 1 2 3</span><span class="font34" style="text-decoration:underline;"> </span><span class="font34">0</span><span class="font34" style="text-decoration:underline;"> </span><span class="font34">1</span></a></p>
<p><span class="font34">receive packet</span></p>
<p><span class="font34">with seq number 0</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 3.27 </span><span class="font50">♦ </span><span class="font5">SR receiver dilemma with too-large windows: A new packet or a retransmission?</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Mechanism</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Use, Comments</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Checksum</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Used to detect bit errors in a transmitted packet.</span></p></td></tr>
<tr><td>
<p><span class="font6">Timer</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Used to timeout/retransmit a packet, possibly because the packet (or its ACK) was lost within the channel. Because timeouts can occur when a packet is delayed but not lost (premature timeout), or when a packet has been received by the receiver but the receiver-to-sender ACK has been lost, duplicate copies of a packet may be received by a receiver.</span></p></td></tr>
<tr><td>
<p><span class="font6">Sequence number</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Used for sequential numbering of packets of data flowing from sender to receiver. Gaps in the sequence numbers of received packets allow the receiver to detect a lost packet. Packets with duplicate sequence numbers allow the receiver to detect duplicate copies of a packet.</span></p></td></tr>
<tr><td>
<p><span class="font6">Acknowledgment</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Used by the receiver to tell the sender that a packet or set of packets has been received correctly. Acknowledgments will typically carry the sequence number of the packet or packets being acknowledged. Acknowledgments may be individual or cumulative, depending on the protocol.</span></p></td></tr>
<tr><td>
<p><span class="font6">Negative acknowledgment</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Used by the receiver to tell the sender that a packet has not been received correctly. Negative acknowledgments will typically carry the sequence number of the packet that was not received correctly.</span></p></td></tr>
<tr><td>
<p><span class="font6">Window, pipelining</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">The sender may be restricted to sending only packets with sequence numbers that fall within a given range. By allowing multiple packets to be transmitted but not yet acknowledged, sender utilization can be increased over a stop-and-wait mode of operation. We'll see shortly that the window size may be set on the basis of the receiver's ability to receive and buffer messages, or the level of congestion in the network, or both.</span></p></td></tr>
</table>
<p><span class="font7" style="font-weight:bold;">Table 3.1 </span><span class="font50">♦ </span><span class="font5">Summary of reliable data transfer mechanisms and their use</span></p>
<p><span class="font53">number of </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> can appear, even though neither the sender’s nor the receiver’s window contains </span><span class="font53" style="font-style:italic;">x</span><span class="font53">. With packet reordering, the channel can be thought of as essentially buffering packets and spontaneously emitting these packets at </span><span class="font53" style="font-style:italic;">any</span><span class="font53"> point in the future. Because sequence numbers may be reused, some care must be taken to guard against such duplicate packets. The approach taken in practice is to ensure that a sequence number is not reused until the sender is “sure” that any previously sent packets with sequence number </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> are no longer in the network. This is done by assuming that a packet cannot “live” in the network for longer than some fixed maximum amount of time. A maximum packet lifetime of approximately three minutes is assumed in the TCP extensions for high-speed networks [RFC 7323]. [Sunshine 1978] describes a method for using sequence numbers such that reordering problems can be completely avoided.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">3.5 </span><span class="font24" style="font-weight:bold;">Connection-Oriented Transport: TCP</span></p></li></ul>
<p><span class="font53">Now that we have covered the underlying principles of reliable data transfer, let’s turn to TCP—the Internet’s transport-layer, connection-oriented, reliable transport protocol. In this section, we’ll see that in order to provide reliable data transfer, TCP relies on many of the underlying principles discussed in the previous section, including error detection, retransmissions, cumulative acknowledgments, timers, and header fields for sequence and acknowledgment numbers. TCP is defined in RFC 793, RFC 1122, RFC 2018, RFC 5681, and RFC 7323.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">3.5.1 </span><span class="font23" style="font-weight:bold;">The TCP Connection</span></p></li></ul>
<p><span class="font53">TCP is said to be </span><span class="font53" style="font-weight:bold;">connection-oriented </span><span class="font53">because before one application process can begin to send data to another, the two processes must first “handshake” with each other—that is, they must send some preliminary segments to each other to establish the parameters of the ensuing data transfer. As part of TCP connection establishment, both sides of the connection will initialize many TCP state variables (many of which will be discussed in this section and in Section 3.7) associated with the TCP connection.</span></p>
<p><span class="font53">The TCP “connection” is not an end-to-end TDM or FDM circuit as in a circuit-switched network. Instead, the “connection” is a logical one, with common state residing only in the TCPs in the two communicating end systems. Recall that because the TCP protocol runs only in the end systems and not in the intermediate network elements (routers and link-layer switches), the intermediate network elements do not maintain TCP connection state. In fact, the intermediate routers are completely oblivious to TCP connections; they see datagrams, not connections.</span></p>
<p><span class="font53">A TCP connection provides a </span><span class="font53" style="font-weight:bold;">full-duplex service</span><span class="font53">: If there is a TCP connection between Process A on one host and Process B on another host, then application-layer data can flow from Process A to Process B at the same time as application-layer data flows from Process B to Process A. A TCP connection is also always </span><span class="font53" style="font-weight:bold;">point-to-point</span><span class="font53">, that is, between a single sender and a single receiver. So-called “multicasting” (see the online supplementary materials for this text)—the transfer of data from one sender to many receivers in a single send operation—is not possible with TCP. With TCP, two hosts are company and three are a crowd!</span></p>
<p><a name="bookmark315"></a><span class="font53">Let’s now take a look at how a TCP connection is established. Suppose a process running in one host wants to initiate a connection with another process in another host. Recall that the process that is initiating the connection is called the </span><span class="font53" style="font-style:italic;">client process,</span><span class="font53"> while the other process is called the </span><span class="font53" style="font-style:italic;">server process.</span><span class="font53"> The client application process first informs the client transport layer that it wants to establish a connection</span></p>
<div><img src="networking_files/networking-198.jpg" alt="" style="width:168pt;height:22pt;">
</div><br clear="all">
<div>
<p><span class="font23" style="font-weight:bold;">CASE HISTORY</span></p>
</div><br clear="all">
<p><span class="font4" style="font-weight:bold;">VINTON CERF, ROBERT KAHN, AND TCP/IP</span></p>
<p><span class="font4">In the early 1970s, packet-switched networks began to proliferate, with the ARPAnet—the precursor of the Internet—being just one of many networks. Each of these networks had its own protocol. Two researchers, Vinton Cerf and Robert Kahn, recognized the importance of interconnecting these networks and invented a crossnetwork protocol called TCP/IP, which stands for Transmission Control Protocol/ Internet Protocol. Although Cerf and Kahn began by seeing the protocol as a single entity, it was later split into its two parts, TCP and IP, which operated separately. Cerf and Kahn published a paper on TCP/IP in May 1974 in </span><span class="font4" style="font-style:italic;">IEEE Transactions on Communications Technology</span><span class="font4"> [Cerf 1974].</span></p>
<p><span class="font4">The TCP/IP protocol, which is the bread and butter of today’s Internet, was devised before PCs, workstations, smartphones, and tablets, before the proliferation of Ethernet, cable, and DSL, WiFi, and other access network technologies, and before the Web, social media, and streaming video. Cerf and Kahn saw the need for a networking protocol that, on the one hand, provides broad support for yet-to-be-defined applications and, on the other hand, allows arbitrary hosts and link-layer protocols to interoperate.</span></p>
<p><span class="font4">In 2004, Cerf and Kahn received the ACM’s Turing Award, considered the “Nobel Prize of Computing” for “pioneering work on internetworking, including the design and implementation of the Internet’s basic communications protocols, TCP/IP, and for inspired leadership in networking.”</span></p>
<p><span class="font53">to a process in the server. Recall from Section 2.7.2, a Python client program does this by issuing the command</span></p>
<p><span class="font36">clientSocket.connect((serverName,serverPort))</span></p>
<p><span class="font53">where </span><span class="font36">serverName </span><span class="font53">is the name of the server and </span><span class="font36">serverPort </span><span class="font53">identifies the process on the server. TCP in the client then proceeds to establish a TCP connection with TCP in the server. At the end of this section we discuss in some detail the connection-establishment procedure. For now it suffices to know that the client first sends a special TCP segment; the server responds with a second special TCP segment; and finally the client responds again with a third special segment. The first two segments carry no payload, that is, no application-layer data; the third of these segments may carry a payload. Because three segments are sent between the two hosts, this connection-establishment procedure is often referred to as a </span><span class="font53" style="font-weight:bold;">three-way handshake</span><span class="font53">.</span></p>
<p><span class="font53">Once a TCP connection is established, the two application processes can send data to each other. Let’s consider the sending of data from the client process to the server process. The client process passes a stream of data through the socket (the door of the process), as described in Section 2.7. Once the data passes through the door, the data is in the hands of TCP running in the client. As shown in Figure 3.28, TCP directs this data to the connection’s </span><span class="font53" style="font-weight:bold;">send buffer</span><span class="font53">, which is one of the buffers that is set aside during the initial three-way handshake. From time to time, TCP will grab chunks of data from the send buffer and pass the data to the network layer. Interestingly, the TCP specification [RFC 793] is very laid back about specifying when TCP should actually send buffered data, stating that TCP should “send that data in segments at its own convenience.” The maximum amount of data that can be grabbed and placed in a segment is limited by the </span><span class="font53" style="font-weight:bold;">maximum segment size (MSS)</span><span class="font53">. The MSS is typically set by first determining the length of the largest link-layer frame that can be sent by the local sending host (the so-called </span><span class="font53" style="font-weight:bold;">maximum transmission unit, MTU</span><span class="font53">), and then setting the MSS to ensure that a TCP segment (when encapsulated in an IP datagram) plus the TCP/IP header length (typically 40 bytes) will fit into a single link-layer frame. Both Ethernet and PPP link-layer protocols have an MTU of 1,500 bytes. Thus, a typical value of MSS is 1460 bytes. Approaches have also been proposed for discovering the path MTU—the largest link-layer frame that can be sent on all links from source to destination [RFC 1191]—and setting the MSS based on the path MTU value. Note that the MSS is the maximum amount of application-layer data in the segment, not the maximum size of the TCP segment including headers. (This terminology is confusing, but we have to live with it, as it is well entrenched.)</span></p>
<p><span class="font53">TCP pairs each chunk of client data with a TCP header, thereby forming </span><span class="font53" style="font-weight:bold;">TCP segments</span><span class="font53">. The segments are passed down to the network layer, where they are separately encapsulated within network-layer IP datagrams. The IP datagrams are then sent into the network. When TCP receives a segment at the other end, the segment’s data is placed in the TCP connection’s receive buffer, as shown in Figure 3.28. The application reads the stream of data from this buffer. Each side of the connection has</span></p><img src="networking_files/networking-199.jpg" alt="" style="width:311pt;height:125pt;">
<p><span class="font7" style="font-weight:bold;">Figure 3.28 </span><span class="font50">♦ </span><span class="font5">TCP send and receive buffers</span></p>
<p><span class="font53">its own send buffer and its own receive buffer. (You can see the online flow-control interactive animation at</span><a href="http://www.awl.com/kurose-ross"><span class="font53"> http://www.awl.com/kurose-ross,</span></a><span class="font53"> which provides an animation of the send and receive buffers.)</span></p>
<p><span class="font53">We see from this discussion that a TCP connection consists of buffers, variables, and a socket connection to a process in one host, and another set of buffers, variables, and a socket connection to a process in another host. As mentioned earlier, no buffers or variables are allocated to the connection in the network elements (routers, switches, and repeaters) between the hosts.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">3.5.2 </span><span class="font23" style="font-weight:bold;">TCP Segment Structure</span></p></li></ul>
<p><span class="font53">Having taken a brief look at the TCP connection, let’s examine the TCP segment structure. The TCP segment consists of header fields and a data field. The data field contains a chunk of application data. As mentioned above, the MSS limits the maximum size of a segment’s data field. When TCP sends a large file, such as an image as part of a Web page, it typically breaks the file into chunks of size MSS (except for the last chunk, which will often be less than the MSS). Interactive applications, however, often transmit data chunks that are smaller than the MSS; for example, with remote login applications such as Telnet and ssh, the data field in the TCP segment is often only one byte. Because the TCP header is typically 20 bytes (12 bytes more than the UDP header), segments sent by Telnet and ssh may be only 21 bytes in length.</span></p>
<p><span class="font53">Figure 3.29 shows the structure of the TCP segment. As with UDP, the header includes </span><span class="font53" style="font-weight:bold;">source and destination port numbers</span><span class="font53">, which are used for multiplexing/ demultiplexing data from/to upper-layer applications. Also, as with UDP, the header includes a </span><span class="font53" style="font-weight:bold;">checksum field</span><span class="font53">. A TCP segment header also contains the following fields:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;The 32-bit </span><span class="font53" style="font-weight:bold;">sequence number field </span><span class="font53">and the 32-bit </span><span class="font53" style="font-weight:bold;">acknowledgment number field </span><span class="font53">are used by the TCP sender and receiver in implementing a reliable data transfer service, as discussed below.</span></p></li>
<li>
<p><span class="font53">• &nbsp;The 16-bit </span><span class="font53" style="font-weight:bold;">receive window </span><span class="font53">field is used for flow control. We will see shortly that it is used to indicate the number of bytes that a receiver is willing to accept.</span></p></li>
<li>
<p><span class="font53">• &nbsp;The 4-bit </span><span class="font53" style="font-weight:bold;">header length field </span><span class="font53">specifies the length of the TCP header in 32-bit words. The TCP header can be of variable length due to the TCP options field. (Typically, the options field is empty, so that the length of the typical TCP header is 20 bytes.)</span></p></li>
<li>
<p><span class="font53">• &nbsp;The optional and variable-length </span><span class="font53" style="font-weight:bold;">options field </span><span class="font53">is used when a sender and receiver negotiate the maximum segment size (MSS) or as a window scaling factor for use in high-speed networks. A time-stamping option is also defined. See RFC 854 and RFC 1323 for additional details.</span></p></li>
<li>
<p><a name="bookmark316"></a><span class="font53">• &nbsp;The </span><span class="font53" style="font-weight:bold;">flag field </span><span class="font53">contains 6 bits. The </span><span class="font53" style="font-weight:bold;">ACK bit </span><span class="font53">is used to indicate that the value carried in the acknowledgment field is valid; that is, the segment contains an acknowledgment for a segment that has been successfully received. The </span><span class="font53" style="font-weight:bold;">RST</span><span class="font53">,</span></p>
<div>
<p><span class="font4">32 bits</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Source port #</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Dest port #</span></p>
</div><br clear="all"></li></ul>
<p><span class="font4">Sequence number</span></p>
<p><span class="font4">Acknowledgment number</span></p>
<div>
<p><span class="font4">Header length</span></p><img src="networking_files/networking-200.jpg" alt="" style="width:112pt;height:45pt;">
</div><br clear="all">
<p><span class="font4">Receive window</span></p>
<p><span class="font4">Urgent data pointer</span></p>
<p><span class="font4">Options</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 3.29 </span><span class="font50">♦ </span><span class="font5">TCP segment structure</span></p>
<p><span class="font53" style="font-weight:bold;">SYN</span><span class="font53">, and </span><span class="font53" style="font-weight:bold;">FIN </span><span class="font53">bits are used for connection setup and teardown, as we will discuss at the end of this section. The CWR and ECE bits are used in explicit congestion notification, as discussed in Section 3.7.2. Setting the </span><span class="font53" style="font-weight:bold;">PSH </span><span class="font53">bit indicates that the receiver should pass the data to the upper layer immediately. Finally, the </span><span class="font53" style="font-weight:bold;">URG </span><span class="font53">bit is used to indicate that there is data in this segment that the sending-side upperlayer entity has marked as “urgent.” The location of the last byte of this urgent data is indicated by the 16-bit </span><span class="font53" style="font-weight:bold;">urgent data pointer field</span><span class="font53">. TCP must inform the receiving-side upper-layer entity when urgent data exists and pass it a pointer to the end of the urgent data. (In practice, the PSH, URG, and the urgent data pointer are not used. However, we mention these fields for completeness.)</span></p>
<p><span class="font53">Our experience as teachers is that our students sometimes find discussion of packet formats rather dry and perhaps a bit boring. For a fun and fanciful look at TCP header fields, particularly if you love Legos™ as we do, see [Pomeranz 2010].</span></p>
<p><span class="font22" style="font-weight:bold;">Sequence Numbers and Acknowledgment Numbers</span></p>
<p><span class="font53">Two of the most important fields in the TCP segment header are the sequence number field and the acknowledgment number field. These fields are a critical part of TCP’s reliable data transfer service. But before discussing how these fields are used to provide reliable data transfer, let us first explain what exactly TCP puts in these fields.</span></p><img src="networking_files/networking-201.jpg" alt="" style="width:336pt;height:109pt;">
<p><span class="font53">TCP views data as an unstructured, but ordered, stream of bytes. TCP’s use of sequence numbers reflects this view in that sequence numbers are over the stream of transmitted bytes and </span><span class="font53" style="font-style:italic;">not</span><span class="font53"> over the series of transmitted segments. The </span><span class="font53" style="font-weight:bold;">sequence number for a segment </span><span class="font53">is therefore the byte-stream number of the first byte in the segment. Let’s look at an example. Suppose that a process in Host A wants to send a stream of data to a process in Host B over a TCP connection. The TCP in Host A will implicitly number each byte in the data stream. Suppose that the data stream consists of a file consisting of 500,000 bytes, that the MSS is 1,000 bytes, and that the first byte of the data stream is numbered 0. As shown in Figure 3.30, TCP constructs 500 segments out of the data stream. The first segment gets assigned sequence number 0, the second segment gets assigned sequence number 1,000, the third segment gets assigned sequence number 2,000, and so on. Each sequence number is inserted in the sequence number field in the header of the appropriate TCP segment.</span></p>
<p><span class="font53">Now let’s consider acknowledgment numbers. These are a little trickier than sequence numbers. Recall that TCP is full-duplex, so that Host A may be receiving data from Host B while it sends data to Host B (as part of the same TCP connection). Each of the segments that arrive from Host B has a sequence number for the data flowing from B to A. </span><span class="font53" style="font-style:italic;">The acknowledgment number that Host A puts in its segment is the sequence number of the next byte Host A is expecting from Host B.</span><span class="font53"> It is good to look at a few examples to understand what is going on here. Suppose that Host A has received all bytes numbered 0 through 535 from B and suppose that it is about to send a segment to Host B. Host A is waiting for byte 536 and all the subsequent bytes in Host B’s data stream. So Host A puts 536 in the acknowledgment number field of the segment it sends to B.</span></p>
<p><span class="font53">As another example, suppose that Host A has received one segment from Host B containing bytes 0 through 535 and another segment containing bytes 900 through 1,000. For some reason Host A has not yet received bytes 536 through 899. In this example, Host A is still waiting for byte 536 (and beyond) in order to re-create B’s data stream. Thus, A’s next segment to B will contain 536 in the acknowledgment number field. Because TCP only acknowledges bytes up to the first missing byte in the stream, TCP is said to provide </span><span class="font53" style="font-weight:bold;">cumulative acknowledgments</span><span class="font53">.</span></p>
<p><span class="font53">This last example also brings up an important but subtle issue. Host A received the third segment (bytes 900 through 1,000) before receiving the second segment (bytes 536 through 899). Thus, the third segment arrived out of order. The subtle issue is: What does a host do when it receives out-of-order segments in a TCP connection? Interestingly, the TCP RFCs do not impose any rules here and leave the decision up to the programmers implementing a TCP implementation. There are basically two choices: either (1) the receiver immediately discards out-of-order segments (which, as we discussed earlier, can simplify receiver design), or (2) the receiver keeps the out-of-order bytes and waits for the missing bytes to fill in the gaps. Clearly, the latter choice is more efficient in terms of network bandwidth, and is the approach taken in practice.</span></p>
<p><span class="font53">In Figure 3.30, we assumed that the initial sequence number was zero. In truth, both sides of a TCP connection randomly choose an initial sequence number. This is done to minimize the possibility that a segment that is still present in the network from an earlier, already-terminated connection between two hosts is mistaken for a valid segment in a later connection between these same two hosts (which also happen to be using the same port numbers as the old connection) [Sunshine 1978].</span></p>
<p><span class="font22" style="font-weight:bold;">Telnet: A Case Study for Sequence and Acknowledgment Numbers</span></p>
<p><span class="font53">Telnet, defined in RFC 854, is a popular application-layer protocol used for remote login. It runs over TCP and is designed to work between any pair of hosts. Unlike the bulk data transfer applications discussed in Chapter 2, Telnet is an interactive application. We discuss a Telnet example here, as it nicely illustrates TCP sequence and acknowledgment numbers. We note that many users now prefer to use the SSH protocol rather than Telnet, since data sent in a Telnet connection (including passwords!) are not encrypted, making Telnet vulnerable to eavesdropping attacks (as discussed in Section 8.7).</span></p>
<p><span class="font53">Suppose Host A initiates a Telnet session with Host B. Because Host A initiates the session, it is labeled the client, and Host B is labeled the server. Each character typed by the user (at the client) will be sent to the remote host; the remote host will send back a copy of each character, which will be displayed on the Telnet user’s screen. This “echo back” is used to ensure that characters seen by the Telnet user have already been received and processed at the remote site. Each character thus traverses the network twice between the time the user hits the key and the time the character is displayed on the user’s monitor.</span></p>
<p><span class="font53">Now suppose the user types a single letter, ‘C,’ and then grabs a coffee. Let’s examine the TCP segments that are sent between the client and server. As shown in Figure 3.31, we suppose the starting sequence numbers are 42 and 79 for the client and server, respectively. Recall that the sequence number of a segment is the sequence number of the first byte in the data field. Thus, the first segment sent from the client will have sequence number 42; the first segment sent from the server will have sequence number 79. Recall that the acknowledgment number is the sequence</span></p>
<div>
<p><span class="font4" style="font-weight:bold;">Host A</span></p><img src="networking_files/networking-202.jpg" alt="" style="width:35pt;height:37pt;">
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Host B</span></p><img src="networking_files/networking-203.jpg" alt="" style="width:34pt;height:37pt;">
</div><br clear="all">
<div>
<p><span class="font4">User types </span><span class="font34">'C'</span></p><img src="networking_files/networking-204.jpg" alt="" style="width:160pt;height:113pt;">
<p><span class="font4">Host ACKs receipt of </span><span class="font34">'C'</span><span class="font4">, echoes back </span><span class="font34">'C'</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Host ACKs</span></p>
<p><span class="font4">receipt of</span></p><img src="networking_files/networking-205.jpg" alt="" style="width:213pt;height:76pt;">
<p><span class="font7" style="font-weight:bold;">Figure 3.31 </span><span class="font50">♦ </span><span class="font5">Sequence and acknowledgment numbers for a simple Telnet application over TCP</span></p>
</div><br clear="all">
<p><span class="font53">number of the next byte of data that the host is waiting for. After the TCP connection is established but before any data is sent, the client is waiting for byte 79 and the server is waiting for byte 42.</span></p>
<p><span class="font53">As shown in Figure 3.31, three segments are sent. The first segment is sent from the client to the server, containing the 1-byte ASCII representation of the letter ‘C’ in its data field. This first segment also has 42 in its sequence number field, as we just described. Also, because the client has not yet received any data from the server, this first segment will have 79 in its acknowledgment number field.</span></p>
<p><span class="font53">The second segment is sent from the server to the client. It serves a dual purpose. First it provides an acknowledgment of the data the server has received. By putting 43 in the acknowledgment field, the server is telling the client that it has successfully received everything up through byte 42 and is now waiting for bytes 43 onward. The second purpose of this segment is to echo back the letter ‘C.’ Thus, the second segment has the ASCII representation of ‘C’ in its data field. This second segment has the sequence number 79, the initial sequence number of the server-to-client data flow of this TCP connection, as this is the very first byte of data that the server is sending. Note that the acknowledgment for client-to-server data is carried in a segment carrying server-to-client data; this acknowledgment is said to be </span><span class="font53" style="font-weight:bold;">piggybacked </span><span class="font53">on the server-to-client data segment.</span></p>
<p><span class="font53">The third segment is sent from the client to the server. Its sole purpose is to acknowledge the data it has received from the server. (Recall that the second segment contained data—the letter ‘C’—from the server to the client.) This segment has an empty data field (that is, the acknowledgment is not being piggybacked with any client-to-server data). The segment has 80 in the acknowledgment number field because the client has received the stream of bytes up through byte sequence number 79 and it is now waiting for bytes 80 onward. You might think it odd that this segment also has a sequence number since the segment contains no data. But because TCP has a sequence number field, the segment needs to have some sequence number.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">3.5.3 </span><span class="font23" style="font-weight:bold;">Round-Trip Time Estimation and Timeout</span></p></li></ul>
<p><span class="font53">TCP, like our </span><span class="font36">rdt </span><span class="font53">protocol in Section 3.4, uses a timeout/retransmit mechanism to recover from lost segments. Although this is conceptually simple, many subtle issues arise when we implement a timeout/retransmit mechanism in an actual protocol such as TCP. Perhaps the most obvious question is the length of the timeout intervals. Clearly, the timeout should be larger than the connection’s round-trip time (RTT), that is, the time from when a segment is sent until it is acknowledged. Otherwise, unnecessary retransmissions would be sent. But how much larger? How should the RTT be estimated in the first place? Should a timer be associated with each and every unacknowledged segment? So many questions! Our discussion in this section is based on the TCP work in [Jacobson 1988] and the current IETF recommendations for managing TCP timers [RFC 6298].</span></p>
<p><span class="font22" style="font-weight:bold;">Estimating the Round-Trip Time</span></p>
<p><span class="font53">Let’s begin our study of TCP timer management by considering how TCP estimates the round-trip time between sender and receiver. This is accomplished as follows. The sample RTT, denoted </span><span class="font36">SampleRTT</span><span class="font53">, for a segment is the amount of time between when the segment is sent (that is, passed to IP) and when an acknowledgment for the segment is received. Instead of measuring a </span><span class="font36">SampleRTT </span><span class="font53">for every transmitted segment, most TCP implementations take only one </span><span class="font36">SampleRTT </span><span class="font53">measurement at a time. That is, at any point in time, the </span><span class="font36">SampleRTT </span><span class="font53">is being estimated for only one of the transmitted but currently unacknowledged segments, leading to a new value of </span><span class="font36">SampleRTT </span><span class="font53">approximately once every RTT. Also, TCP never computes a </span><span class="font36">SampleRTT </span><span class="font53">for a segment that has been retransmitted; it only measures </span><span class="font36">SampleRTT </span><span class="font53">for segments that have been transmitted once [Karn 1987]. (A problem at the end of the chapter asks you to consider why.)</span></p>
<p><a name="bookmark317"></a><span class="font53">Obviously, the </span><span class="font36">SampleRTT </span><span class="font53">values will fluctuate from segment to segment due to congestion in the routers and to the varying load on the end systems. Because of this fluctuation, any given </span><span class="font36">SampleRTT </span><span class="font53">value may be atypical. In order to estimate a typical RTT, it is therefore natural to take some sort of average of the </span><span class="font36">SampleRTT </span><span class="font53">values. TCP maintains an average, called </span><span class="font36">EstimatedRTT</span><span class="font53">, of the </span><span class="font36">SampleRTT </span><span class="font53">values. Upon obtaining a new </span><span class="font36">SampleRTT</span><span class="font53">, TCP updates </span><span class="font36">EstimatedRTT </span><span class="font53">according to the following formula:</span></p>
<p><span class="font36">EstimatedRTT = (1 - </span><span class="font54">a</span><span class="font36">) </span><span class="font60">•</span><span class="font36">EstimatedRTT + </span><span class="font54">a </span><span class="font60">•</span><span class="font36">SampleRTT</span></p>
<p><span class="font53">The formula above is written in the form of a programming-language state-ment—the new value of </span><span class="font53" style="font-weight:bold;">EstimatedRTT </span><span class="font53">is a weighted combination of the previous value of </span><span class="font53" style="font-weight:bold;">EstimatedRTT </span><span class="font53">and the new value for </span><span class="font53" style="font-weight:bold;">SampleRTT</span><span class="font53">. The recommended value of </span><span class="font54">a </span><span class="font53">is </span><span class="font54">a </span><span class="font53">= 0.125 (that is, 1/8) [RFC 6298], in which case the formula above becomes:</span></p>
<p><span class="font36">EstimatedRTT = 0.875</span><span class="font60">•</span><span class="font36">EstimatedRTT + 0.125</span><span class="font60">•</span><span class="font36">SampleRTT</span></p>
<p><span class="font53">Note that </span><span class="font53" style="font-weight:bold;">EstimatedRTT </span><span class="font53">is a weighted average of the </span><span class="font53" style="font-weight:bold;">SampleRTT </span><span class="font53">values. As discussed in a homework problem at the end of this chapter, this weighted average puts more weight on recent samples than on old samples. This is natural, as the more recent samples better reflect the current congestion in the network. In statistics, such an average is called an </span><span class="font53" style="font-weight:bold;">exponential weighted moving average (EWMA)</span><span class="font53">. The word “exponential” appears in EWMA because the weight of a given </span><span class="font36">SampleRTT </span><span class="font53">decays exponentially fast as the updates proceed. In the homework problems, you will be asked to derive the exponential term in </span><span class="font36">EstimatedRTT</span><span class="font53">.</span></p>
<p><span class="font53">Figure 3.32 shows the </span><span class="font36">SampleRTT </span><span class="font53">values and </span><span class="font36">EstimatedRTT </span><span class="font53">for a value of </span><span class="font54">a </span><span class="font53">= 1/8 for a TCP connection between </span><a href="http://gaia.cs.umass.edu"><span class="font36">gaia.cs.umass.edu </span></a><span class="font53">(in Amherst, Massachusetts) to</span><a href="http://fantasia.eurecom.fr"><span class="font53"> </span><span class="font36">fantasia.eurecom.fr </span></a><span class="font53">(in the south of France). Clearly, the variations in the </span><span class="font36">SampleRTT </span><span class="font53">are smoothed out in the computation of the </span><span class="font36">EstimatedRTT</span><span class="font53">.</span></p>
<p><span class="font53">In addition to having an estimate of the RTT, it is also valuable to have a measure of the variability of the RTT. [RFC 6298] defines the RTT variation, </span><span class="font36">DevRTT</span><span class="font53">, as an estimate of how much </span><span class="font36">SampleRTT </span><span class="font53">typically deviates from </span><span class="font36">EstimatedRTT</span><span class="font53">:</span></p>
<p><span class="font36">DevRTT = (1 - </span><span class="font54">p</span><span class="font36">) </span><span class="font60">•</span><span class="font36">DevRTT + </span><span class="font54">p</span><span class="font60">• </span><span class="font36">| SampleRTT - EstimatedRTT |</span></p>
<p><span class="font53">Note that </span><span class="font36">DevRTT </span><span class="font53">is an EWMA of the difference between </span><span class="font36">SampleRTT </span><span class="font53">and </span><span class="font36">EstimatedRTT</span><span class="font53">. If the </span><span class="font36">SampleRTT </span><span class="font53">values have little fluctuation, then </span><span class="font36">DevRTT </span><span class="font53">will be small; on the other hand, if there is a lot of fluctuation, </span><span class="font36">DevRTT </span><span class="font53">will be large. The recommended value of </span><span class="font54">p </span><span class="font53">is 0.25.</span></p>
<p><span class="font22" style="font-weight:bold;">Setting and Managing the Retransmission Timeout Interval</span></p>
<p><span class="font53">Given values of </span><span class="font36">EstimatedRTT </span><span class="font53">and </span><span class="font36">DevRTT</span><span class="font53">, what value should be used for TCP’s timeout interval? Clearly, the interval should be greater than or equal to</span></p>
<div><img src="networking_files/networking-206.jpg" alt="" style="width:131pt;height:21pt;">
</div><br clear="all">
<div>
<p><span class="font23" style="font-weight:bold;">PRINCIPLES IN PRACTICE</span></p>
</div><br clear="all">
<p><span class="font4">TCP provides reliable data transfer by using positive acknowledgments and timers in much the same way that we studied in Section 3.4. TCP acknowledges data that has been received correctly, and it then retransmits segments when segments or their corresponding acknowledgments are thought to be lost or corrupted. Certain versions of TCP also have an implicit NAK mechanism—with TCP’s fast retransmit mechanism, the receipt of three duplicate ACKs for a given segment serves as an implicit NAK for the following segment, triggering retransmission of that segment before timeout. TCP uses sequences of numbers to allow the receiver to identify lost or duplicate segments. Just as in the case of our reliable data transfer protocol, </span><span class="font34">rdt3.0</span><span class="font4">, TCP cannot itself tell for certain if a segment, or its ACK, is lost, corrupted, or overly delayed. At the sender, TCP’s response will be the same: retransmit the segment in question.</span></p>
<p><span class="font4">TCP also uses pipelining, allowing the sender to have multiple transmitted but yet-to-be-acknowledged segments outstanding at any given time. We saw earlier that pipelining can greatly improve a session’s throughput when the ratio of the segment size to roundtrip delay is small. The specific number of outstanding, unacknowledged segments that a sender can have is determined by TCP’s flow-control and congestion-control mechanisms. TCP flow control is discussed at the end of this section; TCP congestion control is discussed in Section 3.7. For the time being, we must simply be aware that the TCP sender uses pipelining.</span></p>
<p><span class="font36">EstimatedRTT</span><span class="font53">, or unnecessary retransmissions would be sent. But the timeout interval should not be too much larger than </span><span class="font36">EstimatedRTT</span><span class="font53">; otherwise, when a segment is lost, TCP would not quickly retransmit the segment, leading to large data transfer delays. It is therefore desirable to set the timeout equal to the </span><span class="font36">EstimatedRTT </span><span class="font53">plus some margin. The margin should be large when there is a lot of fluctuation in the </span><span class="font36">SampleRTT </span><span class="font53">values; it should be small when there is little fluctuation. The value of </span><span class="font36">DevRTT </span><span class="font53">should thus come into play here. All of these considerations are taken into account in TCP’s method for determining the retransmission timeout interval:</span></p>
<p><span class="font36">Timeoutinterval = EstimatedRTT + 4</span><span class="font60">•</span><span class="font36">DevRTT</span></p>
<p><span class="font53">An initial </span><span class="font36">Timeoutinterval </span><span class="font53">value of 1 second is recommended [RFC 6298]. Also, when a timeout occurs, the value of </span><span class="font36">Timeoutinterval </span><span class="font53">is doubled to avoid a premature timeout occurring for a subsequent segment that will soon be acknowledged. However, as soon as a segment is received and </span><span class="font36">EstimatedRTT </span><span class="font53">is updated, the </span><span class="font36">Timeoutinterval </span><span class="font53">is again computed using the formula above.</span></p>
<p><span class="font4">RTT (milliseconds)</span></p><img src="networking_files/networking-207.jpg" alt="" style="width:377pt;height:231pt;">
<p><span class="font7" style="font-weight:bold;">Figure 3.32 </span><span class="font50">♦ </span><span class="font5">RTT samples and RTT estimates</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">3.5.4 </span><span class="font23" style="font-weight:bold;">Reliable Data Transfer</span></p></li></ul>
<p><span class="font53">Recall that the Internet’s network-layer service (IP service) is unreliable. IP does not guarantee datagram delivery, does not guarantee in-order delivery of datagrams, and does not guarantee the integrity of the data in the datagrams. With IP service, datagrams can overflow router buffers and never reach their destination, datagrams can arrive out of order, and bits in the datagram can get corrupted (flipped from 0 to 1 and vice versa). Because transport-layer segments are carried across the network by IP datagrams, transport-layer segments can suffer from these problems as well.</span></p>
<p><span class="font53">TCP creates a </span><span class="font53" style="font-weight:bold;">reliable data transfer service </span><span class="font53">on top of IP’s unreliable besteffort service. TCP’s reliable data transfer service ensures that the data stream that a process reads out of its TCP receive buffer is uncorrupted, without gaps, without duplication, and in sequence; that is, the byte stream is exactly the same byte stream that was sent by the end system on the other side of the connection. How TCP provides a reliable data transfer involves many of the principles that we studied in Section 3.4.</span></p>
<p><a name="bookmark318"></a><span class="font53">In our earlier development of reliable data transfer techniques, it was conceptually easiest to assume that an individual timer is associated with each transmitted but not yet acknowledged segment. While this is great in theory, timer management can require considerable overhead. Thus, the recommended TCP timer management procedures [RFC 6298] use only a </span><span class="font53" style="font-style:italic;">single</span><span class="font53"> retransmission timer, even if there are multiple transmitted but not yet acknowledged segments. The TCP protocol described in this section follows this single-timer recommendation.</span></p>
<p><span class="font53">We will discuss how TCP provides reliable data transfer in two incremental steps. We first present a highly simplified description of a TCP sender that uses only timeouts to recover from lost segments; we then present a more complete description that uses duplicate acknowledgments in addition to timeouts. In the ensuing discussion, we suppose that data is being sent in only one direction, from Host A to Host B, and that Host A is sending a large file.</span></p>
<p><span class="font53">Figure 3.33 presents a highly simplified description of a TCP sender. We see that there are three major events related to data transmission and retransmission in the TCP sender: data received from application above; timer timeout; and ACK</span></p>
<p><span class="font33">/* Assume sender is not constrained by TCP flow or congestion control, that data from above is less than MSS in size, and that data transfer is in one direction only. */</span></p>
<p><span class="font33">NextSeqNum=InitialSeqNumber SendBase=InitialSeqNumber loop (forever) { switch(event)</span></p>
<p><span class="font33">event: data received from application above create TCP segment with sequence number NextSeqNum if (timer currently not running) start timer pass segment to IP NextSeqNum=NextSeqNum+length(data) break; event: timer timeout retransmit not-yet-acknowledged segment with smallest sequence number start timer break;</span></p>
<p><span class="font33">event: ACK received, with ACK field value of y if (y &gt;&nbsp;SendBase) { SendBase=y if (there are currently any not-yet-acknowledged segments) start timer } break;</span></p>
<p><span class="font33">} /* end of loop forever */</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 3.33 </span><span class="font50">♦ </span><span class="font5">Simplified TCP sender </span><span class="font53">receipt. Upon the occurrence of the first major event, TCP receives data from the application, encapsulates the data in a segment, and passes the segment to IP. Note that each segment includes a sequence number that is the byte-stream number of the first data byte in the segment, as described in Section 3.5.2. Also note that if the timer is already not running for some other segment, TCP starts the timer when the segment is passed to IP. (It is helpful to think of the timer as being associated with the oldest unacknowledged segment.) The expiration interval for this timer is the </span><span class="font36">Timeoutinterval</span><span class="font53">, which is calculated from </span><span class="font36">EstimatedRTT </span><span class="font53">and </span><span class="font36">DevRTT</span><span class="font53">, as described in Section 3.5.3.</span></p>
<p><span class="font53">The second major event is the timeout. TCP responds to the timeout event by retransmitting the segment that caused the timeout. TCP then restarts the timer.</span></p>
<p><span class="font53">The third major event that must be handled by the TCP sender is the arrival of an acknowledgment segment (ACK) from the receiver (more specifically, a segment containing a valid ACK field value). On the occurrence of this event, TCP compares the ACK value </span><span class="font36">y </span><span class="font53">with its variable </span><span class="font36">SendBase</span><span class="font53">. The TCP state variable </span><span class="font36">SendBase </span><span class="font53">is the sequence number of the oldest unacknowledged byte. (Thus </span><span class="font36">SendBase-1 </span><span class="font53">is the sequence number of the last byte that is known to have been received correctly and in order at the receiver.) As indicated earlier, TCP uses cumulative acknowledgments, so that </span><span class="font36">y </span><span class="font53">acknowledges the receipt of all bytes before byte number </span><span class="font36">y</span><span class="font53">. If </span><span class="font36">y &gt;&nbsp;Sen dBase</span><span class="font53">, then the ACK is acknowledging one or more previously unacknowledged segments. Thus the sender updates its </span><span class="font36">SendBase </span><span class="font53">variable; it also restarts the timer if there currently are any not-yet-acknowledged segments.</span></p>
<p><span class="font22" style="font-weight:bold;">A Few Interesting Scenarios</span></p>
<p><span class="font53">We have just described a highly simplified version of how TCP provides reliable data transfer. But even this highly simplified version has many subtleties. To get a good feeling for how this protocol works, let’s now walk through a few simple scenarios. Figure 3.34 depicts the first scenario, in which Host A sends one segment to Host B. Suppose that this segment has sequence number 92 and contains 8 bytes of data. After sending this segment, Host A waits for a segment from B with acknowledgment number 100. Although the segment from A is received at B, the acknowledgment from B to A gets lost. In this case, the timeout event occurs, and Host A retransmits the same segment. Of course, when Host B receives the retransmission, it observes from the sequence number that the segment contains data that has already been received. Thus, TCP in Host B will discard the bytes in the retransmitted segment.</span></p>
<p><span class="font53">In a second scenario, shown in Figure 3.35, Host A sends two segments back to back. The first segment has sequence number 92 and 8 bytes of data, and the second segment has sequence number 100 and 20 bytes of data. Suppose that both segments arrive intact at B, and B sends two separate acknowledgments for each of these segments. The first of these acknowledgments has acknowledgment number 100; the second has acknowledgment number 120. Suppose now that neither of the acknowledgments arrives at Host A before the timeout. When the timeout event occurs, Host</span></p>
<p><span class="font4" style="font-weight:bold;">Host A &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Host B</span></p><img src="networking_files/networking-208.jpg" alt="" style="width:194pt;height:37pt;"><img src="networking_files/networking-209.jpg" alt="" style="width:215pt;height:202pt;">
<p><span class="font7" style="font-weight:bold;">Figure 3.34 </span><span class="font50">♦ </span><span class="font5">Retransmission due to a lost acknowledgment</span></p>
<p><span class="font53">A resends the first segment with sequence number 92 and restarts the timer. As long as the ACK for the second segment arrives before the new timeout, the second segment will not be retransmitted.</span></p>
<p><span class="font53">In a third and final scenario, suppose Host A sends the two segments, exactly as in the second example. The acknowledgment of the first segment is lost in the network, but just before the timeout event, Host A receives an acknowledgment with acknowledgment number 120. Host A therefore knows that Host B has received </span><span class="font53" style="font-style:italic;">everything</span><span class="font53"> up through byte 119; so Host A does not resend either of the two segments. This scenario is illustrated in Figure 3.36.</span></p>
<p><span class="font22" style="font-weight:bold;">Doubling the Timeout Interval</span></p>
<p><span class="font53">We now discuss a few modifications that most TCP implementations employ. The first concerns the length of the timeout interval after a timer expiration. In this modification, whenever the timeout event occurs, TCP retransmits the not-yet-acknowl-edged segment with the smallest sequence number, as described above. But each time TCP retransmits, it sets the next timeout interval to twice the previous value,</span></p>
<p><span class="font4" style="font-weight:bold;">Host A &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Host B</span></p>
<div><img src="networking_files/networking-210.jpg" alt="" style="width:34pt;height:37pt;">
</div><br clear="all">
<div><img src="networking_files/networking-211.jpg" alt="" style="width:35pt;height:37pt;">
</div><br clear="all">
<div><img src="networking_files/networking-212.jpg" alt="" style="width:294pt;height:218pt;">
<p><span class="font7" style="font-weight:bold;">Figure 3.35 </span><span class="font50">♦ </span><span class="font5">Segment 100 not retransmitted</span></p>
</div><br clear="all">
<div>
<p><span class="font53">rather than deriving it from the last </span><span class="font36">EstimatedRTT </span><span class="font53">and </span><span class="font36">DevRTT </span><span class="font53">(as described in Section 3.5.3). For example, suppose </span><span class="font36">Timeoutinterval </span><span class="font53">associated with the oldest not yet acknowledged segment is .75 sec when the timer first expires. TCP will then retransmit this segment and set the new expiration time to 1.5 sec. If the timer expires again 1.5 sec later, TCP will again retransmit this segment, now setting the expiration time to 3.0 sec. Thus, the intervals grow exponentially after each retransmission. However, whenever the timer is started after either of the two other events (that is, data received from application above, and ACK received), the </span><span class="font36">Timeoutinterval </span><span class="font53">is derived from the most recent values of </span><span class="font36">EstimatedRTT </span><span class="font53">and </span><span class="font36">DevRTT</span><span class="font53">.</span></p>
<p><span class="font53">This modification provides a limited form of congestion control. (More comprehensive forms of TCP congestion control will be studied in Section 3.7.) The timer expiration is most likely caused by congestion in the network, that is, too many packets arriving at one (or more) router queues in the path between the source and destination, causing packets to be dropped and/or long queuing delays. In times of congestion, if the sources continue to retransmit packets persistently, the congestion</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Host A</span></p><img src="networking_files/networking-213.jpg" alt="" style="width:34pt;height:37pt;">
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Host B</span></p><img src="networking_files/networking-214.jpg" alt="" style="width:34pt;height:37pt;">
</div><br clear="all">
<div><img src="networking_files/networking-215.jpg" alt="" style="width:286pt;height:122pt;">
</div><br clear="all">
<p><span class="font4">Time</span></p>
<div>
<p><span class="font4">Time</span></p>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 3.36 </span><span class="font50">♦ </span><span class="font5">A cumulative acknowledgment avoids retransmission of the first segment</span></p>
<p><span class="font53">may get worse. Instead, TCP acts more politely, with each sender retransmitting after longer and longer intervals. We will see that a similar idea is used by Ethernet when we study CSMA/CD in Chapter 6.</span></p>
<p><span class="font22" style="font-weight:bold;">Fast Retransmit</span></p>
<p><span class="font53">One of the problems with timeout-triggered retransmissions is that the timeout period can be relatively long. When a segment is lost, this long timeout period forces the sender to delay resending the lost packet, thereby increasing the end-to-end delay. Fortunately, the sender can often detect packet loss well before the timeout event occurs by noting so-called duplicate ACKs. A </span><span class="font53" style="font-weight:bold;">duplicate ACK </span><span class="font53">is an ACK that reacknowledges a segment for which the sender has already received an earlier acknowledgment. To understand the sender’s response to a duplicate ACK, we must look at why the receiver sends a duplicate ACK in the first place. Table 3.2 summarizes the TCP receiver’s ACK generation policy [RFC 5681]. When a TCP receiver receives</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Event</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">TCP Receiver Action</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Arrival of in-order segment with expected sequence number. All data up to expected sequence number already acknowledged.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Delayed ACK. Wait up to 500 msec for arrival of another in-order segment. If next in-order segment does not arrive in this interval, send an ACK.</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Arrival of in-order segment with expected sequence number. One other in-order segment waiting for ACK transmission.</span></p></td><td>
<p><span class="font6">Immediately send single cumulative ACK, ACKing both in-order segments.</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Arrival of out-of-order segment with higher-than-expected sequence number. Gap detected.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Immediately send duplicate ACK, indicating sequence number of next expected byte (which is the lower end of the gap).</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Arrival of segment that partially or completely fills in gap in received data.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Immediately send ACK, provided that segment starts at the lower end of gap.</span></p></td></tr>
</table>
<p><span class="font7" style="font-weight:bold;">Table 3.2 </span><span class="font50">♦ </span><span class="font5">TCP ACK Generation Recommendation [RFC 5681]</span></p>
<p><span class="font53">a segment with a sequence number that is larger than the next, expected, in-order sequence number, it detects a gap in the data stream—that is, a missing segment. This gap could be the result of lost or reordered segments within the network. Since TCP does not use negative acknowledgments, the receiver cannot send an explicit negative acknowledgment back to the sender. Instead, it simply reacknowledges (that is, generates a duplicate ACK for) the last in-order byte of data it has received. (Note that Table 3.2 allows for the case that the receiver does not discard out-oforder segments.)</span></p>
<p><span class="font53">Because a sender often sends a large number of segments back to back, if one segment is lost, there will likely be many back-to-back duplicate ACKs. If the TCP sender receives three duplicate ACKs for the same data, it takes this as an indication that the segment following the segment that has been ACKed three times has been lost. (In the homework problems, we consider the question of why the sender waits for three duplicate ACKs, rather than just a single duplicate ACK.) In the case that three duplicate ACKs are received, the TCP sender performs a </span><span class="font53" style="font-weight:bold;">fast retransmit </span><span class="font53">[RFC 5681], retransmitting the missing segment </span><span class="font53" style="font-style:italic;">before</span><span class="font53"> that segment’s timer expires. This is shown in Figure 3.37, where the second segment is lost, then retransmitted before its timer expires. For TCP with fast retransmit, the following code snippet replaces the ACK received event in Figure 3.33:</span></p>
<p><span class="font36">event: ACK received, with ACK field value of y</span></p>
<p><span class="font36">if (y &gt;&nbsp;SendBase) {</span></p>
<p><span class="font36">SendBase=y</span></p>
<p><span class="font36">if (there are currently any not yet acknowledged segments) start timer</span></p>
<p><span class="font36">}</span></p>
<div>
<p><span class="font4">Timeout-</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Host A</span></p>
<p><span class="font4" style="font-weight:bold;">Host B</span></p><img src="networking_files/networking-216.jpg" alt="" style="width:184pt;height:270pt;">
<p><span class="font34">ack=100</span></p>
<p><span class="font34">ack=100</span></p>
<p><span class="font34">ack=100</span></p>
<p><span class="font34">ack=100</span></p>
<p><span class="font4">Time</span></p>
<p><span class="font4">Time</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 3.37 </span><span class="font50">♦ </span><span class="font5">Fast retransmit: retransmitting the missing segment before the segment's timer expires</span></p>
</div><br clear="all">
<p><span class="font36">else {/* a duplicate ACK for already ACKed segment */ increment number of duplicate ACKs received for y</span></p>
<p><span class="font36">if (number of duplicate ACKS received for y==3)</span></p>
<p><span class="font36">/* TCP fast retransmit */</span></p>
<p><span class="font36">resend segment with sequence number y }</span></p>
<p><span class="font36">break;</span></p>
<p><span class="font53">We noted earlier that many subtle issues arise when a timeout/retransmit mechanism is implemented in an actual protocol such as TCP. The procedures above, which have evolved as a result of more than 30 years of experience with TCP timers, should convince you that this is indeed the case!</span></p>
<p><span class="font22" style="font-weight:bold;">Go-Back-N or Selective Repeat?</span></p>
<p><span class="font53">Let us close our study of TCP’s error-recovery mechanism by considering the following question: Is TCP a GBN or an SR protocol? Recall that TCP acknowledgments are cumulative and correctly received but out-of-order segments are not individually ACKed by the receiver. Consequently, as shown in Figure 3.33 (see also Figure 3.19), the TCP sender need only maintain the smallest sequence number of a transmitted but unacknowledged byte (</span><span class="font36">SendBase</span><span class="font53">) and the sequence number of the next byte to be sent (</span><span class="font36">NextSeqNum</span><span class="font53">). In this sense, TCP looks a lot like a GBN-style protocol. But there are some striking differences between TCP and Go-Back-N. Many TCP implementations will buffer correctly received but out-of-order segments [Stevens 1994]. Consider also what happens when the sender sends a sequence of segments 1, 2, . . . , </span><span class="font53" style="font-style:italic;">N,</span><span class="font53"> and all of the segments arrive in order without error at the receiver. Further suppose that the acknowledgment for packet </span><span class="font53" style="font-style:italic;">n</span><span class="font55"> &lt;&nbsp;</span><span class="font53" style="font-style:italic;">N </span><span class="font53">gets lost, but the remaining </span><span class="font53" style="font-style:italic;">N —</span><span class="font53"> 1 acknowledgments arrive at the sender before their respective timeouts. In this example, GBN would retransmit not only packet </span><span class="font53" style="font-style:italic;">n, </span><span class="font53">but also all of the subsequent packets </span><span class="font53" style="font-style:italic;">n</span><span class="font55"> + </span><span class="font53">1, </span><span class="font53" style="font-style:italic;">n</span><span class="font55"> + </span><span class="font53">2, . . . , </span><span class="font53" style="font-style:italic;">N</span><span class="font53">. TCP, on the other hand, would retransmit at most one segment, namely, segment </span><span class="font53" style="font-style:italic;">n</span><span class="font53">. Moreover, TCP would not even retransmit segment </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> if the acknowledgment for segment </span><span class="font53" style="font-style:italic;">n</span><span class="font55"> + </span><span class="font53">1 arrived before the timeout for segment </span><span class="font53" style="font-style:italic;">n</span><span class="font53">.</span></p>
<p><span class="font53">A proposed modification to TCP, the so-called </span><span class="font53" style="font-weight:bold;">selective acknowledgment </span><span class="font53">[RFC 2018], allows a TCP receiver to acknowledge out-of-order segments selectively rather than just cumulatively acknowledging the last correctly received, in-order segment. When combined with selective retransmission—skipping the retransmission of segments that have already been selectively acknowledged by the receiver— TCP looks a lot like our generic SR protocol. Thus, TCP’s error-recovery mechanism is probably best categorized as a hybrid of GBN and SR protocols.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">3.5.5 </span><span class="font23" style="font-weight:bold;">Flow Control</span></p></li></ul>
<p><span class="font53">Recall that the hosts on each side of a TCP connection set aside a receive buffer for the connection. When the TCP connection receives bytes that are correct and in sequence, it places the data in the receive buffer. The associated application process will read data from this buffer, but not necessarily at the instant the data arrives. Indeed, the receiving application may be busy with some other task and may not even attempt to read the data until long after it has arrived. If the application is relatively slow at reading the data, the sender can very easily overflow the connection’s receive buffer by sending too much data too quickly.</span></p>
<p><a name="bookmark319"></a><span class="font53">TCP provides a </span><span class="font53" style="font-weight:bold;">flow-control service </span><span class="font53">to its applications to eliminate the possibility of the sender overflowing the receiver’s buffer. Flow control is thus a speedmatching service—matching the rate at which the sender is sending against the rate at which the receiving application is reading. As noted earlier, a TCP sender can also be throttled due to congestion within the IP network; this form of sender control is referred to as </span><span class="font53" style="font-weight:bold;">congestion control</span><span class="font53">, a topic we will explore in detail in Sections 3.6 and 3.7. Even though the actions taken by flow and congestion control are similar (the throttling of the sender), they are obviously taken for very different reasons. Unfortunately, many authors use the terms interchangeably, and the savvy reader would be wise to distinguish between them. Let’s now discuss how TCP provides its flow-control service. In order to see the forest for the trees, we suppose throughout this section that the TCP implementation is such that the TCP receiver discards out-of-order segments.</span></p>
<p><span class="font53">TCP provides flow control by having the </span><span class="font53" style="font-style:italic;">sender</span><span class="font53"> maintain a variable called the </span><span class="font53" style="font-weight:bold;">receive window</span><span class="font53">. Informally, the receive window is used to give the sender an idea of how much free buffer space is available at the receiver. Because TCP is full-duplex, the sender at each side of the connection maintains a distinct receive window. Let’s investigate the receive window in the context of a file transfer. Suppose that Host A is sending a large file to Host B over a TCP connection. Host B allocates a receive buffer to this connection; denote its size by </span><span class="font36">RcvBuffer</span><span class="font53">. From time to time, the application process in Host B reads from the buffer. Define the following variables:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font36">LastByteRead</span><span class="font53">: the number of the last byte in the data stream read from the buffer by the application process in B</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font36">LastByteRcvd</span><span class="font53">: the number of the last byte in the data stream that has arrived from the network and has been placed in the receive buffer at B</span></p></li></ul>
<p><span class="font53">Because TCP is not permitted to overflow the allocated buffer, we must have</span></p>
<p><span class="font36">LastByteRcvd - LastByteRead </span><span class="font55">^ </span><span class="font36">RcvBuffer</span></p>
<p><span class="font53">The receive window, denoted </span><span class="font36">rwnd </span><span class="font53">is set to the amount of spare room in the buffer:</span></p>
<p><span class="font36">rwnd = RcvBuffer - [LastByteRcvd - LastByteRead]</span></p>
<p><span class="font53">Because the spare room changes with time, </span><span class="font36">rwnd </span><span class="font53">is dynamic. The variable </span><span class="font36">rwnd </span><span class="font53">is illustrated in Figure 3.38.</span></p>
<p><span class="font53">How does the connection use the variable </span><span class="font36">rwnd </span><span class="font53">to provide the flow-control service? Host B tells Host A how much spare room it has in the connection buffer by placing its current value of </span><span class="font36">rwnd </span><span class="font53">in the receive window field of every segment it sends to A. Initially, Host B sets </span><span class="font36">rwnd = RcvBuffer</span><span class="font53">. Note that to pull this off, Host B must keep track of several connection-specific variables.</span></p>
<p><span class="font53">Host A in turn keeps track of two variables, </span><span class="font36">LastByteSent </span><span class="font53">and </span><span class="font36">Last-ByteAcked</span><span class="font53">, which have obvious meanings. Note that the difference between these two variables, </span><span class="font36">LastByteSent - LastByteAcked</span><span class="font53">, is the amount of unacknowledged data that A has sent into the connection. By keeping the amount of unacknowledged data less than the value of </span><span class="font36">rwnd</span><span class="font53">, Host A is assured that it is not</span></p>
<p><span class="font34">RcvBuffer</span></p>
<p><span class="font53">i</span></p>
<p><span class="font4">Data from IP</span></p>
<table border="1">
<tr><td colspan="2" style="vertical-align:bottom;">
<p><span class="font34">rwnd</span></p>
<p><span class="font34">1</span></p></td></tr>
<tr><td></td><td></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font4">Spare room</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">TCP data in buffer</span></p></td></tr>
</table>
<p><span class="font4">Application process</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 3.38 </span><span class="font50">♦ </span><span class="font5">The receive window </span><span class="font36">(rwnd) </span><span class="font5">and the receive buffer </span><span class="font36">(RcvBuffer)</span></p>
<p><span class="font53">overflowing the receive buffer at Host B. Thus, Host A makes sure throughout the connection’s life that</span></p>
<p><span class="font36">LastByteSent - LastByteAcked </span><span class="font55">^ </span><span class="font36">rwnd</span></p>
<p><span class="font53">There is one minor technical problem with this scheme. To see this, suppose Host B’s receive buffer becomes full so that </span><span class="font36">rwnd = 0</span><span class="font53">. After advertising </span><span class="font36">rwnd = 0 </span><span class="font53">to Host A, also suppose that B has </span><span class="font53" style="font-style:italic;">nothing</span><span class="font53"> to send to A. Now consider what happens. As the application process at B empties the buffer, TCP does not send new segments with new </span><span class="font36">rwnd </span><span class="font53">values to Host A; indeed, TCP sends a segment to Host A only if it has data to send or if it has an acknowledgment to send. Therefore, Host A is never informed that some space has opened up in Host B’s receive buffer— Host A is blocked and can transmit no more data! To solve this problem, the TCP specification requires Host A to continue to send segments with one data byte when B’s receive window is zero. These segments will be acknowledged by the receiver. Eventually the buffer will begin to empty and the acknowledgments will contain a nonzero </span><span class="font36">rwnd </span><span class="font53">value.</span></p>
<p><span class="font53">The online site at for this book provides an interactive animation that illustrates the operation of the TCP receive window.</span></p>
<p><span class="font53">Having described TCP’s flow-control service, we briefly mention here that UDP does not provide flow control and consequently, segments may be lost at the receiver due to buffer overflow. For example, consider sending a series of UDP segments from a process on Host A to a process on Host B. For a typical UDP implementation, UDP will append the segments in a finite-sized buffer that “precedes” the corresponding socket (that is, the door to the process). The process reads one entire segment at a time from the buffer. If the process does not read the segments fast enough from the buffer, the buffer will overflow and segments will get dropped.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">3.5.6 </span><span class="font23" style="font-weight:bold;">TCP Connection Management</span></p></li></ul>
<p><span class="font53">In this subsection, we take a closer look at how a TCP connection is established and torn down. Although this topic may not seem particularly thrilling, it is important because TCP connection establishment can significantly add to perceived delays (for example, when surfing the Web). Furthermore, many of the most common network attacks—including the incredibly popular SYN flood attack (see sidebar on the SYN flood attack)—exploit vulnerabilities in TCP connection management. Let’s first take a look at how a TCP connection is established. Suppose a process running in one host (client) wants to initiate a connection with another process in another host (server). The client application process first informs the client TCP that it wants to establish a connection to a process in the server. The TCP in the client then proceeds to establish a TCP connection with the TCP in the server in the following manner:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53" style="font-style:italic;">• &nbsp;Step 1.</span><span class="font53"> The client-side TCP first sends a special TCP segment to the server-side TCP. This special segment contains no application-layer data. But one of the flag bits in the segment’s header (see Figure 3.29), the SYN bit, is set to 1. For this reason, this special segment is referred to as a SYN segment. In addition, the client randomly chooses an initial sequence number (</span><span class="font36">client_isn</span><span class="font53">) and puts this number in the sequence number field of the initial TCP SYN segment. This segment is encapsulated within an IP datagram and sent to the server. There has been considerable interest in properly randomizing the choice of the </span><span class="font36">client_isn </span><span class="font53">in order to avoid certain security attacks [CERT 2001-09; RFC 4987].</span></p></li>
<li>
<p><span class="font53" style="font-style:italic;">• &nbsp;Step 2.</span><span class="font53"> Once the IP datagram containing the TCP SYN segment arrives at the server host (assuming it does arrive!), the server extracts the TCP SYN segment from the datagram, allocates the TCP buffers and variables to the connection, and sends a connection-granted segment to the client TCP. (We’ll see in Chapter 8 that the allocation of these buffers and variables before completing the third step of the three-way handshake makes TCP vulnerable to a denial-of-service attack known as SYN flooding.) This connection-granted segment also contains no application-layer data. However, it does contain three important pieces of information in the segment header. First, the SYN bit is set to 1. Second, the acknowledgment field of the TCP segment header is set to </span><span class="font36">client_isn+1</span><span class="font53">. Finally, the server chooses its own initial sequence number (</span><span class="font36">server_isn</span><span class="font53">) and puts this value in the sequence number field of the TCP segment header. This connection-granted segment is saying, in effect, “I received your SYN packet to start a connection with your initial sequence number, </span><span class="font36">client_isn</span><span class="font53">. I agree to establish this connection. My own initial sequence number is </span><span class="font36">server_isn</span><span class="font53">.” The connection-granted segment is referred to as a </span><span class="font53" style="font-weight:bold;">SYNACK segment</span><span class="font53">.</span></p></li>
<li>
<p><a name="bookmark320"></a><span class="font53" style="font-style:italic;">• &nbsp;Step 3.</span><span class="font53"> Upon receiving the SYNACK segment, the client also allocates buffers and variables to the connection. The client host then sends the server yet another segment; this last segment acknowledges the server’s connection-granted segment (the client does so by putting the value </span><span class="font36">server_isn+1 </span><span class="font53">in the acknowledgment field of the TCP segment header). The SYN bit is set to zero, since the connection is established. This third stage of the three-way handshake may carry client-to-server data in the segment payload.</span></p></li></ul>
<p><span class="font53">Once these three steps have been completed, the client and server hosts can send segments containing data to each other. In each of these future segments, the SYN bit will be set to zero. Note that in order to establish the connection, three packets are sent between the two hosts, as illustrated in Figure 3.39. For this reason, this connection-establishment procedure is often referred to as a </span><span class="font53" style="font-weight:bold;">three-way handshake</span><span class="font53">. Several aspects of the TCP three-way handshake are explored in the homework problems (Why are initial sequence numbers needed? Why is a three-way handshake, as opposed to a two-way handshake, needed?). It’s interesting to note that a rock climber and a belayer (who is stationed below the rock climber and whose job it is to handle the climber’s safety rope) use a three-way-handshake communication protocol that is identical to TCP’s to ensure that both sides are ready before the climber begins ascent.</span></p>
<p><span class="font53">All good things must come to an end, and the same is true with a TCP connection. Either of the two processes participating in a TCP connection can end the connection. When a connection ends, the “resources” (that is, the buffers and variables)</span></p><img src="networking_files/networking-217.jpg" alt="" style="width:272pt;height:242pt;">
<p><span class="font7" style="font-weight:bold;">Figure 3.39 </span><span class="font50">♦ </span><span class="font5">TCP three-way handshake: segment exchange</span></p>
<div><img src="networking_files/networking-218.jpg" alt="" style="width:196pt;height:113pt;">
</div><br clear="all">
<div><img src="networking_files/networking-219.jpg" alt="" style="width:171pt;height:56pt;">
</div><br clear="all">
<p><span class="font4">Timed wait-</span></p>
<p><span class="font4">Closed</span></p>
<p><span class="font9">▼</span></p>
<div>
<p><span class="font4">Time</span></p>
</div><br clear="all">
<p><span class="font4">Time</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 3.40 </span><span class="font50">♦ </span><span class="font5">Closing a TCP connection</span></p>
<p><span class="font53">in the hosts are deallocated. As an example, suppose the client decides to close the connection, as shown in Figure 3.40. The client application process issues a close command. This causes the client TCP to send a special TCP segment to the server process. This special segment has a flag bit in the segment’s header, the FIN bit (see Figure 3.29), set to 1. When the server receives this segment, it sends the client an acknowledgment segment in return. The server then sends its own shutdown segment, which has the FIN bit set to 1. Finally, the client acknowledges the server’s shutdown segment. At this point, all the resources in the two hosts are now deallocated.</span></p>
<p><span class="font53">During the life of a TCP connection, the TCP protocol running in each host makes transitions through various </span><span class="font53" style="font-weight:bold;">TCP states</span><span class="font53">. Figure 3.41 illustrates a typical sequence of TCP states that are visited by the </span><span class="font53" style="font-style:italic;">client</span><span class="font53"> TCP. The client TCP begins in the CLOSED state. The application on the client side initiates a new TCP connection (by creating a Socket object in our Python examples from Chapter 2). This causes TCP in the client to send a SYN segment to TCP in the server. After having sent the SYN segment, the client TCP enters the SYN_SENT state. While in the SYN_SENT state, the client TCP waits for a segment from the server TCP that includes an acknowledgment for the client’s previous segment and has the SYN bit</span></p>
<div>
<p><span class="font4">Wait 30 seconds</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-220.jpg" alt="" style="width:56pt;height:43pt;">
<p><span class="font34">CLOSED</span></p>
</div><br clear="all">
<div>
<p><span class="font34">TIME_WAIT</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Client application initiates a TCP connection</span></p><img src="networking_files/networking-221.jpg" alt="" style="width:85pt;height:59pt;">
</div><br clear="all">
<div>
<p><span class="font4">Receive FIN, send ACK</span></p>
</div><br clear="all">
<div>
<p><span class="font34">FIN_WAIT_2</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Receive ACK, send nothing</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-222.jpg" alt="" style="width:54pt;height:49pt;">
</div><br clear="all">
<div>
<p><span class="font34">FIN_WAIT_1</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Receive SYN &amp;&nbsp;ACK, send ACK</span></p>
</div><br clear="all">
<div>
<p><span class="font34">ESTABLISHED</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-223.jpg" alt="" style="width:59pt;height:46pt;">
<p><span class="font4">Send FIN</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Client application initiates close connection</span></p>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 3.41 </span><span class="font50">♦ </span><span class="font5">A typical sequence of TCP states visited by a client TCP</span></p>
<p><span class="font53">set to 1. Having received such a segment, the client TCP enters the ESTABLISHED state. While in the ESTABLISHED state, the TCP client can send and receive TCP segments containing payload (that is, application-generated) data.</span></p>
<p><span class="font53">Suppose that the client application decides it wants to close the connection. (Note that the server could also choose to close the connection.) This causes the client TCP to send a TCP segment with the FIN bit set to 1 and to enter the FIN_WAIT_1 state. While in the FIN_WAIT_1 state, the client TCP waits for a TCP segment from the server with an acknowledgment. When it receives this segment, the client TCP enters the HN_WAIT_2 state. While in the FIN_WAIT_2 state, the client waits for another segment from the server with the FIN bit set to 1; after receiving this segment, the client TCP acknowledges the server’s segment and enters the TIME_WAIT state. The TIME_ WAIT state lets the TCP client resend the final acknowledgment in case the ACK is lost. The time spent in the TIME_WAIT state is implementation-dependent, but typical values are 30 seconds, 1 minute, and 2 minutes. After the wait, the connection formally closes and all resources on the client side (including port numbers) are released.</span></p>
<p><span class="font53">Figure 3.42 illustrates the series of states typically visited by the server-side TCP, assuming the client begins connection teardown. The transitions are self-explanatory. In these two state-transition diagrams, we have only shown how a TCP connection is normally established and shut down. We have not described what happens in certain pathological scenarios, for example, when both sides of a connection want to initiate or shut down at the same time. If you are interested in learning about</span></p>
<div>
<p><span class="font4">Receive ACK, send nothing</span></p><img src="networking_files/networking-224.jpg" alt="" style="width:56pt;height:43pt;">
<p><span class="font34">CLOSED</span></p>
</div><br clear="all">
<div>
<p><span class="font34">LAST_ACK</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Server application</span></p><img src="networking_files/networking-225.jpg" alt="" style="width:91pt;height:66pt;">
<p><span class="font4">Receive SYN send SYN &amp;&nbsp;ACK</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Send FIN</span></p>
</div><br clear="all">
<div>
<p><span class="font34">CLOSE_WAIT</span></p>
</div><br clear="all">
<div>
<p><span class="font34">SYN_RCVD</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Receive FIN, send ACK</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-226.jpg" alt="" style="width:54pt;height:49pt;">
</div><br clear="all">
<div>
<p><span class="font34">ESTABLISHED</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-227.jpg" alt="" style="width:59pt;height:46pt;">
<p><span class="font4">Receive ACK, send nothing</span></p>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 3.42 </span><span class="font50">♦ </span><span class="font5">A typical sequence of TCP states visited by a server-side TCP</span></p>
<p><span class="font53">this and other advanced issues concerning TCP, you are encouraged to see Stevens’ comprehensive book [Stevens 1994].</span></p>
<p><span class="font53">Our discussion above has assumed that both the client and server are prepared to communicate, that is, that the server is listening on the port to which the client sends its SYN segment. Let’s consider what happens when a host receives a TCP segment whose port numbers or source IP address do not match with any of the ongoing sockets in the host. For example, suppose a host receives a TCP SYN packet with destination port 80, but the host is not accepting connections on port 80 (that is, it is not running a Web server on port 80). Then the host will send a special reset segment to the source. This TCP segment has the RST flag bit (see Section 3.5.2) set to 1. Thus, when a host sends a reset segment, it is telling the source “I don’t have a socket for that segment. Please do not resend the segment.” When a host receives a UDP packet whose destination port number doesn’t match with an ongoing UDP socket, the host sends a special ICMP datagram, as discussed in Chapter 5.</span></p>
<p><span class="font53">Now that we have a good understanding of TCP connection management, let’s revisit the nmap port-scanning tool and examine more closely how it works. To explore a specific TCP port, say port 6789, on a target host, nmap will send a TCP SYN segment with destination port 6789 to that host. There are three possible outcomes:</span></p>
<p><span class="font53" style="font-style:italic;">The source host receives a TCP SYNACK segment from the target host.</span><span class="font53"> Since this means that an application is running with TCP port 6789 on the target post, nmap returns “open.”</span></p>
<div><img src="networking_files/networking-228.jpg" alt="" style="width:167pt;height:21pt;">
</div><br clear="all">
<div>
<p><span class="font23" style="font-weight:bold;">FOCUS ON SECURITY</span></p>
</div><br clear="all">
<p><span class="font4" style="font-weight:bold;">THE SYN FLOOD ATTACK</span></p>
<p><span class="font4">We’ve seen in our discussion of TCP’s three-way handshake that a server allocates and initializes connection variables and buffers in response to a received SYN. The server then sends a SYNACK in response, and awaits an ACK segment from the client. If the client does not send an ACK to complete the third step of this 3-way handshake, eventually (often after a minute or more) the server will terminate the half-open connection and reclaim the allocated resources.</span></p>
<p><span class="font4">This TCP connection management protocol sets the stage for a classic Denial of Service (DoS) attack known as the </span><span class="font5" style="font-weight:bold;">SYN flood attack</span><span class="font4">. In this attack, the attacker(s) send a large number of TCP SYN segments, without completing the third handshake step. With this deluge of SYN segments, the server’s connection resources become exhausted as they are allocated (but never used!) for half-open connections; legitimate clients are then denied service. Such SYN flooding attacks were among the first documented DoS attacks [CERT SYN 1996]. Fortunately, an effective defense known as </span><span class="font5" style="font-weight:bold;">SYN cookies </span><span class="font4">[RFC 4987] are now deployed in most major operating systems. SYN cookies work as follows:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font4">• &nbsp;When the server receives a SYN segment, it does not know if the segment is coming from a legitimate user or is part of a SYN flood attack. So, instead of creating a half-open TCP connection for this SYN, the server creates an initial TCP sequence number that is a complicated function (hash function) of source and destination IP addresses and port numbers of the SYN segment, as well as a secret number only known to the server. This carefully crafted initial sequence number is the so-called “cookie.” The server then sends the client a SYNACK packet with this special initial sequence number. </span><span class="font4" style="font-style:italic;">Importantly, the server does not remember the cookie or any other state information corresponding to the SYN</span><span class="font52" style="font-style:italic;">.</span></p></li>
<li>
<p><span class="font4">• &nbsp;A legitimate client will return an ACK segment. When the server receives this ACK, it must verify that the ACK corresponds to some SYN sent earlier. But how is this done if the server maintains no memory about SYN segments? As you may have guessed, it is done with the cookie. Recall that for a legitimate ACK, the value in the acknowledgment field is equal to the initial sequence number in the SYNACK (the cookie value in this case) plus one (see Figure 3.39). The server can then run the same hash function using the source and destination IP address and port numbers in the SYNACK (which are the same as in the original SYN) and the secret number. If the result of the function plus one is the same as the acknowledgment (cookie) value in the client’s SYNACK, the server concludes that the ACK corresponds to an earlier SYN segment and is hence valid. The server then creates a fully open connection along with a socket.</span></p></li>
<li>
<p><span class="font4">• &nbsp;On the other hand, if the client does not return an ACK segment, then the original SYN has done no harm at the server, since the server hasn’t yet allocated any resources in response to the original bogus SYN.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">The source host receives a TCP RST segment from the target host.</span><span class="font53"> This means that the SYN segment reached the target host, but the target host is not running an application with TCP port 6789. But the attacker at least knows that the segments destined to the host at port 6789 are not blocked by any firewall on the path between source and target hosts. (Firewalls are discussed in Chapter 8.)</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">The source receives nothing.</span><span class="font53"> This likely means that the SYN segment was blocked by an intervening firewall and never reached the target host.</span></p></li></ul>
<p><span class="font53">Nmap is a powerful tool that can “case the joint” not only for open TCP ports, but also for open UDP ports, for firewalls and their configurations, and even for the versions of applications and operating systems. Most of this is done by manipulating TCP connection-management segments. You can download nmap from </span><a href="http://www.nmap.org"><span class="font53">www.nmap.org</span></a><span class="font53">.</span></p>
<p><span class="font53">This completes our introduction to error control and flow control in TCP. In Section 3.7, we’ll return to TCP and look at TCP congestion control in some depth. Before doing so, however, we first step back and examine congestion-control issues in a broader context.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">3.6 </span><span class="font24" style="font-weight:bold;">Principles of Congestion Control</span></p></li></ul>
<p><span class="font53">In the previous sections, we examined both the general principles and specific TCP mechanisms used to provide for a reliable data transfer service in the face of packet loss. We mentioned earlier that, in practice, such loss typically results from the overflowing of router buffers as the network becomes congested. Packet retransmission thus treats a symptom of network congestion (the loss of a specific transport-layer segment) but does not treat the cause of network congestion—too many sources attempting to send data at too high a rate. To treat the cause of network congestion, mechanisms are needed to throttle senders in the face of network congestion.</span></p>
<p><span class="font53">In this section, we consider the problem of congestion control in a general context, seeking to understand why congestion is a bad thing, how network congestion is manifested in the performance received by upper-layer applications, and various approaches that can be taken to avoid, or react to, network congestion. This more general study of congestion control is appropriate since, as with reliable data transfer, it is high on our “top-ten” list of fundamentally important problems in networking. The following section contains a detailed study of TCP’s congestion-control algorithm.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">3.6.1 </span><span class="font23" style="font-weight:bold;">The Causes and the Costs of Congestion</span></p></li></ul>
<p><a name="bookmark321"></a><span class="font53">Let’s begin our general study of congestion control by examining three increasingly complex scenarios in which congestion occurs. In each case, we’ll look at why congestion occurs in the first place and at the cost of congestion (in terms of resources not fully utilized and poor performance received by the end systems). We’ll not (yet) focus on how to react to, or avoid, congestion but rather focus on the simpler issue of understanding what happens as hosts increase their transmission rate and the network becomes congested.</span></p>
<p><span class="font22" style="font-weight:bold;">Scenario 1: Two Senders, a Router with Infinite Buffers</span></p>
<p><span class="font53">We begin by considering perhaps the simplest congestion scenario possible: Two hosts (A and B) each have a connection that shares a single hop between source and destination, as shown in Figure 3.43.</span></p>
<p><span class="font53">Let’s assume that the application in Host A is sending data into the connection (for example, passing data to the transport-level protocol via a socket) at an average rate of </span><span class="font12">l</span><span class="font53"><sub>in</sub> bytes/sec. These data are original in the sense that each unit of data is sent into the socket only once. The underlying transport-level protocol is a simple one. Data is encapsulated and sent; no error recovery (e.g., retransmission), flow control, or congestion control is performed. Ignoring the additional overhead due to adding transport- and lower-layer header information, the rate at which Host A offers traffic to the router in this first scenario is thus </span><span class="font12">l</span><span class="font53"><sub>in</sub> bytes/sec. Host B operates in a similar manner, and we assume for simplicity that it too is sending at a rate of </span><span class="font12">l</span><span class="font53"><sub>in</sub> bytes/sec. Packets from Hosts A and B pass through a router and over a shared outgoing link of capacity </span><span class="font53" style="font-style:italic;">R.</span><span class="font53"> The router has buffers that allow it to store incoming packets when the packet-arrival rate exceeds the outgoing link’s capacity. In this first scenario, we assume that the router has an infinite amount of buffer space.</span></p>
<p><span class="font53">Figure 3.44 plots the performance of Host A’s connection under this first scenario. The left graph plots the </span><span class="font53" style="font-weight:bold;">per-connection throughput </span><span class="font53">(number of bytes per</span></p><img src="networking_files/networking-229.jpg" alt="" style="width:395pt;height:133pt;">
<p><span class="font4">Unlimited shared output link buffers</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 3.43 </span><span class="font50">♦ </span><span class="font5">Congestion scenario 1: Two connections sharing a single hop with infinite buffers</span></p>
<div><img src="networking_files/networking-230.jpg" alt="" style="width:152pt;height:135pt;">
<p><span class="font4" style="font-weight:bold;">a. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;b.</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-231.jpg" alt="" style="width:138pt;height:135pt;">
<p><span class="font7" style="font-weight:bold;">Figure 3.44 </span><span class="font50">♦ </span><span class="font5">Congestion scenario 1: Throughput and delay as a function of host sending rate</span></p>
</div><br clear="all">
<p><span class="font53">second at the receiver) as a function of the connection-sending rate. For a sending rate between 0 and </span><span class="font53" style="font-style:italic;">R/2,</span><span class="font53"> the throughput at the receiver equals the sender’s sending rate—everything sent by the sender is received at the receiver with a finite delay. When the sending rate is above </span><span class="font53" style="font-style:italic;">R</span><span class="font53">/2, however, the throughput is only </span><span class="font53" style="font-style:italic;">R</span><span class="font53">/2. This upper limit on throughput is a consequence of the sharing of link capacity between two connections. The link simply cannot deliver packets to a receiver at a steady-state rate that exceeds </span><span class="font53" style="font-style:italic;">R</span><span class="font53">/2. No matter how high Hosts A and B set their sending rates, they will each never see a throughput higher than </span><span class="font53" style="font-style:italic;">R</span><span class="font53">/2.</span></p>
<p><span class="font53">Achieving a per-connection throughput of </span><span class="font53" style="font-style:italic;">R</span><span class="font53">/2 might actually appear to be a good thing, because the link is fully utilized in delivering packets to their destinations. The right-hand graph in Figure 3.44, however, shows the consequence of operating near link capacity. As the sending rate approaches </span><span class="font53" style="font-style:italic;">R</span><span class="font53">/2 (from the left), the average delay becomes larger and larger. When the sending rate exceeds </span><span class="font53" style="font-style:italic;">R</span><span class="font53">/2, the average number of queued packets in the router is unbounded, and the average delay between source and destination becomes infinite (assuming that the connections operate at these sending rates for an infinite period of time and there is an infinite amount of buffering available). Thus, while operating at an aggregate throughput of near </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> may be ideal from a throughput standpoint, it is far from ideal from a delay standpoint. </span><span class="font53" style="font-style:italic;">Even in this (extremely) idealized scenario, we’ve already found one cost of a congested network—large queuing delays are experienced as the packet-arrival rate nears the link capacity.</span></p>
<p><span class="font22" style="font-weight:bold;">Scenario 2: Two Senders and a Router with Finite Buffers</span></p>
<p><span class="font53">Let’s now slightly modify scenario 1 in the following two ways (see Figure 3.45). First, the amount of router buffering is assumed to be finite. A consequence of this real-world assumption is that packets will be dropped when arriving to an already-full buffer. Second, we assume that each connection is reliable. If a packet containing</span></p><img src="networking_files/networking-232.jpg" alt="" style="width:395pt;height:157pt;">
<p><span class="font4">Finite shared output link buffers</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 3.45 </span><span class="font50">♦ </span><span class="font5">Scenario 2: Two hosts (with retransmissions) and a router with finite buffers</span></p>
<p><span class="font53">a transport-level segment is dropped at the router, the sender will eventually retransmit it. Because packets can be retransmitted, we must now be more careful with our use of the term </span><span class="font53" style="font-style:italic;">sending rate.</span><span class="font53"> Specifically, let us again denote the rate at which the application sends original data into the socket by </span><span class="font12">l</span><span class="font53"><sub>in</sub> bytes/sec. The rate at which the transport layer sends segments (containing original data </span><span class="font53" style="font-style:italic;">and</span><span class="font53"> retransmitted data) into the network will be denoted </span><span class="font12">l</span><span class="font50">'</span><span class="font53"><sub>n</sub> bytes/sec. </span><span class="font12">l</span><span class="font50">'</span><span class="font53"><sub>n</sub> is sometimes referred to as the </span><span class="font53" style="font-weight:bold;">offered load </span><span class="font53">to the network.</span></p>
<p><span class="font53">The performance realized under scenario 2 will now depend strongly on how retransmission is performed. First, consider the unrealistic case that Host A is able to somehow (magically!) determine whether or not a buffer is free in the router and thus sends a packet only when a buffer is free. In this case, no loss would occur, </span><span class="font12">l</span><span class="font53"><sub>in </sub>would be equal to </span><span class="font12">l</span><span class="font50">'</span><span class="font53"><sub>n</sub>, and the throughput of the connection would be equal to </span><span class="font12">l</span><span class="font53"><sub>in</sub>. This case is shown in Figure 3.46(a). From a throughput standpoint, performance is ideal—everything that is sent is received. Note that the average host sending rate cannot exceed </span><span class="font53" style="font-style:italic;">R/2</span><span class="font53"> under this scenario, since packet loss is assumed never to occur.</span></p>
<p><span class="font53">Consider next the slightly more realistic case that the sender retransmits only when a packet is known for certain to be lost. (Again, this assumption is a bit of a stretch. However, it is possible that the sending host might set its timeout large enough to be virtually assured that a packet that has not been acknowledged has been lost.) In this case, the performance might look something like that shown in Figure 3.46(b). To appreciate what is happening here, consider the case that the offered load, </span><span class="font12">l</span><span class="font50">'</span><span class="font53"><sub>n</sub> (the rate of original data transmission plus retransmissions), equals </span><span class="font53" style="font-style:italic;">R/2. </span><span class="font53">According to Figure 3.46(b), at this value of the offered load, the rate at which data</span></p>
<div><img src="networking_files/networking-233.jpg" alt="" style="width:132pt;height:126pt;">
</div><br clear="all">
<div><img src="networking_files/networking-234.jpg" alt="" style="width:133pt;height:126pt;">
</div><br clear="all">
<div><img src="networking_files/networking-235.jpg" alt="" style="width:134pt;height:126pt;">
</div><br clear="all">
<p><span class="font4" style="font-weight:bold;">a. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;b. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;c.</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 3.46 </span><span class="font50">♦ </span><span class="font5">Scenario 2 performance with finite buffers</span></p>
<p><span class="font53">are delivered to the receiver application is </span><span class="font53" style="font-style:italic;">R/3.</span><span class="font53"> Thus, out of the 0.5</span><span class="font53" style="font-style:italic;">R</span><span class="font53"> units of data transmitted, 0.333</span><span class="font53" style="font-style:italic;">R</span><span class="font53"> bytes/sec (on average) are original data and 0.166</span><span class="font53" style="font-style:italic;">R</span><span class="font53"> bytes/sec (on average) are retransmitted data. </span><span class="font53" style="font-style:italic;">We see here another cost of a congested network— the sender must perform retransmissions in order to compensate for dropped (lost) packets due to buffer overflow.</span></p>
<p><span class="font53">Finally, let us consider the case that the sender may time out prematurely and retransmit a packet that has been delayed in the queue but not yet lost. In this case, both the original data packet and the retransmission may reach the receiver. Of course, the receiver needs but one copy of this packet and will discard the retransmission. In this case, the work done by the router in forwarding the retransmitted copy of the original packet was wasted, as the receiver will have already received the original copy of this packet. The router would have better used the link transmission capacity to send a different packet instead. </span><span class="font53" style="font-style:italic;">Here then is yet another cost of a congested network—unneeded retransmissions by the sender in the face of large delays may cause a router to use its link bandwidth to forward unneeded copies of a packet.</span><span class="font53"> Figure 3.46 (c) shows the throughput versus offered load when each packet is assumed to be forwarded (on average) twice by the router. Since each packet is forwarded twice, the throughput will have an asymptotic value of </span><span class="font53" style="font-style:italic;">R</span><span class="font53">/4 as the offered load approaches </span><span class="font53" style="font-style:italic;">R</span><span class="font53">/2.</span></p>
<p><span class="font22" style="font-weight:bold;">Scenario 3: Four Senders, Routers with Finite Buffers, and</span></p>
<p><span class="font22" style="font-weight:bold;">Multihop Paths</span></p>
<p><span class="font53">In our final congestion scenario, four hosts transmit packets, each over overlapping two-hop paths, as shown in Figure 3.47. We again assume that each host uses a timeout/retransmission mechanism to implement a reliable data transfer service, that all hosts have the same value of </span><span class="font12">l</span><span class="font53"><sub>in</sub>, and that all router links have capacity </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> bytes/sec.</span></p>
<div>
<p><span class="font52">^</span><span class="font50">out</span></p>
<p><span class="font4">Host A</span></p>
<p><span class="font4">Host B</span></p>
<p><span class="font52">l'<sub>n</sub></span><span class="font4">: original data, plus retransmitted data</span></p>
<p><span class="font52">l</span><span class="font4"><sub>in</sub>: original data</span></p><img src="networking_files/networking-236.jpg" alt="" style="width:310pt;height:282pt;">
<p><span class="font4">Host D</span></p>
<p><span class="font4">R3</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 3.47 </span><span class="font50">♦ </span><span class="font5">Four senders, routers with finite buffers, and multihop paths</span></p>
</div><br clear="all">
<div>
<p><span class="font58" style="font-weight:bold;">Ml</span></p>
</div><br clear="all">
<p><span class="font4">Finite shared output link buffers</span></p>
<div>
<p><span class="font4">Host C</span></p><img src="networking_files/networking-237.jpg" alt="" style="width:34pt;height:37pt;">
</div><br clear="all">
<p><span class="font53">Let’s consider the connection from Host A to Host C, passing through routers R1 and R2. The A-C connection shares router R1 with the D-B connection and shares router R2 with the B-D connection. For extremely small values of </span><span class="font12">l</span><span class="font53"><sub>in</sub>, buffer overflows are rare (as in congestion scenarios 1 and 2), and the throughput approximately equals the offered load. For slightly larger values of </span><span class="font12">l</span><span class="font53"><sub>in</sub>, the corresponding throughput is also larger, since more original data is being transmitted into the network and delivered to the destination, and overflows are still rare. Thus, for small values of </span><span class="font12">l</span><span class="font53"><sub>in</sub>, an increase in </span><span class="font12">l</span><span class="font53"><sub>in</sub> results in an increase in </span><span class="font12">l</span><span class="font53"><sub>out</sub>.</span></p>
<p><span class="font53">Having considered the case of extremely low traffic, let’s next examine the case that </span><span class="font12">l</span><span class="font53"><sub>in</sub> (and hence </span><span class="font12">l </span><span class="font50">i</span><span class="font53"><sub>n</sub>) is extremely large. Consider router R2. The A-C traffic arriving to router R2 (which arrives at R2 after being forwarded from R1) can have an arrival rate at R2 that is at most </span><span class="font53" style="font-style:italic;">R,</span><span class="font53"> the capacity of the link from R1 to R2, regardless of the value of </span><span class="font12">l</span><span class="font53"><sub>in</sub>. If </span><span class="font53" style="font-style:italic;">l</span><span class="font50"> i</span><span class="font53"><sub>n</sub> is extremely large for all connections (including the</span></p><img src="networking_files/networking-238.jpg" alt="" style="width:185pt;height:131pt;">
<p><span class="font7" style="font-weight:bold;">Figure 3.48 </span><span class="font50">♦ </span><span class="font5">Scenario 3 performance with finite buffers and multihop paths</span></p>
<p><span class="font53">B-D connection), then the arrival rate of B-D traffic at R2 can be much larger than that of the A-C traffic. Because the A-C and B-D traffic must compete at router R2 for the limited amount of buffer space, the amount of A-C traffic that successfully gets through R2 (that is, is not lost due to buffer overflow) becomes smaller and smaller as the offered load from B-D gets larger and larger. In the limit, as the offered load approaches infinity, an empty buffer at R2 is immediately filled by a B-D packet, and the throughput of the A-C connection at R2 goes to zero. This, in turn, </span><span class="font53" style="font-style:italic;">implies that the A-C end-to-end throughput goes to zero</span><span class="font53"> in the limit of heavy traffic. These considerations give rise to the offered load versus throughput tradeoff shown in Figure 3.48.</span></p>
<p><span class="font53">The reason for the eventual decrease in throughput with increasing offered load is evident when one considers the amount of wasted work done by the network. In the high-traffic scenario outlined above, whenever a packet is dropped at a second-hop router, the work done by the first-hop router in forwarding a packet to the second-hop router ends up being “wasted.” The network would have been equally well off (more accurately, equally bad off) if the first router had simply discarded that packet and remained idle. More to the point, the transmission capacity used at the first router to forward the packet to the second router could have been much more profitably used to transmit a different packet. (For example, when selecting a packet for transmission, it might be better for a router to give priority to packets that have already traversed some number of upstream routers.) </span><span class="font53" style="font-style:italic;">So here we see yet another cost of dropping a packet due to congestion—when a packet is dropped along a path, the transmission capacity that was used at each of the upstream links to forward that packet to the point at which it is dropped ends up having been wasted.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">3.6.2 </span><span class="font23" style="font-weight:bold;">Approaches to Congestion Control</span></p></li></ul>
<p><span class="font53">In Section 3.7, we’ll examine TCP’s specific approach to congestion control in great detail. Here, we identify the two broad approaches to congestion control that are taken in practice and discuss specific network architectures and congestion-control protocols embodying these approaches.</span></p>
<p><span class="font53">At the highest level, we can distinguish among congestion-control approaches by whether the network layer provides explicit assistance to the transport layer for congestion-control purposes:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">End-to-end congestion control.</span><span class="font53"> In an end-to-end approach to congestion control, the network layer provides no explicit support to the transport layer for congestion-control purposes. Even the presence of network congestion must be inferred by the end systems based only on observed network behavior (for example, packet loss and delay). We’ll see shortly in Section 3.7.1 that TCP takes this end-to-end approach toward congestion control, since the IP layer is not required to provide feedback to hosts regarding network congestion. TCP segment loss (as indicated by a timeout or the receipt of three duplicate acknowledgments) is taken as an indication of network congestion, and TCP decreases its window size accordingly. We’ll also see a more recent proposal for TCP congestion control that uses increasing round-trip segment delay as an indicator of increased network congestion</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Network-assisted congestion control.</span><span class="font53"> With network-assisted congestion control, routers provide explicit feedback to the sender and/or receiver regarding the congestion state of the network. This feedback may be as simple as a single bit indicating congestion at a link—an approach taken in the early IBM SNA [Schwartz 1982], DEC DECnet [Jain 1989; Ramakrishnan 1990] architectures, and ATM [Black 1995] network architectures. More sophisticated feedback is also possible. For example, in </span><span class="font53" style="font-weight:bold;">ATM Available Bite Rate (ABR) </span><span class="font53">congestion control, a router informs the sender of the maximum host sending rate it (the router) can support on an outgoing link. As noted above, the Internet-default versions of IP and TCP adopt an end-to-end approach towards congestion control. We’ll see, however, in Section 3.7.2 that, more recently, IP and TCP may also optionally implement network-assisted congestion control.</span></p></li></ul>
<p><a name="bookmark322"></a><span class="font53">For network-assisted congestion control, congestion information is typically fed back from the network to the sender in one of two ways, as shown in Figure 3.49. Direct feedback may be sent from a network router to the sender. This form of notification typically takes the form of a choke packet (essentially saying, “I’m congested!”). The second and more common form of notification occurs when a router marks/updates a field in a packet flowing from sender to receiver to indicate congestion. Upon receipt of a marked packet, the receiver then notifies the sender of the congestion indication. This latter form of notification takes a full round-trip time.</span></p>
<p><span class="font4">Host A</span></p>
<p><span class="font4">Host B</span></p><img src="networking_files/networking-239.jpg" alt="" style="width:325pt;height:148pt;">
<p><span class="font7" style="font-weight:bold;">Figure 3.49 </span><span class="font50">♦ </span><span class="font5">Two feedback pathways for network-indicated congestion information</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">3.7 </span><span class="font24" style="font-weight:bold;">TCP Congestion Control</span></p></li></ul>
<p><span class="font53">In this section, we return to our study of TCP. As we learned in Section 3.5, TCP provides a reliable transport service between two processes running on different hosts. Another key component of TCP is its congestion-control mechanism. As indicated in the previous section, what we might refer to as “Classic” TCP—the version of TCP standardized in [RFC 2581] and most recently [RFC 5681]—uses end-to-end congestion control rather than network-assisted congestion control, since the IP layer provides no explicit feedback to the end systems regarding network congestion. We’ll first cover this “classic” version of TCP in depth in Section 7.3.1. In Section 7.3.2, we’ll then look at newer flavors of TCP that use an explicit congestion indication provided by the network layer, or differ a bit from “classic” TCP in any of several different ways. We’ll then cover the challenge of providing fairness among transport layer flows that must share a congested link.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">3.7.1 </span><span class="font23" style="font-weight:bold;">Classic TCP Congestion Control</span></p></li></ul>
<p><a name="bookmark323"></a><span class="font53">The approach taken by TCP is to have each sender limit the rate at which it sends traffic into its connection as a function of perceived network congestion. If a TCP sender perceives that there is little congestion on the path between itself and the destination, then the TCP sender increases its send rate; if the sender perceives that there is congestion along the path, then the sender reduces its send rate. But this approach raises three questions. First, how does a TCP sender limit the rate at which it sends traffic into its connection? Second, how does a TCP sender perceive that there is congestion on the path between itself and the destination? And third, what algorithm should the sender use to change its send rate as a function of perceived end-to-end congestion?</span></p>
<p><span class="font53">Let’s first examine how a TCP sender limits the rate at which it sends traffic into its connection. In Section 3.5, we saw that each side of a TCP connection consists of a receive buffer, a send buffer, and several variables (</span><span class="font36">LastByteRead</span><span class="font53">, </span><span class="font36">rwnd</span><span class="font53">, and so on). The TCP congestion-control mechanism operating at the sender keeps track of an additional variable, the </span><span class="font53" style="font-weight:bold;">congestion window</span><span class="font53">. The congestion window, denoted </span><span class="font36">cwnd</span><span class="font53">, imposes a constraint on the rate at which a TCP sender can send traffic into the network. Specifically, the amount of unacknowledged data at a sender may not exceed the minimum of </span><span class="font36">cwnd </span><span class="font53">and </span><span class="font36">rwnd</span><span class="font53">, that is:</span></p>
<p><span class="font36">LastByteSent - LastByteAcked </span><span class="font55">^ </span><span class="font36">min{cwnd, rwnd}</span></p>
<p><span class="font53">In order to focus on congestion control (as opposed to flow control), let us henceforth assume that the TCP receive buffer is so large that the receive-window constraint can be ignored; thus, the amount of unacknowledged data at the sender is solely limited by </span><span class="font36">cwnd</span><span class="font53">. We will also assume that the sender always has data to send, that is, that all segments in the congestion window are sent.</span></p>
<p><span class="font53">The constraint above limits the amount of unacknowledged data at the sender and therefore indirectly limits the sender’s send rate. To see this, consider a connection for which loss and packet transmission delays are negligible. Then, roughly, at the beginning of every RTT, the constraint permits the sender to send </span><span class="font36">cwnd </span><span class="font53">bytes of data into the connection; at the end of the RTT the sender receives acknowledgments for the data. </span><span class="font53" style="font-style:italic;">Thus the sender’s send rate is roughly cwnd/RTT bytes/sec. By adjusting the value of </span><span class="font53">cwnd</span><span class="font53" style="font-style:italic;">, the sender can therefore adjust the rate at which it sends data into its connection.</span></p>
<p><span class="font53">Let’s next consider how a TCP sender perceives that there is congestion on the path between itself and the destination. Let us define a “loss event” at a TCP sender as the occurrence of either a timeout or the receipt of three duplicate ACKs from the receiver. (Recall our discussion in Section 3.5.4 of the timeout event in Figure 3.33 and the subsequent modification to include fast retransmit on receipt of three duplicate ACKs.) When there is excessive congestion, then one (or more) router buffers along the path overflows, causing a datagram (containing a TCP segment) to be dropped. The dropped datagram, in turn, results in a loss event at the sender—either a timeout or the receipt of three duplicate ACKs—which is taken by the sender to be an indication of congestion on the sender-to-receiver path.</span></p>
<p><span class="font53">Having considered how congestion is detected, let’s next consider the more optimistic case when the network is congestion-free, that is, when a loss event doesn’t occur. In this case, acknowledgments for previously unacknowledged segments will be received at the TCP sender. As we’ll see, TCP will take the arrival of these acknowledgments as an indication that all is well—that segments being transmitted into the network are being successfully delivered to the destination—and will use acknowledgments to increase its congestion window size (and hence its transmission rate). Note that if acknowledgments arrive at a relatively slow rate (e.g., if the end-end path has high delay or contains a low-bandwidth link), then the congestion window will be increased at a relatively slow rate. On the other hand, if acknowledgments arrive at a high rate, then the congestion window will be increased more quickly. Because TCP uses acknowledgments to trigger (or clock) its increase in congestion window size, TCP is said to be </span><span class="font53" style="font-weight:bold;">self-clocking</span><span class="font53">.</span></p>
<p><span class="font53">Given the </span><span class="font53" style="font-style:italic;">mechanism</span><span class="font53"> of adjusting the value of </span><span class="font36">cwnd </span><span class="font53">to control the sending rate, the critical question remains: </span><span class="font53" style="font-style:italic;">How</span><span class="font53"> should a TCP sender determine the rate at which it should send? If TCP senders collectively send too fast, they can congest the network, leading to the type of congestion collapse that we saw in Figure 3.48. Indeed, the version of TCP that we’ll study shortly was developed in response to observed Internet congestion collapse [Jacobson 1988] under earlier versions of TCP. However, if TCP senders are too cautious and send too slowly, they could under utilize the bandwidth in the network; that is, the TCP senders could send at a higher rate without congesting the network. How then do the TCP senders determine their sending rates such that they don’t congest the network but at the same time make use of all the available bandwidth? Are TCP senders explicitly coordinated, or is there a distributed approach in which the TCP senders can set their sending rates based only on local information? TCP answers these questions using the following guiding principles:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">A lost segment implies congestion, and hence, the TCP sender’s rate should be decreased when a segment is lost.</span><span class="font53"> Recall from our discussion in Section 3.5.4, that a timeout event or the receipt of four acknowledgments for a given segment (one original ACK and then three duplicate ACKs) is interpreted as an implicit “loss event” indication of the segment following the quadruply ACKed segment, triggering a retransmission of the lost segment. From a congestion-control standpoint, the question is how the TCP sender should decrease its congestion window size, and hence its sending rate, in response to this inferred loss event.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">An acknowledged segment indicates that the network is delivering the sender’s segments to the receiver, and hence, the sender’s rate can be increased when an ACK arrives for a previously unacknowledged segment.</span><span class="font53"> The arrival of acknowledgments is taken as an implicit indication that all is well—segments are being successfully delivered from sender to receiver, and the network is thus not congested. The congestion window size can thus be increased.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Bandwidth probing</span><span class="font53">. Given ACKs indicating a congestion-free source-to-destina-tion path and loss events indicating a congested path, TCP’s strategy for adjusting its transmission rate is to increase its rate in response to arriving ACKs until a loss event occurs, at which point, the transmission rate is decreased. The TCP sender thus increases its transmission rate to probe for the rate that at which congestion onset begins, backs off from that rate, and then to begins probing again to see if the congestion onset rate has changed. The TCP sender’s behavior is perhaps analogous to the child who requests (and gets) more and more goodies until finally he/she is finally told “No!”, backs off a bit, but then begins making requests again shortly afterward. Note that there is no explicit signaling of congestion state by the network—ACKs and loss events serve as implicit signals—and that each TCP sender acts on local information asynchronously from other TCP senders.</span></p></li></ul>
<p><span class="font53">Given this overview of TCP congestion control, we’re now in a position to consider the details of the celebrated </span><span class="font53" style="font-weight:bold;">TCP congestion-control algorithm</span><span class="font53">, which was first described in [Jacobson 1988] and is standardized in [RFC 5681]. The algorithm has three major components: (1) slow start, (2) congestion avoidance, and (3) fast recovery. Slow start and congestion avoidance are mandatory components of TCP, differing in how they increase the size of </span><span class="font36">cwnd </span><span class="font53">in response to received ACKs. We’ll see shortly that slow start increases the size of </span><span class="font36">cwnd </span><span class="font53">more rapidly (despite its name!) than congestion avoidance. Fast recovery is recommended, but not required, for TCP senders.</span></p>
<p><span class="font22" style="font-weight:bold;">Slow Start</span></p>
<p><span class="font53">When a TCP connection begins, the value of </span><span class="font36">cwnd </span><span class="font53">is typically initialized to a small value of 1 MSS [RFC 3390], resulting in an initial sending rate of roughly MSS/ RTT. For example, if MSS </span><span class="font54">= </span><span class="font53">500 bytes and RTT </span><span class="font54">= </span><span class="font53">200 msec, the resulting initial sending rate is only about 20 kbps. Since the available bandwidth to the TCP sender may be much larger than MSS/RTT, the TCP sender would like to find the amount of available bandwidth quickly. Thus, in the </span><span class="font53" style="font-weight:bold;">slow-start </span><span class="font53">state, the value of </span><span class="font36">cwnd </span><span class="font53">begins at 1 MSS and increases by 1 MSS every time a transmitted segment is first acknowledged. In the example of Figure 3.50, TCP sends the first segment into the network</span></p>
<div>
<p><span class="font4" style="font-weight:bold;">Host A</span></p><img src="networking_files/networking-240.jpg" alt="" style="width:35pt;height:37pt;">
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Host B</span></p><img src="networking_files/networking-241.jpg" alt="" style="width:20pt;height:39pt;">
</div><br clear="all">
<div>
<p><span class="font4">RTT-</span></p><img src="networking_files/networking-242.jpg" alt="" style="width:161pt;height:192pt;">
</div><br clear="all">
<p><span class="font4">Time</span></p>
<div>
<p><span class="font4">Time</span></p>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 3.50 </span><span class="font50">♦ </span><span class="font5">TCP slow start </span><span class="font53">and waits for an acknowledgment. When this acknowledgment arrives, the TCP sender increases the congestion window by one MSS and sends out two maximumsized segments. These segments are then acknowledged, with the sender increasing the congestion window by 1 MSS for each of the acknowledged segments, giving a congestion window of 4 MSS, and so on. This process results in a doubling of the sending rate every RTT. Thus, the TCP send rate starts slow but grows exponentially during the slow start phase.</span></p>
<p><span class="font53">But when should this exponential growth end? Slow start provides several answers to this question. First, if there is a loss event (i.e., congestion) indicated by a timeout, the TCP sender sets the value of </span><span class="font36">cwnd </span><span class="font53">to 1 and begins the slow start process anew. It also sets the value of a second state variable, </span><span class="font36">ssthresh </span><span class="font53">(shorthand for “slow start threshold”) to </span><span class="font36">cwnd/2—</span><span class="font53">half of the value of the congestion window value when congestion was detected. The second way in which slow start may end is directly tied to the value of </span><span class="font36">ssthresh</span><span class="font53">. Since </span><span class="font36">ssthresh </span><span class="font53">is half the value of </span><span class="font36">cwnd </span><span class="font53">when congestion was last detected, it might be a bit reckless to keep doubling </span><span class="font36">cwnd </span><span class="font53">when it reaches or surpasses the value of </span><span class="font36">ssthresh</span><span class="font53">. Thus, when the value of </span><span class="font36">cwnd </span><span class="font53">equals </span><span class="font36">ssthresh</span><span class="font53">, slow start ends and TCP transitions into congestion avoidance mode. As we’ll see, TCP increases </span><span class="font36">cwnd </span><span class="font53">more cautiously when in congestion-avoidance mode. The final way in which slow start can end is if three duplicate ACKs are detected, in which case TCP performs a fast retransmit (see Section 3.5.4) and enters the fast recovery state, as discussed below. TCP’s behavior in slow start is summarized in the FSM description of TCP congestion control in Figure 3.51. The slow-start algorithm traces it roots to [Jacobson 1988]; an approach similar to slow start was also proposed independently in [Jain 1986].</span></p>
<p><span class="font22" style="font-weight:bold;">Congestion Avoidance</span></p>
<p><span class="font53">On entry to the congestion-avoidance state, the value of </span><span class="font36">cwnd </span><span class="font53">is approximately half its value when congestion was last encountered—congestion could be just around the corner! Thus, rather than doubling the value of </span><span class="font36">cwnd </span><span class="font53">every RTT, TCP adopts a more conservative approach and increases the value of </span><span class="font36">cwnd </span><span class="font53">by just a single MSS every RTT [RFC 5681]. This can be accomplished in several ways. A common approach is for the TCP sender to increase </span><span class="font36">cwnd </span><span class="font53">by MSS bytes (MSS/</span><span class="font36">cwnd</span><span class="font53">) whenever a new acknowledgment arrives. For example, if MSS is 1,460 bytes and </span><span class="font36">cwnd </span><span class="font53">is 14,600 bytes, then 10 segments are being sent within an RTT. Each arriving ACK (assuming one ACK per segment) increases the congestion window size by 1/10 MSS, and thus, the value of the congestion window will have increased by one MSS after ACKs when all 10 segments have been received.</span></p>
<p><span class="font53">But when should congestion avoidance’s linear increase (of 1 MSS per RTT) end? TCP’s congestion-avoidance algorithm behaves the same when a timeout occurs as in the case of slow start: The value of </span><span class="font36">cwnd </span><span class="font53">is set to 1 MSS, and the value of </span><span class="font36">ssthresh </span><span class="font53">is updated to half the value of </span><span class="font36">cwnd </span><span class="font53">when the loss event occurred. Recall, however, that a loss event also can be triggered by a triple duplicate ACK event.</span></p>
<p><span class="font33">new ACK</span></p>
<div>
<p><span class="font33">new ACK</span></p>
</div><br clear="all">
<p><span class="font33">duplicat<sup>e</sup></span><span class="font33" style="text-decoration:underline;"><sup> </sup></span><span class="font33"><sup>ACK</sup> &nbsp;&nbsp;&nbsp;cwnd=cwnd+MSS &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cwnd=cwnd+MSS </span><span class="font49">• </span><span class="font33">(MSS/cwnd)</span></p>
<div>
<p><span class="font33">cwnd=1 MSS ssthresh=64 KB dupACKcount=0</span></p>
</div><br clear="all">
<div>
<p><span class="font33">dupACKcount++</span></p><img src="networking_files/networking-243.jpg" alt="" style="width:41pt;height:36pt;">
</div><br clear="all">
<div>
<p><span class="font33">dupACKcount=0</span></p>
<p><span class="font3" style="font-style:italic;">transmit new segment(s), as allowed</span></p>
</div><br clear="all">
<div>
<p><span class="font33">dupACKcount=0</span></p>
<p><span class="font3" style="font-style:italic;">transmit new segment(s), as allowed</span></p>
</div><br clear="all">
<div>
<p><span class="font33">timeout</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-244.jpg" alt="" style="width:42pt;height:58pt;">
</div><br clear="all">
<div>
<p><span class="font4">Slow start</span></p><img src="networking_files/networking-245.jpg" alt="" style="width:39pt;height:55pt;">
</div><br clear="all">
<div>
<p><span class="font33">cwnd </span><span class="font51">$</span><span class="font33">ssthresh</span></p>
</div><br clear="all">
<div>
<p><span class="font4">&gt; Congestion</span></p>
<p><span class="font4">“ avoidance</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-246.jpg" alt="" style="width:36pt;height:37pt;">
</div><br clear="all">
<div>
<p><span class="font33">timeout</span></p>
</div><br clear="all">
<div>
<p><span class="font33" style="text-decoration:underline;">duplicate ACK</span></p>
</div><br clear="all">
<div>
<p><span class="font33">ssthresh=cwnd/2</span></p>
<p><span class="font33">cwnd=ssthresh+3</span><span class="font49">«</span><span class="font33">MSS</span></p>
<p><span class="font3" style="font-style:italic;">retransmit missing segment</span></p>
</div><br clear="all">
<div>
<p><span class="font33">timeout</span></p>
<p><span class="font33">dupACKcount==3</span></p>
<p><span class="font33">ssthresh=cwnd/2 cwnd=1 MSS dupACKcount=0 </span><span class="font3" style="font-style:italic;">retransmit missing segment</span></p><img src="networking_files/networking-247.jpg" alt="" style="width:79pt;height:146pt;">
<p><span class="font33">ssthresh=cwnd/2</span></p>
<p><span class="font33">cwnd =1</span></p>
<p><span class="font33">dupACKcount=0</span></p>
<p><span class="font3" style="font-style:italic;">retransmit missing segment</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Fast recovery</span></p>
</div><br clear="all">
<div>
<p><span class="font33">new ACK</span></p>
<p><span class="font33">cwnd=ssthresh</span></p>
<p><span class="font33">dupACKcount=0</span></p>
<p><span class="font33">ssthresh=cwnd/2 cwnd=1 MSS dupACKcount=0 </span><span class="font3" style="font-style:italic;">retransmit missing segment</span></p><img src="networking_files/networking-248.jpg" alt="" style="width:81pt;height:147pt;">
<p><span class="font33">ssthresh=cwnd/2</span></p>
<p><span class="font33">cwnd=ssthresh+3</span><span class="font49">«</span><span class="font33">MSS</span></p>
<p><span class="font3" style="font-style:italic;">retransmit missing segment</span></p>
</div><br clear="all">
<div>
<p><span class="font33">dupACKcount++</span></p>
</div><br clear="all">
<div>
<p><span class="font33" style="text-decoration:underline;">dupACKcount==3</span></p>
</div><br clear="all">
<div>
<p><span class="font33">duplicate ACK</span></p>
<p><span class="font33">cwnd=cwnd+MSS</span></p><img src="networking_files/networking-249.jpg" alt="" style="width:127pt;height:30pt;">
</div><br clear="all">
<p><span class="font3" style="font-style:italic;">transmit new segment(s), as allowed</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 3.51 </span><span class="font50">♦ </span><span class="font5">FSM description of TCP congestion control</span></p>
<p><span class="font53">In this case, the network is continuing to deliver some segments from sender to receiver (as indicated by the receipt of duplicate ACKs). So TCP’s behavior to this type of loss event should be less drastic than with a timeout-indicated loss: TCP halves the value of </span><span class="font36">cwnd </span><span class="font53">(adding in 3 MSS for good measure to account for the triple duplicate ACKs received) and records the value of </span><span class="font36">ssthresh </span><span class="font53">to be half the value of </span><span class="font36">cwnd </span><span class="font53">when the triple duplicate ACKs were received. The fast-recovery state is then entered.</span></p>
<div>
<p><span class="font16" style="font-weight:bold;">D</span></p>
<p><span class="font2" style="font-weight:bold;">VideoNote</span></p>
<p><span class="font1" style="font-weight:bold;">Examining the behavior of TCP</span></p>
</div><br clear="all">
<p><span class="font22" style="font-weight:bold;">Fast Recovery</span></p>
<p><span class="font53">In fast recovery, the value of </span><span class="font36">cwnd </span><span class="font53">is increased by 1 MSS for every duplicate ACK received for the missing segment that caused TCP to enter the fast-recovery state. Eventually, when an ACK arrives for the missing segment, TCP enters the</span></p>
<div><img src="networking_files/networking-250.jpg" alt="" style="width:131pt;height:21pt;">
</div><br clear="all">
<div>
<p><span class="font23" style="font-weight:bold;">PRINCIPLES IN PRACTICE</span></p>
</div><br clear="all">
<p><span class="font4" style="font-weight:bold;">TCP SPLITTING: OPTIMIZING THE PERFORMANCE OF CLOUD SERVICES</span></p>
<p><span class="font4">For cloud services such as search, e-mail, and social networks, it is desirable to provide a high-level of responsiveness, ideally giving users the illusion that the services are running within their own end systems (including their smartphones). This can be a major challenge, as users are often located far away from the data centers responsible for serving the dynamic content associated with the cloud services. Indeed, if the end system is far from a data center, then the RTT will be large, potentially leading to poor response time performance due to TCP slow start.</span></p>
<p><span class="font4">As a case study, consider the delay in receiving a response for a search query. Typically, the server requires three TCP windows during slow start to deliver the response [Pathak 2010]. Thus the time from when an end system initiates a TCP connection until the time when it receives the last packet of the response is roughly 4 </span><span class="font9">• </span><span class="font4">RTT (one RTT to set up the TCP connection plus three RTTs for the three windows of data) plus the processing time in the data center. These RTT delays can lead to a noticeable delay in returning search results for a significant fraction of queries. Moreover, there can be significant packet loss in access networks, leading to TCP retransmissions and even larger delays.</span></p>
<p><span class="font4">One way to mitigate this problem and improve user-perceived performance is to (1) deploy front-end servers closer to the users, and (2) utilize </span><span class="font5" style="font-weight:bold;">TCP splitting </span><span class="font4">by breaking the TCP connection at the front-end server. With TCP splitting, the client establishes a TCP connection to the nearby front-end, and the front-end maintains a persistent TCP connection to the data center with a very large TCP congestion window [Tariq 2008, Pathak 2010, Chen 2011]. With this approach, the response time roughly becomes 4 </span><span class="font9">• </span><span class="font3" style="font-variant:small-caps;">RTT<sub>fe</sub></span><span class="font53"> + </span><span class="font3" style="font-variant:small-caps;">RTT<sub>be</sub></span><span class="font53"> + </span><span class="font4">processing time, where RTT<sub>FE</sub> is the round-trip time between client and front-end server, and RTT<sub>BE</sub> is the round-trip time between the front-end server and the data center (back-end server). If the front-end server is close to client, then this response time approximately becomes RTT plus processing time, since RTT<sub>FE</sub> is negligibly small and RTT<sub>BE </sub>is approximately RTT. In summary, TCP splitting can reduce the networking delay roughly from 4 </span><span class="font9">• </span><span class="font4">RTT to RTT, significantly improving user-perceived performance, particularly for users who are far from the nearest data center. TCP splitting also helps reduce TCP retransmission delays caused by losses in access networks. Google and Akamai have made extensive use of their CDN servers in access networks (recall our discussion in Section 2.6) to perform TCP splitting for the cloud services they support [Chen 2011].</span></p>
<p><span class="font53">congestion-avoidance state after deflating </span><span class="font36">cwnd</span><span class="font53">. If a timeout event occurs, fast recovery transitions to the slow-start state after performing the same actions as in slow start and congestion avoidance: The value of </span><span class="font36">cwnd </span><span class="font53">is set to 1 MSS, and the value of </span><span class="font36">ssthresh </span><span class="font53">is set to half the value of </span><span class="font36">cwnd </span><span class="font53">when the loss event occurred.</span></p><img src="networking_files/networking-251.jpg" alt="" style="width:242pt;height:142pt;">
<p><span class="font4">Transmission round</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 3.52 </span><span class="font50">♦ </span><span class="font5">Evolution of TCP's congestion window (Tahoe and Reno)</span></p>
<p><span class="font53">Fast recovery is a recommended, but not required, component of TCP [RFC 5681]. It is interesting that an early version of TCP, known as </span><span class="font53" style="font-weight:bold;">TCP Tahoe</span><span class="font53">, unconditionally cut its congestion window to 1 MSS and entered the slow-start phase after either a timeout-indicated or triple-duplicate-ACK-indicated loss event. The newer version of TCP, </span><span class="font53" style="font-weight:bold;">TCP Reno</span><span class="font53">, incorporated fast recovery.</span></p>
<p><span class="font53">Figure 3.52 illustrates the evolution of TCP’s congestion window for both Reno and Tahoe. In this figure, the threshold is initially equal to 8 MSS. For the first eight transmission rounds, Tahoe and Reno take identical actions. The congestion window climbs exponentially fast during slow start and hits the threshold at the fourth round of transmission. The congestion window then climbs linearly until a triple duplicate- ACK event occurs, just after transmission round 8. Note that the congestion window is 12 </span><span class="font60">• </span><span class="font53" style="font-style:italic;">MSS</span><span class="font53"> when this loss event occurs. The value of </span><span class="font36">ssthresh </span><span class="font53">is then set to 0.5 </span><span class="font60">• </span><span class="font36">cwnd </span><span class="font53">= 6 </span><span class="font60">• </span><span class="font53">MSS. Under TCP Reno, the congestion window is set to </span><span class="font36">cwnd </span><span class="font53">= 9 </span><span class="font60">• </span><span class="font53">MSS and then grows linearly. Under TCP Tahoe, the congestion window is set to 1 MSS and grows exponentially until it reaches the value of </span><span class="font36">ssthresh</span><span class="font53">, at which point it grows linearly.</span></p>
<p><span class="font53">Figure 3.51 presents the complete FSM description of TCP’s congestion-control algorithms—slow start, congestion avoidance, and fast recovery. The figure also indicates where transmission of new segments or retransmitted segments can occur. Although it is important to distinguish between TCP error control/retransmission and TCP congestion control, it’s also important to appreciate how these two aspects of TCP are inextricably linked.</span></p>
<p><span class="font22" style="font-weight:bold;">TCP Congestion Control: Retrospective</span></p>
<p><span class="font53">Having delved into the details of slow start, congestion avoidance, and fast recovery, it’s worthwhile to now step back and view the forest from the trees. Ignoring the</span></p><img src="networking_files/networking-252.jpg" alt="" style="width:261pt;height:149pt;">
<p><span class="font7" style="font-weight:bold;">Figure 3.53 </span><span class="font50">♦ </span><span class="font5">Additive-increase, multiplicative-decrease congestion control</span></p>
<p><span class="font53">initial slow-start period when a connection begins and assuming that losses are indicated by triple duplicate ACKs rather than timeouts, TCP’s congestion control consists of linear (additive) increase in </span><span class="font36">cwnd </span><span class="font53">of 1 MSS per RTT and then a halving (multiplicative decrease) of </span><span class="font36">cwnd </span><span class="font53">on a triple duplicate-ACK event. For this reason, TCP congestion control is often referred to as an </span><span class="font53" style="font-weight:bold;">additive-increase, multiplicative-decrease (AIMD) </span><span class="font53">form of congestion control. AIMD congestion control gives rise to the “saw tooth” behavior shown in Figure 3.53, which also nicely illustrates our earlier intuition of TCP “probing” for bandwidth—TCP linearly increases its congestion window size (and hence its transmission rate) until a triple duplicate-ACK event occurs. It then decreases its congestion window size by a factor of two but then again begins increasing it linearly, probing to see if there is additional available bandwidth.</span></p>
<p><span class="font53">TCP’s AIMD algorithm was developed based on a tremendous amount of engineering insight and experimentation with congestion control in operational networks. Ten years after TCP’s development, theoretical analyses showed that TCP’s congestion-control algorithm serves as a distributed asynchronous-optimization algorithm that results in several important aspects of user and network performance being simultaneously optimized [Kelly 1998]. A rich theory of congestion control has since been developed [Srikant 2012].</span></p>
<p><span class="font22" style="font-weight:bold;">TCP Cubic</span></p>
<p><span class="font53">Given TCP Reno’s additive-increase, multiplicative-decrease approach to congestion control, one might naturally wonder whether this is the best way to “probe” for a packet sending rate that is just below the threshold of triggering packet loss. Indeed, cutting the sending rate in half (or even worse, cutting the sending rate to one packet per RTT as in an earlier version of TCP known as TCP Tahoe) and then increasing rather slowly over time may be overly cautious. If the state of the congested link where packet loss occurred hasn’t changed much, then perhaps it’s better to more quickly ramp up the sending rate to get close to the pre-loss sending rate and only then probe cautiously for bandwidth. This insight lies at the heart of a flavor of TCP known as TCP CUBIC [Ha 2008, RFC 8312].</span></p>
<p><span class="font53">TCP CUBIC differs only slightly from TCP Reno. Once again, the congestion window is increased only on ACK receipt, and the slow start and fast recovery phases remain the same. CUBIC only changes the congestion avoidance phase, as follows:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;Let </span><span class="font53" style="font-style:italic;">W</span><span class="font53"> be size of TCP’s congestion control window when loss was last detected, and let </span><span class="font53" style="font-style:italic;">K</span><span class="font53"> be the future point in time when TCP CUBIC’s window size will again reach </span><span class="font53" style="font-style:italic;">W</span><span class="font53"> , assuming no losses. Several tunable CUBIC parameters determine the value </span><span class="font53" style="font-style:italic;">K</span><span class="font53">, that is, how quickly the protocol’s congestion window size would reach </span><span class="font53" style="font-style:italic;">W</span><span class="font53"><sub>max</sub>.</span></p></li>
<li>
<p><span class="font53">• &nbsp;CUBIC increases the congestion window as a function of </span><span class="font53" style="font-style:italic;">cube</span><span class="font53"> of the distance between the current time, </span><span class="font53" style="font-style:italic;">t,</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">K</span><span class="font53">. Thus, when </span><span class="font53" style="font-style:italic;">t</span><span class="font53"> is further away from </span><span class="font53" style="font-style:italic;">K</span><span class="font53">, the congestion window size increases are much larger than when </span><span class="font53" style="font-style:italic;">t</span><span class="font53"> is close to </span><span class="font53" style="font-style:italic;">K</span><span class="font53">. That is, CUBIC quickly ramps up TCP’s sending rate to get close to the pre-loss rate, </span><span class="font53" style="font-style:italic;">W</span><span class="font53"><sub>max</sub>, and only then probes cautiously for bandwidth as it approaches </span><span class="font53" style="font-style:italic;">W</span><span class="font53"><sub>max</sub>.</span></p></li>
<li>
<p><span class="font53">• &nbsp;When </span><span class="font53" style="font-style:italic;">t</span><span class="font53"> is greater than </span><span class="font53" style="font-style:italic;">K</span><span class="font53">, the cubic rule implies that CUBIC’s congestion window increases are small when </span><span class="font53" style="font-style:italic;">t</span><span class="font53"> is still close to </span><span class="font53" style="font-style:italic;">K</span><span class="font53"> (which is good if the congestion level of the link causing loss hasn’t changed much) but then increases rapidly as </span><span class="font53" style="font-style:italic;">t</span><span class="font53"> exceeds </span><span class="font53" style="font-style:italic;">K</span><span class="font53"> (which allows CUBIC to more quickly find a new operating point if the congestion level of the link that caused loss has changed significantly).</span></p></li></ul>
<p><span class="font53">Under these rules, the idealized performance of TCP Reno and TCP CUBIC are compared in Figure 3.54, adapted from [Huston 2017]. We see the slow start phase</span></p><img src="networking_files/networking-253.jpg" alt="" style="width:248pt;height:161pt;">
<p><span class="font7" style="font-weight:bold;">Figure 3.54 </span><span class="font50">♦ </span><span class="font5">TCP congestion avoidance sending rates: TCP Reno and TCP CUBIC</span></p>
<p><span class="font53">ending at </span><span class="font53" style="font-style:italic;">t<sub>0</sub>.</span><span class="font53"> Then, when congestion loss occurs at </span><span class="font53" style="font-style:italic;">t</span><span class="font49" style="font-style:italic;">1</span><span class="font53" style="font-style:italic;">, t<sub>2</sub>,</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">t</span><span class="font49" style="font-style:italic;">3</span><span class="font53" style="font-style:italic;">,</span><span class="font53"> CUBIC more quickly ramps up close to </span><span class="font53" style="font-style:italic;">W</span><span class="font53"><sub>max</sub> (thereby enjoying more overall throughput than TCP Reno). We can see graphically how TCP CUBIC attempts to maintain the flow for as long as possible just below the (unknown to the sender) congestion threshold. Note that at </span><span class="font53" style="font-style:italic;">t</span><span class="font49" style="font-style:italic;">3</span><span class="font53" style="font-style:italic;">,</span><span class="font53"> the congestion level has presumably decreased appreciably, allowing both TCP Reno and TCP CUBIC to achieve sending rates higher than </span><span class="font53" style="font-style:italic;">W</span><span class="font53"><sub>max</sub></span><span class="font53" style="font-style:italic;">.</span></p>
<p><span class="font53">TCP CUBIC has recently gained wide deployment. While measurements taken around 2000 on popular Web servers showed that nearly all were running some version of TCP Reno [Padhye 2001], more recent measurements of the 5000 most popular Web servers shows that nearly 50% are running a version of TCP CUBIC [Yang 2014], which is also the default version of TCP used in the Linux operating system.</span></p>
<p><span class="font22" style="font-weight:bold;">Macroscopic Description of TCP Reno Throughput</span></p>
<p><span class="font53">Given the saw-toothed behavior of TCP Reno, it’s natural to consider what the average throughput (that is, the average rate) of a long-lived TCP Reno connection might be. In this analysis, we’ll ignore the slow-start phases that occur after timeout events. (These phases are typically very short, since the sender grows out of the phase exponentially fast.) During a particular round-trip interval, the rate at which TCP sends data is a function of the congestion window and the current </span><span class="font53" style="font-style:italic;">RTT. </span><span class="font53">When the window size is </span><span class="font53" style="font-style:italic;">w</span><span class="font53"> bytes and the current round-trip time is </span><span class="font53" style="font-style:italic;">RTT</span><span class="font53"> second</span><span class="font53" style="font-style:italic;">s</span><span class="font53">, then TCP’s transmission rate is roughly </span><span class="font53" style="font-style:italic;">w/RTT.</span><span class="font53"> TCP then probes for additional bandwidth by increasing </span><span class="font53" style="font-style:italic;">w</span><span class="font53"> by 1 MSS each </span><span class="font53" style="font-style:italic;">RTT</span><span class="font53"> until a loss event occurs. Denote by </span><span class="font53" style="font-style:italic;">W</span><span class="font53"> the value of </span><span class="font53" style="font-style:italic;">w</span><span class="font53"> when a loss event occurs. Assuming that </span><span class="font53" style="font-style:italic;">RTT</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">W</span><span class="font53"> are approximately constant over the duration of the connection, the TCP transmission rate ranges from </span><span class="font53" style="font-style:italic;">W</span><span class="font53">/(2 • </span><span class="font53" style="font-style:italic;">RTT)</span><span class="font53"> to </span><span class="font53" style="font-style:italic;">W/RTT.</span></p>
<p><span class="font53">These assumptions lead to a highly simplified macroscopic model for the steadystate behavior of TCP. The network drops a packet from the connection when the rate increases to </span><span class="font53" style="font-style:italic;">W/RTT;</span><span class="font53"> the rate is then cut in half and then increases by MSS/</span><span class="font53" style="font-style:italic;">RTT</span><span class="font53"> every </span><span class="font53" style="font-style:italic;">RTT</span><span class="font53"> until it again reaches </span><span class="font53" style="font-style:italic;">W/RTT</span><span class="font53">. This process repeats itself over and over again. Because TCP’s throughput (that is, rate) increases linearly between the two extreme values, we have</span></p>
<div>
<p><span class="font53">average throughput of a connection </span><span class="font54">=</span></p>
</div><br clear="all">
<div>
<p><span class="font53" style="text-decoration:underline;">0.75 </span><span class="font60" style="text-decoration:underline;">• </span><span class="font53" style="font-style:italic;text-decoration:underline;">W</span></p>
</div><br clear="all">
<div>
<p><span class="font53" style="font-style:italic;">RTT</span></p>
</div><br clear="all">
<p><span class="font53">Using this highly idealized model for the steady-state dynamics of TCP, we can also derive an interesting expression that relates a connection’s loss rate to its available bandwidth [Mathis 1997]. This derivation is outlined in the homework problems. A more sophisticated model that has been found empirically to agree with measured data is [Padhye 2000].</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">3.7.2 </span><span class="font23" style="font-weight:bold;">Network-Assisted Explicit Congestion Notification and Delayed-based Congestion Control</span></p></li></ul>
<p><span class="font53">Since the initial standardization of slow start and congestion avoidance in the late 1980’s [RFC 1122], TCP has implemented the form of end-end congestion control that we studied in Section 3.7.1: a TCP sender receives no explicit congestion indications from the network layer, and instead infers congestion through observed packet loss. More recently, extensions to both IP and TCP [RFC 3168] have been proposed, implemented, and deployed that allow the network to explicitly signal congestion to a TCP sender and receiver. In addition, a number of variations of TCP congestion control protocols have been proposed that infer congestion using measured packet delay. We’ll take a look at both network-assisted and delay-based congestion control in this section.</span></p>
<p><span class="font22" style="font-weight:bold;">Explicit Congestion Notification</span></p>
<p><span class="font53">Explicit Congestion Notification [RFC 3168] is the form of network-assisted congestion control performed within the Internet. As shown in Figure 3.55, both TCP and IP are involved. At the network layer, two bits (with four possible values, overall) in the Type of Service field of the IP datagram header (which we’ll discuss in Section 4.3) are used for ECN.</span></p>
<p><span class="font53">One setting of the ECN bits is used by a router to indicate that it (the router) is experiencing congestion. This congestion indication is then carried in the marked IP datagram to the destination host, which then informs the sending host, as shown in Figure 3.55. RFC 3168 does not provide a definition of when a router is congested; that decision is a configuration choice made possible by the router vendor, and decided by the network operator. However, the intuition is that the congestion indication bit can be set to signal the onset of congestion to the send before loss actually occurs. A second setting of the ECN bits is used by the sending host to inform routers that the sender and receiver are ECN-capable, and thus capable of taking action in response to ECN-indicated network congestion.</span></p>
<p><span class="font53">As shown in Figure 3.55, when the TCP in the receiving host receives an ECN congestion indication via a received datagram, the TCP in the receiving host informs the TCP in the sending host of the congestion indication by setting the ECE (Explicit Congestion Notification Echo) bit (see Figure 3.29) in a receiver-to-sender TCP ACK segment. The TCP sender, in turn, reacts to an ACK with a congestion indication by halving the congestion window, as it would react to a lost segment using fast retransmit, and sets the CWR (Congestion Window Reduced) bit in the header of the next transmitted TCP sender-to-receiver segment.</span></p>
<p><a name="bookmark324"></a><span class="font53">Other transport-layer protocols besides TCP may also make use of networklayer-signaled ECN. The Datagram Congestion Control Protocol (DCCP) [RFC 4340] provides a low-overhead, congestion-controlled UDP-like unreliable service that utilizes ECN. DCTCP (Data Center TCP) [Alizadeh 2010, RFC 8257] and</span></p>
<div>
<p><span class="font4">Host A</span></p><img src="networking_files/networking-254.jpg" alt="" style="width:34pt;height:37pt;">
</div><br clear="all">
<div>
<p><span class="font4">ECN Echo bit set in receiver-to-sender TCP ACK segment</span></p><img src="networking_files/networking-255.jpg" alt="" style="width:250pt;height:126pt;">
<p><span class="font7" style="font-weight:bold;">Figure 3.55 </span><span class="font50">♦ </span><span class="font5">Explicit Congestion Notification: network-assisted congestion control</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Host B</span></p><img src="networking_files/networking-256.jpg" alt="" style="width:33pt;height:36pt;">
</div><br clear="all">
<p><span class="font53">DCQCN (Data Center Quantized Congestion Notification) [Zhu 2015] designed specifically for data center networks, also makes use of ECN. Recent Internet measurements show increasing deployment of ECN capabilities in popular servers as well as in routers along paths to those servers [Kuhlewind 2013].</span></p>
<p><span class="font22" style="font-weight:bold;">Delay-based Congestion Control</span></p>
<p><span class="font53">Recall from our ECN discussion above that a congested router can set the congestion indication bit to signal congestion onset to senders </span><span class="font53" style="font-style:italic;">before</span><span class="font53"> full buffers cause packets to be dropped at that router. This allows senders to decrease their sending rates earlier, hopefully </span><span class="font53" style="font-style:italic;">before</span><span class="font53"> packet loss, thus avoiding costly packet loss and retransmission. A second congestion-avoidance approach takes a delay-based approach to also proactively detect congestion onset </span><span class="font53" style="font-style:italic;">before</span><span class="font53"> packet loss occurs.</span></p>
<p><span class="font53">In TCP Vegas [Brakmo 1995], the sender measures the RTT of the source-to-destination path for all acknowledged packets. Let </span><span class="font53" style="font-style:italic;">RTT</span><span class="font53"><sub>min</sub> be the minimum of these measurements at a sender; this occurs when the path is uncongested and packets experience minimal queuing delay. If TCP Vegas’ congestion window size is </span><span class="font36">cwnd</span><span class="font53">, then the uncongested throughput rate would be </span><span class="font36">cwnd</span><span class="font53">/</span><span class="font53" style="font-style:italic;">RTT</span><span class="font53"><sub>min</sub>. The intuition behind TCP Vegas is that if the actual sender-measured throughput is close to this value, the TCP sending rate can be increased since (by definition and by measurement) the path is not yet congested. However, if the actual sender-measured throughput is significantly less than the uncongested throughput rate, the path is congested and the Vegas TCP sender will decrease its sending rate. Details can be found in [Brakmo 1995].</span></p>
<p><span class="font53">TCP Vegas operates under the intuition that TCP senders should </span><span class="font53" style="font-style:italic;">“Keep the pipe just full, but no fuller”</span><span class="font53"> [Kleinrock 2018]. “Keeping the pipe full” means that links (in particular the bottleneck link that is limiting a connection’s throughput) are kept busy transmitting, doing useful work; “but no fuller” means that there is nothing to gain (except increased delay!) if large queues are allowed to build up while the pipe is kept full.</span></p>
<p><span class="font53">The BBR congestion control protocol [Cardwell 2017] builds on ideas in TCP Vegas, and incorporates mechanisms that allows it compete fairly (see Section 3.7.3) with TCP non-BBR senders. [Cardwell 2017] reports that in 2016, Google began using BBR for all TCP traffic on its private B4 network [Jain 2013] that interconnects Google data centers, replacing CUBIC. It is also being deployed on Google and YouTube Web servers. Other delay-based TCP congestion control protocols include TIMELY for data center networks [Mittal 2015], and Compound TCP (CTPC) [Tan 2006] and FAST [Wei 2006] for high-speed and long distance networks.</span></p>
<p><span class="font56" style="font-weight:bold;">3.7.3 </span><span class="font23" style="font-weight:bold;">Fairness</span></p>
<p><span class="font53">Consider </span><span class="font53" style="font-style:italic;">K</span><span class="font53"> TCP connections, each with a different end-to-end path, but all passing through a bottleneck link with transmission rate </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> bps. (By </span><span class="font53" style="font-style:italic;">bottleneck link,</span><span class="font53"> we mean that for each connection, all the other links along the connection’s path are not congested and have abundant transmission capacity as compared with the transmission capacity of the bottleneck link.) Suppose each connection is transferring a large file and there is no UDP traffic passing through the bottleneck link. A congestioncontrol mechanism is said to be </span><span class="font53" style="font-style:italic;">fair</span><span class="font53"> if the average transmission rate of each connection is approximately </span><span class="font53" style="font-style:italic;">R/K;</span><span class="font53"> that is, each connection gets an equal share of the link bandwidth.</span></p>
<p><span class="font53">Is TCP’s AIMD algorithm fair, particularly given that different TCP connections may start at different times and thus may have different window sizes at a given point in time? [Chiu 1989] provides an elegant and intuitive explanation of why TCP congestion control converges to provide an equal share of a bottleneck link’s bandwidth among competing TCP connections.</span></p>
<p><span class="font53">Let’s consider the simple case of two TCP connections sharing a single link with transmission rate </span><span class="font53" style="font-style:italic;">R</span><span class="font53">, as shown in Figure 3.55. Assume that the two connections have the same MSS and RTT (so that if they have the same congestion window size, then they have the same throughput), that they have a large amount of data to send, and that no other TCP connections or UDP datagrams traverse this shared link. Also, ignore the slow-start phase of TCP and assume the TCP connections are operating in CA mode (AIMD) at all times.</span></p>
<p><a name="bookmark325"></a><span class="font53">Figure 3.56 plots the throughput realized by the two TCP connections. If TCP is to share the link bandwidth equally between the two connections, then the realized throughput should fall along the 45-degree arrow (equal bandwidth share) emanating from the origin. Ideally, the sum of the two throughputs should equal </span><span class="font53" style="font-style:italic;">R</span><span class="font53">. (Certainly, each connection receiving an equal, but zero, share of the link capacity is not</span></p><img src="networking_files/networking-257.jpg" alt="" style="width:260pt;height:102pt;">
<p><span class="font4">TCP connection 1</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 3.56 </span><span class="font50">♦ </span><span class="font5">Two TCP connections sharing a single bottleneck link</span></p>
<p><span class="font53">a desirable situation!) So the goal should be to have the achieved throughputs fall somewhere near the intersection of the equal bandwidth share line and the full bandwidth utilization line in Figure 3.56.</span></p>
<p><span class="font53">Suppose that the TCP window sizes are such that at a given point in time, connections 1 and 2 realize throughputs indicated by point </span><span class="font53" style="font-style:italic;">A</span><span class="font53"> in Figure 3.56. Because the amount of link bandwidth jointly consumed by the two connections is less than </span><span class="font53" style="font-style:italic;">R,</span><span class="font53"> no loss will occur, and both connections will increase their window by 1 MSS per RTT as a result of TCP’s congestion-avoidance algorithm. Thus, the joint throughput of the two connections proceeds along a 45-degree line (equal increase for both connections) starting from point </span><span class="font53" style="font-style:italic;">A</span><span class="font53">. Eventually, the link bandwidth jointly consumed by the two connections will be greater than </span><span class="font53" style="font-style:italic;">R,</span><span class="font53"> and eventually packet loss will occur. Suppose that connections 1 and 2 experience packet loss when they realize throughputs indicated by point </span><span class="font53" style="font-style:italic;">B.</span><span class="font53"> Connections 1 and 2 then decrease their windows by a factor of two. The resulting throughputs realized are thus at point </span><span class="font53" style="font-style:italic;">C,</span><span class="font53"> halfway along a vector starting at </span><span class="font53" style="font-style:italic;">B</span><span class="font53"> and ending at the origin. Because the joint bandwidth use is less than </span><span class="font53" style="font-style:italic;">R </span><span class="font53">at point </span><span class="font53" style="font-style:italic;">C,</span><span class="font53"> the two connections again increase their throughputs along a 45-degree line starting from </span><span class="font53" style="font-style:italic;">C</span><span class="font53">. Eventually, loss will again occur, for example, at point </span><span class="font53" style="font-style:italic;">D,</span><span class="font53"> and the two connections again decrease their window sizes by a factor of two, and so on. You should convince yourself that the bandwidth realized by the two connections eventually fluctuates along the equal bandwidth share line. You should also convince yourself that the two connections will converge to this behavior regardless of where they are in the two-dimensional space! Although a number of idealized assumptions lie behind this scenario, it still provides an intuitive feel for why TCP results in an equal sharing of bandwidth among connections.</span></p>
<p><span class="font53">In our idealized scenario, we assumed that only TCP connections traverse the bottleneck link, that the connections have the same RTT value, and that only a single TCP connection is associated with a host-destination pair. In practice, these conditions are typically not met, and client-server applications can thus obtain very unequal portions of link bandwidth. In particular, it has been shown that when</span></p><img src="networking_files/networking-258.jpg" alt="" style="width:213pt;height:211pt;">
<p><span class="font7" style="font-weight:bold;">Figure 3.57 </span><span class="font50">♦ </span><span class="font5">Throughput realized by TCP connections 1 and 2</span></p>
<p><span class="font53">multiple connections share a common bottleneck, those sessions with a smaller RTT are able to grab the available bandwidth at that link more quickly as it becomes free (that is, open their congestion windows faster) and thus will enjoy higher throughput than those connections with larger RTTs [Lakshman 1997].</span></p>
<p><span class="font22" style="font-weight:bold;">Fairness and UDP</span></p>
<p><span class="font53">We have just seen how TCP congestion control regulates an application’s transmission rate via the congestion window mechanism. Many multimedia applications, such as Internet phone and video conferencing, often do not run over TCP for this very reason—they do not want their transmission rate throttled, even if the network is very congested. Instead, these applications prefer to run over UDP, which does not have built-in congestion control. When running over UDP, applications can pump their audio and video into the network at a constant rate and occasionally lose packets, rather than reduce their rates to “fair” levels at times of congestion and not lose any packets. From the perspective of TCP, the multimedia applications running over UDP are not being fair—they do not cooperate with the other connections nor adjust their transmission rates appropriately. Because TCP congestion control will decrease its transmission rate in the face of increasing congestion (loss), while UDP sources need not, it is possible for UDP sources to crowd out TCP traffic. A number of congestion-control mechanisms have been proposed for the Internet that prevent UDP traffic from bringing the Internet’s throughput to a grinding halt [Floyd 1999; Floyd 2000; Kohler 2006; RFC 4340].</span></p>
<p><span class="font22" style="font-weight:bold;">Fairness and Parallel TCP Connections</span></p>
<p><span class="font53">But even if we could force UDP traffic to behave fairly, the fairness problem would still not be completely solved. This is because there is nothing to stop a TCP-based application from using multiple parallel connections. For example, Web browsers often use multiple parallel TCP connections to transfer the multiple objects within a Web page. (The exact number of multiple connections is configurable in most browsers.) When an application uses multiple parallel connections, it gets a larger fraction of the bandwidth in a congested link. As an example, consider a link of rate </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> supporting nine ongoing client-server applications, with each of the applications using one TCP connection. If a new application comes along and also uses one TCP connection, then each application gets approximately the same transmission rate of </span><span class="font53" style="font-style:italic;">R</span><span class="font53">/10. But if this new application instead uses 11 parallel TCP connections, then the new application gets an unfair allocation of more than </span><span class="font53" style="font-style:italic;">R</span><span class="font53">/2. Because Web traffic is so pervasive in the Internet, multiple parallel connections are not uncommon.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">3.8 </span><span class="font24" style="font-weight:bold;">Evolution of Transport-Layer Functionality</span></p></li></ul>
<p><span class="font53">Our discussion of specific Internet transport protocols in this chapter has focused on UDP and TCP—the two “work horses” of the Internet transport layer. However, as we’ve seen, three decades of experience with these two protocols has identified circumstances in which neither is ideally suited, and so the design and implementation of transport layer functionality has continued to evolve.</span></p>
<p><span class="font53">We’ve seen a rich evolution in the use of TCP over the past decade. In Sections 3.7.1 and 3.7.2, we learned that in addition to “classic” versions of TCP such as TCP Tahoe and Reno, there are now several newer versions of TCP that have been developed, implemented, deployed, and are in significant use today. These include TCP CUBIC, DCTCP, CTCP, BBR, and more. Indeed, measurements in [Yang 2014] indicate that CUBIC (and its predecessor, BIC [Xu 2004]) and CTCP are more widely deployed on Web servers than classic TCP Reno; we also saw that BBR is being deployed in Google’s internal B4 network, as well as on many of Google’s public-facing servers.</span></p>
<p><a name="bookmark326"></a><span class="font53">And there are many (many!) more versions of TCP! There are versions of TCP specifically designed for use over wireless links, over high-bandwidth paths with large RTTs, for paths with packet re-ordering, and for short paths strictly within data centers. There are versions of TCP that implement different priorities among TCP connections competing for bandwidth at a bottleneck link, and for TCP connections whose segments are being sent over different source-destination paths in parallel. There are also variations of TCP that deal with packet acknowledgment and TCP session establishment/closure differently than we studied in Section 3.5.6. Indeed, it’s probably not even correct anymore to refer to “the” TCP protocol; perhaps the </span><span class="font53" style="font-style:italic;">only</span><span class="font53"> common features of these protocols is that they use the TCP segment format that we studied in Figure 3.29, and that they should compete “fairly” amongst themselves in the face of network congestion! For a survey of the many flavors of TCP, see [Afanasyev 2010] and [Narayan 2018].</span></p>
<p><span class="font22" style="font-weight:bold;">QUIC: Quick UDP Internet Connections</span></p>
<p><span class="font53">If the transport services needed by an application don’t quite fit either the UDP or TCP service models—perhaps an application needs more services than those provided by UDP but does not want all of the particular functionality that comes with TCP, or may want different services than those provided by TCP—applica-tion designers can always “roll their own” protocol at the application layer. This is the approach taken in the QUIC (Quick UDP Internet Connections) protocol [Langley 2017, QUIC 2020]. Specifically, QUIC is a new application-layer protocol designed from the ground up to improve the performance of transport-layer services for secure HTTP. QUIC has already been widely deployed, although is still in the process of being standardized as an Internet RFC [QUIC 2020]. Google has deployed QUIC on many of its public-facing Web servers, in its mobile video streaming YouTube app, in its Chrome browser, and in Android’s Google Search app. With more than 7% of Internet traffic today now being QUIC [Langley 2017], we’ll want to take a closer look. Our study of QUIC will also serve as a nice culmination of our study of the transport layer, as QUIC uses many of the approaches for reliable data transfer, congestion control, and connection management that we’ve studied in this chapter.</span></p>
<p><span class="font53">As shown in Figure 3.58, QUIC is an application-layer protocol, using UDP as its underlying transport-layer protocol, and is designed to interface above specifically to a simplified but evolved version of HTTP/2. In the near future, HTTP/3 will natively incorporate QUIC [HTTP/3 2020]. Some of QUIC’s major features include:</span></p>
<p><span class="font53">• </span><span class="font53" style="font-weight:bold;">Connection-Oriented and Secure. </span><span class="font53">Like TCP, QUIC is a connection-oriented protocol between two endpoints. This requires a handshake between endpoints to set up the QUIC connection state. Two pieces of connection state are the source and destination connection ID. All QUIC packets are encrypted, and as suggested in Figure 3.58, QUIC combines the handshakes needed to establish connection state with those needed for authentication and encryption (transport layer security topics that we’ll study in Chapter 8), thus providing faster establishment than the protocol stack in Figure 3.58(a), where multiple RTTs are</span></p><img src="networking_files/networking-259.jpg" alt="" style="width:244pt;height:78pt;">
<p><span class="font4" style="font-weight:bold;"><sup>a</sup>- &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;b.</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 3.58 </span><span class="font50">♦ </span><span class="font5">(a) traditional secure HTTP protocol stack, and the (b) secure QUIC-based HTTP/3 protocol stack</span></p>
<p><span class="font53">required to first establish a TCP connection, and then establish a TLS connection over the TCP connection.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-weight:bold;">Streams. </span><span class="font53">QUIC allows several different application-level “streams” to be multiplexed through a single QUIC connection, and once a QUIC connection is established, new streams can be quickly added. A stream is an abstraction for the reliable, in-order bi-directional delivery of data between two QUIC endpoints. In the context of HTTP/3, there would be a different stream for each object in a Web page. Each connection has a connection ID, and each stream within a connection has a stream ID; both of these IDs are contained in a QUIC packet header (along with other header information). Data from multiple streams may be contained within a single QUIC segment, which is carried over UDP. The Stream Control Transmission Protocol (SCTP) [RFC 4960, RFC 3286] is an earlier reliable, message-oriented protocol that pioneered the notion of multiplexing multiple application-level “streams” through a single SCTP connection. We’ll see in Chapter 7 that SCTP is used in control plane protocols in 4G/5G cellular wireless networks.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-weight:bold;">Reliable, TCP-friendly congestion-controlled data transfer. </span><span class="font53">As illustrated in Figure 3.59(b), QUIC provides reliable data transfer to each QUIC stream </span><span class="font53" style="font-style:italic;">separately.</span><span class="font53"> Figure 3.59(a) shows the case of HTTP/1.1 sending multiple HTTP requests, all over a single TCP connection. Since TCP provides reliable, in-order byte delivery, this means that the multiple HTTP requests must be delivered inorder at the destination HTTP server. Thus, if bytes from one HTTP request are lost, the remaining HTTP requests can not be delivered until those lost bytes are retransmitted and correctly received by TCP at the HTTP server—the so-called HOL blocking problem that we encountered earlier in Section 2.2.5. Since QUIC provides a reliable in-order delivery on a </span><span class="font53" style="font-style:italic;">per-stream</span><span class="font53"> basis, a lost UDP segment only impacts those streams whose data was carried in that segment; HTTP messages in other streams can continue to be received and delivered to the application. QUIC provides reliable data transfer using acknowledgment mechanisms similar to TCP’s, as specified in [RFC 5681].</span></p></li></ul>
<p><span class="font4">Transport Application</span></p><img src="networking_files/networking-260.jpg" alt="" style="width:422pt;height:138pt;">
<p><span class="font4" style="font-weight:bold;">a. HTTP 1.1</span></p>
<p><span class="font4" style="font-weight:bold;">b. HTTP/3</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 3.59 </span><span class="font50">♦ </span><span class="font5">(a) HTTP/1.1: a single-connection client and server using application-level TLS encryption over TCP's reliable data transfer (RDT) and congestion control (CC) (b) HTTP/3: a multi-stream client and server using QUIC's encryption, reliable data transfer and congestion control over UDP's unreliable datagram service</span></p>
<p><span class="font53">QUIC’s congestion control is based on TCP NewReno [RFC 6582], a slight modification to the TCP Reno protocol that we studied in Section 3.7.1. QUIC’s Draft specification [QUIC-recovery 2020] notes “Readers familiar with TCP’s loss detection and congestion control will find algorithms here that parallel well-known TCP ones.” Since we’ve carefully studied TCP’s congestion control in Section 3.7.1, we’d be right at home reading the details of QUIC’s draft specification of its congestion control algorithm!</span></p>
<p><span class="font53">In closing, it’s worth highlighting again that QUIC is an </span><span class="font53" style="font-style:italic;">application-layer </span><span class="font53">protocol providing reliable, congestion-controlled data transfer between two endpoints. The authors of QUIC [Langley 2017] stress that this means that changes can be made to QUIC at “application-update timescales,” that is, much faster than TCP or UDP update timescales.</span></p>
<p><span class="font59" style="font-weight:bold;">3.9 </span><span class="font24" style="font-weight:bold;">Summary</span></p>
<p><a name="bookmark327"></a><span class="font53">We began this chapter by studying the services that a transport-layer protocol can provide to network applications. At one extreme, the transport-layer protocol can be very simple and offer a no-frills service to applications, providing only a multiplexing/ demultiplexing function for communicating processes. The Internet’s UDP protocol is an example of such a no-frills transport-layer protocol. At the other extreme, a transport-layer protocol can provide a variety of guarantees to applications, such as reliable delivery of data, delay guarantees, and bandwidth guarantees. Nevertheless, the services that a transport protocol can provide are often constrained by the service model of the underlying network-layer protocol. If the network-layer protocol cannot provide delay or bandwidth guarantees to transport-layer segments, then the transportlayer protocol cannot provide delay or bandwidth guarantees for the messages sent between processes.</span></p>
<p><span class="font53">We learned in Section 3.4 that a transport-layer protocol can provide reliable data transfer even if the underlying network layer is unreliable. We saw that providing reliable data transfer has many subtle points, but that the task can be accomplished by carefully combining acknowledgments, timers, retransmissions, and sequence numbers.</span></p>
<p><span class="font53">Although we covered reliable data transfer in this chapter, we should keep in mind that reliable data transfer can be provided by link-, network-, transport-, or application-layer protocols. Any of the upper four layers of the protocol stack can implement acknowledgments, timers, retransmissions, and sequence numbers and provide reliable data transfer to the layer above. In fact, over the years, engineers and computer scientists have independently designed and implemented link-, network-, transport-, and application-layer protocols that provide reliable data transfer (although many of these protocols have quietly disappeared).</span></p>
<p><span class="font53">In Section 3.5, we took a close look at TCP, the Internet’s connection-oriented and reliable transport-layer protocol. We learned that TCP is complex, involving connection management, flow control, and round-trip time estimation, as well as reliable data transfer. In fact, TCP is actually more complex than our description—we intentionally did not discuss a variety of TCP patches, fixes, and improvements that are widely implemented in various versions of TCP. All of this complexity, however, is hidden from the network application. If a client on one host wants to send data reliably to a server on another host, it simply opens a TCP socket to the server and pumps data into that socket. The client-server application is blissfully unaware of TCP’s complexity.</span></p>
<p><span class="font53">In Section 3.6, we examined congestion control from a broad perspective, and in Section 3.7, we showed how TCP implements congestion control. We learned that congestion control is imperative for the well-being of the network. Without congestion control, a network can easily become gridlocked, with little or no data being transported end-to-end. In Section 3.7, we learned that classic TCP implements an end-to-end congestion-control mechanism that additively increases its transmission rate when the TCP connection’s path is judged to be congestion-free, and multiplicatively decreases its transmission rate when loss occurs. This mechanism also strives to give each TCP connection passing through a congested link an equal share of the link bandwidth. We also studied several newer variations of TCP congestion control that try to determine TCP’s sending rate rate more quickly than classic TCP, use a delay-based approach or explicit congestion notification from the network (rather than a loss-based approach) to determine TCP’s sending rate. We also examined in some depth the impact of TCP connection establishment and slow start on latency. We observed that in many important scenarios, connection establishment and slow start significantly contribute to end-to-end delay. We emphasize once more that while TCP congestion control has evolved over the years, it remains an area of intensive research and will likely continue to evolve in the upcoming years. To wrap up this chapter, in Section 3.8, we studied recent developments in implementing many of the transport layer’s functions—reliable data transfer, congestion control, connection establishment, and more—in the application layer using the QUIC protocol.</span></p>
<p><span class="font53">In Chapter 1, we said that a computer network can be partitioned into the “network edge” and the “network core.” The network edge covers everything that happens in the end systems. Having now covered the application layer and the transport layer, our discussion of the network edge is complete. It is time to explore the network core! This journey begins in the next two chapters, where we’ll study the network layer, and continues into Chapter 6, where we’ll study the link layer.</span></p>
<p><span class="font24" style="font-weight:bold;">Homework Problems and Questions</span></p>
<p><span class="font23" style="font-weight:bold;">Chapter 3 Review Questions</span></p>
<p><span class="font43" style="font-weight:bold;">SECTIONS 3.1-3.3</span></p>
<p><span class="font53">R1. Suppose the network layer provides the following service. The network layer in the source host accepts a segment of maximum size 1,200 bytes and a destination host address from the transport layer. The network layer then guarantees to deliver the segment to the transport layer at the destination host. Suppose many network application processes can be running at the destination host.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Design the simplest possible transport-layer protocol that will get application data to the desired process at the destination host. Assume the operating system in the destination host has assigned a 4-byte port number to each running application process.</span></p></li>
<li>
<p><span class="font53">b. Modify this protocol so that it provides a “return address” to the destination process.</span></p></li>
<li>
<p><a name="bookmark328"></a><span class="font53">c. In your protocols, does the transport layer “have to do anything” in the core of the computer network?</span></p></li></ul>
<p><span class="font53">R2. Consider a planet where everyone belongs to a family of six, every family lives in its own house, each house has a unique address, and each person in a given house has a unique name. Suppose this planet has a mail service that delivers letters from source house to destination house. The mail service requires that (1) the letter be in an envelope, and that (2) the address of the destination house (and nothing more) be clearly written on the envelope. Suppose each family has a delegate family member who collects and distributes letters for the other family members. The letters do not necessarily provide any indication of the recipients of the letters.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Using the solution to Problem R1 above as inspiration, describe a protocol that the delegates can use to deliver letters from a sending family member to a receiving family member.</span></p></li>
<li>
<p><span class="font53">b. In your protocol, does the mail service ever have to open the envelope and examine the letter in order to provide its service?</span></p></li></ul>
<p><span class="font53">R3. How is a UDP socket fully identified? What about a TCP socket? What is the difference between the full identification of both sockets?</span></p>
<p><span class="font53">R4. Describe why an application developer might choose to run an application over UDP rather than TCP.</span></p>
<p><span class="font53">R5. Why is it that voice and video traffic is often sent over TCP rather than UDP in today’s Internet? </span><span class="font53" style="font-style:italic;">(Hint:</span><span class="font53"> The answer we are looking for has nothing to do with TCP’s congestion-control mechanism.)</span></p>
<p><span class="font53">R6. Is it possible for an application to enjoy reliable data transfer even when the application runs over UDP? If so, how?</span></p>
<p><span class="font53">R7. Suppose a process in Host C has a UDP socket with port number 6789. Suppose both Host A and Host B each send a UDP segment to Host C with destination port number 6789. Will both of these segments be directed to the same socket at Host C? If so, how will the process at Host C know that these two segments originated from two different hosts?</span></p>
<p><span class="font53">R8. Suppose that a Web server runs in Host C on port 80. Suppose this Web server uses persistent connections, and is currently receiving requests from two different Hosts, A and B. Are all of the requests being sent through the same socket at Host C? If they are being passed through different sockets, do both of the sockets have port 80? Discuss and explain.</span></p>
<p><span class="font43" style="font-weight:bold;">SECTION 3.4</span></p>
<p><span class="font53">R9. In our </span><span class="font36">rdt </span><span class="font53">protocols, why did we need to introduce sequence numbers?</span></p>
<p><span class="font53">R10. In our </span><span class="font36">rdt </span><span class="font53">protocols, why did we need to introduce timers?</span></p>
<p><span class="font53">R11. Suppose that the roundtrip delay between sender and receiver is constant and known to the sender. Would a timer still be necessary in protocol </span><span class="font36">rdt 3.0</span><span class="font53">, assuming that packets can be lost? Explain.</span></p>
<p><span class="font53">R12. Visit the Go-Back-N interactive animation at the Companion Website.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Have the source send five packets, and then pause the animation before any of the five packets reach the destination. Then kill the first packet and resume the animation. Describe what happens.</span></p></li>
<li>
<p><span class="font53">b. Repeat the experiment, but now let the first packet reach the destination and kill the first acknowledgment. Describe again what happens.</span></p></li>
<li>
<p><span class="font53">c. Finally, try sending six packets. What happens?</span></p></li></ul>
<p><span class="font53">R13. Repeat R12, but now with the Selective Repeat interactive animation. How are Selective Repeat and Go-Back-N different?</span></p>
<p><span class="font43" style="font-weight:bold;">SECTION 3.5</span></p>
<p><span class="font53">R14. True or false?</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Host A is sending Host B a large file over a TCP connection. Assume Host B has no data to send Host A. Host B will not send acknowledgments to Host A because Host B cannot piggyback the acknowledgments on data.</span></p></li>
<li>
<p><span class="font53">b. The size of the TCP </span><span class="font36">rwnd </span><span class="font53">never changes throughout the duration of the connection.</span></p></li>
<li>
<p><span class="font53">c. Suppose Host A is sending Host B a large file over a TCP connection. The number of unacknowledged bytes that A sends cannot exceed the size of the receive buffer.</span></p></li>
<li>
<p><span class="font53">d. Suppose Host A is sending a large file to Host B over a TCP connection. If the sequence number for a segment of this connection is </span><span class="font53" style="font-style:italic;">m,</span><span class="font53"> then the sequence number for the subsequent segment will necessarily be </span><span class="font53" style="font-style:italic;">m</span><span class="font55"> + </span><span class="font53">1.</span></p></li>
<li>
<p><span class="font53">e. The TCP segment has a field in its header for </span><span class="font36">rwnd</span><span class="font53">.</span></p></li>
<li>
<p><span class="font53">f. Suppose that the last </span><span class="font36">SampleRTT </span><span class="font53">in a TCP connection is equal to 1 sec. The current value of </span><span class="font36">Timeoutinterval </span><span class="font53">for the connection will necessarily be </span><span class="font55">&gt;&nbsp;</span><span class="font53">1 sec.</span></p></li>
<li>
<p><span class="font53">g. Suppose Host A sends one segment with sequence number 38 and 4 bytes of data over a TCP connection to Host B. In this same segment, the acknowledgment number is necessarily 42.</span></p></li></ul>
<p><span class="font53">R15. Suppose Host A sends two TCP segments back to back to Host B over a TCP connection. The first segment has sequence number 90; the second has sequence number 110.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. How much data is in the first segment?</span></p></li>
<li>
<p><span class="font53">b. Suppose that the first segment is lost but the second segment arrives at B. In the acknowledgment that Host B sends to Host A, what will be the acknowledgment number?</span></p></li></ul>
<p><span class="font53">R16. Consider the Telnet example discussed in Section 3.5. A few seconds after the user types the letter ‘C,’ the user types the letter ‘R.’ After typing the letter ‘R,’ how many segments are sent, and what is put in the sequence number and acknowledgment fields of the segments?</span></p>
<p><span class="font43" style="font-weight:bold;">SECTION 3.7</span></p>
<p><span class="font53">R17. Consider two hosts, A and B, transmitting a large file to a server C, over a bottleneck link with rate </span><span class="font53" style="font-style:italic;">R.</span><span class="font53"> To transfer the file, the hosts use TCP with the same parameters (including MSS and RTT) and start their transmissions at the same time. Host A uses a single TCP connection for the entire file, while Host B uses 9 simultaneous TCP connections, each for a portion (i.e., a chunk) of the file. What is the overall transmission rate achieved by each host at the beginning of the file transfer? Is this situation fair?</span></p>
<p><span class="font53">R18. True or false? Consider congestion control in TCP. When the timer expires at the sender, the value of </span><span class="font36">ssthresh </span><span class="font53">is set to one half of its previous value.</span></p>
<p><span class="font53">R19. According to the discussion of TCP splitting in the sidebar in Section 3.7, the response time with TCP splitting is approximately 4 </span><span class="font55">X </span><span class="font53">RTT<sub>FE</sub> </span><span class="font55">+ </span><span class="font53">RTT<sub>BE</sub> </span><span class="font55">+ </span><span class="font53">processing time, as opposed to 4 </span><span class="font55">X </span><span class="font53">RTT </span><span class="font55">+ </span><span class="font53">processing time when a direct connection is used. Assume that RTT BE is 0.5 </span><span class="font55">X </span><span class="font53">RTT. For what values of RTT<sub>FE</sub> does TCP splitting have a shorter delay than a direct connection?</span></p>
<p><span class="font24" style="font-weight:bold;">Problems</span></p>
<p><span class="font53">P1. Suppose Client A requests a web page from Server S through HTTP and its socket is associated with port 33000.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. What are the source and destination ports for the segments sent from A to S?</span></p></li>
<li>
<p><span class="font53">b. What are the source and destination ports for the segments sent from S to A?</span></p></li>
<li>
<p><span class="font53">c. Can Client A contact to Server S using UDP as the transport protocol?</span></p></li>
<li>
<p><span class="font53">d. Can Client A request multiple resources in a single TCP connection?</span></p></li></ul>
<p><span class="font53">P2. Consider Figure 3.5.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Let us assume the following change: at B we want to access an FTP server from host A. What port number should be used to replace port 80?</span></p></li>
<li>
<p><span class="font53">b. Would there be an error if the right process of C used port number 8080?</span></p></li>
<li>
<p><span class="font53">c. What are the source and destination network and port values in the segments flowing from the server back to the clients’ processes?</span></p></li></ul>
<p><span class="font53">P3. UDP and TCP use 1s complement for their checksums. Suppose you have the following three 16 bit words: 0101001101100110; 0111010010110100; 0000110111000001. What is the 1s complement of the sum of these words? Show all work. Why is it that UDP offers a checksum? With the 1’s complement scheme, how does the receiver detect errors? Describe how a single bit flip can be detected.</span></p>
<p><span class="font53">P4. Assume that a host receives a UDP segment with 01011101 11110010 (we separated the values of each byte with a space for clarity) as the checksum. The host adds the 16-bit words over all necessary fields </span><span class="font53" style="font-style:italic;">excluding the checksum</span><span class="font53"> and obtains the value 00110010 00001101. Is the segment considered correctly received or not? What does the receiver do?</span></p>
<p><span class="font53">P5. Suppose that the UDP receiver computes the Internet checksum for the received UDP segment and finds that it matches the value carried in the checksum field. Can the receiver be absolutely certain that no bit errors have occurred? Explain.</span></p>
<p><span class="font53">P6. Consider our motivation for correcting protocol </span><span class="font36">rdt2.1</span><span class="font53">. Show that the receiver, shown in Figure 3.60, when operating with the sender shown in Figure 3.11, can lead the sender and receiver to enter into a deadlock state, where each is waiting for an event that will never occur.</span></p>
<p><span class="font53">P7. In protocol </span><span class="font36">rdt3.0</span><span class="font53">, the ACK packets flowing from the receiver to the sender do not have sequence numbers (although they do have an ACK field that contains the sequence number of the packet they are acknowledging). Why is it that our ACK packets do not require sequence numbers?</span></p>
<p><span class="font33">rdt_rcv(rcvpkt) &amp;&amp;&nbsp;notcorrupt(rcvpkt)</span></p>
<p><span class="font33">&amp;&amp; has_seq0(rcvpkt) extract(rcvpkt,data)</span></p>
<p><span class="font33">deliver_data(data) compute chksum</span></p>
<p><span class="font33">make_pkt(sendpkt,ACK,chksum) udt_send(sndpkt)</span></p>
<div><img src="networking_files/networking-261.jpg" alt="" style="width:32pt;height:17pt;">
</div><br clear="all">
<div><img src="networking_files/networking-262.jpg" alt="" style="width:35pt;height:18pt;">
</div><br clear="all">
<div>
<p><span class="font33">rdt_rcv(rcvpkt) &amp;&amp;</span></p>
<p><span class="font33">(corrupt(rcvpkt)||</span></p>
<p><span class="font33">has_seq0(rcvpkt)))</span></p>
</div><br clear="all">
<div>
<p><span class="font33">rdt_rcv(rcvpkt) &amp;&amp;</span></p>
<p><span class="font33">(corrupt(rcvpkt)||</span></p>
<p><span class="font33">has_seq1(rcvpkt)))</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Wait for 0 from below</span></p>
</div><br clear="all">
<div>
<p><span class="font4">below</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Wait for</span></p>
<p><span class="font4">1 from below</span></p>
</div><br clear="all">
<div>
<p><span class="font33">compute chksum</span></p>
<p><span class="font33">make_pkt(sndpkt,NAK,chksum)</span></p>
<p><span class="font33">udt_send(sndpkt)</span></p>
</div><br clear="all">
<p><span class="font33">compute chksum</span></p>
<p><span class="font33">make_pkt(sndpkt,NAK,chksum)</span></p>
<p><span class="font33">udt_send(sndpkt) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rdt_rcv(rcvpkt) &amp;&amp;&nbsp;notcorrupt(rcvpkt)</span></p>
<p><span class="font33">&amp;&amp; has_seq1(rcvpkt) extract(rcvpkt,data)</span></p>
<p><span class="font33">deliver_data(data) compute chksum</span></p>
<p><span class="font33">make_pkt(sendpkt,ACK,chksum) udt_send(sndpkt)</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 3.60 </span><span class="font50">♦ </span><span class="font5">An incorrect receiver for protocol </span><span class="font36">rdt 2.1</span></p>
<p><span class="font53">P8. Draw the FSM for the receiver side of protocol </span><span class="font36">rdt3.0</span><span class="font53">.</span></p>
<p><span class="font53">P9. Give a trace of the operation of protocol </span><span class="font36">rdt3.0 </span><span class="font53">when data packets and acknowledgment packets are garbled. Your trace should be similar to that used in Figure 3.16.</span></p>
<p><span class="font53">P10. Consider a channel that can lose packets but has a maximum delay that is known. Modify protocol </span><span class="font36">rdt2.1 </span><span class="font53">to include sender timeout and retransmit. Informally argue why your protocol can communicate correctly over this channel.</span></p>
<p><span class="font53">P11. Consider the </span><span class="font36">rdt2.2 </span><span class="font53">receiver in Figure 3.14, and the creation of a new packet in the self-transition (i.e., the transition from the state back to itself) in the Wait-for-0-from-below and the Wait-for-1-from-below states: </span><span class="font36">sndpkt=make_pkt(ACK,1,checksum) </span><span class="font53">and </span><span class="font36">sndpkt=make_ pkt(ACK,0,checksum)</span><span class="font53">. Would the protocol work correctly if this action were removed from the self-transition in the Wait-for-1-from-below state? Justify your answer. What if this event were removed from the self-transition in the Wait-for-0-from-below state? </span><span class="font53" style="font-style:italic;">[Hint:</span><span class="font53"> In this latter case, consider what would happen if the first sender-to-receiver packet were corrupted.]</span></p>
<p><span class="font53">P12. The sender side of </span><span class="font36">rdt3.0 </span><span class="font53">simply ignores (that is, takes no action on) all received packets that are either in error or have the wrong value in the </span><span class="font36">acknum </span><span class="font53">field of an acknowledgment packet. Suppose that in such circumstances, </span><span class="font36">rdt3.0 </span><span class="font53">were simply to retransmit the current data packet. Would the protocol still work? (</span><span class="font53" style="font-style:italic;">Hint</span><span class="font53">: Consider what would happen if there were only bit errors; there are no packet losses but premature timeouts can occur. Consider how many times the </span><span class="font53" style="font-style:italic;">n</span><span class="font53">th packet is sent, in the limit as </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> approaches infinity.)</span></p>
<p><span class="font53">P13. Assume Host A is streaming a video from Server B using UDP. Also assume that the network suddenly becomes very congested while Host A is seeing the video. Is there any way to handle this situation with UDP? What about with TCP? Is there any other option?</span></p>
<p><span class="font53">P14. Consider a stop-and-wait data-transfer protocol that provides error checking and retransmissions but uses only negative acknowledgments. Assume that negative acknowledgments are never corrupted. Would such a protocol work over a channel with bit errors? What about over a lossy channel with bit errors?</span></p>
<p><span class="font53">P15. Consider the cross-country example shown in Figure 3.17, with a 10 Gbps link. How big would the window size have to be for the channel utilization to be greater than 98 percent? Suppose that the size of a packet is 1,500 bytes, including header fields and data.</span></p>
<p><span class="font53">P16. Suppose an application uses </span><span class="font36">rdt 3.0 </span><span class="font53">as its transport layer protocol. As the stop-and-wait protocol has very low channel utilization (shown in the crosscountry example), the designers of this application let the receiver keep sending back a number (more than two) of alternating ACK 0 and ACK 1 even if the corresponding data have not arrived at the receiver. Would this application design increase the channel utilization? Why? Are there any potential problems with this approach? Explain.</span></p>
<p><span class="font53">P17. Consider two network entities, A and B, which are connected by a perfect bi-directional channel (i.e., any message sent will be received correctly; the channel will not corrupt, lose, or re-order packets). A and B are to deliver data messages to each other in an alternating manner: First, A must deliver a message to B, then B must deliver a message to A, then A must deliver a message to B and so on. If an entity is in a state where it should not attempt to deliver a message to the other side, and there is an event like </span><span class="font36">rdt_ send(data) </span><span class="font53">call from above that attempts to pass data down for transmission to the other side, this call from above can simply be ignored with a call to </span><span class="font36">rdt_unable_to_send(data)</span><span class="font53">, which informs the higher layer that it is currently not able to send data. [Note: This simplifying assumption is made so you don’t have to worry about buffering data.]</span></p>
<p><span class="font53">Draw a FSM specification for this protocol (one FSM for A, and one FSM for B!). Note that you do not have to worry about a reliability mechanism here; the main point of this question is to create a FSM specification that reflects the synchronized behavior of the two entities. You should use the following events and actions that have the same meaning as protocol rdt1.0 in Figure 3.9: </span><span class="font36">rdt_send(data), packet = make_pkt(data)</span><span class="font53">, </span><span class="font36">udt_ send(packet), rdt_rcv(packet)</span><span class="font53">, </span><span class="font36">extract (packet,data), deliver_data(data)</span><span class="font53">. Make sure your protocol reflects the strict alternation of sending between A and B. Also, make sure to indicate the initial states for A and B in your FSM descriptions.</span></p>
<p><span class="font53">P18. In the generic SR protocol that we studied in Section 3.4.4, the sender transmits a message as soon as it is available (if it is in the window) without waiting for an acknowledgment. Suppose now that we want an SR protocol that sends messages two at a time. That is, the sender will send a pair of messages and will send the next pair of messages only when it knows that both messages in the first pair have been received correctly.</span></p>
<p><span class="font53">Suppose that the channel may lose messages but will not corrupt or reorder messages. Design an error-control protocol for the unidirectional reliable transfer of messages. Give an FSM description of the sender and receiver. Describe the format of the packets sent between sender and receiver, and vice versa. If you use any procedure calls other than those in Section 3.4 (for example, </span><span class="font36">udt_send()</span><span class="font53">, </span><span class="font36">start_timer()</span><span class="font53">, </span><span class="font36">rdt_rcv()</span><span class="font53">, and so on), clearly state their actions. Give an example (a timeline trace of sender and receiver) showing how your protocol recovers from a lost packet.</span></p>
<p><span class="font53">P19. Suppose Host A and Host B use a GBN protocol with window size </span><span class="font53" style="font-style:italic;">N =</span><span class="font53"> 3 and a long-enough range of sequence numbers. Assume Host A sends six application messages to Host B and that all messages are correctly received, except for the first acknowledgment and the fifth data segment. Draw a timing diagram (similar to Figure 3.22), showing the data segments and the acknowledgments sent along with the corresponding sequence and acknowledge numbers, respectively.</span></p>
<p><span class="font53">P20. Consider a scenario in which Host A and Host B want to send messages to Host C. Hosts A and C are connected by a channel that can lose and corrupt (but not reorder) messages. Hosts B and C are connected by another channel (independent of the channel connecting A and C) with the same properties. The transport layer at Host C should alternate in delivering messages from A and B to the layer above (that is, it should first deliver the data from a packet from A, then the data from a packet from B, and so on). Design a stop-and-wait-like error-control protocol for reliably transferring packets from A and B to C, with alternating delivery at C as described above. Give FSM descriptions of A and C. </span><span class="font53" style="font-style:italic;">(Hint:</span><span class="font53"> The FSM for B should be essentially the same as for A.) Also, give a description of the packet format(s) used.</span></p>
<p><span class="font53">P21. Suppose we have two network entities, A and B. B has a supply of data messages that will be sent to A according to the following conventions. When A gets a request from the layer above to get the next data (D) message from B, A must send a request (R) message to B on the A-to-B channel. Only when B receives an R message can it send a data (D) message back to A on the B-to-A channel. A should deliver exactly one copy of each D message to the layer above. R messages can be lost (but not corrupted) in the A-to-B channel; D messages, once sent, are always delivered correctly. The delay along both channels is unknown and variable.</span></p>
<p><span class="font53">Design (give an FSM description of) a protocol that incorporates the appropriate mechanisms to compensate for the loss-prone A-to-B channel and implements message passing to the layer above at entity A, as discussed above. Use only those mechanisms that are absolutely necessary.</span></p>
<p><span class="font53">P22. Consider the GBN protocol with a sender window size of 4 and a sequence number range of 1,024. Suppose that at time </span><span class="font53" style="font-style:italic;">t,</span><span class="font53"> the next in-order packet that the receiver is expecting has a sequence number of </span><span class="font53" style="font-style:italic;">k.</span><span class="font53"> Assume that the medium does not reorder messages. Answer the following questions:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. What are the possible sets of sequence numbers inside the sender’s window at time </span><span class="font53" style="font-style:italic;">t</span><span class="font53">? Justify your answer.</span></p></li>
<li>
<p><span class="font53">b. What are all possible values of the ACK field in all possible messages currently propagating back to the sender at time </span><span class="font53" style="font-style:italic;">t</span><span class="font53">? Justify your answer.</span></p></li></ul>
<p><span class="font53">P23. Give one example where buffering out-of-order segments would significantly improve the throughput of a GBN protocol.</span></p>
<p><span class="font53">P24. Consider a scenario where the three hosts A, B, and C are connected as a ring: A to B, B to C, and C to A. Assume that A and C run protocol </span><span class="font36">rdt3.0</span><span class="font53">, whereas B simply relays all messages received from A to C.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Does this arrangement enable reliable delivery of messages from A to C?</span></p></li>
<li>
<p><span class="font53">b. Can B tell if a certain message has been correctly received by A?</span></p></li></ul>
<p><span class="font53">P25. We have said that an application may choose UDP for a transport protocol because UDP offers finer application control (than TCP) of what data is sent in a segment and when.</span></p>
<p><span class="font53">Why does an application have more control of what data is sent in a segment? Why does an application have more control on when the segment is sent?</span></p>
<p><span class="font53">P26. Consider transferring an enormous file of </span><span class="font53" style="font-style:italic;">L</span><span class="font53"> bytes from Host A to Host B. Assume an MSS of 536 bytes.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. What is the maximum value of </span><span class="font53" style="font-style:italic;">L</span><span class="font53"> such that TCP sequence numbers are not exhausted? Recall that the TCP sequence number field has 4 bytes.</span></p></li>
<li>
<p><span class="font53">b. For the </span><span class="font53" style="font-style:italic;">L</span><span class="font53"> you obtain in (a), find how long it takes to transmit the file. Assume that a total of 66 bytes of transport, network, and data-link header are added to each segment before the resulting packet is sent out over a 155 Mbps link. Ignore flow control and congestion control so A can pump out the segments back to back and continuously.</span></p></li></ul>
<p><span class="font53">P27. Host A and B are communicating over a TCP connection following RFC 5681. Host B has already received from A all bytes up through byte 96. Suppose Host A then sends two segments to Host B back-to-back. The first and the second segments contain 40 and 80 bytes of data, respectively. In the first segment, the sequence number is 97, the source port number is 302, and the destination port number is 80.</span></p>
<p><span class="font53">Host B sends an acknowledgment whenever it receives a segment from Host A.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. In the second segment sent from Host A to B, what are the sequence number, source port number, and destination port number?</span></p></li>
<li>
<p><span class="font53">b. If the first segment arrives before the second segment, in the acknowledgment of the first arriving segment, what is the acknowledgment number, the source port number, and the destination port number?</span></p></li>
<li>
<p><span class="font53">c. If the second segment arrives before the first segment, in the acknowledgment of the first arriving segment, what is the acknowledgment number?</span></p></li>
<li>
<p><span class="font53">d. Suppose the two segments sent by A arrive in order at B. The first acknowledgment arrives after the first timeout interval. What is the sequence number of the next segment that A will transmit?</span></p></li></ul>
<p><span class="font53">P28. Host A and B are directly connected with a 10 Gbps link. There is one TCP connection between the two hosts, and Host A is sending to Host B an enormous file over this connection. Host A can send its application data into its TCP socket at a rate as high as 1 Gbps, but Host B can read out of its TCP receive buffer at a maximum rate of 600 Mbps. Describe the effect of TCP flow control.</span></p>
<p><span class="font53">P29. SYN cookies were discussed in Section 3.5.6.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Why is it necessary for the server to use a special initial sequence number in the SYNACK?</span></p></li>
<li>
<p><span class="font53">b. Suppose an attacker knows that a target host uses SYN cookies. Can the attacker create half-open or fully open connections by simply sending an ACK packet to the target? Why or why not?</span></p></li>
<li>
<p><span class="font53">c. Suppose an attacker collects a large amount of initial sequence numbers sent by the server. Can the attacker cause the server to create many fully open connections by sending ACKs with those initial sequence numbers? Why?</span></p></li></ul>
<p><span class="font53">P30. Consider the network shown in Scenario 2 in Section 3.6.1. Suppose both sending hosts A and B have some fixed timeout values.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Argue that increasing the size of the finite buffer of the router might possibly decrease the throughput (</span><span class="font12">l</span><span class="font53"><sub>out</sub>).</span></p></li>
<li>
<p><span class="font53">b. Now suppose both hosts dynamically adjust their timeout values (like what TCP does) based on the buffering delay at the router. Would increasing the buffer size help to increase the throughput? Why?</span></p></li></ul>
<p><span class="font53">P31. Suppose that the five measured </span><span class="font36">SampleRTT </span><span class="font53">values (see Section 3.5.3) are 112 ms, 140 ms, 110 ms, 90 ms, and 90 ms. Compute the </span><span class="font36">EstimatedRTT </span><span class="font53">after each of these </span><span class="font36">SampleRTT </span><span class="font53">values is obtained, using a value of </span><span class="font53" style="font-style:italic;">a =</span><span class="font53"> 0.125 and assuming that the value of </span><span class="font36">EstimatedRTT </span><span class="font53">was 120 ms just before the first of these five samples were obtained.</span></p>
<p><span class="font53">Compute also the </span><span class="font36">DevRTT </span><span class="font53">after each sample is obtained, assuming a value of </span><span class="font12">b </span><span class="font54">= </span><span class="font53">0.25 and assuming the value of </span><span class="font36">DevRTT </span><span class="font53">was 6 ms just before the first of these five samples was obtained.</span></p>
<p><span class="font53">Finally, compute the TCP </span><span class="font36">Timeoutinterval </span><span class="font53">after each of these samples is obtained.</span></p>
<p><span class="font53">P32. Consider the TCP procedure for estimating RTT. Suppose that </span><span class="font54">a = </span><span class="font53">0.1. Let </span><span class="font36">SampleRTT</span><span class="font33">1 </span><span class="font53">be the most recent sample RTT, let </span><span class="font36">SampleRTT<sub>2</sub> </span><span class="font53">be the next most recent sample RTT, and so on.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. For a given TCP connection, suppose four acknowledgments have been returned with corresponding sample RTTs: </span><span class="font36">SampleRTT<sub>4</sub></span><span class="font53">, </span><span class="font36">SampleRTT<sub>3</sub></span><span class="font53">, </span><span class="font36">SampleRTT<sub>2</sub></span><span class="font53">, and </span><span class="font36">SampleRTT</span><span class="font33">1</span><span class="font53">. Express </span><span class="font36">EstimatedRTT </span><span class="font53">in terms of the four sample RTTs.</span></p></li>
<li>
<p><span class="font53">b. Generalize your formula for </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> sample RTTs.</span></p></li>
<li>
<p><span class="font53">c. For the formula in part (b) let </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> approach infinity. Comment on why this averaging procedure is called an exponential moving average.</span></p></li></ul>
<p><span class="font53">P33. In Section 3.5.3, we discussed TCP’s estimation of RTT. Why do you think TCP avoids measuring the </span><span class="font36">SampleRTT </span><span class="font53">for retransmitted segments?</span></p>
<p><span class="font53">P34. What is the relationship between the variable </span><span class="font36">SendBase </span><span class="font53">in Section 3.5.4 and the variable </span><span class="font36">LastByteRcvd </span><span class="font53">in Section 3.5.5?</span></p>
<p><span class="font53">P35. What is the relationship between the variable </span><span class="font36">LastByteRcvd </span><span class="font53">in Section 3.5.5 and the variable y in Section 3.5.4?</span></p>
<p><span class="font53">P36. In Section 3.5.4, we saw that TCP waits until it has received three duplicate ACKs before performing a fast retransmit. Why do you think the TCP designers chose not to perform a fast retransmit after the first duplicate ACK for a segment is received?</span></p>
<p><span class="font53">P37. Compare GBN, SR, and TCP (no delayed ACK). Assume that the timeout values for all three protocols are sufficiently long such that five consecutive data segments and their corresponding ACKs can be received (if not lost in the channel) by the receiving host (Host B) and the sending host (Host A) respectively. Suppose Host A sends five data segments to Host B, and the second segment (sent from A) is lost. In the end, all five data segments have been correctly received by Host B.</span></p>
<ul style="list-style:none;"><li>
<p class="font53">a. How many segments has Host A sent in total and how many ACKs has Host B sent in total? What are their sequence numbers? Answer this question for all three protocols.</p></li>
<li>
<p class="font53">b. If the timeout values for all three protocol are much longer than 5 RTT, then which protocol successfully delivers all five data segments in shortest time interval?</p></li></ul>
<p><span class="font53">P38. In our description of TCP in Figure 3.53, the value of the threshold, </span><span class="font36">ssthresh</span><span class="font53">, is set as </span><span class="font36">ssthresh=cwnd/2 </span><span class="font53">in several places and </span><span class="font36">ssthresh </span><span class="font53">value is referred to as being set to half the window size when a loss event occurred. Must the rate at which the sender is sending when the loss event occurred be approximately equal to </span><span class="font36">cwnd </span><span class="font53">segments per RTT? Explain your answer. If your answer is no, can you suggest a different manner in which </span><span class="font36">ssthresh </span><span class="font53">should be set?</span></p>
<p><span class="font53">P39. Consider Figure 3.46(b). If </span><span class="font12">l</span><span class="font50">'</span><span class="font53"><sub>n</sub> increases beyond </span><span class="font53" style="font-style:italic;">R/2,</span><span class="font53"> can </span><span class="font12">l</span><span class="font53"><sub>out</sub> increase beyond </span><span class="font53" style="font-style:italic;">R</span><span class="font53">/3? Explain. Now consider Figure 3.46(c). If </span><span class="font53" style="font-style:italic;">l</span><span class="font50">'</span><span class="font53"><sub>n</sub> increases beyond </span><span class="font53" style="font-style:italic;">R</span><span class="font53">/2, can </span><span class="font12">l</span><span class="font53"><sub>out</sub> increase beyond R/4 under the assumption that a packet will be forwarded twice on average from the router to the receiver? Explain.</span></p>
<p><span class="font53">P40. Consider Figure 3.61. Assuming TCP Reno is the protocol experiencing the behavior shown above, answer the following questions. In all cases, you should provide a short discussion justifying your answer.</span></p>
<div><img src="networking_files/networking-263.jpg" alt="" style="width:19pt;height:19pt;">
</div><br clear="all">
<div>
<p><span class="font2" style="font-weight:bold;">VideoNote</span></p>
<p><span class="font1" style="font-weight:bold;">Examining the behavior of TCP</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<p><span class="font53">a. Identify the intervals of time when TCP slow start is operating.</span></p></li>
<li>
<p><span class="font53">b. Identify the intervals of time when TCP congestion avoidance is operating.</span></p></li>
<li>
<p><span class="font53">c. After the 16th transmission round, is segment loss detected by a triple duplicate ACK or by a timeout?</span></p></li>
<li>
<p><span class="font53">d. After the 22nd transmission round, is segment loss detected by a triple duplicate ACK or by a timeout?</span></p>
<div><img src="networking_files/networking-264.jpg" alt="" style="width:232pt;height:178pt;">
<p><span class="font7" style="font-weight:bold;">Figure 3.61 </span><span class="font50">♦ </span><span class="font5">TCP window size as a function of time</span></p>
</div><br clear="all"></li>
<li>
<p><span class="font53">e. What is the initial value of </span><span class="font36">ssthresh </span><span class="font53">at the first transmission round?</span></p></li>
<li>
<p><span class="font53">f. What is the value of </span><span class="font36">ssthresh </span><span class="font53">at the 22nd transmission round?</span></p></li>
<li>
<p><span class="font53">g. During what transmission round is the 70th segment sent?</span></p></li>
<li>
<p><span class="font53">h. Assuming a packet loss is detected after the 26th round by the receipt of a triple duplicate ACK, what will be the values of the congestion window size and of </span><span class="font36">ssthresh</span><span class="font53">?</span></p></li>
<li>
<p><span class="font53">i. Suppose TCP Tahoe is used (instead of TCP Reno), and assume that triple duplicate ACKs are received at the 10th round. What are the </span><span class="font36">ssthresh </span><span class="font53">and the congestion window size at the 11th round?</span></p></li>
<li>
<p><span class="font53">j. Again, suppose TCP Tahoe is used, and there is a timeout event at the 22nd round. How many packets have been sent out from the 17th round till the 22nd round, inclusive?</span></p></li></ul>
<p><span class="font53">P41. Refer to Figure 3.55, which illustrates the convergence of TCP’s AIMD algorithm. Suppose that instead of a multiplicative decrease, TCP decreased the window size by a constant amount. Would the resulting AIAD algorithm converge to an equal share algorithm? Justify your answer using a diagram similar to Figure 3.55.</span></p>
<p><span class="font53">P42. In Section 3.5.4, we discussed the doubling of the timeout interval after a timeout event. This mechanism is a form of congestion control. Why does TCP need a window-based congestion-control mechanism (as studied in Section 3.7) in addition to this doubling-timeout-interval mechanism?</span></p>
<p><span class="font53">P43. Host A is sending an enormous file to Host B over a TCP connection. Over this connection there is never any packet loss and the timers never expire. Denote the transmission rate of the link connecting Host A to the Internet by </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> bps. Suppose that the process in Host A is capable of sending data into its TCP socket at a rate </span><span class="font53" style="font-style:italic;">S</span><span class="font53"> bps, where </span><span class="font53" style="font-style:italic;">S =</span><span class="font53"> 10 </span><span class="font60">• </span><span class="font53" style="font-style:italic;">R</span><span class="font53">. Further suppose that the TCP receive buffer is large enough to hold the entire file, and the send buffer can hold only one percent of the file. What would prevent the process in Host A from continuously passing data to its TCP socket at rate </span><span class="font53" style="font-style:italic;">S</span><span class="font53"> bps? TCP flow control? TCP congestion control? Or something else? Elaborate.</span></p>
<p><span class="font53">P44. Consider sending a large file from a host to another over a TCP connection that has no loss.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Suppose TCP uses AIMD for its congestion control without slow start. Assuming </span><span class="font36">cwnd </span><span class="font53">increases by 1 MSS every time a batch of ACKs is received and assuming approximately constant round-trip times, how long does it take for </span><span class="font36">cwnd </span><span class="font53">increase from 6 MSS to 12 MSS (assuming no loss events)?</span></p></li>
<li>
<p><span class="font53">b. What is the average throughput (in terms of MSS and RTT) for this connection up through time </span><span class="font54">= </span><span class="font53">6 RTT?</span></p></li></ul>
<p><span class="font53">P45. Consider Figure 3.54. Suppose that at </span><span class="font53" style="font-style:italic;">t</span><span class="font49" style="font-style:italic;">3</span><span class="font53" style="font-style:italic;">,</span><span class="font53"> the sending rate at which congestion loss next occurs drops to 0.75*</span><span class="font53" style="font-style:italic;">W</span><span class="font53"><sub>max</sub> (unbeknownst to the TCP senders, of course). Show the evolution of both TCP Reno and TCP CUBIC for two more rounds each </span><span class="font53" style="font-style:italic;">(Hint: note that the times at which TCP Reno and TCP CUBIC react to congestion loss may not be the same anymore).</span></p>
<p><span class="font53">P46. Consider Figure 3.54 again. Suppose that at </span><span class="font53" style="font-style:italic;">t</span><span class="font53"><sub>3</sub>, the sending rate at which congestion loss next occurs increases to 1.5* </span><span class="font53" style="font-style:italic;">W .</span><span class="font53"> Show the evolution of both TCP Reno and TCP CUBIC for at two more rounds each </span><span class="font53" style="font-style:italic;">(Hint: see the hint in P45).</span></p>
<p><span class="font53">P47. Recall the macroscopic description of TCP throughput. In the period of time from when the connection’s rate varies from </span><span class="font53" style="font-style:italic;">W</span><span class="font53">/(2 • RTT) to </span><span class="font53" style="font-style:italic;">W/RTT,</span><span class="font53"> only one packet is lost (at the very end of the period).</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Show that the loss rate (fraction of packets lost) is equal to</span></p></li></ul>
<p><span class="font53">1</span></p>
<p><span class="font53" style="font-style:italic;">L =</span><span class="font53"> loss rate = ------------</span></p>
<p><span class="font59"><sup>3</sup> </span><span class="font53" style="font-style:italic;">W</span><span class="font53"><sup>2</sup> </span><span class="font55">+ </span><span class="font59"><sup>3</sup> </span><span class="font53" style="font-style:italic;">W</span></p>
<p><span class="font53">8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">b. Use the result above to show that if a connection has loss rate </span><span class="font53" style="font-style:italic;">L</span><span class="font53">, then its average rate is approximately given by</span></p></li></ul>
<p><span class="font53" style="text-decoration:underline;">1.22 </span><span class="font60" style="text-decoration:underline;">• </span><span class="font53" style="font-style:italic;text-decoration:underline;">MSS</span></p>
<p><span class="font53" style="font-style:italic;">~ RTT VL</span></p>
<p><span class="font53">P48. Consider that only a single TCP (Reno) connection uses one 54 Mbps wireless link which does not buffer any data. Suppose that this link is the only congested link between the sending and receiving hosts. Assume that the TCP sender has a huge file to send to the receiver and the receiver’s receive buffer is much larger than the congestion window.</span></p>
<p><span class="font53">We also make the following assumptions: each TCP segment size is 536 bytes; the two-way propagation delay of this connection is 6 msec; and this TCP connection is always in congestion avoidance phase, that is, ignore slow start.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. What is the maximum window size (in segments) that this TCP connection can achieve?</span></p></li>
<li>
<p><span class="font53">b. What is the average window size (in segments) and average throughput (in bps) of this TCP connection?</span></p></li>
<li>
<p><span class="font53">c. How long would it take for this TCP connection to reach its maximum window again after recovering from a packet loss?</span></p></li></ul>
<p><span class="font53">P49. Consider the scenario described in the previous problem. Suppose that the 10 Mbps link can buffer a finite number of segments. Argue that in order for the link to always be busy sending data, we would like to choose a buffer size that is at least the product of the link speed </span><span class="font53" style="font-style:italic;">C</span><span class="font53"> and the two-way propagation delay between the sender and the receiver.</span></p>
<p><span class="font53">P50. Repeat Problem 48, but replacing the 54 Mbps link with a 100 Gbps link and an RTT of 60 ms. Note that in your answer to part c, you will realize that it takes a very long time for the congestion window size to reach its maximum window size after recovering from a packet loss.</span></p>
<p><span class="font53">Can you consider solutions for this?</span></p>
<p><span class="font53">P51. Let </span><span class="font53" style="font-style:italic;">T</span><span class="font53"> (measured by RTT) denote the time interval that a TCP connection takes to increase its congestion window size from </span><span class="font53" style="font-style:italic;">W/2</span><span class="font53"> to </span><span class="font53" style="font-style:italic;">W,</span><span class="font53"> where </span><span class="font53" style="font-style:italic;">W</span><span class="font53"> is the maximum congestion window size. Argue that T is a function of TCP’s average throughput.</span></p>
<p><span class="font53">P52. Consider a simplified TCP’s AIMD algorithm where the congestion window size is measured in number of segments, not in bytes. In additive increase, the congestion window size increases by one segment in each RTT. In multiplicative decrease, the congestion window size decreases by half (if the result is not an integer, round down to the nearest integer). Suppose that two TCP connections, C<sub>1</sub> and C<sub>2</sub>, share a single congested link of speed 30 segments per second. Assume that both C<sub>1</sub> and C<sub>2</sub> are in the congestion avoidance phase. Connection C<sub>1</sub>’s RTT is 50 msec and connection C<sub>2</sub>’s RTT is 100 msec. Assume that when the data rate in the link exceeds the link’s speed, all TCP connections experience data segment loss.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. If both C<sub>1</sub> and C<sub>2</sub> at time t<sub>0</sub> have a congestion window of 10 segments, what are their congestion window sizes after 1000 msec?</span></p></li>
<li>
<p><span class="font53">b. In the long run, will these two connections get the same share of the bandwidth of the congested link? Explain.</span></p></li></ul>
<p><span class="font53">P53. Consider the network described in the previous problem. Now suppose that the two TCP connections, C1 and C2, have the same RTT of 100 msec. Suppose that at time t<sub>0</sub>, C1’s congestion window size is 15 segments but C2’s congestion window size is 10 segments.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. What are their congestion window sizes after 2200 msec?</span></p></li>
<li>
<p><span class="font53">b. In the long run, will these two connections get about the same share of the bandwidth of the congested link?</span></p></li>
<li>
<p><span class="font53">c. We say that two connections are synchronized, if both connections reach their maximum window sizes at the same time and reach their minimum window sizes at the same time. In the long run, will these two connections get synchronized eventually? If so, what are their maximum window sizes?</span></p></li>
<li>
<p><span class="font53">d. Will this synchronization help to improve the utilization of the shared link? Why? Sketch some idea to break this synchronization.</span></p></li></ul>
<p><span class="font53">P54. Consider a modification to TCP’s congestion control algorithm. Instead of additive increase, we can use multiplicative increase. A TCP sender increases its window size by a small positive constant </span><span class="font53" style="font-style:italic;">a</span><span class="font53"> (0 </span><span class="font55">&lt;&nbsp;</span><span class="font53" style="font-style:italic;">a &lt;</span><span class="font53">&nbsp;1) whenever it receives a valid ACK. Find the functional relationship between loss rate L and maximum congestion window W. Argue that for this modified TCP, regardless of TCP’s average throughput, a TCP connection always spends the same amount of time to increase its congestion window size from </span><span class="font53" style="font-style:italic;">W/2</span><span class="font53"> to </span><span class="font53" style="font-style:italic;">W.</span></p>
<p><span class="font53">P55. In our discussion of TCP futures in Section 3.7, we noted that to achieve a throughput of 10 Gbps, TCP could only tolerate a segment loss probability of 2 </span><span class="font60">• </span><span class="font53">10 </span><span class="font3">-</span><span class="font53"><sup>10</sup> (or equivalently, one loss event for every 5,000,000,000 segments). Show the derivation for the values of 2 </span><span class="font60">• </span><span class="font53">10</span><span class="font3">-</span><span class="font53"><sup>10</sup> (1 out of 5,000,000) for the RTT and MSS values given in Section 3.7. If TCP needed to support a 100 Gbps connection, what would the tolerable loss be?</span></p>
<p><span class="font53">P56. In our discussion of TCP congestion control in Section 3.7, we implicitly assumed that the TCP sender always had data to send. Consider now the case that the TCP sender sends a large amount of data and then goes idle (since it has no more data to send) at </span><span class="font53" style="font-style:italic;">t<sub>1</sub>.</span><span class="font53"> TCP remains idle for a relatively long period of time and then wants to send more data at </span><span class="font53" style="font-style:italic;">t</span><span class="font53"><sub>2</sub>. What are the advantages and disadvantages of having TCP use the </span><span class="font36">cwnd </span><span class="font53">and </span><span class="font36">ssthresh </span><span class="font53">values from </span><span class="font53" style="font-style:italic;">t</span><span class="font53"><sub>1 </sub>when starting to send data at </span><span class="font53" style="font-style:italic;">t</span><span class="font53"><sub>2</sub>? What alternative would you recommend? Why?</span></p>
<p><span class="font53">P57. In this problem, we investigate whether either UDP or TCP provides a degree of end-point authentication.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Consider a server that receives a request within a UDP packet and responds to that request within a UDP packet (for example, as done by a DNS server). If a client with IP address X spoofs its address with address Y, where will the server send its response?</span></p></li>
<li>
<p><span class="font53">b. Suppose a server receives a SYN with IP source address Y, and after responding with a SYNACK, receives an ACK with IP source address Y with the correct acknowledgment number. Assuming the server chooses a random initial sequence number and there is no “man-in-the-middle,” can the server be certain that the client is indeed at Y (and not at some other address X that is spoofing Y)?</span></p></li></ul>
<p><span class="font53">P58. In this problem, we consider the delay introduced by the TCP slow-start phase. Consider a client and a Web server directly connected by one link of rate </span><span class="font53" style="font-style:italic;">R.</span><span class="font53"> Suppose the client wants to retrieve an object whose size is exactly equal to 15 </span><span class="font53" style="font-style:italic;">S,</span><span class="font53"> where </span><span class="font53" style="font-style:italic;">S</span><span class="font53"> is the maximum segment size (MSS). Denote the round-trip time between client and server as RTT (assumed to be constant). Ignoring protocol headers, determine the time to retrieve the object (including TCP connection establishment) when</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. 4 </span><span class="font53" style="font-style:italic;">S</span><span class="font53">/</span><span class="font53" style="font-style:italic;">R</span><span class="font55"> &gt;&nbsp;</span><span class="font53" style="font-style:italic;">S</span><span class="font53">/</span><span class="font53" style="font-style:italic;">R</span><span class="font55"> + </span><span class="font53" style="font-style:italic;">RTT &gt;&nbsp;2S/R</span></p></li>
<li>
<p><span class="font53">b. </span><span class="font53" style="font-style:italic;">S/R</span><span class="font55"> + </span><span class="font53" style="font-style:italic;">RTT &gt;</span><span class="font53">&nbsp;4 </span><span class="font53" style="font-style:italic;">S/R</span></p></li>
<li>
<p><span class="font53">c. </span><span class="font53" style="font-style:italic;">S/R &gt;&nbsp;RTT</span><span class="font53">.</span></p></li></ul>
<p><span class="font24" style="font-weight:bold;">Programming Assignments</span></p>
<p><span class="font23" style="font-weight:bold;">Implementing a Reliable Transport Protocol</span></p>
<p><span class="font53">In this laboratory programming assignment, you will be writing the sending and receiving transport-level code for implementing a simple reliable data transfer protocol. There are two versions of this lab, the alternating-bit-protocol version and the GBN version. This lab should be fun—your implementation will differ very little from what would be required in a real-world situation.</span></p>
<p><span class="font53">Since you probably don’t have standalone machines (with an OS that you can modify), your code will have to execute in a simulated hardware/software environment. However, the programming interface provided to your routines—the code that would call your entities from above and from below—is very close to what is done in an actual UNIX environment. (Indeed, the software interfaces described in this programming assignment are much more realistic than the infinite loop senders and receivers that many texts describe.) Stopping and starting timers are also simulated, and timer interrupts will cause your timer handling routine to be activated.</span></p>
<p><span class="font53">The full lab assignment, as well as code you will need to compile with your own code, are available at this book’s Web site: </span><a href="http://www.pearsonglobaleditions.com"><span class="font53">www.pearsonglobaleditions.com</span></a><span class="font53">.</span></p>
<p><span class="font24" style="font-weight:bold;">Wireshark Lab: Exploring TCP</span></p>
<p><span class="font53">In this lab, you’ll use your Web browser to access a file from a Web server. As in earlier Wireshark labs, you’ll use Wireshark to capture the packets arriving at your computer. Unlike earlier labs, you’ll </span><span class="font53" style="font-style:italic;">also</span><span class="font53"> be able to download a Wireshark-readable packet trace from the Web server from which you downloaded the file. In this server trace, you’ll find the packets that were generated by your own access of the Web server. You’ll analyze the client- and server-side traces to explore aspects of TCP. In particular, you’ll evaluate the performance of the TCP connection between your computer and the Web server. You’ll trace TCP’s window behavior, and infer packet loss, retransmission, flow control and congestion control behavior, and estimated roundtrip time.</span></p>
<p><span class="font53">As is the case with all Wireshark labs, the full description of this lab is available at this book’s Web site, </span><a href="http://www.pearsonglobaleditions.com"><span class="font53">www.pearsonglobaleditions.com</span></a><span class="font53">.</span></p>
<p><span class="font24" style="font-weight:bold;">Wireshark Lab: Exploring UDP</span></p>
<p><span class="font53">In this short lab, you’ll do a packet capture and analysis of your favorite application that uses UDP (for example, DNS or a multimedia application such as Skype). As we learned in Section 3.3, UDP is a simple, no-frills transport protocol. In this lab, you’ll investigate the header fields in the UDP segment as well as the checksum calculation.</span></p>
<p><a name="bookmark329"></a><span class="font53">As is the case with all Wireshark labs, the full description of this lab is available at this book’s Web site, </span><a href="http://www.pearsonglobaleditions.com"><span class="font53">www.pearsonglobaleditions.com</span></a><span class="font53">.</span></p>
<p><span class="font23" style="font-weight:bold;">AN INTERVIEW WITH...</span></p>
<p><span class="font11" style="font-weight:bold;">Van Jacobson</span></p>
<div><img src="networking_files/networking-265.jpg" alt="" style="width:98pt;height:146pt;">
<p><span class="font3">Courtesy of Van Jacobson</span></p>
</div><br clear="all">
<p><span class="font46">Van Jacobson works at Google and was previously a Research Fellow at PARC. Prior to that, he was co-founder and Chief Scientist of Packet Design. Before that, he was Chief Scientist at Cisco. Before joining Cisco, he was head of the Network Research Group at Lawrence Berkeley National Laboratory and taught at UC Berkeley and Stanford. Van received the ACM SIGCOMM Award in 2001 for outstanding lifetime contribution to the field of communication networks and the IEEE Kobayashi Award in 2002 for “contributing to the understanding of network congestion and developing congestion control mechanisms that enabled the successful scaling of the Internet”. He was elected to the U.S. National Academy of Engineering in 2004.</span></p>
<p><span class="font4" style="font-weight:bold;">Please describe one or two of the most exciting projects you have worked on during your career. What were the biggest challenges?</span></p>
<p><span class="font52">School teaches us lots of ways to find answers. In every interesting problem I’ve worked on, the challenge has been finding the right question. When Mike Karels and I started looking at TCP congestion, we spent months staring at protocol and packet traces asking “Why is it failing?”. One day in Mike’s office, one of us said “The reason I can’t figure out why it fails is because I don’t understand how it ever worked to begin with.” That turned out to be the right question and it forced us to figure out the “ack clocking” that makes TCP work. After that, the rest was easy.</span></p>
<p><span class="font4" style="font-weight:bold;">More generally, where do you see the future of networking and the Internet?</span></p>
<p><a name="bookmark330"></a><span class="font52">For most people, the Web is the Internet. Networking geeks smile politely since we know the Web is an application running over the Internet but what if they’re right? The Internet is about enabling conversations between pairs of hosts. The Web is about distributed information production and consumption. “Information propagation” is a very general view of communication of which “pairwise conversation” is a tiny subset. We need to move into the larger tent. Networking today deals with broadcast media (radios, PONs, etc.) by pretending it’s a point-to-point wire. That’s massively inefficient. Terabits-per-second of data are being exchanged all over the World via thumb drives or smart phones but we don’t know how to treat that as “networking”. ISPs are busily setting up caches and CDNs to scalably distribute video and audio. Caching is a necessary part of the solution but there’s no part of today’s networking—from Information, Queuing or Traffic Theory down to the Internet protocol specs—that tells us how to engineer and deploy it. I think and hope that over the next few years, networking will evolve to embrace the much larger vision of communication that underlies the Web.</span></p>
<p><span class="font4" style="font-weight:bold;">What people inspired you professionally?</span></p>
<p><span class="font52">When I was in grad school, Richard Feynman visited and gave a colloquium. He talked about a piece of Quantum theory that I’d been struggling with all semester and his explanation was so simple and lucid that what had been incomprehensible gibberish to me became obvious and inevitable. That ability to see and convey the simplicity that underlies our complex world seems to me a rare and wonderful gift.</span></p>
<p><span class="font4" style="font-weight:bold;">What are your recommendations for students who want careers in computer science and networking?</span></p>
<p><span class="font52">It’s a wonderful field—computers and networking have probably had more impact on society than any invention since the book. Networking is fundamentally about connecting stuff, and studying it helps you make intellectual connections: Ant foraging &amp;&nbsp;Bee dances demonstrate protocol design better than RFCs, traffic jams or people leaving a packed stadium are the essence of congestion, and students finding flights back to school in a post-Thanksgiving blizzard are the core of dynamic routing. If you’re interested in lots of stuff and want to have an impact, it’s hard to imagine a better field.</span></p><img src="networking_files/networking-266.jpg" alt="" style="width:531pt;height:153pt;">
<h1><a name="bookmark4"></a><span class="font27" style="font-weight:bold;">The Network</span></h1>
<h1><span class="font27" style="font-weight:bold;">Layer: Data</span></h1>
<h1><span class="font27" style="font-weight:bold;">Plane</span></h1>
<p><span class="font53">We learned in the previous chapter that the transport layer provides various forms of process-to-process communication by relying on the network layer’s host-to-host communication service. We also learned that the transport layer does so without any knowledge about how the network layer actually implements this service. So perhaps you’re now wondering, what’s under the hood of the host-to-host communication service, what makes it tick?</span></p>
<p><span class="font53">In this chapter and the next, we’ll learn exactly how the network layer can provide its host-to-host communication service. We’ll see that unlike the transport and application layers, </span><span class="font53" style="font-style:italic;">there is a piece of the network layer in each and every host and router in the network.</span><span class="font53"> Because of this, network-layer protocols are among the most challenging (and therefore among the most interesting!) in the protocol stack.</span></p>
<p><a name="bookmark331"></a><span class="font53">Since the network layer is arguably the most complex layer in the protocol stack, we’ll have a lot of ground to cover here. Indeed, there is so much to cover that we cover the network layer in two chapters. We’ll see that the network layer can be decomposed into two interacting parts, the </span><span class="font53" style="font-weight:bold;">data plane </span><span class="font53">and the </span><span class="font53" style="font-weight:bold;">control plane</span><span class="font53">. In Chapter 4, we’ll first cover the data plane functions of the network layer—the </span><span class="font53" style="font-style:italic;">per-router</span><span class="font53"> functions in the network layer that determine how a datagram (that is, a network-layer packet) arriving on one of a router’s input links is forwarded to one of that router’s output links. We’ll cover both traditional IP forwarding (where forwarding is based on a datagram’s destination address) and generalized forwarding (where forwarding and other functions may be performed using values in several different fields in the datagram’s header). We’ll study the IPv4 and IPv6 protocols and addressing in detail. In Chapter 5, we’ll cover the control plane functions of the network layer—the </span><span class="font53" style="font-style:italic;">network-wide</span><span class="font53"> logic that controls how a datagram is routed among routers along an end-to-end path from the source host to the destination host. We’ll cover routing algorithms, as well as routing protocols, such as OSPF and BGP, that are in widespread use in today’s Internet. Traditionally, these control-plane routing protocols and data-plane forwarding functions have been implemented together, monolithically, within a router. Software-defined networking (SDN) explicitly separates the data plane and control plane by implementing these control plane functions as a separate service, typically in a remote “controller.” We’ll also cover SDN controllers in Chapter 5.</span></p>
<p><span class="font53">This distinction between data-plane and control-plane functions in the network layer is an important concept to keep in mind as you learn about the network layer— it will help structure your thinking about the network layer and reflects a modern view of the network layer’s role in computer networking.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">4.1 </span><span class="font24" style="font-weight:bold;">Overview of Network Layer</span></p></li></ul>
<p><span class="font53">Figure 4.1 shows a simple network with two hosts, H1 and H2, and several routers on the path between H1 and H2. Let’s suppose that H1 is sending information to H2, and consider the role of the network layer in these hosts and in the intervening routers. The network layer in H1 takes segments from the transport layer in H1, encapsulates each segment into a datagram, and then sends the datagrams to its nearby router, R1. At the receiving host, H2, the network layer receives the datagrams from its nearby router R2, extracts the transport-layer segments, and delivers the segments up to the transport layer at H2. The primary data-plane role of each router is to forward datagrams from its input links to its output links; the primary role of the network control plane is to coordinate these local, per-router forwarding actions so that datagrams are ultimately transferred end-to-end, along paths of routers between source and destination hosts. Note that the routers in Figure 4.1 are shown with a truncated protocol stack, that is, with no upper layers above the network layer, because routers do not run application-and transport-layer protocols such as those we examined in Chapters 2 and 3.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">4.1.1 </span><span class="font23" style="font-weight:bold;">Forwarding and Routing: The Data and</span></p></li></ul>
<p><span class="font23" style="font-weight:bold;">Control Planes</span></p>
<p><span class="font53">The primary role of the network layer is deceptively simple—to move packets from a sending host to a receiving host. To do so, two important network-layer functions can be identified:</span></p>
<p><a name="bookmark332"></a><span class="font53">• </span><span class="font53" style="font-style:italic;">Forwarding.</span><span class="font53"> When a packet arrives at a router’s input link, the router must move the packet to the appropriate output link. For example, a packet arriving from Host H1 to Router R1 in Figure 4.1 must be forwarded to the next router on a path to H2. As we will see, forwarding is but one function (albeit the most</span></p>
<div style="border:solid;">
<p><span class="font4">Application</span></p>
<p><span class="font4">Transport</span></p>
<p><span class="font4" style="font-weight:bold;">Network</span></p>
<p><span class="font4">Link</span></p>
<p><span class="font4">Physical</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Network</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Link</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">End System H1</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Physical</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Router R1</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Network</span></p>
<p><span class="font4">Link</span></p>
<p><span class="font4">Physical</span></p>
</div><br clear="all">
<div style="border:solid;">
<p><span class="font4" style="font-weight:bold;">Network</span></p>
<p><span class="font4">Link</span></p>
<p><span class="font4">Physical</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Network</span></p>
<p><span class="font4">Link</span></p>
<p><span class="font4">Physical</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Physical</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Router R2</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Network</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Link</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Physical</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Enterprise Network</span></p>
</div><br clear="all">
<div>
<p><span class="font7" style="font-weight:bold;">Figure 4.1 </span><span class="font50">♦ </span><span class="font5">The network layer</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Application</span></p>
<p><span class="font4">Transport</span></p>
<p><span class="font4" style="font-weight:bold;">Network</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Link</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Physical</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">End System H2</span></p>
</div><br clear="all">
<p><span class="font53">common and important one!) implemented in the data plane. In the more general case, which we’ll cover in Section 4.4, a packet might also be blocked from exiting a router (for example, if the packet originated at a known malicious sending host, or if the packet were destined to a forbidden destination host), or might be duplicated and sent over multiple outgoing links.</span></p>
<p><span class="font53">• </span><span class="font53" style="font-style:italic;">Routing.</span><span class="font53"> The network layer must determine the route or path taken by packets as they flow from a sender to a receiver. The algorithms that calculate these paths are referred to as </span><span class="font53" style="font-weight:bold;">routing algorithms</span><span class="font53">. A routing algorithm would determine, for example, the path along which packets flow from H1 to H2 in Figure 4.1. Routing is implemented in the control plane of the network layer.</span></p>
<p><span class="font53">The terms </span><span class="font53" style="font-style:italic;">forwarding</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">routing</span><span class="font53"> are often used interchangeably by authors discussing the network layer. We’ll use these terms much more precisely in this book. </span><span class="font53" style="font-weight:bold;">Forwarding </span><span class="font53">refers to the router-local action of transferring a packet from an input link interface to the appropriate output link interface. Forwarding takes place at very short timescales (typically a few nanoseconds), and thus is typically implemented in hardware. </span><span class="font53" style="font-weight:bold;">Routing </span><span class="font53">refers to the network-wide process that determines the end-to-end paths that packets take from source to destination. Routing takes place on much longer timescales (typically seconds), and as we will see is often implemented in software. Using our driving analogy, consider the trip from Pennsylvania to Florida undertaken by our traveler back in Section 1.3.1. During this trip, our driver passes through many interchanges en route to Florida. We can think of forwarding as the process of getting through a single interchange: A car enters the interchange from one road and determines which road it should take to leave the interchange. We can think of routing as the process of planning the trip from Pennsylvania to Florida: Before embarking on the trip, the driver has consulted a map and chosen one of many paths possible, with each path consisting of a series of road segments connected at interchanges.</span></p>
<p><span class="font53">A key element in every network router is its </span><span class="font53" style="font-weight:bold;">forwarding table</span><span class="font53">. A router forwards a packet by examining the value of one or more fields in the arriving packet’s header, and then using these header values to index into its forwarding table. The value stored in the forwarding table entry for those values indicates the outgoing link interface at that router to which that packet is to be forwarded. For example, in Figure 4.2, a packet with header field value of 0110 arrives to a router. The router indexes into its forwarding table and determines that the output link interface for this packet is interface 2. The router then internally forwards the packet to interface 2. In Section 4.2, we’ll look inside a router and examine the forwarding function in much greater detail. Forwarding is the key function performed by the data-plane functionality of the network layer.</span></p>
<p><span class="font23" style="font-weight:bold;">Control Plane: The Traditional Approach</span></p>
<p><span class="font53">But now you are undoubtedly wondering how a router’s forwarding tables are configured in the first place. This is a crucial issue, one that exposes the important interplay between forwarding (in data plane) and routing (in control plane). As shown</span></p>
<div><img src="networking_files/networking-267.jpg" alt="" style="width:350pt;height:145pt;">
<p><span class="font4">Values in arriving packet's header</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-268.jpg" alt="" style="width:287pt;height:49pt;">
<p><span class="font7" style="font-weight:bold;">Figure 4.2 </span><span class="font50">♦ </span><span class="font5">Routing algorithms determine values in forward tables</span></p>
</div><br clear="all">
<p><span class="font53">in Figure 4.2, the routing algorithm determines the contents of the routers’ forwarding tables. In this example, a routing algorithm runs in each and every router and both forwarding and routing functions are contained within a router. As we’ll see in Sections 5.3 and 5.4, the routing algorithm function in one router communicates with the routing algorithm function in other routers to compute the values for its forwarding table. How is this communication performed? By exchanging routing messages containing routing information according to a routing protocol! We’ll cover routing algorithms and protocols in Sections 5.2 through 5.4.</span></p>
<p><span class="font53">The distinct and different purposes of the forwarding and routing functions can be further illustrated by considering the hypothetical (and unrealistic, but technically feasible) case of a network in which all forwarding tables are configured directly by human network operators physically present at the routers. In this case, </span><span class="font53" style="font-style:italic;">no</span><span class="font53"> routing protocols would be required! Of course, the human operators would need to interact with each other to ensure that the forwarding tables were configured in such a way that packets reached their intended destinations. It’s also likely that human configuration would be more error-prone and much slower to respond to changes in the network topology than a routing protocol. We’re thus fortunate that all networks have both a forwarding </span><span class="font53" style="font-style:italic;">and</span><span class="font53"> a routing function!</span></p>
<p><span class="font23" style="font-weight:bold;">Control Plane: The SDN Approach</span></p>
<p><span class="font53">The approach to implementing routing functionality shown in Figure 4.2—with each router having a routing component that communicates with the routing component of other routers—has been the traditional approach adopted by routing vendors in their products, at least until recently. Our observation that humans could manually configure forwarding tables does suggest, however, that there may be other ways for controlplane functionality to determine the contents of the data-plane forwarding tables.</span></p>
<p><span class="font53">Figure 4.3 shows an alternative approach in which a physically separate, remote controller computes and distributes the forwarding tables to be used by each and every router. Note that the data plane components of Figures 4.2 and 4.3 are identical. In Figure 4.3; however, control-plane routing functionality is separated from the physical router—the routing device performs forwarding only, while the remote controller computes and distributes forwarding tables. The remote controller might be implemented in a remote data center with high reliability and redundancy, and might be managed by the ISP or some third party. How might the routers and the remote controller communicate? By exchanging messages containing forwarding tables and other pieces of routing information. The control-plane approach shown in Figure 4.3 is at the heart of </span><span class="font53" style="font-weight:bold;">software-defined networking (SDN)</span><span class="font53">, where the network is “software-defined” because the controller that computes forwarding tables and interacts with routers is implemented in software. Increasingly, these software implementations are also open, that is, similar to Linux OS code, the code is publically available, allowing ISPs (and networking researchers and students!) to innovate and propose changes to the software that controls network-layer functionality. We will cover the SDN control plane in Section 5.5.</span></p>
<div><img src="networking_files/networking-269.jpg" alt="" style="width:19pt;height:37pt;">
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Control plane</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Data plane</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-270.jpg" alt="" style="width:300pt;height:79pt;">
</div><br clear="all">
<div><img src="networking_files/networking-271.jpg" alt="" style="width:62pt;height:20pt;">
</div><br clear="all">
<div>
<table border="1">
<tr><td colspan="2" style="vertical-align:bottom;">
<p><span class="font50">Local forwarding</span></p></td></tr>
<tr><td colspan="2">
<p><span class="font50">table</span></p></td></tr>
<tr><td>
<p><span class="font50">header</span></p></td><td>
<p><span class="font50">output</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font50">0100</span></p></td><td style="vertical-align:bottom;">
<p><span class="font50">3</span></p></td></tr>
<tr><td>
<p><span class="font50">0110</span></p></td><td>
<p><span class="font50">2</span></p></td></tr>
<tr><td>
<p><span class="font50">0111</span></p></td><td>
<p><span class="font50">2</span></p></td></tr>
<tr><td>
<p><span class="font50">1001</span></p></td><td>
<p><span class="font50">1</span></p></td></tr>
</table>
</div><br clear="all">
<div><img src="networking_files/networking-272.jpg" alt="" style="width:178pt;height:106pt;">
</div><br clear="all">
<div>
<p><span class="font4">Values in arriving packet's header</span></p><img src="networking_files/networking-273.jpg" alt="" style="width:54pt;height:19pt;">
</div><br clear="all">
<div><img src="networking_files/networking-274.jpg" alt="" style="width:204pt;height:50pt;">
<p><span class="font7" style="font-weight:bold;">Figure 4.3 </span><span class="font50">♦ </span><span class="font5">A remote controller determines and distributes values in forwarding tables</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">4.1.2 </span><span class="font23" style="font-weight:bold;">Network Service Model</span></p></li></ul>
<p><span class="font53">Before delving into the network layer’s data plane, let’s wrap up our introduction by taking the broader view and consider the different types of service that might be offered by the network layer. When the transport layer at a sending host transmits a packet into the network (that is, passes it down to the network layer at the sending host), can the transport layer rely on the network layer to deliver the packet to the destination? When multiple packets are sent, will they be delivered to the transport layer in the receiving host in the order in which they were sent? Will the amount of time between the sending of two sequential packet transmissions be the same as the amount of time between their reception? Will the network provide any feedback about congestion in the network? The answers to these questions and others are determined by the service model provided by the network layer. The </span><span class="font53" style="font-weight:bold;">network service model </span><span class="font53">defines the characteristics of end-to-end delivery of packets between sending and receiving hosts.</span></p>
<p><span class="font53">Let’s now consider some possible services that the network layer could provide. These services could include:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Guaranteed delivery.</span><span class="font53"> This service guarantees that a packet sent by a source host will eventually arrive at the destination host.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Guaranteed delivery with bounded delay.</span><span class="font53"> This service not only guarantees delivery of the packet, but delivery within a specified host-to-host delay bound (for example, within 100 msec).</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">In-order packet delivery.</span><span class="font53"> This service guarantees that packets arrive at the destination in the order that they were sent.</span></p></li>
<li>
<p><a name="bookmark333"></a><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Guaranteed minimal bandwidth.</span><span class="font53"> This network-layer service emulates the behavior of a transmission link of a specified bit rate (for example, 1 Mbps) between sending and receiving hosts. As long as the sending host transmits bits (as part of packets) at a rate below the specified bit rate, then all packets are eventually delivered to the destination host.</span></p></li></ul>
<p><span class="font53">• </span><span class="font53" style="font-style:italic;">Security.</span><span class="font53"> The network layer could encrypt all datagrams at the source and decrypt them at the destination, thereby providing confidentiality to all transport-layer segments.</span></p>
<p><span class="font53">This is only a partial list of services that a network layer could provide—there are countless variations possible.</span></p>
<p><span class="font53">The Internet’s network layer provides a single service, known as </span><span class="font53" style="font-weight:bold;">best-effort service</span><span class="font53">. With best-effort service, packets are neither guaranteed to be received in the order in which they were sent, nor is their eventual delivery even guaranteed. There is no guarantee on the end-to-end delay nor is there a minimal bandwidth guarantee. It might appear that </span><span class="font53" style="font-style:italic;">best-effort service</span><span class="font53"> is a euphemism for </span><span class="font53" style="font-style:italic;">no service at all—</span><span class="font53">a network that delivered </span><span class="font53" style="font-style:italic;">no</span><span class="font53"> packets to the destination would satisfy the definition of best-effort delivery service! Other network architectures have defined and implemented service models that go beyond the Internet’s best-effort service. For example, the ATM network architecture [Black 1995] provides for guaranteed in-order delay, bounded delay, and guaranteed minimal bandwidth. There have also been proposed service model extensions to the Internet architecture; for example, the Intserv architecture [RFC 1633] aims to provide end-end delay guarantees and congestion-free communication. Interestingly, in spite of these well-developed alternatives, the Internet’s basic best-effort service model combined with adequate bandwidth provisioning and bandwidth-adaptive application-level protocols such as the DASH protocol we encountered in Section 2.6.2 have arguably proven to be more than “good enough” to enable an amazing range of applications, including streaming video services such as Netflix and video-over-IP, real-time conferencing applications such as Skype and Facetime.</span></p>
<p><span class="font23" style="font-weight:bold;">An Overview of Chapter 4</span></p>
<p><span class="font53">Having now provided an overview of the network layer, we’ll cover the data-plane component of the network layer in the following sections in this chapter. In Section 4.2, we’ll dive down into the internal hardware operations of a router, including input and output packet processing, the router’s internal switching mechanism, and packet queuing and scheduling. In Section 4.3, we’ll take a look at traditional IP forwarding, in which packets are forwarded to output ports based on their destination IP addresses. We’ll encounter IP addressing, the celebrated IPv4 and IPv6 protocols and more. In Section 4.4, we’ll cover more generalized forwarding, where packets may be forwarded to output ports based on a large number of header values (i.e., not only based on destination IP address). Packets may be blocked or duplicated at the router, or may have certain header field values rewritten—all under software control. This more generalized form of packet forwarding is a key component of a modern network data plane, including the data plane in software-defined networks (SDN). In Section 4.5, we’ll learn about “middleboxes” that can perform functions in addition to forwarding.</span></p>
<p><span class="font53">We mention here in passing that the terms </span><span class="font53" style="font-style:italic;">forwarding</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">switching</span><span class="font53"> are often used interchangeably by computer-networking researchers and practitioners; we’ll use both terms interchangeably in this textbook as well. While we’re on the topic of terminology, it’s also worth mentioning two other terms that are often used interchangeably, but that we will use more carefully. We’ll reserve the term </span><span class="font53" style="font-style:italic;">packet switch </span><span class="font53">to mean a general packet-switching device that transfers a packet from input link interface to output link interface, according to values in a packet’s header fields. Some packet switches, called </span><span class="font53" style="font-weight:bold;">link-layer switches </span><span class="font53">(examined in Chapter 6), base their forwarding decision on values in the fields of the link-layer frame; switches are thus referred to as link-layer (layer 2) devices. Other packet switches, called </span><span class="font53" style="font-weight:bold;">routers</span><span class="font53">, base their forwarding decision on header field values in the network-layer datagram. Routers are thus network-layer (layer 3) devices. (To fully appreciate this important distinction, you might want to review Section 1.5.2, where we discuss network-layer datagrams and link-layer frames and their relationship.) Since our focus in this chapter is on the network layer, we’ll mostly use the term </span><span class="font53" style="font-style:italic;">router</span><span class="font53"> in place of </span><span class="font53" style="font-style:italic;">packet switch.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">4.2 </span><span class="font24" style="font-weight:bold;">What’s Inside a Router?</span></p></li></ul>
<p><span class="font53">Now that we’ve overviewed the data and control planes within the network layer, the important distinction between forwarding and routing, and the services and functions of the network layer, let’s turn our attention to its forwarding function—the actual transfer of packets from a router’s incoming links to the appropriate outgoing links at that router.</span></p>
<p><span class="font53">A high-level view of a generic router architecture is shown in Figure 4.4. Four router components can be identified:</span></p><img src="networking_files/networking-275.jpg" alt="" style="width:383pt;height:183pt;">
<p><a name="bookmark334"></a><span class="font7" style="font-weight:bold;">Figure 4.4 </span><span class="font50">♦ </span><span class="font5">Router architecture</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Input ports.</span><span class="font53"> An </span><span class="font53" style="font-weight:bold;">input port </span><span class="font53">performs several key functions. It performs the physical layer function of terminating an incoming physical link at a router; this is shown in the leftmost box of an input port and the rightmost box of an output port in Figure 4.4. An input port also performs link-layer functions needed to interoperate with the link layer at the other side of the incoming link; this is represented by the middle boxes in the input and output ports. Perhaps most crucially, a lookup function is also performed at the input port; this will occur in the rightmost box of the input port. It is here that the forwarding table is consulted to determine the router output port to which an arriving packet will be forwarded via the switching fabric. Control packets (for example, packets carrying routing protocol information) are forwarded from an input port to the routing processor. Note that the term “port” here—referring to the physical input and output router interfaces—is distinctly different from the software ports associated with network applications and sockets discussed in Chapters 2 and 3. In practice, the number of ports supported by a router can range from a relatively small number in enterprise routers, to hundreds of 10 Gbps ports in a router at an ISP’s edge, where the number of incoming lines tends to be the greatest. The Juniper MX2020, edge router, for example, supports up to 800 100 Gbps Ethernet ports, with an overall router system capacity of 800 Tbps [Juniper MX 2020 2020].</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Switching fabric.</span><span class="font53"> The switching fabric connects the router’s input ports to its output ports. This switching fabric is completely contained within the router—a network inside of a network router!</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Output ports.</span><span class="font53"> An </span><span class="font53" style="font-weight:bold;">output port </span><span class="font53">stores packets received from the switching fabric and transmits these packets on the outgoing link by performing the necessary link-layer and physical-layer functions. When a link is bidirectional (that is, carries traffic in both directions), an output port will typically be paired with the input port for that link on the same line card.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Routing processor.</span><span class="font53"> The routing processor performs control-plane functions. In traditional routers, it executes the routing protocols (which we’ll study in Sections 5.3 and 5.4), maintains routing tables and attached link state information, and computes the forwarding table for the router. In SDN routers, the routing processor is responsible for communicating with the remote controller in order to (among other activities) receive forwarding table entries computed by the remote controller, and install these entries in the router’s input ports. The routing processor also performs the network management functions that we’ll study in Section 5.7.</span></p></li></ul>
<p><span class="font53">A router’s input ports, output ports, and switching fabric are almost always implemented in hardware, as shown in Figure 4.4. To appreciate why a hardware implementation is needed, consider that with a 100 Gbps input link and a 64-byte IP datagram, the input port has only 5.12 ns to process the datagram before another datagram may arrive. If </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> ports are combined on a line card (as is often done in practice), the datagram-processing pipeline must operate </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> times faster—far too fast for software implementation. Forwarding hardware can be implemented either using a router vendor’s own hardware designs, or constructed using purchased merchant-silicon chips (for example, as sold by companies such as Intel and Broadcom).</span></p>
<p><span class="font53">While the data plane operates at the nanosecond time scale, a router’s control functions—executing the routing protocols, responding to attached links that go up or down, communicating with the remote controller (in the SDN case) and performing management functions—operate at the millisecond or second timescale. These </span><span class="font53" style="font-weight:bold;">control plane </span><span class="font53">functions are thus usually implemented in software and execute on the routing processor (typically a traditional CPU).</span></p>
<p><span class="font53">Before delving into the details of router internals, let’s return to our analogy from the beginning of this chapter, where packet forwarding was compared to cars entering and leaving an interchange. Let’s suppose that the interchange is a roundabout, and that as a car enters the roundabout, a bit of processing is required. Let’s consider what information is required for this processing:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Destination-based forwarding.</span><span class="font53"> Suppose the car stops at an entry station and indicates its final destination (not at the local roundabout, but the ultimate destination of its journey). An attendant at the entry station looks up the final destination, determines the roundabout exit that leads to that final destination, and tells the driver which roundabout exit to take.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Generalized forwarding.</span><span class="font53"> The attendant could also determine the car’s exit ramp on the basis of many other factors besides the destination. For example, the selected exit ramp might depend on the car’s origin, for example the state that issued the car’s license plate. Cars from a certain set of states might be directed to use one exit ramp (that leads to the destination via a slow road), while cars from other states might be directed to use a different exit ramp (that leads to the destination via superhighway). The same decision might be made based on the model, make and year of the car. Or a car not deemed roadworthy might be blocked and not be allowed to pass through the roundabout. In the case of generalized forwarding, any number of factors may contribute to the attendant’s choice of the exit ramp for a given car.</span></p></li></ul>
<p><span class="font53">Once the car enters the roundabout (which may be filled with other cars entering from other input roads and heading to other roundabout exits), it eventually leaves at the prescribed roundabout exit ramp, where it may encounter other cars leaving the roundabout at that exit.</span></p>
<p><span class="font53">We can easily recognize the principal router components in Figure 4.4 in this analogy—the entry road and entry station correspond to the input port (with a lookup function to determine to local outgoing port); the roundabout corresponds to the switch fabric; and the roundabout exit road corresponds to the output port. With this analogy, it’s instructive to consider where bottlenecks might occur. What happens if cars arrive blazingly fast (for example, the roundabout is in Germany or Italy!) but the station attendant is slow? How fast must the attendant work to ensure there’s no backup on an entry road? Even with a blazingly fast attendant, what happens if cars traverse the roundabout slowly—can backups still occur? And what happens if most of the cars entering at all of the roundabout’s entrance ramps all want to leave the roundabout at the same exit ramp—can backups occur at the exit ramp or elsewhere? How should the roundabout operate if we want to assign priorities to different cars, or block certain cars from entering the roundabout in the first place? These are all analogous to critical questions faced by router and switch designers.</span></p>
<p><span class="font53">In the following subsections, we’ll look at router functions in more detail. [Turner 1988; McKeown 1997a; Partridge 1998; Iyer 2008; Serpanos 2011; Zilberman 2019] provide a discussion of specific router architectures. For concreteness and simplicity, we’ll initially assume in this section that forwarding decisions are based only on the packet’s destination address, rather than on a generalized set of packet header fields. We will cover the case of more generalized packet forwarding in Section 4.4.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">4.2.1 </span><span class="font23" style="font-weight:bold;">Input Port Processing and Destination-Based Forwarding</span></p></li></ul>
<p><span class="font53">A more detailed view of input processing is shown in Figure 4.5. As just discussed, the input port’s line-termination function and link-layer processing implement the physical and link layers for that individual input link. The lookup performed in the input port is central to the router’s operation—it is here that the router uses the forwarding table to look up the output port to which an arriving packet will be forwarded via the switching fabric. The forwarding table is either computed and updated by the routing processor (using a routing protocol to interact with the routing processors in other network routers) or is received from a remote SDN controller. The forwarding table is copied from the routing processor to the line cards over a separate bus (e.g., a PCI bus) indicated by the dashed line from the routing processor to the input line cards in Figure 4.4. With such a shadow copy at each line card, forwarding decisions can be made locally, at each input port, without invoking the centralized routing processor on a per-packet basis and thus avoiding a centralized processing bottleneck.</span></p>
<p><span class="font53">Let’s now consider the “simplest” case that the output port to which an incoming packet is to be switched is based on the packet’s destination address. In the case of 32-bit IP addresses, a brute-force implementation of the forwarding table would have one entry for every possible destination address. Since there are more than 4 billion possible addresses, this option is totally out of the question.</span></p>
<div><img src="networking_files/networking-276.jpg" alt="" style="width:257pt;height:52pt;">
<p><a name="bookmark335"></a><span class="font7" style="font-weight:bold;">Figure 4.5 </span><span class="font50">♦ </span><span class="font5">Input port processing</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Switch fabric</span></p>
</div><br clear="all">
<p><span class="font53">As an example of how this issue of scale can be handled, let’s suppose that our router has four links, numbered 0 through 3, and that packets are to be forwarded to the link interfaces as follows:</span></p>
<div>
<p><span class="font53" style="font-weight:bold;">Link Interface</span></p>
</div><br clear="all">
<p><span class="font53" style="font-weight:bold;">Destination Address Range</span></p>
<table border="1">
<tr><td>
<p><span class="font36">11001000 00010111 00010000 00000000 </span><span class="font53">through</span></p>
<p><span class="font36">11001000 00010111 00010111 11111111</span></p></td><td style="vertical-align:middle;">
<p><span class="font36">0</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font36">11001000 00010111 00011000 00000000</span></p></td><td></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font53">through</span></p></td><td style="vertical-align:bottom;">
<p><span class="font36">1</span></p></td></tr>
<tr><td>
<p><span class="font36">11001000 00010111 00011000 11111111</span></p></td><td></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font36">11001000 00010111 00011001 00000000</span></p></td><td></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font53">through</span></p></td><td style="vertical-align:bottom;">
<p><span class="font36">2</span></p></td></tr>
<tr><td>
<p><span class="font36">11001000 00010111 00011111 11111111</span></p></td><td></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font53">Otherwise</span></p></td><td style="vertical-align:bottom;">
<p><span class="font36">3</span></p></td></tr>
</table>
<p><span class="font53">Clearly, for this example, it is not necessary to have 4 billion entries in the router’s forwarding table. We could, for example, have the following forwarding table with just four entries:</span></p>
<div>
<p><span class="font53" style="font-weight:bold;">Link Interface</span></p>
</div><br clear="all">
<p><span class="font53" style="font-weight:bold;">Prefix</span></p>
<table border="1">
<tr><td>
<p><span class="font36">11001000</span></p></td><td>
<p><span class="font36">00010111</span></p></td><td>
<p><span class="font36">00010</span></p></td><td>
<p><span class="font36">0</span></p></td></tr>
<tr><td>
<p><span class="font36">11001000</span></p></td><td>
<p><span class="font36">00010111</span></p></td><td>
<p><span class="font36">00011000</span></p></td><td>
<p><span class="font36">1</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font36">11001000</span></p></td><td style="vertical-align:bottom;">
<p><span class="font36">00010111</span></p></td><td style="vertical-align:bottom;">
<p><span class="font36">00011</span></p></td><td style="vertical-align:bottom;">
<p><span class="font36">2</span></p></td></tr>
<tr><td></td><td style="vertical-align:bottom;">
<p><span class="font53">Otherwise</span></p></td><td></td><td style="vertical-align:bottom;">
<p><span class="font36">3</span></p></td></tr>
</table>
<p><span class="font53">With this style of forwarding table, the router matches a </span><span class="font53" style="font-weight:bold;">prefix </span><span class="font53">of the packet’s destination address with the entries in the table; if there’s a match, the router forwards the packet to a link associated with the match. For example, suppose the packet’s destination address is </span><span class="font36">11001000 00010111 00010110 10100001</span><span class="font53">; because the 21-bit prefix of this address matches the first entry in the table, the router forwards the packet to link interface 0. If a prefix doesn’t match any of the first three entries, then the router forwards the packet to the default interface 3. Although this sounds simple enough, there’s a very important subtlety here. You may have noticed that it is possible for a destination address to match more than one entry. For example, the first 24 bits of the address </span><span class="font36">11001000 00010111 00011000 10101010 </span><span class="font53">match the second entry in the table, and the first 21 bits of the address match the third entry in the table. When there are multiple matches, the router uses the </span><span class="font53" style="font-weight:bold;">longest prefix matching rule</span><span class="font53">; that is, it finds the longest matching entry in the table and forwards the packet to the link interface associated with the longest prefix match. We’ll see exactly </span><span class="font53" style="font-style:italic;">why</span><span class="font53"> this longest prefix-matching rule is used when we study Internet addressing in more detail in Section 4.3.</span></p>
<p><span class="font53">Given the existence of a forwarding table, lookup is conceptually simple— hardware logic just searches through the forwarding table looking for the longest prefix match. But at Gigabit transmission rates, this lookup must be performed in nanoseconds (recall our earlier example of a 10 Gbps link and a 64-byte IP datagram). Thus, not only must lookup be performed in hardware, but techniques beyond a simple linear search through a large table are needed; surveys of fast lookup algorithms can be found in [Gupta 2001, Ruiz-Sanchez 2001]. Special attention must also be paid to memory access times, resulting in designs with embedded on-chip DRAM and faster SRAM (used as a DRAM cache) memories. In practice, Ternary Content Addressable Memories (TCAMs) are also often used for lookup [Yu 2004]. With a TCAM, a 32-bit IP address is presented to the memory, which returns the content of the forwarding table entry for that address in essentially constant time. The Cisco Catalyst 6500 and 7600 Series routers and switches can hold upwards of a million TCAM forwarding table entries [Cisco TCAM 2014].</span></p>
<p><span class="font53">Once a packet’s output port has been determined via the lookup, the packet can be sent into the switching fabric. In some designs, a packet may be temporarily blocked from entering the switching fabric if packets from other input ports are currently using the fabric. A blocked packet will be queued at the input port and then scheduled to cross the fabric at a later point in time. We’ll take a closer look at the blocking, queuing, and scheduling of packets (at both input ports and output ports) shortly. Although “lookup” is arguably the most important action in input port processing, many other actions must be taken: (1) physical- and link-layer processing must occur, as discussed previously; (2) the packet’s version number, checksum and time-to-live field—all of which we’ll study in Section 4.3—must be checked and the latter two fields rewritten; and (3) counters used for network management (such as the number of IP datagrams received) must be updated.</span></p>
<p><span class="font53">Let’s close our discussion of input port processing by noting that the input port steps of looking up a destination IP address (“match”) and then sending the packet into the switching fabric to the specified output port (“action”) is a specific case of a more general “match plus action” abstraction that is performed in many networked devices, not just routers. In link-layer switches (covered in Chapter 6), link-layer destination addresses are looked up and several actions may be taken in addition to sending the frame into the switching fabric towards the output port. In firewalls (covered in Chapter 8)—devices that filter out selected incoming packets—an incoming packet whose header matches a given criteria (e.g., a combination of source/destina-tion IP addresses and transport-layer port numbers) may be dropped (action). In a network address translator (NAT, covered in Section 4.3), an incoming packet whose transport-layer port number matches a given value will have its port number rewritten before forwarding (action). Indeed, the “match plus action” abstraction [Bosshart 2013] is both powerful and prevalent in network devices today, and is central to the notion of generalized forwarding that we’ll study in Section 4.4.</span></p>
<p><span class="font56" style="font-weight:bold;">4.2.2 </span><span class="font23" style="font-weight:bold;">Switching</span></p>
<p><span class="font53">The switching fabric is at the very heart of a router, as it is through this fabric that the packets are actually switched (that is, forwarded) from an input port to an output port. Switching can be accomplished in a number of ways, as shown in Figure 4.6:</span></p>
<p><span class="font53">• </span><span class="font53" style="font-style:italic;">Switching via memory.</span><span class="font53"> The simplest, earliest routers were traditional computers, with switching between input and output ports being done under direct control of the CPU (routing processor). Input and output ports functioned as traditional I/O devices in a traditional operating system. An input port with an arriving packet first signaled the routing processor via an interrupt. The packet was then copied from the input port into processor memory. The routing processor then extracted the destination address from the header, looked up the appropriate output port in the forwarding table, and copied the packet to the output port’s buffers. In this scenario, if the memory bandwidth is such that a maximum of </span><span class="font53" style="font-style:italic;">B</span><span class="font53"> packets per second can be written into, or read from, memory, then the overall forwarding throughput (the total rate at which packets are transferred from input ports to output ports) must be less than </span><span class="font53" style="font-style:italic;">B</span><span class="font53">/2. Note also that two packets cannot be forwarded</span></p>
<div>
<p><span class="font4" style="font-weight:bold;">Memory</span></p><img src="networking_files/networking-277.jpg" alt="" style="width:215pt;height:77pt;">
</div><br clear="all">
<div><img src="networking_files/networking-278.jpg" alt="" style="width:183pt;height:87pt;">
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Interconnection Network</span></p><img src="networking_files/networking-279.jpg" alt="" style="width:162pt;height:176pt;">
</div><br clear="all">
<p><span class="font4">Key:</span></p>
<p><span class="font41">□</span><span class="font41" style="text-decoration:underline;"> | &nbsp;&nbsp;&nbsp;| [iiiiil</span><span class="font41"> Input port </span><span class="font41" style="text-decoration:underline;">|lii»] I I </span><span class="font41">□ Output port</span></p>
<p><a name="bookmark336"></a><span class="font7" style="font-weight:bold;">Figure 4.6 </span><span class="font50">♦ </span><span class="font5">Three switching techniques </span><span class="font53">at the same time, even if they have different destination ports, since only one memory read/write can be done at a time over the shared system bus.</span></p>
<p><span class="font53">Some modern routers switch via memory. A major difference from early routers, however, is that the lookup of the destination address and the storing of the packet into the appropriate memory location are performed by processing on the input line cards. In some ways, routers that switch via memory look very much like shared-memory multiprocessors, with the processing on a line card switching (writing) packets into the memory of the appropriate output port. Cisco’s Catalyst 8500 series switches [Cisco 8500 2020] internally switches packets via a shared memory.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Switching via a bus.</span><span class="font53"> In this approach, an input port transfers a packet directly to the output port over a shared bus, without intervention by the routing processor. This is typically done by having the input port pre-pend a switch-internal label (header) to the packet indicating the local output port to which this packet is being transferred and transmitting the packet onto the bus. All output ports receive the packet, but only the port that matches the label will keep the packet. The label is then removed at the output port, as this label is only used within the switch to cross the bus. If multiple packets arrive to the router at the same time, each at a different input port, all but one must wait since only one packet can cross the bus at a time. Because every packet must cross the single bus, the switching speed of the router is limited to the bus speed; in our roundabout analogy, this is as if the roundabout could only contain one car at a time. Nonetheless, switching via a bus is often sufficient for routers that operate in small local area and enterprise networks. The Cisco 6500 router [Cisco 6500 2020] internally switches packets over a 32-Gbps-backplane bus.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Switching via an interconnection network.</span><span class="font53"> One way to overcome the bandwidth limitation of a single, shared bus is to use a more sophisticated interconnection network, such as those that have been used in the past to interconnect processors in a multiprocessor computer architecture. A crossbar switch is an interconnection network consisting of </span><span class="font53" style="font-style:italic;">2N</span><span class="font53"> buses that connect </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> input ports to </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> output ports, as shown in Figure 4.6. Each vertical bus intersects each horizontal bus at a crosspoint, which can be opened or closed at any time by the switch fabric controller (whose logic is part of the switching fabric itself). When a packet arrives from port A and needs to be forwarded to port Y, the switch controller closes the crosspoint at the intersection of busses A and Y, and port A then sends the packet onto its bus, which is picked up (only) by bus Y. Note that a packet from port B can be forwarded to port X at the same time, since the A-to-Y and B-to-X packets use different input and output busses. Thus, unlike the previous two switching approaches, crossbar switches are capable of forwarding multiple packets in parallel. A crossbar switch is </span><span class="font53" style="font-weight:bold;">non-blocking—</span><span class="font53">a packet being forwarded to an output port will not be blocked from reaching that output port as long as no other packet is currently being forwarded to that output port. However, if two packets from two different input ports are destined to that same output port, then one will have to wait at the input, since only one packet can be sent over any given bus at a time. Cisco 12000 series switches [Cisco 12000 2020] use a crossbar switching network; the Cisco 7600 series can be configured to use either a bus or crossbar switch [Cisco 7600 2020].</span></p></li></ul>
<p><span class="font53">More sophisticated interconnection networks use multiple stages of switching elements to allow packets from different input ports to proceed towards the same output port at the same time through the multi-stage switching fabric. See [Tobagi 1990] for a survey of switch architectures. The Cisco CRS employs a three-stage non-blocking switching strategy. A router’s switching capacity can also be scaled by running multiple switching fabrics in parallel. In this approach, input ports and output ports are connected to </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> switching fabrics that operate in parallel. An input port breaks a packet into </span><span class="font53" style="font-style:italic;">K</span><span class="font53"> smaller chunks, and sends (“sprays”) the chunks through </span><span class="font53" style="font-style:italic;">K</span><span class="font53"> of these </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> switching fabrics to the selected output port, which reassembles the </span><span class="font53" style="font-style:italic;">K</span><span class="font53"> chunks back into the original packet.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">4.2.3 </span><span class="font23" style="font-weight:bold;">Output Port Processing</span></p></li></ul>
<p><span class="font53">Output port processing, shown in Figure 4.7, takes packets that have been stored in the output port’s memory and transmits them over the output link. This includes selecting (i.e., scheduling) and de-queuing packets for transmission, and performing the needed link-layer and physical-layer transmission functions.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">4.2.4 </span><span class="font23" style="font-weight:bold;">Where Does Queuing Occur?</span></p></li></ul>
<p><span class="font53">If we consider input and output port functionality and the configurations shown in Figure 4.6, it’s clear that packet queues may form at both the input ports </span><span class="font53" style="font-style:italic;">and</span><span class="font53"> the output ports, just as we identified cases where cars may wait at the inputs and outputs of the traffic intersection in our roundabout analogy. The location and extent of queuing (either at the input port queues or the output port queues) will depend on the traffic load, the relative speed of the switching fabric, and the line speed. Let’s now consider these queues in a bit more detail, since as these queues grow large, the router’s memory can eventually be exhausted and </span><span class="font53" style="font-weight:bold;">packet loss </span><span class="font53">will occur when no memory is available to store arriving packets. Recall that in our earlier discussions, we said that packets were “lost within the network” or “dropped at a router.” </span><span class="font53" style="font-style:italic;">It is here, at these queues within a router, where such packets are actually dropped and lost.</span></p><img src="networking_files/networking-280.jpg" alt="" style="width:333pt;height:77pt;">
<p><a name="bookmark337"></a><span class="font7" style="font-weight:bold;">Figure 4.7 </span><span class="font50">♦ </span><span class="font5">Output port processing</span></p>
<p><span class="font53">Suppose that the input and output line speeds (transmission rates) all have an identical transmission rate of </span><span class="font53" style="font-style:italic;">A</span><span class="font53"><sub>line</sub> packets per second, and that there are </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> input ports and </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> output ports. To further simplify the discussion, let’s assume that all packets have the same fixed length, and that packets arrive to input ports in a synchronous manner. That is, the time to send a packet on any link is equal to the time to receive a packet on any link, and during such an interval of time, either zero or one packets can arrive on an input link. Define the switching fabric transfer rate </span><span class="font53" style="font-style:italic;">A</span><span class="font53"><sub>switch</sub> as the rate at which packets can be moved from input port to output port. If </span><span class="font53" style="font-style:italic;">A</span><span class="font53"><sub>switch</sub> is </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> times faster than </span><span class="font53" style="font-style:italic;">^<sub>u</sub> </span><span class="font53">then only negligible queuing will occur at the input ports. This is because even in the worst case, where all </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> input lines are receiving packets, and all packets are to be forwarded to the same output port, each batch of </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> packets (one packet per input port) can be cleared through the switch fabric before the next batch arrives.</span></p>
<p><span class="font22" style="font-weight:bold;">Input Queuing</span></p>
<p><span class="font53">But what happens if the switch fabric is not fast enough (relative to the input line speeds) to transfer </span><span class="font53" style="font-style:italic;">all</span><span class="font53"> arriving packets through the fabric without delay? In this case, packet queuing can also occur at the input ports, as packets must join input port queues to wait their turn to be transferred through the switching fabric to the output port. To illustrate an important consequence of this queuing, consider a crossbar switching fabric and suppose that (1) all link speeds are identical, (2) that one packet can be transferred from any one input port to a given output port in the same amount of time it takes for a packet to be received on an input link, and (3) packets are moved from a given input queue to their desired output queue in an FCFS manner. Multiple packets can be transferred in parallel, as long as their output ports are different. However, if two packets at the front of two input queues are destined for the same output queue, then one of the packets will be blocked and must wait at the input queue—the switching fabric can transfer only one packet to a given output port at a time.</span></p>
<p><span class="font53">Figure 4.8 shows an example in which two packets (darkly shaded) at the front of their input queues are destined for the same upper-right output port. Suppose that the switch fabric chooses to transfer the packet from the front of the upper-left queue. In this case, the darkly shaded packet in the lower-left queue must wait. But not only must this darkly shaded packet wait, so too must the lightly shaded packet that is queued behind that packet in the lower-left queue, even though there is </span><span class="font53" style="font-style:italic;">no</span><span class="font53"> contention for the middle-right output port (the destination for the lightly shaded packet). This phenomenon is known as </span><span class="font53" style="font-weight:bold;">head-of-the-line (HOL) blocking </span><span class="font53">in an input-queued switch—a queued packet in an input queue must wait for transfer through the fabric (even though its output port is free) because it is blocked by another packet at the head of the line. [Karol 1987] shows that due to HOL blocking, the input queue will grow to unbounded length (informally, this is equivalent to saying that significant packet loss will occur) under certain assumptions as soon as the packet arrival rate on the input links reaches only 58 percent of their capacity. A number of solutions to HOL blocking are discussed in [McKeown 1997].</span></p>
<div>
<p><span class="font4">Output port contention at time </span><span class="font4" style="font-style:italic;">t— </span><span class="font4">one dark packet can be transferred</span></p><img src="networking_files/networking-281.jpg" alt="" style="width:292pt;height:95pt;">
</div><br clear="all">
<div>
<p><span class="font4">Light blue packet experiences HOL blocking</span></p><img src="networking_files/networking-282.jpg" alt="" style="width:292pt;height:25pt;">
<p><span class="font4">Switch fabric</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-283.jpg" alt="" style="width:100pt;height:25pt;">
</div><br clear="all">
<div><img src="networking_files/networking-284.jpg" alt="" style="width:115pt;height:25pt;">
</div><br clear="all">
<div><img src="networking_files/networking-285.jpg" alt="" style="width:37pt;height:25pt;">
<p><span class="font4">Key:</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-286.jpg" alt="" style="width:14pt;height:16pt;">
</div><br clear="all">
<div><img src="networking_files/networking-287.jpg" alt="" style="width:122pt;height:25pt;">
</div><br clear="all">
<p><span class="font41">destined for upper output destined for middle output destined for lower output</span></p>
<p><span class="font41">port &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;port &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;port</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 4.8 </span><span class="font50">♦ </span><span class="font5">HOL blocking at and input-queued switch</span></p>
<p><span class="font22" style="font-weight:bold;">Output Queuing</span></p>
<p><span class="font53">Let’s next consider whether queuing can occur at a switch’s output ports. Suppose that </span><span class="font53" style="font-style:italic;">■^</span><span class="font50">switch </span><span class="font53">is again </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> times faster than </span><span class="font53" style="font-style:italic;">A</span><span class="font53"><sub>line</sub> and that packets arriving at each of the </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> input ports are destined to the same output port. In this case, in the time it takes to send a single packet onto the outgoing link, </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> new packets will arrive at this output port (one from each of the </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> input ports). Since the output port can transmit only a single packet in a unit of time (the packet transmission time), the </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> arriving packets will have to queue (wait) for transmission over the outgoing link. Then </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> more packets can possibly arrive in the time it takes to transmit just one of the </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> packets that had just previously been queued. And so on. Thus, packet queues can form at the output ports even when the switching fabric is </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> times faster than the port line speeds. Eventually, the number of queued packets can grow large enough to exhaust available memory at the output port.</span></p>
<p><span class="font4">Output port contention at time </span><span class="font4" style="font-style:italic;">t</span></p>
<div><img src="networking_files/networking-288.jpg" alt="" style="width:100pt;height:23pt;">
</div><br clear="all">
<div><img src="networking_files/networking-289.jpg" alt="" style="width:37pt;height:25pt;">
</div><br clear="all">
<div><img src="networking_files/networking-290.jpg" alt="" style="width:22pt;height:18pt;">
</div><br clear="all">
<div><img src="networking_files/networking-291.jpg" alt="" style="width:100pt;height:24pt;">
</div><br clear="all">
<div><img src="networking_files/networking-292.jpg" alt="" style="width:47pt;height:96pt;">
</div><br clear="all">
<div><img src="networking_files/networking-293.jpg" alt="" style="width:42pt;height:25pt;">
</div><br clear="all">
<div><img src="networking_files/networking-294.jpg" alt="" style="width:42pt;height:25pt;">
</div><br clear="all">
<div><img src="networking_files/networking-295.jpg" alt="" style="width:42pt;height:25pt;">
</div><br clear="all">
<div>
<p><span class="font4">One packet time later</span></p><img src="networking_files/networking-296.jpg" alt="" style="width:292pt;height:95pt;">
<p><span class="font7" style="font-weight:bold;">Figure 4.9 </span><span class="font50">♦ </span><span class="font5">Output port queuing</span></p>
</div><br clear="all">
<p><span class="font53">When there is not enough memory to buffer an incoming packet, a decision must be made to either drop the arriving packet (a policy known as </span><span class="font53" style="font-weight:bold;">drop-tail</span><span class="font53">) or remove one or more already-queued packets to make room for the newly arrived packet. In some cases, it may be advantageous to drop (or mark the header of) a packet </span><span class="font53" style="font-style:italic;">before </span><span class="font53">the buffer is full in order to provide a congestion signal to the sender. This marking could be done using the Explicit Congestion Notification bits that we studied in Section 3.7.2. A number of proactive packet-dropping and -marking policies (which collectively have become known as </span><span class="font53" style="font-weight:bold;">active queue management (AQM) </span><span class="font53">algorithms) have been proposed and analyzed [Labrador 1999, Hollot 2002]. One of the most widely studied and implemented AQM algorithms is the </span><span class="font53" style="font-weight:bold;">Random Early Detection (RED) </span><span class="font53">algorithm [Christiansen 2001]. More recent AQM policies include PIE (the Proportional Integral controller Enhanced [RFC 8033]), and CoDel [Nichols 2012].</span></p>
<p><span class="font53">Output port queuing is illustrated in Figure 4.9. At time </span><span class="font53" style="font-style:italic;">t,</span><span class="font53"> a packet has arrived at each of the incoming input ports, each destined for the uppermost outgoing port. Assuming identical line speeds and a switch operating at three times the line speed, one time unit later (that is, in the time needed to receive or send a packet), all three original packets have been transferred to the outgoing port and are queued awaiting transmission. In the next time unit, one of these three packets will have been transmitted over the outgoing link. In our example, two </span><span class="font53" style="font-style:italic;">new</span><span class="font53"> packets have arrived at the incoming side of the switch; one of these packets is destined for this uppermost output port. A consequence of such queuing is that a </span><span class="font53" style="font-weight:bold;">packet scheduler </span><span class="font53">at the output port must choose one packet, among those queued, for transmission—a topic we’ll cover in the following section.</span></p>
<p><span class="font22" style="font-weight:bold;">How Much Buffering Is “Enough?”</span></p>
<p><span class="font53">Our study above has shown how a packet queue forms when bursts of packets arrive at a router’s input or (more likely) output port, and the packet arrival rate temporarily exceeds the rate at which packets can be forwarded. The longer the amount of time that this mismatch persists, the longer the queue will grow, until eventually a port’s buffers become full and packets are dropped. One natural question is how </span><span class="font53" style="font-style:italic;">much </span><span class="font53">buffering should be provisioned at a port. It turns out the answer to this question is much more complicated than one might imagine and can teach us quite a bit about the subtle interaction among congestion-aware senders at the network’s edge and the network core!</span></p>
<p><span class="font53">For many years, the rule of thumb [RFC 3439] for buffer sizing was that the amount of buffering </span><span class="font53" style="font-weight:bold;">(B) </span><span class="font53">should be equal to an average round-trip time (</span><span class="font53" style="font-weight:bold;">RTT</span><span class="font53">, say 250 msec) times the link capacity </span><span class="font53" style="font-weight:bold;">(C)</span><span class="font53">. Thus, a 10-Gbps link with an RTT of 250 msec would need an amount of buffering equal to </span><span class="font53" style="font-weight:bold;">B </span><span class="font54">= </span><span class="font53" style="font-weight:bold;">RTT </span><span class="font60">• </span><span class="font53" style="font-weight:bold;">C </span><span class="font54">= </span><span class="font53">2.5 Gbits of buffers. This result was based on an analysis of the queuing dynamics of a relatively small number of TCP flows [Villamizar 1994]. More recent theoretical and experimental efforts [Appenzeller 2004], however, suggest that when a large number of </span><span class="font53" style="font-style:italic;">independent</span><span class="font53"> TCP flows (</span><span class="font53" style="font-weight:bold;">N</span><span class="font53">) pass through a link, the amount of buffering needed is </span><span class="font53" style="font-weight:bold;">B </span><span class="font54">= </span><span class="font53" style="font-weight:bold;">RTT </span><span class="font60">• </span><span class="font53" style="font-weight:bold;">C</span><span class="font53">/ </span><span class="font58">2</span><span class="font53" style="font-weight:bold;">N</span><span class="font53">. In core networks, where a large number of TCP flows typically pass through large backbone router links, the value of </span><span class="font53" style="font-weight:bold;">N </span><span class="font53">can be large, with the decrease in needed buffer size becoming quite significant. [Appenzeller 2004; Wischik 2005; Beheshti 2008] provide very readable discussions of the buffer-sizing problem from a theoretical, implementation, and operational standpoint.</span></p>
<p><span class="font53">It’s temping to think that more buffering </span><span class="font53" style="font-style:italic;">must</span><span class="font53"> be better—larger buffers would allow a router to absorb larger fluctuations in the packet arrival rate, thereby decreasing the router’s packet loss rate. But larger buffers also mean potentially longer queuing delays. For gamers and for interactive teleconferencing users, tens of milliseconds count. Increasing the amount of per-hop buffer by a factor of 10 to decrease packet loss could increase the end-end delay by a factor of 10! Increased RTTs also make TCP senders less responsive and slower to respond to incipient congestion and/ or packet loss. These delay-based considerations show that buffering is a doubleedged sword—buffering can be used to absorb short-term statistical fluctuations in traffic but can also lead to increased delay and the attendant concerns. Buffering is a bit like salt—just the right amount of salt makes food better, but too much makes it inedible!</span></p>
<p><span class="font53">In the discussion above, we’ve implicitly assumed that many independent senders are competing for bandwidth and buffers at a congested link. While this is probably an excellent assumption for routers within the network core, at the network edge</span></p>
<div><img src="networking_files/networking-297.jpg" alt="" style="width:72pt;height:61pt;">
</div><br clear="all">
<div><img src="networking_files/networking-298.jpg" alt="" style="width:94pt;height:48pt;">
</div><br clear="all">
<div><img src="networking_files/networking-299.jpg" alt="" style="width:69pt;height:30pt;">
</div><br clear="all">
<div><img src="networking_files/networking-300.jpg" alt="" style="width:172pt;height:133pt;">
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 4.10 </span><span class="font50">♦ </span><span class="font5">Bufferbloat: persistent queues</span></p>
<p><span class="font53">this may not hold. Figure 4.10(a) shows a home router sending TCP segments to a remote game server. Following [Nichols 2012], suppose that it takes 20 ms to transmit a packet (containing a gamer’s TCP segment), that there are negligible queuing delays elsewhere on the path to the game server, and that the RTT is 200 ms. As shown in Figure 4.10(b), suppose that at time </span><span class="font53" style="font-style:italic;">t =</span><span class="font53"> 0, a burst of 25 packets arrives to the queue. One of these queued packets is then transmitted once every 20 ms, so that at </span><span class="font53" style="font-style:italic;">t</span><span class="font54"> = </span><span class="font53">200 msec, the first ACK arrives, just as the 21st packet is being transmitted. This ACK arrival causes the TCP sender to send another packet, which is queued at the outgoing link of the home router. At </span><span class="font53" style="font-style:italic;">t</span><span class="font54"> = </span><span class="font53">220, the next ACK arrives, and another TCP segment is released by the gamer and is queued, as the 22nd packet is being transmitted, and so on. You should convince yourself that in this scenario, ACK clocking results in a new packet arriving at the queue every time a queued packet is sent, resulting in queue size at the home router’s outgoing link that is </span><span class="font53" style="font-style:italic;">always</span><span class="font53"> five packets! That is, the end-end-pipe is full (delivering packets to the destination at the path bottleneck rate of one packet every 20 ms), but the amount of queuing delay is constant and </span><span class="font53" style="font-style:italic;">persistent.</span><span class="font53"> As a result, the gamer is unhappy with the delay, and the parent (who even knows wireshark!) is confused because he or she doesn’t understand why delays are persistent and excessively long, even when there is no other traffic on the home network.</span></p>
<p><span class="font53">This scenario above of long delay due to persistent buffering is known as </span><span class="font53" style="font-weight:bold;">bufferbloat </span><span class="font53">and illustrates that not only is throughput important, but also minimal delay is important as well [Kleinrock 2018], and that the interaction among senders at the network edge and queues within the network can indeed be complex and subtle. The DOCSIS 3.1 standard for cable networks that we will study in Chapter 6, recently added a specific AQM mechanism [RFC 8033, RFC 8034] to combat bufferbloat, while preserving bulk throughput performance.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">4.2.5 </span><span class="font23" style="font-weight:bold;">Packet Scheduling</span></p></li></ul>
<p><span class="font53">Let’s now return to the question of determining the order in which queued packets are transmitted over an outgoing link. Since you yourself have undoubtedly had to wait in long lines on many occasions and observed how waiting customers are served, you’re no doubt familiar with many of the queuing disciplines commonly used in routers. There is first-come-first-served (FCFS, also known as first-in-first-out, FIFO). The British are famous for patient and orderly FCFS queuing at bus stops and in the marketplace (“Oh, are you queuing?”). Other countries operate on a priority basis, with one class of waiting customers given priority service over other waiting customers. There is also round-robin queuing, where customers are again divided into classes (as in priority queuing) but each class of customer is given service in turn.</span></p>
<p><span class="font22" style="font-weight:bold;">First-in-First-Out (FIFO)</span></p>
<p><span class="font53">Figure 4.11 shows the queuing model abstraction for the FIFO link-scheduling discipline. Packets arriving at the link output queue wait for transmission if the link is currently busy transmitting another packet. If there is not sufficient buffering space to hold the arriving packet, the queue’s packet-discarding policy then determines whether the packet will be dropped (lost) or whether other packets will be removed from the queue to make space for the arriving packet, as discussed above. In our discussion below, we’ll ignore packet discard. When a packet is completely transmitted over the outgoing link (that is, receives service) it is removed from the queue.</span></p>
<p><span class="font53">The FIFO (also known as first-come-first-served, or FCFS) scheduling discipline selects packets for link transmission in the same order in which they arrived at the output link queue. We’re all familiar with FIFO queuing from service centers, where arriving customers join the back of the single waiting line, remain in order, and are then served when they reach the front of the line. Figure 4.12 shows the FIFO queue in operation. Packet arrivals are indicated by numbered arrows above the upper timeline, with the number indicating the order in which the packet arrived. Individual packet departures are shown below the lower timeline. The time that a packet spends in service (being transmitted) is indicated by the shaded rectangle between the two timelines. In</span></p><img src="networking_files/networking-301.jpg" alt="" style="width:242pt;height:85pt;">
<p><a name="bookmark338"></a><span class="font7" style="font-weight:bold;">Figure 4.11 </span><span class="font50">♦ </span><span class="font5">FIFO queuing abstraction</span></p>
<p><span class="font4">1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2 &nbsp;&nbsp;&nbsp;&nbsp;3 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5</span></p>
<p><span class="font4">Arrivals</span></p>
<p><span class="font4">T----</span><span class="font6" style="text-decoration:line-through;">1*1*</span><span class="font4">1-----1-----1-----1-----’—I-----1-----1-----1-----1----*----1-----1-----I—► Time</span></p>
<p><span class="font4">Packet in service I</span></p>
<p><span class="font4">I-------------1-------------1-------------1-------------1-------------1-------------1-------------1-------------1-------------1-------------1-------------1-------------1-------------1-------------1-------------1-------------I—► Time</span></p>
<p><span class="font4" style="font-style:italic;">t</span><span class="font4"> = 0 </span><span class="font4" style="font-style:italic;">t</span><span class="font4"> = 2 </span><span class="font4" style="font-style:italic;">t</span><span class="font4"> = 4 </span><span class="font4" style="font-style:italic;">t</span><span class="font4"> = 6 </span><span class="font4" style="font-style:italic;">t</span><span class="font4"> = 8 </span><span class="font4" style="font-style:italic;">t</span><span class="font4"> = 10 </span><span class="font4" style="font-style:italic;">t</span><span class="font4"> = 12 </span><span class="font4" style="font-style:italic;">t</span><span class="font4"> = 14</span></p>
<p><span class="font4">Departures</span></p>
<p><span class="font4">| 1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| 2 | &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| 3^ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;f 5</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 4.12 </span><span class="font50">♦ </span><span class="font5">The FIFO queue in operation</span></p>
<p><span class="font53">our examples here, let’s assume that each packet takes three units of time to be transmitted. Under the FIFO discipline, packets leave in the same order in which they arrived. Note that after the departure of packet 4, the link remains idle (since packets 1 through 4 have been transmitted and removed from the queue) until the arrival of packet 5.</span></p>
<p><span class="font22" style="font-weight:bold;">Priority Queuing</span></p>
<p><span class="font53">Under priority queuing, packets arriving at the output link are classified into priority classes upon arrival at the queue, as shown in Figure 4.13. In practice, a network operator may configure a queue so that packets carrying network management information (for example, as indicated by the source or destination TCP/UDP port number) receive priority over user traffic; additionally, real-time voice-over-IP packets might receive priority over non-real-time traffic such e-mail packets. Each priority class typically has its own queue. When choosing a packet to transmit, the priority</span></p>
<p><span class="font4">High-priority queue</span></p><img src="networking_files/networking-302.jpg" alt="" style="width:301pt;height:107pt;">
<p><span class="font4">(waiting area)</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 4.13 </span><span class="font50">♦ </span><span class="font5">The priority queuing model</span></p>
<div>
<p><span class="font4">Arrivals</span></p><img src="networking_files/networking-303.jpg" alt="" style="width:18pt;height:39pt;">
</div><br clear="all">
<div><img src="networking_files/networking-304.jpg" alt="" style="width:32pt;height:26pt;">
</div><br clear="all">
<div><img src="networking_files/networking-305.jpg" alt="" style="width:26pt;height:42pt;">
</div><br clear="all">
<div><img src="networking_files/networking-306.jpg" alt="" style="width:18pt;height:39pt;">
</div><br clear="all">
<div>
<p><span class="font4">4—► Time</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Packet in service</span></p>
</div><br clear="all">
<div>
<p><span class="font4">3 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2 r</span><span class="font4" style="text-decoration:underline;"> </span><span class="font4">4</span></p>
</div><br clear="all">
<p><span class="font4">I--------------1--------------1--------------1--------------1--------------1--------------1--------------1--------------1--------------1--------------1--------------1--------------1--------------1--------------1--------------1--------------Time</span></p>
<p><span class="font4" style="font-style:italic;">t</span><span class="font4"> = 0 </span><span class="font4" style="font-style:italic;">t</span><span class="font4"> = 2 </span><span class="font4" style="font-style:italic;">t</span><span class="font4"> = 4 </span><span class="font4" style="font-style:italic;">t</span><span class="font4"> = 6 </span><span class="font4" style="font-style:italic;">t</span><span class="font4"> = 8 </span><span class="font4" style="font-style:italic;">t</span><span class="font4"> = 10 </span><span class="font4" style="font-style:italic;">t</span><span class="font4"> = 12 </span><span class="font4" style="font-style:italic;">t</span><span class="font4"> = 14</span></p>
<p><span class="font4">Departures</span></p>
<p><span class="font4">1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 4.14 </span><span class="font50">♦ </span><span class="font5">The priority queue in operation</span></p>
<p><span class="font53">queuing discipline will transmit a packet from the highest priority class that has a nonempty queue (that is, has packets waiting for transmission). The choice among packets in the same priority class is typically done in a FIFO manner.</span></p>
<p><span class="font53">Figure 4.14 illustrates the operation of a priority queue with two priority classes. Packets 1, 3, and 4 belong to the high-priority class, and packets 2 and 5 belong to the low-priority class. Packet 1 arrives and, finding the link idle, begins transmission. During the transmission of packet 1, packets 2 and 3 arrive and are queued in the low-and high-priority queues, respectively. After the transmission of packet 1, packet 3 (a high-priority packet) is selected for transmission over packet 2 (which, even though it arrived earlier, is a low-priority packet). At the end of the transmission of packet 3, packet 2 then begins transmission. Packet 4 (a high-priority packet) arrives during the transmission of packet 2 (a low-priority packet). Under a </span><span class="font53" style="font-weight:bold;">non-preemptive priority queuing </span><span class="font53">discipline, the transmission of a packet is not interrupted once it</span></p>
<div><img src="networking_files/networking-307.jpg" alt="" style="width:131pt;height:21pt;">
<p><span class="font4" style="font-weight:bold;">NET NEUTRALITY</span></p>
</div><br clear="all">
<div>
<p><span class="font23" style="font-weight:bold;">PRINCIPLES IN PRACTICE</span></p>
</div><br clear="all">
<p><span class="font4">We’ve seen that packet scheduling mechanisms (e.g., priority traffic scheduling disciplines such a strict priority, and WFQ) can be used to provide different levels of service to different “classes” of traffic. The definition of what precisely constitutes a “class” of traffic is up to an ISP to decide, but could be potentially based on any set of fields in the IP datagram header. For example, the port field in the IP datagram header could be used to classify datagrams according to the “well-know service” associated with that port: SNMP network management datagram (port 161) might be assigned to a higher priority class than an IMAP e-mail protocol (ports 143, or 993) datagram and therefore receive better service. An ISP could also potentially use a datagram’s source IP address to provide priority to datagrams being sent by certain companies (who have presumably paid the ISP for this privilege) over datagrams being sent from other companies (who have not paid); an ISP could even block traffic with a source IP address in a given company, or country. There are many </span><span class="font4" style="font-style:italic;">mechanisms</span><span class="font4"> that would allow an ISP to provide different levels of service to different classes of traffic. The real question is what </span><span class="font4" style="font-style:italic;">policies</span><span class="font4"> and </span><span class="font4" style="font-style:italic;">laws</span><span class="font4"> determine what an ISP can actually do. Of course, these laws will vary by country; see [Smithsonian 2017] for a brief survey. Here, we'll briefly consider US policy on what has come to be known as “net neutrality.”</span></p>
<p><span class="font4">The term “net neutrality&quot; doesn't have a precise decision, but the March 2015 </span><span class="font4" style="font-style:italic;">Order on Protecting and Promoting an Open Internet</span><span class="font4"> [FCC 2015] by the US Federal Communications Commission provides three “clear, bright line&quot; rules that are now often associated with net neutrality:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font4">“</span><span class="font5" style="font-weight:bold;">No Blocking. </span><span class="font4">. . . A person engaged in the provision of broadband Internet access service, . . . shall not block lawful content, applications, services, or non-harmful devices, subject to reasonable network management.&quot;</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font4">“</span><span class="font5" style="font-weight:bold;">No Throttling. </span><span class="font4">. . . A person engaged in the provision of broadband Internet access service, . . . shall not impair or degrade lawful Internet traffic on the basis of Internet content, application, or service, or use of a non-harmful device, subject to reasonable network management.&quot;</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font4">“</span><span class="font5" style="font-weight:bold;">No Paid Prioritization. </span><span class="font4">. . . A person engaged in the provision of broadband Internet access service, . . . shall not engage in paid prioritization. “Paid prioritization&quot; refers to the management of a broadband provider's network to directly or indirectly favor some traffic over other traffic, including through use of techniques such as traffic shaping, prioritization, resource reservation, or other forms of preferential traffic management, . . .&quot;</span></p></li></ul>
<p><span class="font4">Quite interestingly, before the Order, ISP behaviors violating the first two of these rules had been observed [Faulhaber 2012]. In 2005, an ISP in North Carolina agreed to stop its practice of blocking its customers from using Vonage, a voice-over-IP service that competed with its own telephone service. In 2007, Comcast was judged to be interfering with BitTorrent P2P traffic by internally creating and sending TCP RST packets to BitTorrent senders and receivers, which caused them to close their BitTorrent connection [FCC 2008].</span></p>
<p><span class="font4">Both sides of the net neutrality debate have been argued strenuously, mostly focused on the extent to which net neutrality provides benefits to customers, while at the same time promoting innovation. See [Peha 2006, Faulhaber 2012, Economides 2017, Madhyastha 2017].</span></p>
<p><span class="font4">The 2015 FCC </span><span class="font4" style="font-style:italic;">Order on Protecting and Promoting an Open Internet,</span><span class="font4"> which banned ISPs from blocking, throttling, or providing paid prioritizing, was superseded by the 2017 FCC </span><span class="font4" style="font-style:italic;">Restoring Internet Freedom Order,</span><span class="font4"> [FCC 2017] which rolled back these prohibitions and focused instead on ISP transparency. With so much interest and so many changes, it's probably safe to say we aren't close to having seen the final chapter written on net neutrality in the United States, or elsewhere.</span></p>
<p><span class="font53">has begun. In this case, packet 4 queues for transmission and begins being transmitted after the transmission of packet 2 is completed.</span></p>
<p><span class="font22" style="font-weight:bold;">Round Robin and Weighted Fair Queuing (WFQ)</span></p>
<p><span class="font53">Under the round robin queuing discipline, packets are sorted into classes as with priority queuing. However, rather than there being a strict service priority among classes, a round robin scheduler alternates service among the classes. In the simplest form of round robin scheduling, a class 1 packet is transmitted, followed by a class 2 packet, followed by a class 1 packet, followed by a class 2 packet, and so on. A so-called </span><span class="font53" style="font-weight:bold;">work-conserving queuing </span><span class="font53">discipline will never allow the link to remain idle whenever there are packets (of any class) queued for transmission. A workconserving round robin discipline that looks for a packet of a given class but finds none will immediately check the next class in the round robin sequence.</span></p>
<p><span class="font53">Figure 4.15 illustrates the operation of a two-class round robin queue. In this example, packets 1, 2, and 4 belong to class 1, and packets 3 and 5 belong to the second class. Packet 1 begins transmission immediately upon arrival at the output queue. Packets 2 and 3 arrive during the transmission of packet 1 and thus queue for transmission. After the transmission of packet 1, the link scheduler looks for a class 2 packet and thus transmits packet 3. After the transmission of packet 3, the scheduler looks for a class 1 packet and thus transmits packet 2. After the transmission of packet 2, packet 4 is the only queued packet; it is thus transmitted immediately after packet 2.</span></p>
<p><span class="font53">A generalized form of round robin queuing that has been widely implemented in routers is the so-called </span><span class="font53" style="font-weight:bold;">weighted fair queuing (WFQ) discipline </span><span class="font53">[Demers 1990; Parekh 1993. WFQ is illustrated in Figure 4.16. Here, arriving packets are classified and queued in the appropriate per-class waiting area. As in round robin scheduling, a WFQ scheduler will serve classes in a circular manner—first serving class 1, then serving class 2, then serving class 3, and then (assuming there are three classes) repeating the service pattern. WFQ is also a work-conserving queuing discipline and</span></p>
<div>
<p><span class="font4">1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2 &nbsp;&nbsp;&nbsp;&nbsp;3</span></p>
<p><span class="font4">Arrivals ___</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-308.jpg" alt="" style="width:26pt;height:42pt;">
</div><br clear="all">
<div>
<p><span class="font4">5</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Packet in service</span></p>
</div><br clear="all">
<div>
<p><span class="font4">1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3 I&quot;</span><span class="font4" style="text-decoration:underline;"> </span><span class="font4">2</span><span class="font4" style="text-decoration:underline;"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font4">4</span></p>
</div><br clear="all">
<div>
<p><span class="font43" style="font-weight:bold;">£----1-----</span><span class="font4">1-----1—► Time</span></p><img src="networking_files/networking-309.jpg" alt="" style="width:62pt;height:14pt;">
</div><br clear="all">
<p><span class="font4">I-------------1-------------1-------------1-------------1-------------1-------------1-------------1-------------1-------------1-------------1-------------1-------------1-------------1-------------1-------------1-------------I—► Time</span></p>
<p><span class="font4" style="font-style:italic;">t</span><span class="font4"> = 0 </span><span class="font4" style="font-style:italic;">t</span><span class="font4"> = 2 </span><span class="font4" style="font-style:italic;">t</span><span class="font4"> = 4 </span><span class="font4" style="font-style:italic;">t</span><span class="font4"> = 6 </span><span class="font4" style="font-style:italic;">t</span><span class="font4"> = 8 </span><span class="font4" style="font-style:italic;">t</span><span class="font4"> = 10 </span><span class="font4" style="font-style:italic;">t</span><span class="font4"> = 12 </span><span class="font4" style="font-style:italic;">t</span><span class="font4"> = 14</span></p>
<p><span class="font4">Departures</span></p>
<p><span class="font4">1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;J 3 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| 2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 4.15 </span><span class="font50">♦ </span><span class="font5">The two-class robin queue in operation</span></p>
<p><span class="font4">Classify</span></p>
<p><span class="font4">Arrivals</span></p><img src="networking_files/networking-310.jpg" alt="" style="width:237pt;height:131pt;">
<p><span class="font4">Departures</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 4.16 </span><span class="font50">♦ </span><span class="font5">Weighted fair queuing</span></p>
<p><span class="font53">thus will immediately move on to the next class in the service sequence when it finds an empty class queue.</span></p>
<p><span class="font53">WFQ differs from round robin in that each class may receive a differential amount of service in any interval of time. Specifically, each class, </span><span class="font53" style="font-style:italic;">i,</span><span class="font53"> is assigned a weight, </span><span class="font53" style="font-style:italic;">w. </span><span class="font53">Under WFQ, during any interval of time during which there are class </span><span class="font53" style="font-style:italic;">i</span><span class="font53"> packets to send, class </span><span class="font53" style="font-style:italic;">i</span><span class="font53"> will then be guaranteed to receive a fraction of service equal to </span><span class="font53" style="font-style:italic;">w<sub>{</sub></span><span class="font53">/ (G </span><span class="font53" style="font-style:italic;">W</span><span class="font50" style="font-style:italic;">j</span><span class="font53" style="font-style:italic;">),</span><span class="font53"> where the sum in the denominator is taken over all classes that also have packets queued for transmission. In the worst case, even if all classes have queued packets, class </span><span class="font53" style="font-style:italic;">i</span><span class="font53"> will still be guaranteed to receive a fraction </span><span class="font53" style="font-style:italic;">w<sub>{</sub> </span><span class="font9" style="font-style:italic;">/</span><span class="font53"> (G </span><span class="font53" style="font-style:italic;">w</span><span class="font50" style="font-style:italic;">j</span><span class="font53" style="font-style:italic;">)</span><span class="font53"> of the bandwidth, where in this worst case the sum in the denominator is over </span><span class="font53" style="font-style:italic;">all</span><span class="font53"> classes. Thus, for a link with transmission rate </span><span class="font53" style="font-style:italic;">R,</span><span class="font53"> class </span><span class="font53" style="font-style:italic;">i</span><span class="font53"> will always achieve a throughput of at least </span><span class="font53" style="font-style:italic;">R </span><span class="font60" style="font-style:italic;">• </span><span class="font53" style="font-style:italic;">w<sub>i</sub> </span><span class="font9" style="font-style:italic;">/</span><span class="font53">(G </span><span class="font53" style="font-style:italic;">W</span><span class="font50" style="font-style:italic;">j</span><span class="font53">). Our description of WFQ has been idealized, as we have not considered the fact that packets are discrete and a packet’s transmission will not be interrupted to begin transmission of another packet; [Demers 1990; Parekh 1993] discuss this packetization issue.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">4.3 </span><span class="font24" style="font-weight:bold;">The Internet Protocol (IP): IPv4, Addressing, IPv6, and More</span></p></li></ul>
<p><span class="font53">Our study of the network layer thus far in Chapter 4—the notion of the data and control plane component of the network layer, our distinction between forwarding and routing, the identification of various network service models, and our look inside a router—have often been without reference to any specific computer network architecture or protocol. In this section, we’ll focus on key aspects of the network layer on today’s Internet and the celebrated Internet Protocol (IP).</span></p>
<p><a name="bookmark339"></a><span class="font53">There are two versions of IP in use today. We’ll first examine the widely deployed IP protocol version 4, which is usually referred to simply as IPv4 [RFC 791] in Section 4.3.1. We’ll examine IP version 6 [RFC 2460; RFC 4291], which has been proposed to replace IPv4, in Section 4.3.4. In between, we’ll primarily cover Internet addressing—a topic that might seem rather dry and detail-oriented but we’ll see is crucial to understanding how the Internet’s network layer works. To master IP addressing is to master the Internet’s network layer itself!</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">4.3.1 </span><span class="font23" style="font-weight:bold;">IPv4 Datagram Format</span></p></li></ul>
<p><span class="font53">Recall that the Internet’s network-layer packet is referred to as a </span><span class="font53" style="font-style:italic;">datagram.</span><span class="font53"> We begin our study of IP with an overview of the syntax and semantics of the IPv4 datagram. You might be thinking that nothing could be drier than the syntax and semantics of a packet’s bits. Nevertheless, the datagram plays a central role in the Internet—every networking student and professional needs to see it, absorb it, and master it. (And just to see that protocol headers can indeed be fun to study, check out [Pomeranz 2010]). The IPv4 datagram format is shown in Figure 4.17. The key fields in the IPv4 datagram are the following:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Version number.</span><span class="font53"> These 4 bits specify the IP protocol version of the datagram. By looking at the version number, the router can determine how to interpret the remainder of the IP datagram. Different versions of IP use different datagram formats. The datagram format for IPv4 is shown in Figure 4.17. The datagram format for the new version of IP (IPv6) is discussed in Section 4.3.4.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Header length.</span><span class="font53"> Because an IPv4 datagram can contain a variable number of options (which are included in the IPv4 datagram header), these 4 bits are needed</span></p></li></ul>
<p><span class="font4">32 bits</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font4">Header</span></p>
<p><span class="font4">Version length</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Type of service</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Datagram length (bytes)</span></p></td></tr>
<tr><td colspan="2" style="vertical-align:middle;">
<p><span class="font4">16-bit Identifier</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Flags 13-bit Fragmentation offset</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font4">Time-to-live</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Upper-layer protocol</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Header checksum</span></p></td></tr>
</table>
<p><span class="font4">32-bit Source IP address</span></p>
<p><span class="font4">32-bit Destination IP address</span></p>
<p><span class="font4">Options (if any)</span></p>
<p><span class="font4">Data</span></p>
<p><span class="font53">to determine where in the IP datagram the payload (for example, the transportlayer segment being encapsulated in this datagram) actually begins. Most IP datagrams do not contain options, so the typical IP datagram has a 20-byte header.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Type of service.</span><span class="font53"> The type of service (TOS) bits were included in the IPv4 header to allow different types of IP datagrams to be distinguished from each other. For example, it might be useful to distinguish real-time datagrams (such as those used by an IP telephony application) from non-real-time traffic (e.g., FTP). The specific level of service to be provided is a policy issue determined and configured by the network administrator for that router. We also learned in Section 3.7.2 that two of the TOS bits are used for Explicit Congestion Notification.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Datagram length.</span><span class="font53"> This is the total length of the IP datagram (header plus data), measured in bytes. Since this field is 16 bits long, the theoretical maximum size of the IP datagram is 65,535 bytes. However, datagrams are rarely larger than 1,500 bytes, which allows an IP datagram to fit in the payload field of a maximally sized Ethernet frame.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Identifier, flags, fragmentation offset.</span><span class="font53"> These three fields have to do with so-called IP fragmentation, when a large IP datagram is broken into several smaller IP datagrams which are then forwarded independently to the destination, where they are reassembled before their payload data (see below) is passed up to the transport layer at the destination host. Interestingly, the new version of IP, IPv6, does not allow for fragmentation. We’ll not cover fragmentation here; but readers can find a detailed discussion online, among the “retired” material from earlier versions of this book.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Time-to-live.</span><span class="font53"> The time-to-live (TTL) field is included to ensure that datagrams do not circulate forever (due to, for example, a long-lived routing loop) in the network. This field is decremented by one each time the datagram is processed by a router. If the TTL field reaches 0, a router must drop that datagram.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Protocol.</span><span class="font53"> This field is typically used only when an IP datagram reaches its final destination. The value of this field indicates the specific transport-layer protocol to which the data portion of this IP datagram should be passed. For example, a value of 6 indicates that the data portion is passed to TCP, while a value of 17 indicates that the data is passed to UDP. For a list of all possible values, see [IANA Protocol Numbers 2016]. Note that the protocol number in the IP datagram has a role that is analogous to the role of the port number field in the transport-layer segment. The protocol number is the glue that binds the network and transport layers together, whereas the port number is the glue that binds the transport and application layers together. We’ll see in Chapter 6 that the link-layer frame also has a special field that binds the link layer to the network layer.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Header checksum.</span><span class="font53"> The header checksum aids a router in detecting bit errors in a received IP datagram. The header checksum is computed by treating each 2 bytes in the header as a number and summing these numbers using 1s complement arithmetic. As discussed in Section 3.3, the 1s complement of this sum, known as the Internet checksum, is stored in the checksum field. A router computes the header checksum for each received IP datagram and detects an error condition if the checksum carried in the datagram header does not equal the computed checksum. Routers typically discard datagrams for which an error has been detected. Note that the checksum must be recomputed and stored again at each router, since the TTL field, and possibly the options field as well, will change. An interesting discussion of fast algorithms for computing the Internet checksum is [RFC 1071]. A question often asked at this point is, why does TCP/IP perform error checking at both the transport and network layers? There are several reasons for this repetition. First, note that only the IP header is checksummed at the IP layer, while the TCP/ UDP checksum is computed over the entire TCP/UDP segment. Second, TCP/ UDP and IP do not necessarily both have to belong to the same protocol stack. TCP can, in principle, run over a different network-layer protocol (for example, ATM) [Black 1995]) and IP can carry data that will not be passed to TCP/UDP.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Source and destination IP addresses.</span><span class="font53"> When a source creates a datagram, it inserts its IP address into the source IP address field and inserts the address of the ultimate destination into the destination IP address field. Often the source host determines the destination address via a DNS lookup, as discussed in Chapter 2. We’ll discuss IP addressing in detail in Section 4.3.2.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Options.</span><span class="font53"> The options fields allow an IP header to be extended. Header options were meant to be used rarely—hence the decision to save overhead by not including the information in options fields in every datagram header. However, the mere existence of options does complicate matters—since datagram headers can be of variable length, one cannot determine a priori where the data field will start. Also, since some datagrams may require options processing and others may not, the amount of time needed to process an IP datagram at a router can vary greatly. These considerations become particularly important for IP processing in high-performance routers and hosts. For these reasons and others, IP options were not included in the IPv6 header, as discussed in Section 4.3.4.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Data (payload).</span><span class="font53"> Finally, we come to the last and most important field—the </span><span class="font53" style="font-style:italic;">raison d’etre</span><span class="font53"> for the datagram in the first place! In most circumstances, the data field of the IP datagram contains the transport-layer segment (TCP or UDP) to be delivered to the destination. However, the data field can carry other types of data, such as ICMP messages (discussed in Section 5.6).</span></p></li></ul>
<p><span class="font53">Note that an IP datagram has a total of 20 bytes of header (assuming no options). If the datagram carries a TCP segment, then each datagram carries a total of 40 bytes of header (20 bytes of IP header plus 20 bytes of TCP header) along with the application-layer message.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">4.3.2 </span><span class="font23" style="font-weight:bold;">IPv4 Addressing</span></p></li></ul>
<p><a name="bookmark340"></a><span class="font53">We now turn our attention to IPv4 addressing. Although you may be thinking that addressing must be a straightforward topic, hopefully by the end of this section you’ll be convinced that Internet addressing is not only a juicy, subtle, and interesting topic but also one that is of central importance to the Internet. An excellent treatment of IPv4 addressing can be found in the first chapter in [Stewart 1999].</span></p>
<p><span class="font53">Before discussing IP addressing, however, we’ll need to say a few words about how hosts and routers are connected into the Internet. A host typically has only a single link into the network; when IP in the host wants to send a datagram, it does so over this link. The boundary between the host and the physical link is called an </span><span class="font53" style="font-weight:bold;">interface</span><span class="font53">. Now consider a router and its interfaces. Because a router’s job is to receive a datagram on one link and forward the datagram on some other link, a router necessarily has two or more links to which it is connected. The boundary between the router and any one of its links is also called an interface. A router thus has multiple interfaces, one for each of its links. Because every host and router is capable of sending and receiving IP datagrams, IP requires each host and router interface to have its own IP address. </span><span class="font53" style="font-style:italic;">Thus, an IP address is technically associated with an interface, rather than with the host or router containing that interface.</span></p>
<p><span class="font53">Each IP address is 32 bits long (equivalently, 4 bytes), and there are thus a total of 2<sup>32</sup> (or approximately 4 billion) possible IP addresses. These addresses are typically written in so-called </span><span class="font53" style="font-weight:bold;">dotted-decimal notation</span><span class="font53">, in which each byte of the address is written in its decimal form and is separated by a period (dot) from other bytes in the address. For example, consider the IP address 193.32.216.9. The 193 is the decimal equivalent of the first 8 bits of the address; the 32 is the decimal equivalent of the second 8 bits of the address, and so on. Thus, the address 193.32.216.9 in binary notation is</span></p>
<p><span class="font53">11000001 00100000 11011000 00001001</span></p>
<p><span class="font53">Each interface on every host and router in the global Internet must have an IP address that is globally unique (except for interfaces behind NATs, as discussed in Section 4.3.3). These addresses cannot be chosen in a willy-nilly manner, however. A portion of an interface’s IP address will be determined by the subnet to which it is connected.</span></p>
<p><span class="font53">Figure 4.18 provides an example of IP addressing and interfaces. In this figure, one router (with three interfaces) is used to interconnect seven hosts. Take a close look at the IP addresses assigned to the host and router interfaces, as there are several things to notice. The three hosts in the upper-left portion of Figure 4.18, and the router interface to which they are connected, all have an IP address of the form 223.1.1.xxx. That is, they all have the same leftmost 24 bits in their IP address. These four interfaces are also interconnected to each other by a network </span><span class="font53" style="font-style:italic;">that contains no routers.</span><span class="font53"> This network could be interconnected by an Ethernet LAN, in which case the interfaces would be interconnected by an Ethernet switch (as we’ll discuss in Chapter 6), or by a wireless access point (as we’ll discuss in Chapter 7). We’ll represent this routerless network connecting these hosts as a cloud for now, and dive into the internals of such networks in Chapters 6 and 7.</span></p>
<p><span class="font53">In IP terms, this network interconnecting three host interfaces and one router interface forms a </span><span class="font53" style="font-weight:bold;">subnet </span><span class="font53">[RFC 950]. (A subnet is also called an </span><span class="font53" style="font-style:italic;">IP network</span><span class="font53"> or simply</span></p>
<div><img src="networking_files/networking-311.jpg" alt="" style="width:66pt;height:50pt;">
<p><span class="font4">223.1.1.1</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-312.jpg" alt="" style="width:56pt;height:43pt;">
<p><span class="font4">223.1.1.2</span></p>
</div><br clear="all">
<div>
<p><span class="font4">223.1.1.4</span></p><img src="networking_files/networking-313.jpg" alt="" style="width:87pt;height:68pt;">
<p><span class="font4">^223.1.3.27</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-314.jpg" alt="" style="width:70pt;height:44pt;">
<p><span class="font4">223.1.2.1</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-315.jpg" alt="" style="width:65pt;height:43pt;">
<p><span class="font4">223.1.1.3</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-316.jpg" alt="" style="width:69pt;height:64pt;">
<p><span class="font4">223.1.2.2</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-317.jpg" alt="" style="width:42pt;height:35pt;">
<p><span class="font4">223.1.3.1</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-318.jpg" alt="" style="width:30pt;height:33pt;">
<p><span class="font4">223.1.3.2</span></p>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 4.18 </span><span class="font50">♦ </span><span class="font5">Interface addresses and subnets</span></p>
<p><span class="font53">a </span><span class="font53" style="font-style:italic;">network</span><span class="font53"> in the Internet literature.) IP addressing assigns an address to this subnet: 223.1.1.0/24, where the /24 (“slash-24”) notation, sometimes known as a </span><span class="font53" style="font-weight:bold;">subnet mask</span><span class="font53">, indicates that the leftmost 24 bits of the 32-bit quantity define the subnet address. The 223.1.1.0/24 subnet thus consists of the three host interfaces (223.1.1.1, 223.1.1.2, and 223.1.1.3) and one router interface (223.1.1.4). Any additional hosts attached to the 223.1.1.0/24 subnet would be </span><span class="font53" style="font-style:italic;">required</span><span class="font53"> to have an address of the form 223.1.1.xxx. There are two additional subnets shown in Figure 4.18: the 223.1.2.0/24 network and the 223.1.3.0/24 subnet. Figure 4.19 illustrates the three IP subnets present in Figure 4.18.</span></p>
<p><span class="font53">The IP definition of a subnet is not restricted to Ethernet segments that connect multiple hosts to a router interface. To get some insight here, consider Figure 4.20, which shows three routers that are interconnected with each other by point-to-point links. Each router has three interfaces, one for each point-to-point link and one for the broadcast link that directly connects the router to a pair of hosts. What subnets are present here? Three subnets, 223.1.1.0/24, 223.1.2.0/24, and 223.1.3.0/24, are similar to the subnets we encountered in Figure 4.18. But note that there are three additional subnets in this example as well: one subnet, 223.1.9.0/24, for the interfaces that connect routers R1 and R2; another subnet, 223.1.8.0/24, for the interfaces that connect routers R2 and R3; and a third subnet, 223.1.7.0/24, for the interfaces that connect routers R3 and R1. For a general interconnected system of routers and hosts, we can use the following recipe to define the subnets in the system:</span></p>
<div><img src="networking_files/networking-319.jpg" alt="" style="width:67pt;height:166pt;">
<p><span class="font7" style="font-weight:bold;">Figure 4.19 </span><span class="font50">♦ </span><span class="font5">Subnet addresses</span></p>
</div><br clear="all">
<div>
<p><span class="font4">223.1.1.0/24</span></p>
<p><span class="font4">223.1.2.0/24</span></p><img src="networking_files/networking-320.jpg" alt="" style="width:119pt;height:67pt;">
</div><br clear="all">
<div><img src="networking_files/networking-321.jpg" alt="" style="width:72pt;height:53pt;">
</div><br clear="all">
<div>
<p><span class="font4">223.1.3.0/24</span></p><img src="networking_files/networking-322.jpg" alt="" style="width:118pt;height:60pt;">
</div><br clear="all">
<div><img src="networking_files/networking-323.jpg" alt="" style="width:74pt;height:63pt;">
</div><br clear="all">
<p><span class="font53" style="font-style:italic;">To determine the subnets, detach each interface from its host or router, creating islands of isolated networks, with interfaces terminating the end points of the isolated networks. Each of these isolated networks is called a </span><span class="font53" style="font-weight:bold;font-style:italic;">subnet</span><span class="font53" style="font-style:italic;">.</span></p>
<p><span class="font53">If we apply this procedure to the interconnected system in Figure 4.20, we get six islands or subnets.</span></p>
<p><span class="font53">From the discussion above, it’s clear that an organization (such as a company or academic institution) with multiple Ethernet segments and point-to-point links will have multiple subnets, with all of the devices on a given subnet having the same subnet address. In principle, the different subnets could have quite different subnet addresses. In practice, however, their subnet addresses often have much in common. To understand why, let’s next turn our attention to how addressing is handled in the global Internet.</span></p>
<p><span class="font53">The Internet’s address assignment strategy is known as </span><span class="font53" style="font-weight:bold;">Classless Interdomain Routing (CIDR—</span><span class="font53">pronounced </span><span class="font53" style="font-style:italic;">cider)</span><span class="font53"> [RFC 4632]. CIDR generalizes the notion of subnet addressing. As with subnet addressing, the 32-bit IP address is divided into two parts and again has the dotted-decimal form </span><span class="font53" style="font-style:italic;">a.b.c.d/x,</span><span class="font53"> where </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> indicates the number of bits in the first part of the address.</span></p>
<p><span class="font53">The </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> most significant bits of an address of the form </span><span class="font53" style="font-style:italic;">a.b.c.d/x</span><span class="font53"> constitute the network portion of the IP address, and are often referred to as the </span><span class="font53" style="font-weight:bold;">prefix </span><span class="font53">(or </span><span class="font53" style="font-style:italic;">network prefix</span><span class="font53">) of the address. An organization is typically assigned a block of contiguous addresses, that is, a range of addresses with a common prefix (see the Principles in Practice feature). In this case, the IP addresses of devices within the organization will share the common prefix. When we cover the Internet’s BGP routing protocol in</span></p>
<div>
<p><span class="font4">223.1.1.1</span></p><img src="networking_files/networking-324.jpg" alt="" style="width:31pt;height:40pt;">
</div><br clear="all">
<div>
<p><span class="font4">223.1.1.4</span></p><img src="networking_files/networking-325.jpg" alt="" style="width:38pt;height:41pt;">
</div><br clear="all">
<div><img src="networking_files/networking-326.jpg" alt="" style="width:232pt;height:126pt;">
</div><br clear="all">
<div><img src="networking_files/networking-327.jpg" alt="" style="width:102pt;height:46pt;">
<p><span class="font4">223.1.2.1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;223.1.2.2</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 4.20 </span><span class="font50">♦ </span><span class="font5">Three routers interconnecting six subnets</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-328.jpg" alt="" style="width:103pt;height:46pt;">
<p><span class="font4">223.1.3.1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;223.1.3.2</span></p>
</div><br clear="all">
<p><span class="font53">Section 5.4, we’ll see that only these </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> leading prefix bits are considered by routers outside the organization’s network. That is, when a router outside the organization forwards a datagram whose destination address is inside the organization, only the leading </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> bits of the address need be considered. This considerably reduces the size of the forwarding table in these routers, since a </span><span class="font53" style="font-style:italic;">single</span><span class="font53"> entry of the form </span><span class="font53" style="font-style:italic;">a.b.c.d/x</span><span class="font53"> will be sufficient to forward packets to </span><span class="font53" style="font-style:italic;">any</span><span class="font53"> destination within the organization.</span></p>
<p><span class="font53">The remaining 32-</span><span class="font53" style="font-style:italic;">x</span><span class="font53"> bits of an address can be thought of as distinguishing among the devices </span><span class="font53" style="font-style:italic;">within</span><span class="font53"> the organization, all of which have the same network prefix. These are the bits that will be considered when forwarding packets at routers </span><span class="font53" style="font-style:italic;">within</span><span class="font53"> the organization. These lower-order bits may (or may not) have an additional subnetting structure, such as that discussed above. For example, suppose the first 21 bits of the CIDRized address a.b.c.d/21 specify the organization’s network prefix and are common to the IP addresses of all devices in that organization. The remaining 11 bits then identify the specific hosts in the organization. The organization’s internal structure might be such that these 11 rightmost bits are used for subnetting within the organization, as discussed above. For example, a.b.c.d/24 might refer to a specific subnet within the organization.</span></p>
<p><span class="font53">Before CIDR was adopted, the network portions of an IP address were constrained to be 8, 16, or 24 bits in length, an addressing scheme known as </span><span class="font53" style="font-weight:bold;">classful addressing</span><span class="font53">,</span></p>
<p><span class="font53">since subnets with 8-, 16-, and 24-bit subnet addresses were known as class A, B, and C networks, respectively. The requirement that the subnet portion of an IP address be exactly 1, 2, or 3 bytes long turned out to be problematic for supporting the rapidly growing number of organizations with small and medium-sized subnets. A class C (/24) subnet could accommodate only up to 2<sup>8</sup> </span><span class="font54">— </span><span class="font53">2 </span><span class="font54">= </span><span class="font53">254 hosts (two of the 2<sup>8</sup> </span><span class="font54">= </span><span class="font53">256 addresses are reserved for special use)—too small for many organizations. However, a class B (/16) subnet, which supports up to 65,634 hosts, was too large. Under classful addressing, an organization with, say, 2,000 hosts was typically allocated a class B (/16) subnet address. This led to a rapid depletion of the class B address space and poor utilization of the assigned address space. For example, the organization that used a class B address for its 2,000 hosts was allocated enough of the address space for up to 65,534 interfaces—leaving more than 63,000 addresses that could not be used by other organizations.</span></p>
<div><img src="networking_files/networking-329.jpg" alt="" style="width:132pt;height:22pt;">
</div><br clear="all">
<div>
<p><span class="font23" style="font-weight:bold;">PRINCIPLES IN PRACTICE</span></p>
</div><br clear="all">
<p><span class="font4">This example of an ISP that connects eight organizations to the Internet nicely illustrates how carefully allocated CIDRized addresses facilitate routing. Suppose, as shown in Figure 4.21, that the ISP (which we’ll call Fly-By-Night-ISP) advertises to the outside world that it should be sent any datagrams whose first 20 address bits match 200.23.16.0/20. The rest of the world need not know that within the address block 200.23.16.0/20 there are in fact eight other organizations, each with its own subnets. This ability to use a single prefix to advertise multiple networks is often referred to as </span><span class="font5" style="font-weight:bold;">address aggregation </span><span class="font4">(also </span><span class="font5" style="font-weight:bold;">route aggregation </span><span class="font4">or </span><span class="font5" style="font-weight:bold;">route summarization</span><span class="font4">).</span></p>
<p><span class="font4">Address aggregation works extremely well when addresses are allocated in blocks to ISPs and then from ISPs to client organizations. But what happens when addresses are not allocated in such a hierarchical manner? What would happen, for example, if Fly-By-Night-ISP acquires ISPs-R-Us and then has Organization 1 connect to the Internet through its subsidiary ISPs-R-Us? As shown in Figure 4.21, the subsidiary ISPs-R-Us owns the address block 199.31.0.0/16, but Organization 1’s IP addresses are unfortunately outside of this address block. What should be done here? Certainly, Organization 1 could renumber all of its routers and hosts to have addresses within the ISPs-R-Us address block. But this is a costly solution, and Organization 1 might well be reassigned to another subsidiary in the future. The solution typically adopted is for Organization 1 to keep its IP addresses in 200.23.18.0/23. In this case, as shown in Figure 4.22, Fly-By-Night-ISP continues to advertise the address block 200.23.16.0/20 and ISPs-R-Us continues to advertise 199.31.0.0/16. However, ISPs-R-Us now </span><span class="font4" style="font-style:italic;">also</span><span class="font4"> advertises the block of addresses for Organization 1, 200.23.18.0/23. When other routers in the larger Internet see the address blocks 200.23.16.0/20 (from Fly-By-Night-ISP) and 200.23.18.0/23 (from ISPs-R-Us) and want to route to an address in the block 200.23.18.0/23, they will use </span><span class="font4" style="font-style:italic;">longest prefix matching</span><span class="font4"> (see Section 4.2.1), and route toward ISPs-R-Us, as it advertises the longest (i.e., most-specific) address prefix that matches the destination address.</span></p>
<div>
<p><span class="font4">Organization 0</span></p>
<p><span class="font4">200.23.16.0/23</span></p><img src="networking_files/networking-330.jpg" alt="" style="width:175pt;height:128pt;">
<p><span class="font4">“Send me anything with addresses beginning 200.23.16.0/20”</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Internet</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-331.jpg" alt="" style="width:32pt;height:30pt;">
</div><br clear="all">
<div>
<p><span class="font4">ISPs-R-Us</span></p>
</div><br clear="all">
<div>
<p><span class="font7" style="font-weight:bold;">Figure 4.21 </span><span class="font50">♦ </span><span class="font5">Hierarchical addressing and route aggregation</span></p>
<p><span class="font4">Organization 0</span></p><img src="networking_files/networking-332.jpg" alt="" style="width:175pt;height:79pt;">
<p><span class="font4">&quot;Send me anything with addresses beginning 200.23.16.0/20”</span></p>
</div><br clear="all">
<div>
<p><span class="font4">“Send me anything with addresses beginning 199.31.0.0/16”</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Organization 1</span></p><img src="networking_files/networking-333.jpg" alt="" style="width:108pt;height:36pt;">
</div><br clear="all">
<div>
<p><span class="font4">ISPs-R-Us</span></p>
</div><br clear="all">
<p><span class="font4">&quot;Send me anything with addresses beginning 199.31.0.0/16 or 200.23.18.0/23”</span></p>
<div>
<p><span class="font4">Internet</span></p>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 4.22 </span><span class="font50">♦ </span><span class="font5">ISPs-R-Us has a more specific route to Organization 1</span></p>
<p><span class="font53">We would be remiss if we did not mention yet another type of IP address, the IP broadcast address 255.255.255.255. When a host sends a datagram with destination address 255.255.255.255, the message is delivered to all hosts on the same subnet. Routers optionally forward the message into neighboring subnets as well (although they usually don’t).</span></p>
<p><span class="font53">Having now studied IP addressing in detail, we need to know how hosts and subnets get their addresses in the first place. Let’s begin by looking at how an organization gets a block of addresses for its devices, and then look at how a device (such as a host) is assigned an address from within the organization’s block of addresses.</span></p>
<p><span class="font22" style="font-weight:bold;">Obtaining a Block of Addresses</span></p>
<p><span class="font53">In order to obtain a block of IP addresses for use within an organization’s subnet, a network administrator might first contact its ISP, which would provide addresses from a larger block of addresses that had already been allocated to the ISP. For example, the ISP may itself have been allocated the address block 200.23.16.0/20. The ISP, in turn, could divide its address block into eight equal-sized contiguous address blocks and give one of these address blocks out to each of up to eight organizations that are supported by this ISP, as shown below. (We have underlined the subnet part of these addresses for your convenience.)</span></p>
<p><span class="font53">ISP’s block: &nbsp;&nbsp;&nbsp;&nbsp;200.23.16.0/20 &nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font53" style="text-decoration:underline;">11001000 00010111 0001</span><span class="font53">0000 00000000</span></p>
<p><span class="font53">Organization 0 &nbsp;200.23.16.0/23 &nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font53" style="text-decoration:underline;">11001000 00010111 0001000</span><span class="font53">0 00000000</span></p>
<p><span class="font53">Organization 1 &nbsp;200.23.18.0/23 &nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font53" style="text-decoration:underline;">11001000 00010111 0001001</span><span class="font53">0 00000000</span></p>
<p><span class="font53">Organization 2 &nbsp;200.23.20.0/23 &nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font53" style="text-decoration:underline;">11001000 00010111 0001010</span><span class="font53">0 00000000</span></p>
<p><span class="font53">Organization 7 &nbsp;200.23.30.0/23 &nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font53" style="text-decoration:underline;">11001000 00010111 0001111</span><span class="font53">0 00000000</span></p>
<p><span class="font53">While obtaining a set of addresses from an ISP is one way to get a block of addresses, it is not the only way. Clearly, there must also be a way for the ISP itself to get a block of addresses. Is there a global authority that has ultimate responsibility for managing the IP address space and allocating address blocks to ISPs and other organizations? Indeed there is! IP addresses are managed under the authority of the Internet Corporation for Assigned Names and Numbers (ICANN) [ICANN 2020], based on guidelines set forth in [RFC 7020]. The role of the nonprofit ICANN organization is not only to allocate IP addresses, but also to manage the DNS root servers. It also has the very contentious job of assigning domain names and resolving domain name disputes. The ICANN allocates addresses to regional Internet registries (for example, ARIN, RIPE, APNIC, and LACNIC, which together form the Address Supporting Organization of ICANN [ASO-ICANN 2020]), and handle the alloca-tion/management of addresses within their regions.</span></p>
<p><span class="font22" style="font-weight:bold;">Obtaining a Host Address: The Dynamic Host Configuration Protocol</span></p>
<p><span class="font53">Once an organization has obtained a block of addresses, it can assign individual IP addresses to the host and router interfaces in its organization. A system administrator will typically manually configure the IP addresses into the router (often remotely, with a network management tool). Host addresses can also be configured manually, but typically this is done using the </span><span class="font53" style="font-weight:bold;">Dynamic Host Configuration Protocol (DHCP) </span><span class="font53">[RFC 2131]. DHCP allows a host to obtain (be allocated) an IP address automatically. A network administrator can configure DHCP so that a given host receives the same IP address each time it connects to the network, or a host may be assigned a </span><span class="font53" style="font-weight:bold;">temporary IP address </span><span class="font53">that will be different each time the host connects to the network. In addition to host IP address assignment, DHCP also allows a host to learn additional information, such as its subnet mask, the address of its first-hop router (often called the default gateway), and the address of its local DNS server.</span></p>
<p><span class="font53">Because of DHCP’s ability to automate the network-related aspects of connecting a host into a network, it is often referred to as a </span><span class="font53" style="font-weight:bold;">plug-and-play </span><span class="font53">or </span><span class="font53" style="font-weight:bold;">zeroconf </span><span class="font53">(zero-configuration) protocol. This capability makes it </span><span class="font53" style="font-style:italic;">very</span><span class="font53"> attractive to the network administrator who would otherwise have to perform these tasks manually! DHCP is also enjoying widespread use in residential Internet access networks, enterprise networks, and in wireless LANs, where hosts join and leave the network frequently. Consider, for example, the student who carries a laptop from a dormitory room to a library to a classroom. It is likely that in each location, the student will be connecting into a new subnet and hence will need a new IP address at each location. DHCP is ideally suited to this situation, as there are many users coming and going, and addresses are needed for only a limited amount of time. The value of DHCP’s plug-and-play capability is clear, since it’s unimaginable that a system administrator would be able to reconfigure laptops at each location, and few students (except those taking a computer networking class!) would have the expertise to configure their laptops manually.</span></p>
<p><span class="font53">DHCP is a client-server protocol. A client is typically a newly arriving host wanting to obtain network configuration information, including an IP address for itself. In the simplest case, each subnet (in the addressing sense of Figure 4.20) will have a DHCP server. If no server is present on the subnet, a DHCP relay agent (typically a router) that knows the address of a DHCP server for that network is needed. Figure 4.23 shows a DHCP server attached to subnet 223.1.2/24, with the router serving as the relay agent for arriving clients attached to subnets 223.1.1/24 and 223.1.3/24. In our discussion below, we’ll assume that a DHCP server is available on the subnet.</span></p>
<div><img src="networking_files/networking-334.jpg" alt="" style="width:63pt;height:50pt;">
<p><span class="font4">223.1.1.1</span></p>
</div><br clear="all">
<div>
<p><span class="font4">DHCP server</span></p><img src="networking_files/networking-335.jpg" alt="" style="width:42pt;height:42pt;">
<p><span class="font4">223.1.2.5</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-336.jpg" alt="" style="width:67pt;height:68pt;">
<p><span class="font4">223.1.2.1</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-337.jpg" alt="" style="width:57pt;height:45pt;">
<p><span class="font4">223.1.1.2</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-338.jpg" alt="" style="width:63pt;height:43pt;">
<p><span class="font4">223.1.1.3</span></p>
</div><br clear="all">
<div>
<p><span class="font4">223.1.1.4 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;223.1.2.9</span></p><img src="networking_files/networking-339.jpg" alt="" style="width:145pt;height:142pt;">
<p><span class="font4">223.1.3.1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;223.1.3.2</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 4.23 </span><span class="font50">♦ </span><span class="font5">DHCP client and server</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-340.jpg" alt="" style="width:70pt;height:47pt;">
<p><span class="font4">223.1.2.2</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-341.jpg" alt="" style="width:28pt;height:30pt;">
<p><span class="font4">Arriving</span></p>
<p><span class="font4">DHCP client</span></p>
</div><br clear="all">
<p><span class="font53">For a newly arriving host, the DHCP protocol is a four-step process, as shown in Figure 4.24 for the network setting shown in Figure 4.23. In this figure, </span><span class="font36">yiaddr </span><span class="font53">(as in “your Internet address”) indicates the address being allocated to the newly arriving client. The four steps are:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">DHCP server discovery.</span><span class="font53"> The first task of a newly arriving host is to find a DHCP server with which to interact. This is done using a </span><span class="font53" style="font-weight:bold;">DHCP discover message</span><span class="font53">, which a client sends within a UDP packet to port 67. The UDP packet is encapsulated in an IP datagram. But to whom should this datagram be sent? The host doesn’t even know the IP address of the network to which it is attaching, much less the address of a DHCP server for this network. Given this, the DHCP client creates an IP datagram containing its DHCP discover message along with the broadcast destination IP address of 255.255.255.255 and a “this host” source IP address of 0.0.0.0. The DHCP client passes the IP datagram to the link layer, which then broadcasts this frame to all nodes attached to the subnet (we will cover the details of link-layer broadcasting in Section 6.4).</span></p></li>
<li>
<p><span class="font53">• </span><span class="font53" style="font-style:italic;">DHCP server offer(s).</span><span class="font53"> A DHCP server receiving a DHCP discover message responds to the client with a </span><span class="font53" style="font-weight:bold;">DHCP offer message </span><span class="font53">that is broadcast to all</span></p>
<div>
<p><span class="font4" style="font-weight:bold;">DHCP server:</span></p>
<p><span class="font4">223.1.2.5</span></p><img src="networking_files/networking-342.jpg" alt="" style="width:122pt;height:191pt;">
<p><span class="font4">DHCP offer</span></p>
<p><span class="font41">src: 223.1.2.5, 67</span></p>
<p><span class="font41">dest: 255.255.255.255,68</span></p>
<p><span class="font41">DHCPOFFER</span></p>
<p><span class="font41">yiaddrr: 223.1.2.4</span></p>
<p><span class="font41">transaction ID: 654</span></p>
<p><span class="font41">DHCP server ID: 223.1.2.5</span></p>
<p><span class="font41">L ifetime: 3600 secs</span></p>
<p><span class="font4">DHCP discover</span></p>
<p><span class="font41">src: 0.0.0.0, 68</span></p>
<p><span class="font41">dest: 255.255.255.255,67</span></p>
<p><span class="font41">DHCPDISCOVER</span></p>
<p><span class="font41">yiaddr: 0.0.0.0</span></p>
<p><span class="font41">transaction ID: 654</span></p>
<p><span class="font4">DHCP request</span></p>
<p><span class="font41">src: 0.0.0.0, 68</span></p>
<p><span class="font41">dest: 255.255.255.255, 67</span></p>
<p><span class="font41">DHCPREQUEST</span></p>
<p><span class="font41">yiaddrr: 223.1.2.4</span></p>
<p><span class="font41">transaction ID: 655</span></p>
<p><span class="font41">DHCP server ID: 223.1.2.5</span></p>
<p><span class="font41">Lifetime: 3600 secs</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Arriving client</span></p><img src="networking_files/networking-343.jpg" alt="" style="width:221pt;height:306pt;">
<p><span class="font4">DHCP ACK</span></p>
<p><span class="font4">Time</span></p>
<p><span class="font4">Time</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 4.24 </span><span class="font50">♦ </span><span class="font5">DHCP client-server interaction</span></p>
</div><br clear="all"></li></ul>
<p><span class="font41">src: 223.1.2.5, 67</span></p>
<p><span class="font41">dest: 255.255.255.255,68</span></p>
<p><span class="font41">DHCPACK</span></p>
<p><span class="font41">yiaddrr: 223.1.2.4</span></p>
<p><span class="font41">transaction ID: 655</span></p>
<p><span class="font41">DHCP server ID: 223.1.2.5</span></p>
<p><span class="font41">Lifetime: 3600 secs</span></p>
<p><span class="font53">nodes on the subnet, again using the IP broadcast address of 255.255.255.255. (You might want to think about why this server reply must also be broadcast). Since several DHCP servers can be present on the subnet, the client may find itself in the enviable position of being able to choose from among several offers. Each server offer message contains the transaction ID of the received discover message, the proposed IP address for the client, the network mask, and an IP </span><span class="font53" style="font-weight:bold;">address lease time—</span><span class="font53">the amount of time for which the IP address will be valid. It is common for the server to set the lease time to several hours or days [Droms 2002].</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">DHCP request.</span><span class="font53"> The newly arriving client will choose from among one or more server offers and respond to its selected offer with a </span><span class="font53" style="font-weight:bold;">DHCP request message</span><span class="font53">, echoing back the configuration parameters.</span></p></li>
<li>
<p><span class="font53">• </span><span class="font53" style="font-style:italic;">DHCP ACK.</span><span class="font53"> The server responds to the DHCP request message with a </span><span class="font53" style="font-weight:bold;">DHCP ACK message</span><span class="font53">, confirming the requested parameters.</span></p></li></ul>
<p><span class="font53">Once the client receives the DHCP ACK, the interaction is complete and the client can use the DHCP-allocated IP address for the lease duration. Since a client may want to use its address beyond the lease’s expiration, DHCP also provides a mechanism that allows a client to renew its lease on an IP address.</span></p>
<p><span class="font53">From a mobility aspect, DHCP does have one very significant shortcoming. Since a new IP address is obtained from DHCP each time a node connects to a new subnet, a TCP connection to a remote application cannot be maintained as a mobile node moves between subnets. In Chapter 7, we will learn how mobile cellular networks allow a host to retain its IP address and ongoing TCP connections as it moves between base stations in a provider’s cellular network. Additional details about DHCP can be found in [Droms 2002] and [dhc 2020]. An open source reference implementation of DHCP is available from the Internet Systems Consortium [ISC 2020].</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">4.3.3 </span><span class="font23" style="font-weight:bold;">Network Address Translation (NAT)</span></p></li></ul>
<p><span class="font53">Given our discussion about Internet addresses and the IPv4 datagram format, we’re now well aware that every IP-capable device needs an IP address. With the proliferation of small office, home office (SOHO) subnets, this would seem to imply that whenever a SOHO wants to install a LAN to connect multiple machines, a range of addresses would need to be allocated by the ISP to cover all of the SOHO’s IP devices (including phones, tablets, gaming devices, IP TVs, printers and more). If the subnet grew bigger, a larger block of addresses would have to be allocated. But what if the ISP had already allocated the contiguous portions of the SOHO network’s current address range? And what typical homeowner wants (or should need) to know how to manage IP addresses in the first place? Fortunately, there is a simpler approach to address allocation that has found increasingly widespread use in such scenarios: </span><span class="font53" style="font-weight:bold;">network address translation (NAT) </span><span class="font53">[RFC 2663; RFC 3022; Huston 2004, Zhang 2007; Huston 2017].</span></p>
<p><a name="bookmark341"></a><span class="font53">Figure 4.25 shows the operation of a NAT-enabled router. The NAT-enabled router, residing in the home, has an interface that is part of the home network on the right of Figure 4.25. Addressing within the home network is exactly as we have seen above—all four interfaces in the home network have the same subnet address of 10.0.0.0/24. The address space 10.0.0.0/8 is one of three portions of the IP address space that is reserved in [RFC 1918] for a </span><span class="font53" style="font-weight:bold;">private network </span><span class="font53">or a </span><span class="font53" style="font-weight:bold;">realm with private addresses</span><span class="font53">, such as the home network in Figure 4.25. A realm with private addresses refers to a network whose addresses only have meaning to</span></p>
<table border="1">
<tr><td colspan="2" style="vertical-align:middle;">
<p><span class="font4" style="font-weight:bold;">NAT translation table</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font4">WAN side</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">LAN side</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font4">138.76.29.7, 5001</span></p>
<p><span class="font4">...</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">10.0.0.1, 3345</span></p>
<p><span class="font4">...</span></p></td></tr>
</table><img src="networking_files/networking-344.jpg" alt="" style="width:417pt;height:131pt;">
<p><span class="font7" style="font-weight:bold;">Figure 4.25 </span><span class="font50">♦ </span><span class="font5">Network address translation</span></p>
<p><span class="font53">devices within that network. To see why this is important, consider the fact that there are hundreds of thousands of home networks, many using the same address space, 10.0.0.0/24. Devices within a given home network can send packets to each other using 10.0.0.0/24 addressing. However, packets forwarded </span><span class="font53" style="font-style:italic;">beyond</span><span class="font53"> the home network into the larger global Internet clearly cannot use these addresses (as either a source or a destination address) because there are hundreds of thousands of networks using this block of addresses. That is, the 10.0.0.0/24 addresses can only have meaning within the given home network. But if private addresses only have meaning within a given network, how is addressing handled when packets are sent to or received from the global Internet, where addresses are necessarily unique? The answer lies in understanding NAT.</span></p>
<p><span class="font53">The NAT-enabled router does not </span><span class="font53" style="font-style:italic;">look</span><span class="font53"> like a router to the outside world. Instead the NAT router behaves to the outside world as a </span><span class="font53" style="font-style:italic;">single</span><span class="font53"> device with a </span><span class="font53" style="font-style:italic;">single</span><span class="font53"> IP address. In Figure 4.25, all traffic leaving the home router for the larger Internet has a source IP address of 138.76.29.7, and all traffic entering the home router must have a destination address of 138.76.29.7. In essence, the NAT-enabled router is hiding the details of the home network from the outside world. (As an aside, you might wonder where the home network computers get their addresses and where the router gets its single IP address. Often, the answer is the same—DHCP! The router gets its address from the ISP’s DHCP server, and the router runs a DHCP server to provide addresses to computers within the NAT-DHCP-router-controlled home network’s address space.)</span></p>
<p><span class="font53">If all datagrams arriving at the NAT router from the WAN have the same destination IP address (specifically, that of the WAN-side interface of the NAT router), then how does the router know the internal host to which it should forward a given datagram? The trick is to use a </span><span class="font53" style="font-weight:bold;">NAT translation table </span><span class="font53">at the NAT router, and to include port numbers as well as IP addresses in the table entries.</span></p>
<p><span class="font53">Consider the example in Figure 4.25. Suppose a user sitting in a home network behind host 10.0.0.1 requests a Web page on some Web server (port 80) with IP address 128.119.40.186. The host 10.0.0.1 assigns the (arbitrary) source port number 3345 and sends the datagram into the LAN. The NAT router receives the datagram, generates a new source port number 5001 for the datagram, replaces the source IP address with its WAN-side IP address 138.76.29.7, and replaces the original source port number 3345 with the new source port number 5001. When generating a new source port number, the NAT router can select any source port number that is not currently in the NAT translation table. (Note that because a port number field is 16 bits long, the NAT protocol can support over 60,000 simultaneous connections with a single WAN-side IP address for the router!) NAT in the router also adds an entry to its NAT translation table. The Web server, blissfully unaware that the arriving datagram containing the HTTP request has been manipulated by the NAT router, responds with a datagram whose destination address is the IP address of the NAT router, and whose destination port number is 5001. When this datagram arrives at the NAT router, the router indexes the NAT translation table using the destination IP address and destination port number to obtain the appropriate IP address (10.0.0.1) and destination port number (3345) for the browser in the home network. The router then rewrites the datagram’s destination address and destination port number, and forwards the datagram into the home network.</span></p>
<p><span class="font53">NAT has enjoyed widespread deployment in recent years. But NAT is not without detractors. First, one might argue that, port numbers are meant to be used for addressing processes, not for addressing hosts. This violation can indeed cause problems for servers running on the home network, since, as we have seen in Chapter 2, server processes wait for incoming requests at well-known port numbers and peers in a P2P protocol need to accept incoming connections when acting as servers. How can one peer connect to another peer that is behind a NAT server, and has a DHCP-provided NAT address? Technical solutions to these problems include </span><span class="font53" style="font-weight:bold;">NAT traversal </span><span class="font53">tools [RFC 5389] [RFC 5389, RFC 5128, Ford 2005].</span></p>
<p><span class="font53">More “philosophical” arguments have also been raised against NAT by architectural purists. Here, the concern is that routers are meant to be layer 3 (i.e., network-layer) devices, and should process packets only up to the network layer. NAT violates this principle that hosts should be talking directly with each other, without interfering nodes modifying IP addresses, much less port numbers. We’ll return to this debate later in Section 4.5, when we cover middleboxes.</span></p>
<p><span class="font23" style="font-weight:bold;">FOCUS ON SECURITY</span></p>
<p><span class="font4" style="font-weight:bold;">INSPECTING DATAGRAMS: FIREWALLS AND INTRUSION DETECTION SYSTEMS</span></p>
<p><span class="font4">Suppose you are assigned the task of administering a home, departmental, university, or corporate network. Attackers, knowing the IP address range of your network, can easily send IP datagrams to addresses in your range. These datagrams can do all kinds of devious things, including mapping your network with ping sweeps and port scans, crashing vulnerable hosts with malformed packets, scanning for open TCP/UDP ports on servers in your network, and infecting hosts by including malware in the packets. As the network administrator, what are you going to do about all those bad guys out there, each capable of sending malicious packets into your network? Two popular defense mechanisms to malicious packet attacks are firewalls and intrusion detection systems (IDSs).</span></p>
<p><span class="font4">As a network administrator, you may first try installing a firewall between your network and the Internet. (Most access routers today have firewall capability.) Firewalls inspect the datagram and segment header fields, denying suspicious datagrams entry into the internal network. For example, a firewall may be configured to block all ICMP echo request packets (see Section 5.6), thereby preventing an attacker from doing a traditional port scan across your IP address range. Firewalls can also block packets based on source and destination IP addresses and port numbers. Additionally, firewalls can be configured to track TCP connections, granting entry only to datagrams that belong to approved connections.</span></p>
<p><span class="font4">Additional protection can be provided with an IDS. An IDS, typically situated at the network boundary, performs “deep packet inspection,” examining not only header fields but also the payloads in the datagram (including application-layer data). An IDS has a database of packet signatures that are known to be part of attacks. This database is automatically updated as new attacks are discovered. As packets pass through the IDS, the IDS attempts to match header fields and payloads to the signatures in its signature database. If such a match is found, an alert is created. An intrusion prevention system (IPS) is similar to an IDS, except that it actually blocks packets in addition to creating alerts. We’ll explore firewalls and IDSs in more detail in Section 4.5 and in again Chapter 8.</span></p>
<p><span class="font4">Can firewalls and IDSs fully shield your network from all attacks? The answer is clearly no, as attackers continually find new attacks for which signatures are not yet available. But firewalls and traditional signature-based IDSs are useful in protecting your network from known attacks.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">4.3.4 </span><span class="font23" style="font-weight:bold;">IPv6</span></p></li></ul>
<p><a name="bookmark342"></a><span class="font53">In the early 1990s, the Internet Engineering Task Force began an effort to develop a successor to the IPv4 protocol. A prime motivation for this effort was the realization that the 32-bit IPv4 address space was beginning to be used up, with new subnets and IP nodes being attached to the Internet (and being allocated unique IP addresses) at a breathtaking rate. To respond to this need for a large IP address space, a new IP protocol, IPv6, was developed. The designers of IPv6 also took this opportunity to tweak and augment other aspects of IPv4, based on the accumulated operational experience with IPv4.</span></p>
<p><span class="font53">The point in time when IPv4 addresses would be completely allocated (and hence no new networks could attach to the Internet) was the subject of considerable debate. The estimates of the two leaders of the IETF’s Address Lifetime Expectations working group were that addresses would become exhausted in 2008 and 2018, respectively [Solensky 1996]. In February 2011, IANA allocated out the last remaining pool of unassigned IPv4 addresses to a regional registry. While these registries still have available IPv4 addresses within their pool, once these addresses are exhausted, there are no more available address blocks that can be allocated from a central pool [Huston 2011a]. A recent survey of IPv4 address-space exhaustion, and the steps taken to prolong the life of the address space is [Richter 2015]; a recent analysis of IPv4 address use is [Huston 2019].</span></p>
<p><span class="font53">Although the mid-1990s estimates of IPv4 address depletion suggested that a considerable amount of time might be left until the IPv4 address space was exhausted, it was realized that considerable time would be needed to deploy a new technology on such an extensive scale, and so the process to develop IP version 6 (IPv6) [RFC 2460] was begun [RFC 1752]. (An often-asked question is what happened to IPv5? It was initially envisioned that the ST-2 protocol would become IPv5, but ST-2 was later dropped.) An excellent source of information about IPv6 is [Huitema 1998].</span></p>
<p><span class="font22" style="font-weight:bold;">IPv6 Datagram Format</span></p>
<p><span class="font53">The format of the IPv6 datagram is shown in Figure 4.26. The most important changes introduced in IPv6 are evident in the datagram format:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Expanded addressing capabilities.</span><span class="font53"> IPv6 increases the size of the IP address from 32 to 128 bits. This ensures that the world won’t run out of IP addresses. Now, every grain of sand on the planet can be IP-addressable. In addition to unicast and multicast addresses, IPv6 has introduced a new type of address, called an </span><span class="font53" style="font-weight:bold;">anycast address</span><span class="font53">, that allows a datagram to be delivered to any one of a group of hosts. (This feature could be used, for example, to send an HTTP GET to the nearest of a number of mirror sites that contain a given document.)</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">A streamlined 40-byte header.</span><span class="font53"> As discussed below, a number of IPv4 fields have been dropped or made optional. The resulting 40-byte fixed-length header allows for faster processing of the IP datagram by a router. A new encoding of options allows for more flexible options processing.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Flow labeling.</span><span class="font53"> IPv6 has an elusive definition of a </span><span class="font53" style="font-weight:bold;">flow</span><span class="font53">. RFC 2460 states that this allows “labeling of packets belonging to particular flows for which the sender</span></p></li></ul>
<p><span class="font4">32 bits</span></p>
<p><span class="font4">Version &nbsp;&nbsp;&nbsp;Traffic class &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Flow label</span></p>
<p><span class="font4">Payload length &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Next hdr &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Hop limit</span></p>
<p><span class="font4">Source address (128 bits)</span></p>
<p><span class="font4">Destination address (128 bits)</span></p>
<p><span class="font4">Data</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 4.26 </span><span class="font50">♦ </span><span class="font5">IPv6 datagram format</span></p>
<p><span class="font53">requests special handling, such as a non-default quality of service or real-time service.” For example, audio and video transmission might likely be treated as a flow. On the other hand, the more traditional applications, such as file transfer and e-mail, might not be treated as flows. It is possible that the traffic carried by a high-priority user (for example, someone paying for better service for their traffic) might also be treated as a flow. What is clear, however, is that the designers of IPv6 foresaw the eventual need to be able to differentiate among the flows, even if the exact meaning of a flow had yet to be determined.</span></p>
<p><span class="font53">As noted above, a comparison of Figure 4.26 with Figure 4.17 reveals the simpler, more streamlined structure of the IPv6 datagram. The following fields are defined in IPv6:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Version.</span><span class="font53"> This 4-bit field identifies the IP version number. Not surprisingly, IPv6 carries a value of 6 in this field. Note that putting a 4 in this field does not create a valid IPv4 datagram. (If it did, life would be a lot simpler—see the discussion below regarding the transition from IPv4 to IPv6.)</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Traffic class.</span><span class="font53"> The 8-bit traffic class field, like the TOS field in IPv4, can be used to give priority to certain datagrams within a flow, or it can be used to give priority to datagrams from certain applications (for example, voice-over-IP) over datagrams from other applications (for example, SMTP e-mail).</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Flow label.</span><span class="font53"> As discussed above, this 20-bit field is used to identify a flow of datagrams.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Payload length.</span><span class="font53"> This 16-bit value is treated as an unsigned integer giving the number of bytes in the IPv6 datagram following the fixed-length, 40-byte datagram header.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Next header.</span><span class="font53"> This field identifies the protocol to which the contents (data field) of this datagram will be delivered (for example, to TCP or UDP). The field uses the same values as the protocol field in the IPv4 header.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Hop limit.</span><span class="font53"> The contents of this field are decremented by one by each router that forwards the datagram. If the hop limit count reaches zero, a router must discard that datagram.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Source and destination addresses.</span><span class="font53"> The various formats of the IPv6 128-bit address are described in RFC 4291.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Data.</span><span class="font53"> This is the payload portion of the IPv6 datagram. When the datagram reaches its destination, the payload will be removed from the IP datagram and passed on to the protocol specified in the next header field.</span></p></li></ul>
<p><span class="font53">The discussion above identified the purpose of the fields that are included in the IPv6 datagram. Comparing the IPv6 datagram format in Figure 4.26 with the IPv4 datagram format that we saw in Figure 4.17, we notice that several fields appearing in the IPv4 datagram are no longer present in the IPv6 datagram:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Fragmentation/reassembly.</span><span class="font53"> IPv6 does not allow for fragmentation and reassembly at intermediate routers; these operations can be performed only by the source and destination. If an IPv6 datagram received by a router is too large to be forwarded over the outgoing link, the router simply drops the datagram and sends a “Packet Too Big” ICMP error message (see Section 5.6) back to the sender. The sender can then resend the data, using a smaller IP datagram size. Fragmentation and reassembly is a time-consuming operation; removing this functionality from the routers and placing it squarely in the end systems considerably speeds up IP forwarding within the network.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Header checksum.</span><span class="font53"> Because the transport-layer (for example, TCP and UDP) and link-layer (for example, Ethernet) protocols in the Internet layers perform checksumming, the designers of IP probably felt that this functionality was sufficiently redundant in the network layer that it could be removed. Once again, fast processing of IP packets was a central concern. Recall from our discussion of IPv4 in Section 4.3.1 that since the IPv4 header contains a TTL field (similar to the hop limit field in IPv6), the IPv4 header checksum needed to be recomputed at every router. As with fragmentation and reassembly, this too was a costly operation in IPv4.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Options.</span><span class="font53"> An options field is no longer a part of the standard IP header. However, it has not gone away. Instead, the options field is one of the possible next headers pointed to from within the IPv6 header. That is, just as TCP or UDP protocol headers can be the next header within an IP packet, so too can an options field. The removal of the options field results in a fixed-length, 40-byte IP header.</span></p></li></ul>
<p><span class="font22" style="font-weight:bold;">Transitioning from IPv4 to IPv6</span></p>
<p><span class="font53">Now that we have seen the technical details of IPv6, let us consider a very practical matter: How will the public Internet, which is based on IPv4, be transitioned to IPv6? The problem is that while new IPv6-capable systems can be made backwardcompatible, that is, can send, route, and receive IPv4 datagrams, already deployed IPv4-capable systems are not capable of handling IPv6 datagrams. Several options are possible [Huston 2011b, RFC 4213].</span></p>
<p><span class="font53">One option would be to declare a flag day—a given time and date when all Internet machines would be turned off and upgraded from IPv4 to IPv6. The last major technology transition (from using NCP to using TCP for reliable transport service) occurred almost 40 years ago. Even back then [RFC 801], when the Internet was tiny and still being administered by a small number of “wizards,” it was realized that such a flag day was not possible. A flag day involving billions of devices is even more unthinkable today.</span></p>
<p><span class="font53">The approach to IPv4-to-IPv6 transition that has been most widely adopted in practice involves </span><span class="font53" style="font-weight:bold;">tunneling </span><span class="font53">[RFC 4213]. The basic idea behind tunneling—a key concept with applications in many other scenarios beyond IPv4-to-IPv6 transition, including wide use in the all-IP cellular networks that we’ll cover in Chapter 7—is the following. Suppose two IPv6 nodes (in this example, B and E in Figure 4.27) want to interoperate using IPv6 datagrams but are connected to each other by intervening IPv4 routers. We refer to the intervening set of IPv4 routers between two IPv6 routers as a </span><span class="font53" style="font-weight:bold;">tunnel</span><span class="font53">, as illustrated in Figure 4.27. With tunneling, the IPv6 node on the sending side of the tunnel (in this example, B) takes the </span><span class="font53" style="font-style:italic;">entire</span><span class="font53"> IPv6 datagram and puts it in the data (payload) field of an IPv4 datagram. This IPv4 datagram is then addressed to the IPv6 node on the receiving side of the tunnel (in this example, E) and sent to the first node in the tunnel (in this example, C). The intervening IPv4 routers in the tunnel route this IPv4 datagram among themselves, just as they would any other datagram, blissfully unaware that the IPv4 datagram itself contains a complete IPv6 datagram. The IPv6 node on the receiving side of the tunnel eventually receives the IPv4 datagram (it is the destination of the IPv4 datagram!), determines that the IPv4 datagram contains an IPv6 datagram (by observing that the protocol number field in the IPv4 datagram is 41 [RFC 4213], indicating that the IPv4 payload is a IPv6 datagram), extracts the IPv6 datagram, and then routes the IPv6 datagram exactly as it would if it had received the IPv6 datagram from a directly connected IPv6 neighbor.</span></p>
<p><span class="font53">We end this section by noting that while the adoption of IPv6 was initially slow to take off [Lawton 2001; Huston 2008b], momentum has been building. NIST [NIST IPv6 2020] reports that more than a third of US government second-level domains are IPv6-enabled. On the client side, Google reports that about 25 percent of the clients accessing Google services do so via IPv6 [Google IPv6 2020]. Other recent measurements [Czyz 2014] indicate that IPv6 adoption has been accelerating. The proliferation of devices such as IP-enabled phones and other portable devices</span></p>
<p><span class="font4" style="font-weight:bold;">Logical view</span></p>
<div>
<p><span class="font4">IPv6</span></p><img src="networking_files/networking-345.jpg" alt="" style="width:27pt;height:15pt;">
</div><br clear="all">
<div>
<p><span class="font4">IPv6</span></p><img src="networking_files/networking-346.jpg" alt="" style="width:30pt;height:18pt;">
</div><br clear="all">
<div>
<p><span class="font4">Tunnel</span></p>
</div><br clear="all">
<div>
<p><span class="font4">IPv6</span></p><img src="networking_files/networking-347.jpg" alt="" style="width:28pt;height:15pt;">
</div><br clear="all">
<div>
<p><span class="font4">IPv6</span></p><img src="networking_files/networking-348.jpg" alt="" style="width:27pt;height:15pt;">
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Physical view</span></p><img src="networking_files/networking-349.jpg" alt="" style="width:320pt;height:36pt;">
<p><span class="font4">Flow: </span><span class="font4" style="font-style:italic;">X</span></p>
<p><span class="font4">Source: </span><span class="font4" style="font-style:italic;">A</span></p>
<p><span class="font4">Dest: </span><span class="font4" style="font-style:italic;">F</span></p>
<p><span class="font4">Source: </span><span class="font4" style="font-style:italic;">B</span></p>
<p><span class="font4">Dest: </span><span class="font4" style="font-style:italic;">E</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-style:italic;">data</span></p>
<p><span class="font4" style="font-style:italic;">A</span><span class="font4"> to </span><span class="font4" style="font-style:italic;">B:</span><span class="font4"> IPv6</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Flow: </span><span class="font4" style="font-style:italic;">X</span></p>
<p><span class="font4">Source: </span><span class="font4" style="font-style:italic;">A</span></p>
<p><span class="font4">Dest: </span><span class="font4" style="font-style:italic;">F</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-style:italic;">data</span></p>
<p><span class="font4" style="font-style:italic;">B</span><span class="font4"> to </span><span class="font4" style="font-style:italic;">C</span><span class="font4">: IPv4 (encapsulating IPv6)</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Source: </span><span class="font4" style="font-style:italic;">B</span><span class="font4"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Flow: </span><span class="font4" style="font-style:italic;">X</span></p>
<p><span class="font4">Dest: </span><span class="font4" style="font-style:italic;">E</span><span class="font4"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Source: </span><span class="font4" style="font-style:italic;">A</span></p>
<p><span class="font4">Dest: </span><span class="font4" style="font-style:italic;">F</span></p>
<p><span class="font4">Flow: </span><span class="font4" style="font-style:italic;">X </span><span class="font4">Source: </span><span class="font4" style="font-style:italic;">A </span><span class="font4">Dest: </span><span class="font4" style="font-style:italic;">F &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;data</span></p>
<p><span class="font4" style="font-style:italic;">E</span><span class="font4"> to </span><span class="font4" style="font-style:italic;">F</span><span class="font4">: IPv6 </span><span class="font4" style="font-style:italic;">data</span></p>
<p><span class="font4" style="font-style:italic;">D</span><span class="font4"> to </span><span class="font4" style="font-style:italic;">E</span><span class="font4">: IPv4 (encapsulating IPv6)</span></p>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 4.27 </span><span class="font50">♦ </span><span class="font5">Tunneling</span></p>
<p><span class="font53">provides an additional push for more widespread deployment of IPv6. Europe’s Third Generation Partnership Program [3GPP 2020] has specified IPv6 as the standard addressing scheme for mobile multimedia.</span></p>
<p><span class="font53">One important lesson that we can learn from the IPv6 experience is that it is enormously difficult to change network-layer protocols. Since the early 1990s, numerous new network-layer protocols have been trumpeted as the next major revolution for the Internet, but most of these protocols have had limited penetration to date. These protocols include IPv6, multicast protocols, and resource reservation protocols; a discussion of these latter two classes of protocols can be found in the online supplement to this text. Indeed, introducing new protocols into the network layer is like replacing the foundation of a house—it is difficult to do without tearing the whole house down or at least temporarily relocating the house’s residents. On the other hand, the Internet has witnessed rapid deployment of new protocols at the application layer. The classic examples, of course, are the Web, instant messaging, streaming media, distributed games, and various forms of social media. Introducing new applicationlayer protocols is like adding a new layer of paint to a house—it is relatively easy to do, and if you choose an attractive color, others in the neighborhood will copy you.</span></p>
<p><span class="font53">In summary, in the future, we can certainly expect to see changes in the Internet’s network layer, but these changes will likely occur on a time scale that is much slower than the changes that will occur at the application layer.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">4.4 </span><span class="font24" style="font-weight:bold;">Generalized Forwarding and SDN</span></p></li></ul>
<p><span class="font53">Recall that Section 4.2.1 characterized destination-based forwarding as the two steps of looking up a destination IP address (“match”), then sending the packet into the switching fabric to the specified output port (“action”). Let’s now consider a significantly more general “match-plus-action” paradigm, where the “match” can be made over multiple header fields associated with different protocols at different layers in the protocol stack. The “action” can include forwarding the packet to one or more output ports (as in destination-based forwarding), load balancing packets across multiple outgoing interfaces that lead to a service (as in load balancing), rewriting header values (as in NAT), purposefully blocking/dropping a packet (as in a firewall), sending a packet to a special server for further processing and action (as in DPI), and more.</span></p>
<p><span class="font53">In generalized forwarding, a match-plus-action table generalizes the notion of the destination-based forwarding table that we encountered in Section 4.2.1. Because forwarding decisions may be made using network-layer and/or link-layer source and destination addresses, the forwarding devices shown in Figure 4.28 are more accurately described as “packet switches” rather than layer 3 “routers” or layer 2 “switches.” Thus, in the remainder of this section, and in Section 5.5, we’ll refer to these devices as packet switches, adopting the terminology that is gaining widespread adoption in SDN literature.</span></p>
<p><span class="font53">Figure 4.28 shows a match-plus-action table in each packet switch, with the table being computed, installed, and updated by a remote controller. We note that while it is possible for the control components at the individual packet switches to interact with each other (e.g., in a manner similar to that in Figure 4.2), in practice, generalized match-plus-action capabilities are implemented via a remote controller that computes, installs, and updates these tables. You might take a minute to compare Figures 4.2, 4.3, and 4.28—what similarities and differences do you notice between destination-based forwarding shown in Figures 4.2 and 4.3, and generalized forwarding shown in Figure 4.28?</span></p>
<p><a name="bookmark343"></a><span class="font53">Our following discussion of generalized forwarding will be based on OpenFlow [McKeown 2008, ONF 2020, Casado 2014, Tourrilhes 2014]—a highly visible standard that has pioneered the notion of the match-plus-action forwarding abstraction and controllers, as well as the SDN revolution more generally [Feamster 2013]. We’ll primarily consider OpenFlow 1.0, which introduced key SDN abstractions and functionality in a particularly clear and concise manner. Later versions of OpenFlow introduced additional capabilities as a result of experience gained through</span></p>
<div><img src="networking_files/networking-350.jpg" alt="" style="width:364pt;height:205pt;">
<p><span class="font4">Values in arriving packet's header</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-351.jpg" alt="" style="width:292pt;height:49pt;">
<p><span class="font7" style="font-weight:bold;">Figure 4.28 </span><span class="font50">♦ </span><span class="font5">Generalized forwarding: Each packet switch contains a match-plus-action table that is computed and distributed by a remote controller</span></p>
</div><br clear="all">
<p><span class="font53">implementation and use; current and earlier versions of the OpenFlow standard can be found at [ONF 2020].</span></p>
<p><span class="font53">Each entry in the match-plus-action forwarding table, known as a </span><span class="font53" style="font-weight:bold;">flow table </span><span class="font53">in OpenFlow, includes:</span></p>
<p><span class="font53">• </span><span class="font53" style="font-style:italic;">A set of header field values</span><span class="font53"> to which an incoming packet will be matched. As in the case of destination-based forwarding, hardware-based matching is most rapidly performed in TCAM memory, with more than a million destination address entries being possible [Bosshart 2013]. A packet that matches no flow table entry can be dropped or sent to the remote controller for more processing. In practice, a flow table may be implemented by multiple flow tables for performance or cost reasons [Bosshart 2013], but we’ll focus here on the abstraction of a single flow table.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">A set of counters</span><span class="font53"> that are updated as packets are matched to flow table entries. These counters might include the number of packets that have been matched by that table entry, and the time since the table entry was last updated.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">A set of actions to be taken</span><span class="font53"> when a packet matches a flow table entry. These actions might be to forward the packet to a given output port, to drop the packet, makes copies of the packet and sent them to multiple output ports, and/or to rewrite selected header fields.</span></p></li></ul>
<p><span class="font53">We’ll explore matching and actions in more detail in Sections 4.4.1 and 4.4.2, respectively. We’ll then study how the network-wide collection of per-packet switch matching rules can be used to implement a wide range of functions including routing, layer-2 switching, firewalling, load-balancing, virtual networks, and more in Section 4.4.3. In closing, we note that the flow table is essentially an API, the abstraction through which an individual packet switch’s behavior can be programmed; we’ll see in Section 4.4.3 that network-wide behaviors can similarly be programmed by appropriately programming/configuring these tables in a </span><span class="font53" style="font-style:italic;">collection</span><span class="font53"> of network packet switches [Casado 2014].</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">4.4.1 </span><span class="font23" style="font-weight:bold;">Match</span></p></li></ul>
<p><span class="font53">Figure 4.29 shows the 11 packet-header fields and the incoming port ID that can be matched in an OpenFlow 1.0 match-plus-action rule. Recall from Section 1.5.2 that a link-layer (layer 2) frame arriving to a packet switch will contain a network-layer (layer 3) datagram as its payload, which in turn will typically contain a transport-layer (layer 4) segment. The first observation we make is that OpenFlow’s match abstraction allows for a match to be made on selected fields from </span><span class="font53" style="font-style:italic;">three</span><span class="font53"> layers of protocol headers (thus rather brazenly defying the layering principle we studied in Section 1.5). Since we’ve not yet covered the link layer, suffice it to say that the source and destination MAC addresses shown in Figure 4.29 are the link-layer addresses associated with the frame’s sending and receiving interfaces; by forwarding on the basis of Ethernet addresses rather than IP addresses, we can see that an OpenFlow-enabled device can equally perform</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font4">Ingress Port</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Src MAC</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Dst MAC</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Eth</span></p>
<p><span class="font4">Type</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">VLAN ID</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">VLAN Pri</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">IP Src</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">IP Dst</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">IP Proto</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">IP TOS</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">TCP/UDP Src Port</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">TCP/UDP Dst Port</span></p></td></tr>
<tr><td rowspan="2"></td><td colspan="11" style="vertical-align:bottom;">
<p><span class="font46">II &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;II &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1</span></p></td></tr>
<tr><td colspan="11">
<p><span class="font46">n &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;i &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;n</span></p>
<p><span class="font4">Link layer &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Network layer &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Transport layer</span></p></td></tr>
</table>
<p><a name="bookmark344"></a><span class="font7" style="font-weight:bold;">Figure 4.29 </span><span class="font50">♦ </span><span class="font5">Packet matching fields, OpenFlow 1.0 flow table</span></p>
<p><span class="font53">as a router (layer-3 device) forwarding datagrams as well as a switch (layer-2 device) forwarding frames. The Ethernet type field corresponds to the upper layer protocol (e.g., IP) to which the frame’s payload will be de-multiplexed, and the VLAN fields are concerned with so-called virtual local area networks that we’ll study in Chapter 6. The set of 12 values that can be matched in the OpenFlow 1.0 specification has grown to 41 values in more recent OpenFlow specifications [Bosshart 2014].</span></p>
<p><span class="font53">The ingress port refers to the input port at the packet switch on which a packet is received. The packet’s IP source address, IP destination address, IP protocol field, and IP type of service fields were discussed earlier in Section 4.3.1. The transport-layer source and destination port number fields can also be matched.</span></p>
<p><span class="font53">Flow table entries may also have wildcards. For example, an IP address of 128.119.*.* in a flow table will match the corresponding address field of any datagram that has 128.119 as the first 16 bits of its address. Each flow table entry also has an associated priority. If a packet matches multiple flow table entries, the selected match and corresponding action will be that of the highest priority entry with which the packet matches.</span></p>
<p><span class="font53">Lastly, we observe that not all fields in an IP header can be matched. For example OpenFlow does </span><span class="font53" style="font-style:italic;">not</span><span class="font53"> allow matching on the basis of TTL field or datagram length field. Why are some fields allowed for matching, while others are not? Undoubtedly, the answer has to do with the tradeoff between functionality and complexity. The “art” in choosing an abstraction is to provide for enough functionality to accomplish a task (in this case to implement, configure, and manage a wide range of networklayer functions that had previously been implemented through an assortment of network-layer devices), without over-burdening the abstraction with so much detail and generality that it becomes bloated and unusable. Butler Lampson has famously noted [Lampson 1983]:</span></p>
<p><span class="font53" style="font-style:italic;">Do one thing at a time, and do it well. An interface should capture the minimum essentials of an abstraction. Don’t generalize; generalizations are generally wrong.</span></p>
<p><span class="font53">Given OpenFlow’s success, one can surmise that its designers indeed chose their abstraction well. Additional details of OpenFlow matching can be found in [ONF 2020].</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">4.4.2 </span><span class="font23" style="font-weight:bold;">Action</span></p></li></ul>
<p><a name="bookmark345"></a><span class="font53">As shown in Figure 4.28, each flow table entry has a list of zero or more actions that determine the processing that is to be applied to a packet that matches a flow table entry. If there are multiple actions, they are performed in the order specified in the list.</span></p>
<p><span class="font53">Among the most important possible actions are:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Forwarding.</span><span class="font53"> An incoming packet may be forwarded to a particular physical output port, broadcast over all ports (except the port on which it arrived) or multicast over a selected set of ports. The packet may be encapsulated and sent to the remote controller for this device. That controller then may (or may not) take some action on that packet, including installing new flow table entries, and may return the packet to the device for forwarding under the updated set of flow table rules.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Dropping.</span><span class="font53"> A flow table entry with no action indicates that a matched packet should be dropped.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Modify-field.</span><span class="font53"> The values in 10 packet-header fields (all layer 2, 3, and 4 fields shown in Figure 4.29 except the IP Protocol field) may be re-written before the packet is forwarded to the chosen output port.</span></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">4.4.3 </span><span class="font23" style="font-weight:bold;">OpenFlow Examples of Match-plus-action in Action</span></p></li></ul>
<p><span class="font53">Having now considered both the match and action components of generalized forwarding, let’s put these ideas together in the context of the sample network shown in Figure 4.30. The network has 6 hosts (h1, h2, h3, h4, h5 and h6) and three packet switches (s1, s2 and s3), each with four local interfaces (numbered 1 through 4). We’ll consider a number of network-wide behaviors that we’d like to implement, and the flow table entries in s1, s2 and s3 needed to implement this behavior.</span></p>
<p><span class="font4">OpenFlow controller</span></p>
<p><span class="font4">Host h6</span></p>
<p><span class="font4">10.3.0.6</span></p>
<p><span class="font4">Host h5</span></p>
<p><span class="font4">10.3.0.5</span></p><img src="networking_files/networking-352.jpg" alt="" style="width:240pt;height:142pt;">
<p><span class="font4">Host h4 10.2.0.4</span></p>
<p><span class="font4">Host h1</span></p>
<p><span class="font4">10.1.0.1</span></p>
<p><span class="font4">Host h3</span></p>
<p><span class="font4">10.2.0.3</span></p>
<p><span class="font4">Host h2</span></p>
<p><span class="font4">10.1.0.2</span></p>
<p><a name="bookmark346"></a><span class="font7" style="font-weight:bold;">Figure 4.30 </span><span class="font50">♦ </span><span class="font5">OpenFlow match-plus-action network with three packet switches, 6 hosts, and an OpenFlow controller</span></p>
<p><span class="font22" style="font-weight:bold;">A First Example: Simple Forwarding</span></p>
<p><span class="font53">As a very simple example, suppose that the desired forwarding behavior is that packets from h5 or h6 destined to h3 or h4 are to be forwarded from s3 to s1, and then from s1 to s2 (thus completely avoiding the use of the link between s3 and s2). The flow table entry in s1 would be:</span></p>
<table border="1">
<tr><td colspan="3">
<p><span class="font6">s1 Flow Table (Example 1)</span></p></td></tr>
<tr><td colspan="2" style="vertical-align:bottom;">
<p><span class="font6">Match</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Action</span></p></td></tr>
<tr><td>
<p><span class="font6">Ingress Port = 1</span></p></td><td>
<p><span class="font6">; IP Src = 10.3.*.* ; IP Dst = 10.2.*.*</span></p></td><td>
<p><span class="font6">Forward(4)</span></p></td></tr>
</table>
<p><span class="font53">Of course, we’ll also need a flow table entry in s3 so that datagrams sent from h5 or h6 are forwarded to s1 over outgoing interface 3:</span></p>
<p><span class="font6">s3 Flow Table (Example 1)</span></p>
<p><span class="font6">Match &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Action</span></p>
<p><span class="font6">IP Src = 10.3.*.* ; IP Dst = 10.2.*.* Forward(3)</span></p>
<p><span class="font53">Lastly, we’ll also need a flow table entry in s2 to complete this first example, so that datagrams arriving from s1 are forwarded to their destination, either host h3 or h4:</span></p>
<p><span class="font6">s2 Flow Table (Example 1)</span></p>
<p><span class="font6">Match &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Action</span></p>
<p><span class="font6">Ingress port = 2 ; IP Dst = 10.2.0.3 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Forward(3)</span></p>
<p><span class="font6">Ingress port = 2 ; IP Dst = 10.2.0.4 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Forward(4)</span></p>
<p><span class="font22" style="font-weight:bold;">A Second Example: Load Balancing</span></p>
<p><span class="font53">As a second example, let’s consider a load-balancing scenario, where datagrams from h3 destined to 10.1.*.* are to be forwarded over the direct link between s2 and s1, while datagrams from h4 destined to 10.1.*.* are to be forwarded over the link between s2 and s3 (and then from s3 to s1). Note that this behavior couldn’t be achieved with IP’s destination-based forwarding. In this case, the flow table in s2 would be: </span><span class="font6">s2 Flow Table (Example 2)</span></p>
<p><span class="font6">Match &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Action</span></p>
<p><span class="font6">Ingress port = 3; IP Dst = 10.1.*.* &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Forward(2)</span></p>
<p><span class="font6">Ingress port = 4; IP Dst = 10.1.*.* &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Forward(1)</span></p>
<p><span class="font53">Flow table entries are also needed at si to forward the datagrams received from s2 to either hi or h2; and flow table entries are needed at s3 to forward datagrams received on interface 4 from s2 over interface 3 toward si. See if you can figure out these flow table entries at si and s3.</span></p>
<p><span class="font22" style="font-weight:bold;">A Third Example: Firewalling</span></p>
<p><span class="font53">As a third example, let’s consider a firewall scenario in which s2 wants only to receive (on any of its interfaces) traffic sent from hosts attached to s3.</span></p>
<p><span class="font6">s2 Flow Table (Example 3)</span></p>
<p><span class="font6">Match &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Action</span></p>
<p><span class="font6">IP Src = 10.3.*.* IP Dst = 10.2.0.3 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Forward(3)</span></p>
<p><span class="font6">IP Src = 10.3.*.* IP Dst = 10.2.0.4 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Forward(4)</span></p>
<p><span class="font53">If there were no other entries in s2’s flow table, then only traffic from 10.3.*.* would be forwarded to the hosts attached to s2.</span></p>
<p><span class="font53">Although we’ve only considered a few basic scenarios here, the versatility and advantages of generalized forwarding are hopefully apparent. In homework problems, we’ll explore how flow tables can be used to create many different logical behaviors, including virtual networks—two or more logically separate networks (each with their own independent and distinct forwarding behavior)—that use the </span><span class="font53" style="font-style:italic;">same</span><span class="font53"> physical set of packet switches and links. In Section 5.5, we’ll return to flow tables when we study the SDN controllers that compute and distribute the flow tables, and the protocol used for communicating between a packet switch and its controller.</span></p>
<p><span class="font53">The match-plus-action flow tables that we’ve seen in this section are actually a limited form of </span><span class="font53" style="font-style:italic;">programmability,</span><span class="font53"> specifying how a router should forward and manipulate (e.g., change a header field) a datagram, based on the match between the datagram’s header values and the matching conditions. One could imagine an even richer form of programmability—a programming language with higher-level constructs such as variables, general purpose arithmetic and Boolean operations, variables, functions, and conditional statements, as well as constructs specifically designed for datagram processing at line rate. P4 (Programming Protocol-independent Packet Processors) [P4 2020] is such a language, and has gained considerable interest and traction since its introduction five years ago [Bosshart 2014].</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">4.5 </span><span class="font24" style="font-weight:bold;">Middleboxes</span></p></li></ul>
<p><span class="font53">Routers are the workhorses of the network layer, and in this chapter, we’ve learned how they accomplish their “bread and butter” job of forwarding IP datagrams toward their destination. But in this chapter, and in earlier chapters, we’ve also encountered other network equipment (“boxes”) within the network that sit on the data path and perform functions other than forwarding. We encountered Web caches in Section 2.2.5; TCP connection splitters in section 3.7; and network address translation (NAT), firewalls, and intrusion detection systems in Section 4.3.4. We learned in Section 4.4 that generalized forwarding allows a modern router to easily and naturally perform firewalling and load balancing with generalized “match plus action” operations.</span></p>
<p><span class="font53">In the past 20 years, we’ve seen tremendous growth in such </span><span class="font53" style="font-weight:bold;">middleboxes</span><span class="font53">, which RFC 3234 defines as:</span></p>
<p><span class="font53" style="font-style:italic;">“any intermediary box performing functions apart from normal, standard functions of an IP router on the data path between a source host and destination host”</span></p>
<p><span class="font53">We can broadly identify three types of services performed by middleboxes:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">NAT Translation.</span><span class="font53"> As we saw in Section 4.3.4, NAT boxes implement private network addressing, rewriting datagram header IP addresses and port numbers.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Security Services.</span><span class="font53"> Firewalls block traffic based on header-field values or redirect packets for additional processing, such as deep packet inspection (DPI). Intrusion Detection Systems (IDS) are able to detect predetermined patterns and filter packets accordingly. Application-level e-mail filters block e-mails considered to be junk, phishing or otherwise posing a security threat.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Performance Enhancement.</span><span class="font53"> These middleboxes perform services such as compression, content caching, and load balancing of service requests (e.g., an HTTP request, or a search engine query) to one of a set of servers that can provide the desired service.</span></p></li></ul>
<p><span class="font53">Many other middleboxes [RFC 3234] provide capabilities belonging to these three types of services, in both wired and wireless cellular [Wang 2011] networks.</span></p>
<p><a name="bookmark347"></a><span class="font53">With the proliferation of middleboxes comes the attendant need to operate, manage, and upgrade this equipment. Separate specialized hardware boxes, separate software stacks, and separate management/operation skills translate to significant operational and capital costs. It is perhaps not surprising then that researchers are exploring the use of commodity hardware (networking, computing, and storage) with specialized software built on top of a common software stack—</span><span class="font53" style="font-style:italic;">exactly</span><span class="font53"> the approach taken in SDN a decade earlier—to implement these services. This approach has become known as </span><span class="font53" style="font-weight:bold;">network function virtualization (NFV) </span><span class="font53">[Mijumbi 2016]. An alternate approach that has also been explored is to outsource middlebox functionality to the cloud [Sherry 2012].</span></p>
<p><span class="font53">For many years, the Internet architecture had a clear separation between the network layer and the transport/application layers. In these “good old days,” the network layer consisted of routers, operating within the network </span><span class="font53" style="font-style:italic;">core,</span><span class="font53"> to forward datagrams toward their destinations using fields only in the IP datagram header. The transport and application layers were implemented in hosts operating at the network </span><span class="font53" style="font-style:italic;">edge.</span><span class="font53"> Hosts exchanged packets among themselves in transport-layer segments and application-layer messages. Today’s middleboxes clearly violate this separation: a NAT box, sitting between a router and host, rewrites network-layer IP addresses and transport-layer port numbers; an in-network firewall blocks suspect datagrams using application-layer (e.g., HTTP), transport-layer, and network-layer header fields; e-mail security gateways are injected between the e-mail sender (whether malicious or not) and the intended e-mail receiver, filtering application-layer e-mail messages based on whitelisted/blacklisted IP addresses as well as e-mail message content. While there are those who have considered such middleboxes as a bit of an architectural abomination [Garfinkel 2003], others have adopted the philosophy that such middleboxes “exist for important and permanent reasons”—that they fill an important need—and that we’ll have more, not fewer, middleboxes in the future [Walfish 2004]. See the section in attached sidebar on “The end-to-end argument” for a slightly different lens on the question of where to place service functionality in a network.</span></p>
<div><img src="networking_files/networking-353.jpg" alt="" style="width:133pt;height:22pt;">
<p><span class="font4" style="font-weight:bold;">ARCHITECTURAL PRINCIPLES OF THE INTERNET</span></p>
</div><br clear="all">
<div>
<p><span class="font23" style="font-weight:bold;">PRINCIPLES IN PRACTICE</span></p>
</div><br clear="all">
<p><span class="font4">Given the phenomenal success of the Internet, one might naturally wonder about the architectural principles that have guided the development of what is arguably the largest and most complex engineered system ever built by humankind. RFC 1958, entitled “Architectural Principles of the Internet,” suggests that these principles, if indeed they exist, are truly minimal:</span></p>
<p><span class="font4">“Many members of the Internet community would argue that there is no architecture, but only a tradition, which was not written down for the first 25 years (or at least not by the IAB). However, in very general terms, the community believes that the goal is connectivity, the tool is the Internet Protocol, and the intelligence is end to end rather than hidden in the network.” [RFC 1958]</span></p>
<p><span class="font4">So there we have it! The goal was to provide connectivity, there would be just one network-layer protocol (the celebrated IP protocol we have studied in this chapter), and “intelligence” (one might say the “complexity”) would be placed at the network edge, rather than in the network core. Let's look these last two considerations in a bit more detail.</span></p>
<p><span class="font4" style="font-weight:bold;">THE IP HOURGLASS</span></p>
<p><span class="font4">By now, we're well acquainted with the five-layer Internet protocol stack that we first encountered in Figure 1.23. Another visualization of this stack, shown in Figure 4.31 and sometimes known as the “</span><span class="font5" style="font-weight:bold;">IP hourglass</span><span class="font4">,” illustrates the “</span><span class="font5" style="font-weight:bold;">narrow waist</span><span class="font4">” of the layered Internet architecture. While the Internet has many protocols in the physical, link, transport, and application layers, there is only </span><span class="font4" style="font-style:italic;">one</span><span class="font4"> network layer protocol—the IP protocol. This is the one protocol that </span><span class="font4" style="font-style:italic;">must</span><span class="font4"> be implemented by each and every of the billions of Internet-connected devices. This narrow waist has played a critical role in the phenomenal growth of the Internet. The relative simplicity of the IP protocol, and the fact that it is the </span><span class="font4" style="font-style:italic;">only </span><span class="font4">universal requirement for Internet connectivity has allowed a rich variety of networks—with very different underlying link-layer technologies, from Ethernet to WiFi to cellular to optical networks to become part of the Internet. [Clark 1997] notes that role of the narrow waist, which he refers to as a “spanning layer,” is to &quot;... hide the detailed differences among these various [underlying] technologies and present a uniform service interface to the applications above.” For the IP layer in particular: “How does the IP spanning layer achieve its purpose? It defines a basic set of services, which were carefully designed so that they could be constructed from a wide range of underlying network technologies. Software, as a part of the Internet [i.e., network] layer, translates what each of these lower-layer technologies offers into the common service of the Internet layer.”</span></p>
<p><span class="font4">For a discussion the narrow waist, including examples beyond the Internet, see [Beck 2019; Akhshabi 2011]. We note here that as the Internet architecture enters mid-life (certainly,</span></p>
<p><span class="font4" style="text-decoration:underline;">( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;T</span></p>
<p><span class="font5">HTTP SMTP RTP &nbsp;&nbsp;&nbsp;)</span></p>
<p><span class="font5">\</span><span class="font5" style="text-decoration:underline;"> </span><span class="font5">QUIC</span><span class="font5" style="text-decoration:underline;"> </span><span class="font5">DASH</span><span class="font5" style="text-decoration:underline;"> </span><span class="font5">■/</span></p>
<p><span class="font69">TCP UDP</span></p>
<p><span class="font69">IP</span></p>
<p><span class="font4">/ Ethernet PPP </span><span class="font7">■</span><span class="font69"> 0\ </span><span class="font4">/ PDCPWiFi Bluetooth\</span></p>
<p><span class="font5">/ copper radio fiber \</span></p>
<p><span class="font4" style="text-decoration:underline;">( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 4.31 </span><span class="font50">♦ </span><span class="font5">The narrow-waisted Internet hourglass </span><span class="font4">the Internet's age of 40 to 50 years qualifies it for middle age!), one might observe that its “narrow waist” may indeed be widening a bit (as often happens in middle age!) via the rise of middleboxes.</span></p>
<p><span class="font4" style="font-weight:bold;">THE END-TO-END ARGUMENT</span></p>
<p><span class="font4">The third principle in RFC 1958—that “intelligence is end to end rather than hidden in the network&quot;—speaks to the placement of functionality within the network. Here, we've seen that until the recent rise of middleboxes, most Internet functionality was indeed placed at the network's edge. It's worth noting that, in direct contrast with the 20<sup>th</sup> century telephone network—which had “dumb&quot; (non-programmable) endpoints and smart switches—the Internet has always had smart endpoints (programmable computers), enabling complex functionality to be placed at those endpoints. But a more principled argument for actually placing functionality at the endpoints was made in an extremely influential paper [Saltzer 1984] that articulated the “end-to-end argument.&quot; It stated:</span></p>
<p><span class="font4">“ . . . there is a list of functions each of which might be implemented in any of several ways: by the communication subsystem, by its client, as a joint venture, or perhaps redundantly, each doing its own version. In reasoning about this choice, the requirements of the application provide the basis for a class of arguments, which go as follows:</span></p>
<p><span class="font4">The function in question can completely and correctly be implemented only with the knowledge and help of the application standing at the end points of the communication system. Therefore, providing that questioned function as a feature of the communication system itself is not possible. (Sometimes an incomplete version of the function provided by the communication system may be useful as a performance enhancement.)</span></p>
<p><span class="font4">We call this line of reasoning against low-level function implementation the “end-to-end argument.&quot;</span></p>
<p><span class="font4">An example illustrating the end-to-end argument is that of reliable data transfer. Since packets can be lost within the network (e.g., even without buffer overflows, a router holding a queued packet could crash, or a portion of the network in which a packet is queued becomes detached due to link failures), the endpoints (in this case via the TCP protocol) </span><span class="font4" style="font-style:italic;">must</span><span class="font4"> perform error control. As we will see in Chapter 6, some link-layer protocols do indeed perform local error control, but this local error control alone is “incomplete&quot; and not sufficient to provide end-to-end reliable data transfer. And so reliable data transfer must be implemented end to end.</span></p>
<p><span class="font4">RFC 1958 deliberately includes only two references, both of which are “fundamental papers on the Internet architecture.&quot; One of these is the end-to-end paper itself [Saltzer 1984]; the second paper [Clark 1988] discusses the design philosophy of the DARPA Internet Protocols. Both are interesting “must reads&quot; for anyone interested in Internet architecture. Follow-ons to [Clark 1988] are [Blumenthal 2001; Clark 2005] which reconsider Internet architecture in light of the much more complex environment in which today's Internet must now operate.</span></p>
<p><span class="font59" style="font-weight:bold;">4.6 </span><span class="font24" style="font-weight:bold;">Summary</span></p>
<p><span class="font53">In this chapter, we’ve covered the </span><span class="font53" style="font-weight:bold;">data plane </span><span class="font53">functions of the network layer—the </span><span class="font53" style="font-style:italic;">perrouter</span><span class="font53"> functions that determine how packets arriving on one of a router’s input links are forwarded to one of that router’s output links. We began by taking a detailed look at the internal operations of a router, studying input and output port functionality and destinationbased forwarding, a router’s internal switching mechanism, packet queue management and more. We covered both traditional IP forwarding (where forwarding is based on a datagram’s destination address) and generalized forwarding (where forwarding and other functions may be performed using values in several different fields in the datagram’s header) and seen the versatility of the latter approach. We also studied the IPv4 and IPv6 protocols in detail, and Internet addressing, which we found to be much deeper, subtler, and more interesting than we might have expected. We completed our study of the network-layer data plane with a study of middleboxes, and a broad discussion of Internet architecture.</span></p>
<p><span class="font53">With our newfound understanding of the network-layer’s data plane, we’re now ready to dive into the network layer’s control plane in Chapter 5!</span></p>
<p><span class="font24" style="font-weight:bold;">Homework Problems and Questions</span></p>
<p><span class="font23" style="font-weight:bold;">Chapter 4 Review Questions</span></p>
<p><span class="font43" style="font-weight:bold;">SECTION 4.1</span></p>
<p><span class="font53">R1. Let’s review some of the terminology used in this textbook. Recall that the name of a transport-layer packet is </span><span class="font53" style="font-style:italic;">segment</span><span class="font53"> and that the name of a link-layer packet is </span><span class="font53" style="font-style:italic;">frame.</span><span class="font53"> What is the name of a network-layer packet? Recall that both routers and link-layer switches are called </span><span class="font53" style="font-style:italic;">packet switches.</span><span class="font53"> What is the fundamental difference between a router and link-layer switch?</span></p>
<p><span class="font53">R2. We noted that network layer functionality can be broadly divided into data plane functionality and control plane functionality. What are the main functions of the data plane? Of the control plane?</span></p>
<p><span class="font53">R3. We made a distinction between the forwarding function and the routing function performed in the network layer. What are the key differences between routing and forwarding?</span></p>
<p><span class="font53">R4. What is the role of the forwarding table within a router?</span></p>
<p><span class="font53">R5. We said that a network layer’s service model “defines the characteristics of end-to-end transport of packets between sending and receiving hosts.” What is the service model of the Internet’s network layer? What guarantees are made by the Internet’s service model regarding the host-to-host delivery of datagrams?</span></p>
<p><span class="font43" style="font-weight:bold;">SECTION 4.2</span></p>
<p><a name="bookmark348"></a><span class="font53">R6. In Section 4.2, we saw that a router typically consists of input ports, output ports, a switching fabric and a routing processor. Which of these are implemented in hardware and which are implemented in software? Why? Returning to the notion of the network layer’s data plane and control plane, which are implemented in hardware and which are implemented in software? Why?</span></p>
<p><span class="font53">R7. How can the input ports of a high-speed router facilitate fast forwarding decisions?</span></p>
<p><span class="font53">R8. What is meant by destination-based forwarding? How does this differ from generalized forwarding (assuming you’ve read Section 4.4, which of the two approaches are adopted by Software-Defined Networking)?</span></p>
<p><span class="font53">R9. Suppose that an arriving packet matches two or more entries in a router’s forwarding table. With traditional destination-based forwarding, what rule does a router apply to determine which of these rules should be applied to determine the output port to which the arriving packet should be switched?</span></p>
<p><span class="font53">R10. Switching in a router forwards data from an input port to an output port. What is the advantage of switching via an interconnection network over switching via memory and switching via bus?</span></p>
<p><span class="font53">R11. What is the role of a </span><span class="font53" style="font-style:italic;">packet scheduler</span><span class="font53"> at the output port of a router?</span></p>
<p><span class="font53">R12. a. What is a drop-tail policy?</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">b. What are AQM algorithms?</span></p></li>
<li>
<p><span class="font53">c. Name one of the most widely studied and implemented AQM algorithms and explain how it works.</span></p></li></ul>
<p><span class="font53">R13. What is HOL blocking? Does it occur in input ports or output ports?</span></p>
<p><span class="font53">R14. In Section 4.2, we studied FIFO, Priority, Round Robin (RR), and Weighted Fair Queuing (WFQ) packet scheduling disciplines? Which of these queuing disciplines ensure that all packets depart in the order in which they arrived?</span></p>
<p><span class="font53">R15. Give an example showing why a network operator might want one class of packets to be given priority over another class of packets.</span></p>
<p><span class="font53">R16. What is an essential different between RR and WFQ packet scheduling? Is there a case </span><span class="font53" style="font-style:italic;">(Hint:</span><span class="font53"> Consider the WFQ weights) where RR and WFQ will behave exactly the same?</span></p>
<p><span class="font43" style="font-weight:bold;">SECTION 4.3</span></p>
<p><span class="font53">R17. Suppose Host A sends Host B a TCP segment encapsulated in an IP datagram. When Host B receives the datagram, how does the network layer in Host B know it should pass the segment (that is, the payload of the datagram) to TCP rather than to UDP or to some other upper-layer protocol?</span></p>
<p><span class="font53">R18. What field in the IP header can be used to ensure that a packet is forwarded through no more than </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> routers?</span></p>
<p><span class="font53">R19. Recall that we saw the Internet checksum being used in both transport-layer segment (in UDP and TCP headers, Figures 3.7 and 3.29 respectively) and in network-layer datagrams (IP header, Figure 4.17). Now consider a transport layer segment encapsulated in an IP datagram. Are the checksums in the segment header and datagram header computed over any common bytes in the IP datagram? Explain your answer.</span></p>
<p><span class="font53">R20. When a large datagram is fragmented into multiple smaller datagrams, where are these smaller datagrams reassembled into a single larger datagram?</span></p>
<p><span class="font53">R21. How many IP addresses does a router have?</span></p>
<p><span class="font53">R22. What is the 32-bit binary equivalent of the IP address 202.3.14.25?</span></p>
<p><span class="font53">R23. Visit a host that uses DHCP to obtain its IP address, network mask, default router, and IP address of its local DNS server. List these values.</span></p>
<p><span class="font53">R24. Suppose there are four routers between a source host and a destination host. Ignoring fragmentation, an IP datagram sent from the source host to the destination host will travel over how many interfaces? How many forwarding tables will be indexed to move the datagram from the source to the destination?</span></p>
<p><span class="font53">R25. Suppose an application generates chunks of 40 bytes of data every 20 msec, and each chunk gets encapsulated in a TCP segment and then an IP datagram. What percentage of each datagram will be overhead, and what percentage will be application data?</span></p>
<p><span class="font53">R26. Suppose you purchase a wireless router and connect it to your cable modem. Also suppose that your ISP dynamically assigns your connected device (that is, your wireless router) one IP address. Also suppose that you have five PCs at home that use 802.11 to wirelessly connect to your wireless router. How are IP addresses assigned to the five PCs? Does the wireless router use NAT? Why or why not?</span></p>
<p><span class="font53">R27. What is meant by the term “route aggregation”? Why is it useful for a router to perform route aggregation?</span></p>
<p><span class="font53">R28. What is meant by a “plug-and-play” or “zeroconf” protocol?</span></p>
<p><span class="font53">R29. What is a private network address? Should a datagram with a private network address ever be present in the larger public Internet? Explain.</span></p>
<p><span class="font53">R30. Compare and contrast the IPv4 and the IPv6 header fields. Do they have any fields in common?</span></p>
<p><span class="font53">R31. It has been said that when IPv6 tunnels through IPv4 routers, IPv6 treats the IPv4 tunnels as link-layer protocols. Do you agree with this statement? Why or why not?</span></p>
<p><span class="font43" style="font-weight:bold;">SECTION 4.4</span></p>
<p><span class="font53">R32. How does generalized forwarding differ from destination-based forwarding?</span></p>
<p><span class="font53">R33. What is the difference between a forwarding table that we encountered in destination-based forwarding in Section 4.1 and OpenFlow’s flow table that we encountered in Section 4.4?</span></p>
<p><span class="font53">R34. What is meant by the “match plus action” operation of a router or switch? In the case of destination-based forwarding packet switch, what is matched and what is the action taken? In the case of an SDN, name three fields that can be matched, and three actions that can be taken.</span></p>
<p><span class="font53">R35. Name three header fields in an IP datagram that can be “matched” in OpenFlow 1.0 generalized forwarding. What are three IP datagram header fields that </span><span class="font53" style="font-style:italic;">cannot</span><span class="font53"> be “matched” in OpenFlow?</span></p>
<p><span class="font24" style="font-weight:bold;">Problems</span></p>
<p><span class="font53">P1. Consider the network below.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Show the forwarding table in router A, such that all traffic destined to host H3 is forwarded through interface 3.</span></p></li>
<li>
<p><span class="font53">b. Can you write down a forwarding table in router A, such that all traffic from H1 destined to host H3 is forwarded through interface 3, while all traffic from H2 destined to host H3 is forwarded through interface 4? </span><span class="font53" style="font-style:italic;">(Hint:</span><span class="font53"> This is a trick question.)</span></p></li></ul><img src="networking_files/networking-354.jpg" alt="" style="width:234pt;height:89pt;">
<p><span class="font4">H2</span></p>
<p><span class="font53">P2. Suppose two packets arrive to two different input ports of a router at exactly the same time. Also suppose there are no other packets anywhere in the router.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Suppose the two packets are to be forwarded to two different output ports. Is it possible to forward the two packets through the switch fabric at the same time when the fabric uses a shared bus?</span></p></li>
<li>
<p><span class="font53">b. Suppose the two packets are to be forwarded to two different output ports. Is it possible to forward the two packets through the switch fabric at the same time when the fabric uses switching via memory?</span></p></li>
<li>
<p><span class="font53">c. Suppose the two packets are to be forwarded to the same output port. Is it possible to forward the two packets through the switch fabric at the same time when the fabric uses a crossbar?</span></p></li></ul>
<p><span class="font53">P3. In Section 4.2.4, it was said that if </span><span class="font53" style="font-style:italic;">R_switch</span><span class="font53"> is </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> times faster than </span><span class="font53" style="font-style:italic;">R_line, </span><span class="font53">then only negligible queuing will occur at the input ports, even if all the packets are to be forwarded to the same output port. Now suppose that </span><span class="font53" style="font-style:italic;">R_switch = R_line,</span><span class="font53"> but all packets are to be forwarded to different output ports. Let </span><span class="font53" style="font-style:italic;">D</span><span class="font53"> be the time to transmit a packet. As a function of </span><span class="font53" style="font-style:italic;">D,</span><span class="font53"> what is the maximum input queuing delay for a packet for the (a) memory, (b) bus, and (c) crossbar switching fabrics?</span></p>
<p><span class="font53">P4. Consider the switch shown below. Suppose that all datagrams have the same fixed length, that the switch operates in a slotted, synchronous manner, and that in one time slot a datagram can be transferred from an input port to an output port. The switch fabric is a crossbar so that at most one datagram can be transferred to a given output port in a time slot, but different output ports can receive datagrams from different input ports in a single time slot. What is the minimal number of time slots needed to transfer the packets shown from input ports to their output ports, assuming any input queue scheduling order you want (i.e., it need not have HOL blocking)? What is the largest number of slots needed, assuming the worst-case scheduling order you can devise, assuming that a non-empty input queue is never idle?</span></p><img src="networking_files/networking-355.jpg" alt="" style="width:175pt;height:90pt;">
<p><span class="font4">Output port X —►</span></p>
<p><span class="font4">Output port Y --►</span></p>
<p><span class="font4">Output port Z --►</span></p>
<p><span class="font53">P5. Suppose that the WEQ scheduling policy is applied to a buffer that supports three classes, and suppose the weights are 0.5, 0.25, and 0.25 for the three classes.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Suppose that each class has a large number of packets in the buffer.</span></p></li></ul>
<p><span class="font53">In what sequence might the three classes be served in order to achieve the WFQ weights? (For round robin scheduling, a natural sequence is 123123123 . . .).</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">b. Suppose that classes 1 and 2 have a large number of packets in the buffer, and there are no class 3 packets in the buffer. In what sequence might the three classes be served in to achieve the WFQ weights?</span></p></li></ul>
<p><span class="font53">P6. Consider the figure below. Answer the following questions:</span></p>
<div><img src="networking_files/networking-356.jpg" alt="" style="width:116pt;height:67pt;">
</div><br clear="all">
<div><img src="networking_files/networking-357.jpg" alt="" style="width:38pt;height:67pt;">
</div><br clear="all">
<div>
<p><span class="font4">t—► Time</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Packet in service</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-358.jpg" alt="" style="width:21pt;height:13pt;">
</div><br clear="all">
<div>
<p><span class="font4">I------1------1—</span></p>
<p><span class="font4" style="font-style:italic;">t =</span><span class="font4"> 0 </span><span class="font4" style="font-style:italic;">t = 2</span></p>
<p><span class="font4">Departures &nbsp;&nbsp;&nbsp;I</span></p>
</div><br clear="all">
<div>
<p><span class="font4">—I----------------1----------------1----------------1---------------1----------------1----------------1----------------1----------------1----------</span></p>
<p><span class="font4" style="font-style:italic;">t</span><span class="font4"> = 6 </span><span class="font4" style="font-style:italic;">t</span><span class="font4"> = 8 </span><span class="font4" style="font-style:italic;">t</span><span class="font4"> = 10 </span><span class="font4" style="font-style:italic;">t</span><span class="font4"> = 12 </span><span class="font4" style="font-style:italic;">t</span><span class="font4"> = 14</span></p>
</div><br clear="all">
<div>
<p><span class="font4">t—► Time</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-359.jpg" alt="" style="width:18pt;height:11pt;">
</div><br clear="all">
<ul style="list-style:none;"><li>
<p><span class="font53">a. Assuming FIFO service, indicate the time at which packets 2 through</span></p></li></ul>
<p><span class="font53">12 each leave the queue. For each packet, what is the delay between its arrival and the beginning of the slot in which it is transmitted? What is the average of this delay over all 12 packets?</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">b. Now assume a priority service, and assume that odd-numbered packets are high priority, and even-numbered packets are low priority. Indicate the time at which packets 2 through 12 each leave the queue. For each packet, what is the delay between its arrival and the beginning of the slot in which it is transmitted? What is the average of this delay over all 12 packets?</span></p></li>
<li>
<p><span class="font53">c. Now assume round robin service. Assume that packets 1, 2, 3, 6, 11, and 12 are from class 1, and packets 4, 5, 7, 8, 9, and 10 are from class 2. Indicate the time at which packets 2 through 12 each leave the queue. For each packet, what is the delay between its arrival and its departure? What is the average delay over all 12 packets?</span></p></li>
<li>
<p><span class="font53">d. Now assume weighted fair queuing (WFQ) service. Assume that odd-numbered packets are from class 1, and even-numbered packets are from class 2. Class 1 has a WFQ weight of 2, while class 2 has a WFQ weight of 1. Note that it may not be possible to achieve an idealized WFQ schedule as described in the text, so indicate why you have chosen the particular packet to go into service at each time slot. For each packet what is the delay between its arrival and its departure? What is the average delay over all 12 packets?</span></p></li>
<li>
<p><span class="font53">e. What do you notice about the average delay in all four cases (FIFO, RR, priority, and WFQ)?</span></p></li></ul>
<p><span class="font53">P7. Consider again the figure for P6.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Assume a priority service, with packets 1, 4, 5, 6, and 11 being high-priority packets. The remaining packets are low priority. Indicate the slots in which packets 2 through 12 each leave the queue.</span></p></li>
<li>
<p><span class="font53">b. Now suppose that round robin service is used, with packets 1, 4, 5, 6, and</span></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font53">11 belonging to one class of traffic, and the remaining packets belonging to the second class of traffic. Indicate the slots in which packets 2 through</span></p></li>
<li>
<p><span class="font53">12 each leave the queue.</span></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font53">c. Now suppose that WFQ service is used, with packets 1, 4, 5, 6, and 11 belonging to one class of traffic, and the remaining packets belonging to the second class of traffic. Class 1 has a WFQ weight of 1, while class 2 has a WFQ weight of 2 (note that these weights are different than in the previous question). Indicate the slots in which packets 2 through 12 each leave the queue. See also the caveat in the question above regarding WFQ service.</span></p></li></ul>
<p><span class="font53">P8. Consider a datagram network using 32-bit host addresses. Suppose a router has four links, numbered 0 through 3, and packets are to be forwarded to the link interfaces as follows:</span></p>
<p><span class="font53" style="font-weight:bold;">Destination Address Range &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Link Interface</span></p>
<p><a href="#bookmark349"><span class="font53">11100000 00000000 00000000 00000000 through</span></a></p>
<p><span class="font53">11100000 00111111 11111111 11111111</span></p>
<p><span class="font53">11100000 01000000 00000000 00000000</span></p>
<p><a href="#bookmark350"><span class="font53">through</span></a></p>
<p><span class="font53">11100000 01000000 11111111 11111111</span></p>
<p><span class="font53">11100000 01000001 00000000 00000000</span></p>
<p><a href="#bookmark351"><span class="font53">through</span></a></p>
<p><span class="font53">11100001 01111111 11111111 11111111</span></p>
<p><span class="font53">otherwise</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Provide a forwarding table that has five entries, uses longest prefix matching, and forwards packets to the correct link interfaces.</span></p></li>
<li>
<p><span class="font53">b. Describe how your forwarding table determines the appropriate link interface for datagrams with destination addresses:</span></p></li></ul>
<p><span class="font53">11001000 10010001 01010001 01010101</span></p>
<p><span class="font53">11100001 01000000 11000011 00111100</span></p>
<p><span class="font53">11100001 10000000 00010001 01110111 P9. Consider a datagram network using 8-bit host addresses. Suppose a router uses longest prefix matching and has the following forwarding table:</span></p>
<table border="1">
<tr><td>
<p><span class="font6">Prefix Match</span></p></td><td>
<p><span class="font6">Interface</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">00</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">0</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">010</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">1</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">011</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">2</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">10</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">2</span></p></td></tr>
<tr><td>
<p><span class="font6">11</span></p></td><td>
<p><span class="font6">3</span></p></td></tr>
</table>
<p><span class="font53">For each of the four interfaces, give the associated range of destination host addresses and the number of addresses in the range.</span></p>
<p><span class="font53">P10. Consider a datagram network using 8-bit host addresses. Suppose a router uses longest prefix matching and has the following forwarding table:</span></p>
<table border="1">
<tr><td>
<p><span class="font6">Prefix Match</span></p></td><td>
<p><span class="font6">Interface</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">0</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">10</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">1</span></p></td></tr>
<tr><td>
<p><span class="font6">111</span></p></td><td>
<p><span class="font6">2</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">otherwise</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">3</span></p></td></tr>
</table>
<p><span class="font53">For each of the four interfaces, give the associated range of destination host addresses and the number of addresses in the range.</span></p>
<p><span class="font53">P11. Consider a router that interconnects three subnets: Subnet 1, Subnet 2, and Subnet 3. Suppose all of the interfaces in each of these three subnets are required to have the prefix 223.1.17/24. Also suppose that Subnet 1 is required to support at least 60 interfaces, Subnet 2 is to support at least 90 interfaces, and Subnet 3 is to support at least 12 interfaces. Provide three network addresses (of the form a.b.c.d/x) that satisfy these constraints.</span></p>
<p><span class="font53">P12. In Section 4.2.2, an example forwarding table (using longest prefix matching) is given. Rewrite this forwarding table using the a.b.c.d/x notation instead of the binary string notation.</span></p>
<p><span class="font53">P13. In Problem P8, you are asked to provide a forwarding table (using longest prefix matching). Rewrite this forwarding table using the a.b.c.d/x notation instead of the binary string notation.</span></p>
<p><span class="font53">P14. Consider a subnet with prefix 128.119.40.128/26. Give an example of one IP address (of form xxx.xxx.xxx.xxx) that can be assigned to this network.</span></p>
<p><span class="font53">Suppose an ISP owns the block of addresses of the form 128.119.40.64/26. Suppose it wants to create four subnets from this block, with each block having the same number of IP addresses. What are the prefixes (of form a.b.c.d/x) for the four subnets?</span></p>
<p><span class="font53">P15. Consider the topology shown in Figure 4.20. Denote the three subnets with hosts (starting clockwise at 12:00) as Networks A, B, and C. Denote the subnets without hosts as Networks D, E, and F.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Assign network addresses to each of these six subnets, with the following constraints: All addresses must be allocated from 214.97.254/23; Subnet A should have enough addresses to support 250 interfaces; Subnet B should have enough addresses to support 120 interfaces; and Subnet C should have enough addresses to support 120 interfaces. Of course, subnets D, E and F should each be able to support two interfaces. For each subnet, the assignment should take the form a.b.c.d/x or a.b.c.d/x - e.f.g.h/y.</span></p></li>
<li>
<p><span class="font53">b. Using your answer to part (a), provide the forwarding tables (using longest prefix matching) for each of the three routers.</span></p></li></ul>
<p><span class="font53">P16. Use the whois service at the American Registry for Internet Numbers (</span><a href="http://www.arin.net/whois"><span class="font53">http://www.arin.net/whois)</span></a><span class="font53"> to determine the IP address blocks for three universities. Can the whois services be used to determine with certainty the geographical location of a specific IP address? Use </span><a href="http://www.maxmind.com"><span class="font53">www.maxmind.com</span></a><span class="font53"> to determine the locations of the Web servers at each of these universities.</span></p>
<p><span class="font53">P17. Suppose datagrams are limited to 1,500 bytes (including header) between source Host A and destination Host B. Assuming a 20-byte IP header, how many datagrams would be required to send an MP3 consisting of 5 million bytes? Explain how you computed your answer.</span></p>
<p><span class="font53">P18. Consider the network setup in Figure 4.25. Suppose that the ISP instead assigns the router the address 24.34.101.225 and that the network address of the home network is 192.168.0/24.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Assign addresses to all interfaces in the home network.</span></p></li>
<li>
<p><span class="font53">b. Suppose each host has two ongoing TCP connections, all to port 80 at host 128.119.40.86. Provide the six corresponding entries in the NAT translation table.</span></p></li></ul>
<p><span class="font53">P19. Suppose you are interested in detecting the number of hosts behind a NAT.</span></p>
<p><span class="font53">You observe that the IP layer stamps an identification number sequentially on each IP packet. The identification number of the first IP packet generated by a host is a random number, and the identification numbers of the subsequent IP packets are sequentially assigned. Assume all IP packets generated by hosts behind the NAT are sent to the outside world.</span></p>
<p><span class="font53">a. Based on this observation, and assuming you can sniff all packets sent by the NAT to the outside, can you outline a simple technique that detects the number of unique hosts behind a NAT? Justify your answer. b. If the identification numbers are not sequentially assigned but randomly assigned, would your technique work? Justify your answer.</span></p>
<p><span class="font53">P20. In this problem, we’ll explore the impact of NATs on P2P applications.</span></p>
<p><span class="font53">Suppose a peer with username Arnold discovers through querying that a peer with username Bernard has a file it wants to download. Also suppose that Bernard and Arnold are both behind a NAT. Try to devise a technique that will allow Arnold to establish a TCP connection with Bernard without application-specific NAT configuration. If you have difficulty devising such a technique, discuss why.</span></p>
<p><span class="font53">P21. Consider the SDN OpenFlow network shown in Figure 4.30. Suppose that the desired forwarding behavior for datagrams arriving at s2 is as follows:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;any datagrams arriving on input port 1 from hosts h5 or h6 that are destined to hosts h1 or h2 should be forwarded over output port 2;</span></p></li>
<li>
<p><span class="font53">• &nbsp;any datagrams arriving on input port 2 from hosts h1 or h2 that are destined to hosts h5 or h6 should be forwarded over output port 1;</span></p></li>
<li>
<p><span class="font53">• &nbsp;any arriving datagrams on input ports 1 or 2 and destined to hosts h3 or h4 should be delivered to the host specified;</span></p></li>
<li>
<p><span class="font53">• &nbsp;hosts h3 and h4 should be able to send datagrams to each other.</span></p></li></ul>
<p><span class="font53">Specify the flow table entries in s2 that implement this forwarding behavior.</span></p>
<p><span class="font53">P22. Consider again the SDN OpenFlow network shown in Figure 4.30. Suppose that the desired forwarding behavior for datagrams arriving from hosts h3 or h4 at s2 is as follows:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;any datagrams arriving from host h3 and destined for h1, h2, h5 or h6 should be forwarded in a clockwise direction in the network;</span></p></li>
<li>
<p><span class="font53">• &nbsp;any datagrams arriving from host h4 and destined for h1, h2, h5 or h6 should be forwarded in a counter-clockwise direction in the network.</span></p></li></ul>
<p><span class="font53">Specify the flow table entries in s2 that implement this forwarding behavior. P23. Consider again the scenario from P21 above. Give the flow tables entries at packet switches s1 and s3, such that any arriving datagrams with a source address of h3 or h4 are routed to the destination hosts specified in the destination address field in the IP datagram. </span><span class="font53" style="font-style:italic;">(Hint:</span><span class="font53"> Your forwarding table rules should include the cases that an arriving datagram is destined for a directly attached host or should be forwarded to a neighboring router for eventual host delivery there.)</span></p>
<p><span class="font53">P24. Consider again the SDN OpenFlow network shown in Figure 4.30. Suppose we want switch s2 to function as a firewall. Specify the flow table in s2 that implements the following firewall behaviors (specify a different flow table for each of the four firewalling behaviors below) for delivery of datagrams</span></p>
<p><span class="font53">destined to h3 and h4. You do not need to specify the forwarding behavior in s2 that forwards traffic to other routers.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;Only traffic arriving from hosts h1 and h6 should be delivered to hosts h3 or h4 (i.e., that arriving traffic from hosts h2 and h5 is blocked).</span></p></li>
<li>
<p><span class="font53">• &nbsp;Only TCP traffic is allowed to be delivered to hosts h3 or h4 (i.e., that UDP traffic is blocked).</span></p></li>
<li>
<p><span class="font53">• &nbsp;Only traffic destined to h3 is to be delivered (i.e., all traffic to h4 is blocked).</span></p></li>
<li>
<p><span class="font53">• &nbsp;Only UDP traffic from h1 and destined to h3 is to be delivered. All other traffic is blocked.</span></p></li></ul>
<p><span class="font53">P25. Consider the Internet protocol stack in Figures 1.23 and 4.31. Would you consider the ICMP protocol to be a network-layer protocol or a transportlayer protocol? Justify your answer.</span></p>
<p><span class="font24" style="font-weight:bold;">Wireshark Lab: IP</span></p>
<p><a name="bookmark352"></a><span class="font53">In the Web site for this textbook, </span><a href="http://www.pearsonglobaleditions.com"><span class="font53">www.pearsonglobaleditions.com</span></a><span class="font53">, you’ll find a Wireshark lab assignment that examines the operation of the IP protocol, and the IP datagram format in particular.</span></p>
<p><span class="font23" style="font-weight:bold;">AN INTERVIEW WITH...</span></p>
<p><span class="font13" style="font-weight:bold;">Vinton G. Cerf</span></p>
<div><img src="networking_files/networking-360.jpg" alt="" style="width:86pt;height:110pt;">
<p><span class="font3">Courtesy of Vinton G. Cerf</span></p>
</div><br clear="all">
<p><span class="font46">Vinton G. Cerf has served as Vice President and Chief Internet Evangelist for Google since 2005. He served for over 15 years at MCI in various positions, ending up his tenure there as Senior Vice President for Technology Strategy. He is widely known as the co-designer of the TCP/IP protocols and the architecture of the Internet. During his time from 1976 to 1982 at the US Department of Defense Advanced Research Projects Agency (DARPA), he played a key role leading the development of Internet and Internet-related packet communication and security techniques. He received the US Presidential Medal of Freedom in 2005 and the US National Medal of Technology in 1997. He holds a BS in Mathematics from Stanford University and an MS and PhD in computer science from UCLA.</span></p>
<p><span class="font4" style="font-weight:bold;">What brought you to specialize in networking?</span></p>
<p><span class="font52">I was working as a programmer at UCLA in the late 1960s. My job was supported by the US Defense Advanced Research Projects Agency (called ARPA then and DARPA now). I was working in the laboratory of Professor Leonard Kleinrock in the Network Measurement Center of the newly created ARPANet. The first node of the ARPANet was installed at UCLA on September 1, 1969. I was responsible for programming a computer that was used to capture performance information about the ARPANet and to report this information back for comparison with mathematical models and predictions of the performance of the network.</span></p>
<p><span class="font52">Several of the other graduate students and I were made responsible for working on the so-called host-level protocols of the ARPAnet—the procedures and formats that would allow many different kinds of computers on the network to interact with each other. It was a fascinating exploration into a new world (for me) of distributed computing and communication.</span></p>
<p><span class="font4" style="font-weight:bold;">Did you imagine that IP would become as pervasive as it is today when you first designed the protocol?</span></p>
<p><a name="bookmark353"></a><span class="font52">When Bob Kahn and I first worked on this in 1973, I think we were mostly very focused on the central question: How can we make heterogeneous packet networks interoperate with one another, assuming we cannot actually change the networks themselves? We hoped that we could find a way to permit an arbitrary collection of packet-switched networks to be interconnected in a transparent fashion, so that host computers could communicate end-to-end without having to do any translations in between. I think we knew that we were dealing </span><span class="font43" style="font-weight:bold;">405 </span><span class="font52">with powerful and expandable technology, but I doubt we had a clear image of what the world would be like with billions of computers all interlinked on the Internet.</span></p>
<p><span class="font4" style="font-weight:bold;">What do you now envision for the future of networking and the Internet? What major challenges/obstacles do you think lie ahead in their development?</span></p>
<p><span class="font52">I believe the Internet itself and networks in general will continue to proliferate. There are already billions of Internet-enabled devices on the Internet, including appliances like cell phones, refrigerators, personal digital assistants, home servers, televisions, as well as the usual array of laptops, servers, and so on. Big challenges include support for mobility, battery life, capacity of the access links to the network, and ability to scale the optical core of the network in an unlimited fashion. The interplanetary extension of the Internet is a project that is well underway at NASA and other space agencies. We still need to add IPv6 [128-bit] addressing to the original IPv4 [32-bit addresses] packet format. The list is long!</span></p>
<p><span class="font4" style="font-weight:bold;">Who has inspired you professionally?</span></p>
<p><span class="font52">My colleague Bob Kahn; my thesis advisor, Gerald Estrin; my best friend, Steve Crocker (we met in high school and he introduced me to computers in 1960!); and the thousands of engineers who continue to evolve the Internet today.</span></p>
<p><span class="font4" style="font-weight:bold;">Do you have any advice for students entering the networking/Internet field?</span></p>
<p><span class="font52">Think outside the limitations of existing systems—imagine what might be possible; but then do the hard work of figuring out how to get there from the current state of affairs. Dare to dream. The “Internet of Things” is the next big phase of Internet expansion. Safety, security, privacy, reliability, and autonomy all need attention. The interplanetary extension of the terrestrial Internet started as a speculative design but is becoming a reality. It may take decades to implement this, mission by mission, but to paraphrase: “A man’s reach should exceed his grasp, or what are the heavens for?”</span></p><img src="networking_files/networking-361.jpg" alt="" style="width:531pt;height:153pt;">
<h1><a name="bookmark5"></a><span class="font27" style="font-weight:bold;">The Network</span></h1>
<h1><span class="font27" style="font-weight:bold;">Layer: Control</span></h1>
<h1><span class="font27" style="font-weight:bold;">Plane</span></h1>
<p><span class="font53">In this chapter, we’ll complete our journey through the network layer by covering the </span><span class="font53" style="font-weight:bold;">control-plane </span><span class="font53">component of the network layer—the </span><span class="font53" style="font-style:italic;">network-wide</span><span class="font53"> logic that controls not only how a datagram is routed along an end-to-end path from the source host to the destination host, but also how network-layer components and services are configured and managed. In Section 5.2, we’ll cover traditional routing algorithms for computing least cost paths in a graph; these algorithms are the basis for two widely deployed Internet routing protocols: OSPF and BGP, that we’ll cover in Sections 5.3 and 5.4, respectively. As we’ll see, OSPF is a routing protocol that operates within a single ISP’s network. BGP is a routing protocol that serves to interconnect all of the networks in the Internet; BGP is thus often referred to as the “glue” that holds the Internet together. Traditionally, control-plane routing protocols have been implemented together with data-plane forwarding functions, monolithically, within a router. As we learned in the introduction to Chapter 4, software-defined networking (SDN) makes a clear separation between the data and control planes, implementing control-plane functions in a separate “controller” service that is distinct, and remote, from the forwarding components of the routers it controls. We’ll cover SDN controllers in Section 5.5.</span></p>
<p><a name="bookmark354"></a><span class="font53">In Sections 5.6 and 5.7, we’ll cover some of the nuts and bolts of managing an IP network: ICMP (the Internet Control Message Protocol) and SNMP (the Simple Network Management Protocol).</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">5.1 </span><span class="font24" style="font-weight:bold;">Introduction</span></p></li></ul>
<p><span class="font53">Let’s quickly set the context for our study of the network control plane by recalling Figures 4.2 and 4.3. There, we saw that the forwarding table (in the case of destination-based forwarding) and the flow table (in the case of generalized forwarding) were the principal elements that linked the network layer’s data and control planes. We learned that these tables specify the local data-plane forwarding behavior of a router. We saw that in the case of generalized forwarding, the actions taken could include not only forwarding a packet to a router’s output port, but also dropping a packet, replicating a packet, and/or rewriting layer 2, 3 or 4 packet-header fields.</span></p>
<p><span class="font53">In this chapter, we’ll study how those forwarding and flow tables are computed, maintained and installed. In our introduction to the network layer in Section 4.1, we learned that there are two possible approaches for doing so.</span></p>
<p><span class="font53">• </span><span class="font53" style="font-style:italic;">Per-router control.</span><span class="font53"> Figure 5.1 illustrates the case where a routing algorithm runs in each and every router; both a forwarding and a routing function are contained</span></p>
<div>
<p><span class="font4" style="font-weight:bold;">Control plane</span></p>
<p><span class="font4" style="font-weight:bold;">Data plane</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-362.jpg" alt="" style="width:275pt;height:82pt;">
<p><span class="font50">Forwarding Table</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-363.jpg" alt="" style="width:60pt;height:22pt;">
</div><br clear="all">
<div><img src="networking_files/networking-364.jpg" alt="" style="width:178pt;height:54pt;">
</div><br clear="all">
<div><img src="networking_files/networking-365.jpg" alt="" style="width:236pt;height:57pt;">
<p><a name="bookmark355"></a><span class="font7" style="font-weight:bold;">Figure 5.1 </span><span class="font50">♦ </span><span class="font5">Per-router control: Individual routing algorithm components interact in the control plane</span></p>
</div><br clear="all">
<p><span class="font53">within each router. Each router has a routing component that communicates with the routing components in other routers to compute the values for its forwarding table. This per-router control approach has been used in the Internet for decades. The OSPF and BGP protocols that we’ll study in Sections 5.3 and 5.4 are based on this per-router approach to control.</span></p>
<p><span class="font53">• </span><span class="font53" style="font-style:italic;">Logically centralized control.</span><span class="font53"> Figure 5.2 illustrates the case in which a logically centralized controller computes and distributes the forwarding tables to be used by each and every router. As we saw in Sections 4.4 and 4.5, the generalized match-plus-action abstraction allows the router to perform traditional IP forwarding as well as a rich set of other functions (load sharing, firewalling, and NAT) that had been previously implemented in separate middleboxes.</span></p>
<div><img src="networking_files/networking-366.jpg" alt="" style="width:325pt;height:79pt;">
</div><br clear="all">
<p><span class="font4" style="font-weight:bold;">Control plane</span></p>
<div>
<p><span class="font4" style="font-weight:bold;">Data plane</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-367.jpg" alt="" style="width:59pt;height:59pt;">
</div><br clear="all">
<div><img src="networking_files/networking-368.jpg" alt="" style="width:128pt;height:27pt;">
</div><br clear="all">
<div><img src="networking_files/networking-369.jpg" alt="" style="width:60pt;height:60pt;">
</div><br clear="all">
<div><img src="networking_files/networking-370.jpg" alt="" style="width:178pt;height:63pt;">
</div><br clear="all">
<div><img src="networking_files/networking-371.jpg" alt="" style="width:199pt;height:50pt;">
<p><span class="font7" style="font-weight:bold;">Figure 5.2 </span><span class="font50">♦ </span><span class="font5">Logically centralized control: A distinct, typically remote, controller interacts with local control agents (CAs)</span></p>
</div><br clear="all">
<p><span class="font53">The controller interacts with a control agent (CA) in each of the routers via a well-defined protocol to configure and manage that router’s flow table. Typically, the CA has minimum functionality; its job is to communicate with the controller, and to do as the controller commands. Unlike the routing algorithms in Figure 5.1, the CAs do not directly interact with each other nor do they actively take part in computing the forwarding table. This is a key distinction between per-router control and logically centralized control.</span></p>
<p><span class="font53">By “logically centralized” control [Levin 2012] we mean that the routing control service is accessed as if it were a single central service point, even though the service is likely to be implemented via multiple servers for fault-tolerance, and performance scalability reasons. As we will see in Section 5.5, SDN adopts this notion of a logically centralized controller—an approach that is finding increased use in production deployments. Google uses SDN to control the routers in its internal B4 global wide-area network that interconnects its data centers [Jain 2013]. SWAN [Hong 2013], from Microsoft Research, uses a logically centralized controller to manage routing and forwarding between a wide area network and a data center network. Major ISP deployments, including COMCAST’s ActiveCore and Deutsche Telecom’s Access 4.0 are actively integrating SDN into their networks. And as we’ll see in Chapter 8, SDN control is central to 4G/5G cellular networking as well. [AT&amp;T 2019] notes, “ ... SDN, isn’t a vision, a goal, or a promise. It’s a reality. By the end of next year, 75% of our network functions will be fully virtualized and software-controlled.” China Telecom and China Unicom are using SDN both within data centers and between data centers [Li 2015].</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">5.2 </span><span class="font24" style="font-weight:bold;">Routing Algorithms</span></p></li></ul>
<p><span class="font53">In this section, we’ll study </span><span class="font53" style="font-weight:bold;">routing algorithms</span><span class="font53">, whose goal is to determine good paths (equivalently, routes), from senders to receivers, through the network of routers. Typically, a “good” path is one that has the least cost. We’ll see that in practice, however, real-world concerns such as policy issues (for example, a rule such as “router </span><span class="font53" style="font-style:italic;">x,</span><span class="font53"> belonging to organization </span><span class="font53" style="font-style:italic;">Y,</span><span class="font53"> should not forward any packets originating from the network owned by organization </span><span class="font53" style="font-style:italic;">Z</span><span class="font53"> ”) also come into play. We note that whether the network control plane adopts a per-router control approach or a logically centralized approach, there must always be a well-defined sequence of routers that a packet will cross in traveling from sending to receiving host. Thus, the routing algorithms that compute these paths are of fundamental importance, and another candidate for our top-10 list of fundamentally important networking concepts.</span></p>
<p><a name="bookmark356"></a><span class="font53">A graph is used to formulate routing problems. Recall that a </span><span class="font53" style="font-weight:bold;">graph </span><span class="font53" style="font-style:italic;">G = (N, E</span><span class="font53">) is a set </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> of nodes and a collection </span><span class="font53" style="font-style:italic;">E</span><span class="font53"> of edges, where each edge is a pair of nodes from </span><span class="font53" style="font-style:italic;">N</span><span class="font53">. In the context of network-layer routing, the nodes in the graph represent</span></p><img src="networking_files/networking-372.jpg" alt="" style="width:170pt;height:100pt;">
<p><span class="font7" style="font-weight:bold;">Figure 5.3 </span><span class="font50">♦ </span><span class="font5">Abstract graph model of a computer network</span></p>
<p><span class="font53">routers—the points at which packet-forwarding decisions are made—and the edges connecting these nodes represent the physical links between these routers. Such a graph abstraction of a computer network is shown in Figure 5.3. When we study the BGP inter-domain routing protocol, we’ll see that nodes represent networks, and the edge connecting two such nodes represents direction connectivity (know as peering) between the two networks. To view some graphs representing real network maps, see [CAIDA 2020]; for a discussion of how well different graph-based models model the Internet, see [Zegura 1997, Faloutsos 1999, Li 2004].</span></p>
<p><span class="font53">As shown in Figure 5.3, an edge also has a value representing its cost. Typically, an edge’s cost may reflect the physical length of the corresponding link (for example, a transoceanic link might have a higher cost than a short-haul terrestrial link), the link speed, or the monetary cost associated with a link. For our purposes, we’ll simply take the edge costs as a given and won’t worry about how they are determined. For any edge (</span><span class="font53" style="font-style:italic;">x</span><span class="font53">, </span><span class="font53" style="font-style:italic;">y</span><span class="font53">) in </span><span class="font53" style="font-style:italic;">E,</span><span class="font53"> we denote </span><span class="font53" style="font-style:italic;">c(x, y)</span><span class="font53"> as the cost of the edge between nodes </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">y. </span><span class="font53">If the pair (</span><span class="font53" style="font-style:italic;">x</span><span class="font53">, </span><span class="font53" style="font-style:italic;">y</span><span class="font53">) does not belong to </span><span class="font53" style="font-style:italic;">E</span><span class="font53">, we set </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(</span><span class="font53" style="font-style:italic;">x</span><span class="font53">, </span><span class="font53" style="font-style:italic;">y</span><span class="font53">) </span><span class="font54">= &lt;»</span><span class="font53">. Also, we’ll only consider undirected graphs (i.e., graphs whose edges do not have a direction) in our discussion here, so that edge (</span><span class="font53" style="font-style:italic;">x</span><span class="font53">, </span><span class="font53" style="font-style:italic;">y</span><span class="font53">) is the same as edge (</span><span class="font53" style="font-style:italic;">y</span><span class="font53">, </span><span class="font53" style="font-style:italic;">x</span><span class="font53">) and that </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(</span><span class="font53" style="font-style:italic;">x</span><span class="font53">, </span><span class="font53" style="font-style:italic;">y</span><span class="font53">) </span><span class="font54">= </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(</span><span class="font53" style="font-style:italic;">y</span><span class="font53">, </span><span class="font53" style="font-style:italic;">x</span><span class="font53">); however, the algorithms we’ll study can be easily extended to the case of directed links with a different cost in each direction. Also, a node </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> is said to be a </span><span class="font53" style="font-weight:bold;">neighbor </span><span class="font53">of node </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> if (</span><span class="font53" style="font-style:italic;">x</span><span class="font53">, </span><span class="font53" style="font-style:italic;">y</span><span class="font53">) belongs to </span><span class="font53" style="font-style:italic;">E</span><span class="font53">.</span></p>
<p><span class="font53">Given that costs are assigned to the various edges in the graph abstraction, a natural goal of a routing algorithm is to identify the least costly paths between sources and destinations. To make this problem more precise, recall that a </span><span class="font53" style="font-weight:bold;">path </span><span class="font53">in a graph </span><span class="font53" style="font-style:italic;">G = (N, E</span><span class="font53">) is a sequence of nodes (</span><span class="font53" style="font-style:italic;">x</span><span class="font50">1</span><span class="font53">, </span><span class="font53" style="font-style:italic;">x</span><span class="font53"><sub>2</sub>, • • • , </span><span class="font53" style="font-style:italic;">x<sub>p</sub>)</span><span class="font53"> such that each</span></p>
<p><span class="font53">of the pairs (</span><span class="font53" style="font-style:italic;">x</span><span class="font50">1</span><span class="font53">, </span><span class="font53" style="font-style:italic;">x</span><span class="font53"><sub>2</sub>), (</span><span class="font53" style="font-style:italic;">x</span><span class="font53"><sub>2</sub>, </span><span class="font53" style="font-style:italic;">x</span><span class="font53"><sub>3</sub>), • • •, </span><span class="font53" style="font-style:italic;">(x<sub>p</sub></span><span class="font3">_ </span><span class="font50">1</span><span class="font53">, </span><span class="font53" style="font-style:italic;">x<sub>p</sub>)</span><span class="font53"> are edges in </span><span class="font53" style="font-style:italic;">E</span><span class="font53">. The cost of a path</span></p>
<p><span class="font53">(</span><span class="font53" style="font-style:italic;">x</span><span class="font50">1</span><span class="font53">, </span><span class="font53" style="font-style:italic;">x</span><span class="font53"><sub>2</sub>, </span><span class="font55"><sub>g</sub> </span><span class="font53">, </span><span class="font53" style="font-style:italic;">x<sub>p</sub>)</span><span class="font53"> is simply the sum of all the edge costs along the path, that is, </span><span class="font53" style="font-style:italic;">c(x<sub>1</sub>, x<sub>2</sub>)</span><span class="font55"> + </span><span class="font53" style="font-style:italic;">c(x<sub>2</sub>, x<sub>3</sub>)</span><span class="font55"> + <sub>g</sub> + </span><span class="font53" style="font-style:italic;">c(x<sub>p</sub></span><span class="font3">-</span><span class="font50">1, </span><span class="font53" style="font-style:italic;">x<sub>p</sub>).</span><span class="font53"> Given any two nodes </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">y,</span><span class="font53"> there are typically many paths between the two nodes, with each path having a cost. One or more of these paths is a </span><span class="font53" style="font-weight:bold;">least-cost path</span><span class="font53">. The least-cost problem is therefore clear: Find a path between the source and destination that has least cost. In Figure 5.3, for example, the least-cost path between source node </span><span class="font53" style="font-style:italic;">u</span><span class="font53"> and destination node </span><span class="font53" style="font-style:italic;">w</span><span class="font53"> is </span><span class="font53" style="font-style:italic;">(u, x, y, w) </span><span class="font53">with a path cost of 3. Note that if all edges in the graph have the same cost, the leastcost path is also the </span><span class="font53" style="font-weight:bold;">shortest path </span><span class="font53">(that is, the path with the smallest number of links between the source and the destination).</span></p>
<p><span class="font53">As a simple exercise, try finding the least-cost path from node </span><span class="font53" style="font-style:italic;">u</span><span class="font53"> to </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> in Figure 5.3 and reflect for a moment on how you calculated that path. If you are like most people, you found the path from </span><span class="font53" style="font-style:italic;">u</span><span class="font53"> to </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> by examining Figure 5.3, tracing a few routes from </span><span class="font53" style="font-style:italic;">u</span><span class="font53"> to </span><span class="font53" style="font-style:italic;">z</span><span class="font53">, and somehow convincing yourself that the path you had chosen had the least cost among all possible paths. (Did you check all of the 17 possible paths between </span><span class="font53" style="font-style:italic;">u</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">z</span><span class="font53">? Probably not!) Such a calculation is an example of a centralized routing algorithm—the routing algorithm was run in one location, your brain, with complete information about the network. Broadly, one way in which we can classify routing algorithms is according to whether they are centralized or decentralized.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;A </span><span class="font53" style="font-weight:bold;">centralized routing algorithm </span><span class="font53">computes the least-cost path between a source and destination using complete, global knowledge about the network. That is, the algorithm takes the connectivity between all nodes and all link costs as inputs. This then requires that the algorithm somehow obtain this information before actually performing the calculation. The calculation itself can be run at one site (e.g., a logically centralized controller as in Figure 5.2) or could be replicated in the routing component of each and every router (e.g., as in Figure 5.1). The key distinguishing feature here, however, is that the algorithm has complete information about connectivity and link costs. Algorithms with global state information are often referred to as </span><span class="font53" style="font-weight:bold;">link-state (LS) algorithms</span><span class="font53">, since the algorithm must be aware of the cost of each link in the network. We’ll study LS algorithms in Section 5.2.1.</span></p></li>
<li>
<p><span class="font53">• &nbsp;In a </span><span class="font53" style="font-weight:bold;">decentralized routing algorithm</span><span class="font53">, the calculation of the least-cost path is carried out in an iterative, distributed manner by the routers. No node has complete information about the costs of all network links. Instead, each node begins with only the knowledge of the costs of its own directly attached links. Then, through an iterative process of calculation and exchange of information with its neighboring nodes, a node gradually calculates the least-cost path to a destination or set of destinations. The decentralized routing algorithm we’ll study below in Section 5.2.2 is called a distance-vector (DV) algorithm, because each node maintains a vector of estimates of the costs (distances) to all other nodes in the network. Such decentralized algorithms, with interactive message exchange between neighboring routers is perhaps more naturally suited to control planes where the routers interact directly with each other, as in Figure 5.1.</span></p></li></ul>
<p><span class="font53">A second broad way to classify routing algorithms is according to whether they are static or dynamic. In </span><span class="font53" style="font-weight:bold;">static routing algorithms</span><span class="font53">, routes change very slowly over time, often as a result of human intervention (for example, a human manually editing a link costs). </span><span class="font53" style="font-weight:bold;">Dynamic routing algorithms </span><span class="font53">change the routing paths as the network traffic loads or topology change. A dynamic algorithm can be run either periodically or in direct response to topology or link cost changes. While dynamic algorithms are more responsive to network changes, they are also more susceptible to problems such as routing loops and route oscillation.</span></p>
<p><span class="font53">A third way to classify routing algorithms is according to whether they are loadsensitive or load-insensitive. In a </span><span class="font53" style="font-weight:bold;">load-sensitive algorithm</span><span class="font53">, link costs vary dynamically to reflect the current level of congestion in the underlying link. If a high cost is associated with a link that is currently congested, a routing algorithm will tend to choose routes around such a congested link. While early ARPAnet routing algorithms were load-sensitive [McQuillan 1980], a number of difficulties were encountered [Huitema 1998]. Today’s Internet routing algorithms (such as RIP, OSPF, and BGP) are </span><span class="font53" style="font-weight:bold;">load-insensitive</span><span class="font53">, as a link’s cost does not explicitly reflect its current (or recent past) level of congestion.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">5.2.1 </span><span class="font23" style="font-weight:bold;">The Link-State (LS) Routing Algorithm</span></p></li></ul>
<p><span class="font53">Recall that in a link-state algorithm, the network topology and all link costs are known, that is, available as input to the LS algorithm. In practice, this is accomplished by having each node broadcast link-state packets to </span><span class="font53" style="font-style:italic;">all</span><span class="font53"> other nodes in the network, with each link-state packet containing the identities and costs of its attached links. In practice (for example, with the Internet’s OSPF routing protocol, discussed in Section 5.3), this is often accomplished by a </span><span class="font53" style="font-weight:bold;">link-state broadcast </span><span class="font53">algorithm [Perlman 1999]. The result of the nodes’ broadcast is that all nodes have an identical and complete view of the network. Each node can then run the LS algorithm and compute the same set of least-cost paths as every other node.</span></p>
<p><a name="bookmark357"></a><span class="font53">The link-state routing algorithm we present below is known as </span><span class="font53" style="font-style:italic;">Dijkstra’s algorithm,</span><span class="font53"> named after its inventor. A closely related algorithm is Prim’s algorithm; see [Cormen 2001] for a general discussion of graph algorithms. Dijkstra’s algorithm computes the least-cost path from one node (the source, which we will refer to as </span><span class="font53" style="font-style:italic;">u)</span><span class="font53"> to all other nodes in the network. Dijkstra’s algorithm is iterative and has the property that after the </span><span class="font53" style="font-style:italic;">k</span><span class="font53">th iteration of the algorithm, the least-cost paths are known to </span><span class="font53" style="font-style:italic;">k</span><span class="font53"> destination nodes, and among the least-cost paths to all destination nodes, these </span><span class="font53" style="font-style:italic;">k</span><span class="font53"> paths will have the </span><span class="font53" style="font-style:italic;">k</span><span class="font53"> smallest costs. Let us define the following notation:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">D(v):</span><span class="font53"> cost of the least-cost path from the source node to destination </span><span class="font53" style="font-style:italic;">v</span><span class="font53"> as of this iteration of the algorithm.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">p(v):</span><span class="font53"> previous node (neighbor of </span><span class="font53" style="font-style:italic;">v</span><span class="font53">) along the current least-cost path from the source to </span><span class="font53" style="font-style:italic;">v.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">N':</span><span class="font53"> subset of nodes; </span><span class="font53" style="font-style:italic;">v</span><span class="font53"> is in </span><span class="font53" style="font-style:italic;">N'</span><span class="font53"> if the least-cost path from the source to </span><span class="font53" style="font-style:italic;">v</span><span class="font53"> is definitively known.</span></p></li></ul>
<p><span class="font53">The centralized routing algorithm consists of an initialization step followed by a loop. The number of times the loop is executed is equal to the number of nodes in the network. Upon termination, the algorithm will have calculated the shortest paths from the source node </span><span class="font53" style="font-style:italic;">u</span><span class="font53"> to every other node in the network.</span></p>
<p><span class="font22" style="font-weight:bold;">Link-State (LS) Algorithm for Source Node </span><span class="font53" style="font-style:italic;">u</span></p>
<ul style="list-style:none;"><li>
<p><span class="font36">1 &nbsp;&nbsp;</span><span class="font53" style="font-weight:bold;">Initialization:</span></p></li>
<li>
<p><span class="font36">2 &nbsp;&nbsp;&nbsp;N’ = {u}</span></p></li>
<li>
<p><span class="font36">3 &nbsp;&nbsp;for all nodes v</span></p></li>
<li>
<p><span class="font36">4 &nbsp;&nbsp;&nbsp;&nbsp;if v is a neighbor of u</span></p></li>
<li>
<p><span class="font36">5 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;then D(v) = c(u,v)</span></p></li>
<li>
<p><span class="font36">6 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;else D(v) = &lt;»</span></p></li></ul>
<p><span class="font36">7</span></p>
<ul style="list-style:none;"><li>
<p><span class="font36">8 &nbsp;</span><span class="font53" style="font-weight:bold;">Loop</span></p></li>
<li>
<p><span class="font36">9 &nbsp;&nbsp;find w not in N’ such that D(w) is a minimum</span></p></li>
<li>
<p><span class="font36">10 &nbsp;add w to N’</span></p></li>
<li>
<p><span class="font36">11 &nbsp;update D(v) for each neighbor v of w and not in N’:</span></p></li>
<li>
<p><span class="font36">12 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;D(v) = min(D(v), D(w) + c(w,v) )</span></p></li>
<li>
<p><span class="font36">13 &nbsp;&nbsp;/<a name="footnote1"></a><sup><a href="#bookmark358">1</a></sup> new cost to v is either old cost to v or known</span></p></li>
<li>
<p><span class="font36">14 &nbsp;&nbsp;&nbsp;least path cost to w plus cost from w to v <sup><a href="#bookmark358">1</a></sup>/</span></p></li>
<li>
<p><span class="font36">15 </span><span class="font53" style="font-weight:bold;">until </span><span class="font36">N’= N</span></p></li></ul>
<p><span class="font53">As an example, let’s consider the network in Figure 5.3 and compute the leastcost paths from </span><span class="font53" style="font-style:italic;">u</span><span class="font53"> to all possible destinations. A tabular summary of the algorithm’s computation is shown in Table 5.1, where each line in the table gives the values of the algorithm’s variables at the end of the iteration. Let’s consider the few first steps in detail.</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font6" style="font-style:italic;">step</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6" style="font-style:italic;">N'</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6" style="font-style:italic;">D</span><span class="font6"> (</span><span class="font6" style="font-style:italic;">v</span><span class="font6">), </span><span class="font6" style="font-style:italic;">p</span><span class="font6"> (</span><span class="font6" style="font-style:italic;">v</span><span class="font6">)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6" style="font-style:italic;">D </span><span class="font5" style="font-style:italic;">(</span><span class="font6" style="font-style:italic;">w</span><span class="font5" style="font-style:italic;">), </span><span class="font6" style="font-style:italic;">p</span><span class="font6"> (</span><span class="font6" style="font-style:italic;">w</span><span class="font6">)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6" style="font-style:italic;">D</span><span class="font6"> (</span><span class="font6" style="font-style:italic;">x</span><span class="font6">), </span><span class="font6" style="font-style:italic;">p </span><span class="font5" style="font-style:italic;">(</span><span class="font6" style="font-style:italic;">x</span><span class="font5" style="font-style:italic;">)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6" style="font-style:italic;">D</span><span class="font6"> (</span><span class="font6" style="font-style:italic;">y</span><span class="font6">), </span><span class="font6" style="font-style:italic;">p </span><span class="font5" style="font-style:italic;">(</span><span class="font6" style="font-style:italic;">y</span><span class="font5" style="font-style:italic;">)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6" style="font-style:italic;">D</span><span class="font6"> (</span><span class="font6" style="font-style:italic;">z</span><span class="font6">), </span><span class="font6" style="font-style:italic;">p</span><span class="font6"> (</span><span class="font6" style="font-style:italic;">z</span><span class="font6">)</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">u</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">2, u</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">5, u</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">1,u</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6" style="font-variant:small-caps;">to</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6" style="font-variant:small-caps;">to</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">ux</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">2, u</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">4, x</span></p></td><td></td><td style="vertical-align:bottom;">
<p><span class="font6">2, x</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6" style="font-variant:small-caps;">to</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">uxy</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">2, u</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">3, y</span></p></td><td></td><td></td><td style="vertical-align:bottom;">
<p><span class="font6">4, y</span></p></td></tr>
<tr><td>
<p><span class="font6">3</span></p></td><td>
<p><span class="font6">uxyv</span></p></td><td></td><td>
<p><span class="font6">3, y</span></p></td><td></td><td></td><td>
<p><span class="font6">4, y</span></p></td></tr>
<tr><td>
<p><span class="font6">4</span></p></td><td>
<p><span class="font6">uxyvw</span></p></td><td></td><td></td><td></td><td></td><td>
<p><span class="font6">4, y</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">5</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">uxyvwz</span></p></td><td></td><td></td><td></td><td></td><td></td></tr>
</table>
<p><span class="font7" style="font-weight:bold;">Table 5.1 </span><span class="font50">♦ </span><span class="font5">Running the link-state algorithm on the network in Figure 5.3</span></p>
<p><span class="font53">particular that the cost to </span><span class="font53" style="font-style:italic;">w</span><span class="font53"> is set to 5 (even though we will soon see that a lesser-cost path does indeed exist) since this is the cost of the direct (one hop) link from </span><span class="font53" style="font-style:italic;">u</span><span class="font53"> to</span></p>
<p><span class="font53" style="font-style:italic;">w.</span><span class="font53"> The costs to </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> are set to infinity because they are not directly connected to </span><span class="font53" style="font-style:italic;">u.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;In the first iteration, we look among those nodes not yet added to the set </span><span class="font53" style="font-style:italic;">N'</span><span class="font53"> and find that node with the least cost as of the end of the previous iteration. That node is </span><span class="font53" style="font-style:italic;">x,</span><span class="font53"> with a cost of 1, and thus </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> is added to the set </span><span class="font53" style="font-style:italic;">N</span><span class="font54">'</span><span class="font53">. Line 12 of the LS algorithm is then performed to update </span><span class="font53" style="font-style:italic;">D(v)</span><span class="font53"> for all nodes </span><span class="font53" style="font-style:italic;">v,</span><span class="font53"> yielding the results shown in the second line (Step 1) in Table 5.1. The cost of the path to </span><span class="font53" style="font-style:italic;">v</span><span class="font53"> is unchanged. The cost of the path to </span><span class="font53" style="font-style:italic;">w</span><span class="font53"> (which was 5 at the end of the initialization) through node </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> is found to have a cost of 4. Hence this lower-cost path is selected and </span><span class="font53" style="font-style:italic;">w</span><span class="font53">’s predecessor along the shortest path from </span><span class="font53" style="font-style:italic;">u</span><span class="font53"> is set to </span><span class="font53" style="font-style:italic;">x</span><span class="font53">. Similarly, the cost to </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> (through </span><span class="font53" style="font-style:italic;">x</span><span class="font53">) is computed to be 2, and the table is updated accordingly.</span></p></li>
<li>
<p><span class="font53">• &nbsp;In the second iteration, nodes </span><span class="font53" style="font-style:italic;">v</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> are found to have the least-cost paths (2), and we break the tie arbitrarily and add </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> to the set </span><span class="font53" style="font-style:italic;">N</span><span class="font54">' </span><span class="font53">so that </span><span class="font53" style="font-style:italic;">N</span><span class="font54">' </span><span class="font53">now contains </span><span class="font53" style="font-style:italic;">u,</span></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font53" style="font-style:italic;">x,</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">y.</span><span class="font53"> The cost to the remaining nodes not yet in </span><span class="font53" style="font-style:italic;">N</span><span class="font54">'</span><span class="font53">, that is, nodes </span><span class="font53" style="font-style:italic;">v, w,</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">z</span><span class="font53">, are updated via line 12 of the LS algorithm, yielding the results shown in the third row in Table 5.1.</span></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;And so on . . .</span></p></li></ul>
<p><span class="font53">When the LS algorithm terminates, we have, for each node, its predecessor along the least-cost path from the source node. For each predecessor, we also have </span><span class="font53" style="font-style:italic;">its </span><span class="font53">predecessor, and so in this manner we can construct the entire path from the source to all destinations. The forwarding table in a node, say node </span><span class="font53" style="font-style:italic;">u</span><span class="font53">, can then be constructed from this information by storing, for each destination, the next-hop node on the leastcost path from </span><span class="font53" style="font-style:italic;">u</span><span class="font53"> to the destination. Figure 5.4 shows the resulting least-cost paths and forwarding table in </span><span class="font53" style="font-style:italic;">u</span><span class="font53"> for the network in Figure 5.3.</span></p>
<div><img src="networking_files/networking-373.jpg" alt="" style="width:60pt;height:67pt;">
</div><br clear="all">
<div><img src="networking_files/networking-374.jpg" alt="" style="width:62pt;height:68pt;">
</div><br clear="all">
<div>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font5">Destination</span></p></td><td style="vertical-align:middle;">
<p><span class="font5">Link</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font5">v</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">(u, v)</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font5">w</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">(u, x)</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font5">x</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">(u, x)</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font5">y</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">(u, x)</span></p></td></tr>
<tr><td>
<p><span class="font5">z</span></p></td><td>
<p><span class="font5">(u, x)</span></p></td></tr>
</table>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 5.4 </span><span class="font50">♦ </span><span class="font5">Least cost path and forwarding table for node u</span></p>
<p><span class="font53">What is the computational complexity of this algorithm? That is, given </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> nodes (not counting the source), how much computation must be done in the worst case to find the least-cost paths from the source to all destinations? In the first iteration, we need to search through all </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> nodes to determine the node, </span><span class="font53" style="font-style:italic;">w,</span><span class="font53"> not in </span><span class="font53" style="font-style:italic;">N'</span><span class="font53"> that has the minimum cost. In the second iteration, we need to check </span><span class="font53" style="font-style:italic;">n —</span><span class="font53"> 1 nodes to determine the minimum cost; in the third iteration </span><span class="font53" style="font-style:italic;">n —</span><span class="font53"> 2 nodes, and so on. Overall, the total number of nodes we need to search through over all the iterations is </span><span class="font53" style="font-style:italic;">n</span><span class="font53">(</span><span class="font53" style="font-style:italic;">n</span><span class="font55"> + </span><span class="font53">1)/2, and thus we say that the preceding implementation of the LS algorithm has worst-case complexity of order </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> squared: </span><span class="font53" style="font-style:italic;">O(n</span><span class="font49" style="font-style:italic;">2</span><span class="font53" style="font-style:italic;">).</span><span class="font53"> (A more sophisticated implementation of this algorithm, using a data structure known as a heap, can find the minimum in line 9 in logarithmic rather than linear time, thus reducing the complexity.)</span></p>
<p><span class="font53">Before completing our discussion of the LS algorithm, let us consider a pathology that can arise. Figure 5.5 shows a simple network topology where link costs are equal to the load carried on the link, for example, reflecting the delay that would be experienced. In this example, link costs are not symmetric; that is, </span><span class="font53" style="font-style:italic;">c(u,v)</span><span class="font53"> equals </span><span class="font53" style="font-style:italic;">c(v,u)</span><span class="font53"> only if the load carried on both directions on the link </span><span class="font53" style="font-style:italic;">(u,v)</span><span class="font53"> is the same. In this example, node </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> originates a unit of traffic destined for </span><span class="font53" style="font-style:italic;">w</span><span class="font53">, node </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> also originates a unit of traffic destined for </span><span class="font53" style="font-style:italic;">w</span><span class="font53">, and node </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> injects an amount of traffic equal to </span><span class="font53" style="font-style:italic;">e,</span><span class="font53"> also destined for </span><span class="font53" style="font-style:italic;">w</span><span class="font53">. The initial routing is shown in Figure 5.5(a) with the link costs corresponding to the amount of traffic carried.</span></p>
<p><span class="font53">When the LS algorithm is next run, node </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> determines (based on the link costs shown in Figure 5.5(a)) that the clockwise path to </span><span class="font53" style="font-style:italic;">w</span><span class="font53"> has a cost of 1, while the counterclockwise path to </span><span class="font53" style="font-style:italic;">w</span><span class="font53"> (which it had been using) has a cost of 1 </span><span class="font55">+ </span><span class="font53" style="font-style:italic;">e</span><span class="font53">. Hence </span><span class="font53" style="font-style:italic;">y’</span><span class="font53">s leastcost path to </span><span class="font53" style="font-style:italic;">w</span><span class="font53"> is now clockwise. Similarly, </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> determines that its new least-cost path to </span><span class="font53" style="font-style:italic;">w</span><span class="font53"> is also clockwise, resulting in costs shown in Figure 5.5(b). When the LS algorithm is run next, nodes </span><span class="font53" style="font-style:italic;">x, y,</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> all detect a zero-cost path to </span><span class="font53" style="font-style:italic;">w</span><span class="font53"> in the counterclockwise direction, and all route their traffic to the counterclockwise routes. The next time the LS algorithm is run, </span><span class="font53" style="font-style:italic;">x, y</span><span class="font53">, and </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> all then route their traffic to the clockwise routes.</span></p>
<p><span class="font53">What can be done to prevent such oscillations (which can occur in any algorithm, not just an LS algorithm, that uses a congestion or delay-based link metric)? One solution would be to mandate that link costs not depend on the amount of traffic</span></p>
<div><img src="networking_files/networking-375.jpg" alt="" style="width:138pt;height:111pt;">
<p><span class="font4" style="font-weight:bold;">a. Initial routing</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-376.jpg" alt="" style="width:129pt;height:110pt;">
<p><span class="font4" style="font-weight:bold;">b. </span><span class="font4" style="font-weight:bold;font-style:italic;">x</span><span class="font52" style="font-style:italic;">, </span><span class="font4" style="font-weight:bold;font-style:italic;">y</span><span class="font4" style="font-weight:bold;"> detect better path to </span><span class="font4" style="font-weight:bold;font-style:italic;">w</span><span class="font52" style="font-style:italic;">,</span><span class="font4" style="font-weight:bold;"> clockwise</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-377.jpg" alt="" style="width:302pt;height:105pt;">
<p><span class="font4" style="font-weight:bold;">c. </span><span class="font4" style="font-weight:bold;font-style:italic;">x</span><span class="font4" style="font-weight:bold;">, </span><span class="font4" style="font-weight:bold;font-style:italic;">y</span><span class="font4" style="font-weight:bold;">, </span><span class="font4" style="font-weight:bold;font-style:italic;">z</span><span class="font4" style="font-weight:bold;"> detect better path to </span><span class="font4" style="font-weight:bold;font-style:italic;">w</span><span class="font4" style="font-weight:bold;">, counterclockwise</span></p>
<p><span class="font4" style="font-weight:bold;">d. </span><span class="font4" style="font-weight:bold;font-style:italic;">x</span><span class="font4" style="font-weight:bold;">, </span><span class="font4" style="font-weight:bold;font-style:italic;">y</span><span class="font4" style="font-weight:bold;">, </span><span class="font4" style="font-weight:bold;font-style:italic;">z</span><span class="font4" style="font-weight:bold;">, detect better path to </span><span class="font4" style="font-weight:bold;font-style:italic;">w</span><span class="font4" style="font-weight:bold;">, clockwise</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 5.5 </span><span class="font50">♦ </span><span class="font5">Oscillations with congestion-sensitive routing</span></p>
</div><br clear="all">
<p><span class="font53">carried—an unacceptable solution since one goal of routing is to avoid highly congested (for example, high-delay) links. Another solution is to ensure that not all routers run the LS algorithm at the same time. This seems a more reasonable solution, since we would hope that even if routers ran the LS algorithm with the same periodicity, the execution instance of the algorithm would not be the same at each node. Interestingly, researchers have found that routers in the Internet can self-synchronize among themselves [Floyd Synchronization 1994]. That is, even though they initially execute the algorithm with the same period but at different instants of time, the algorithm execution instance can eventually become, and remain, synchronized at the routers. One way to avoid such self-synchronization is for each router to randomize the time it sends out a link advertisement.</span></p>
<p><span class="font53">Having studied the LS algorithm, let’s consider the other major routing algorithm that is used in practice today—the distance-vector routing algorithm.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">5.2.2 </span><span class="font23" style="font-weight:bold;">The Distance-Vector (DV) Routing Algorithm</span></p></li></ul>
<p><span class="font53">Whereas the LS algorithm is an algorithm using global information, the </span><span class="font53" style="font-weight:bold;">distancevector (DV) </span><span class="font53">algorithm is iterative, asynchronous, and distributed. It is </span><span class="font53" style="font-style:italic;">distributed</span><span class="font53"> in that each node receives some information from one or more of its </span><span class="font53" style="font-style:italic;">directly attached </span><span class="font53">neighbors, performs a calculation, and then distributes the results of its calculation back to its neighbors. It is </span><span class="font53" style="font-style:italic;">iterative</span><span class="font53"> in that this process continues on until no more information is exchanged between neighbors. (Interestingly, the algorithm is also self-terminating—there is no signal that the computation should stop; it just stops.) The algorithm is </span><span class="font53" style="font-style:italic;">asynchronous</span><span class="font53"> in that it does not require all of the nodes to operate in lockstep with each other. We’ll see that an asynchronous, iterative, self-terminating, distributed algorithm is much more interesting and fun than a centralized algorithm!</span></p>
<p><span class="font53">Before we present the DV algorithm, it will prove beneficial to discuss an important relationship that exists among the costs of the least-cost paths. Let </span><span class="font53" style="font-style:italic;">d<sub>x</sub>(y)</span><span class="font53"> be the cost of the least-cost path from node </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> to node </span><span class="font53" style="font-style:italic;">y</span><span class="font53">. Then the least costs are related by the celebrated Bellman-Ford equation, namely,</span></p>
<p><span class="font53" style="font-style:italic;">d</span><span class="font50" style="font-style:italic;">x</span><span class="font53">(</span><span class="font53" style="font-style:italic;">y</span><span class="font53">) </span><span class="font54">= </span><span class="font53">min</span><span class="font50" style="font-style:italic;">v</span><span class="font53"> { </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(</span><span class="font53" style="font-style:italic;">x</span><span class="font53">, </span><span class="font53" style="font-style:italic;">v</span><span class="font53">) </span><span class="font55">+ </span><span class="font53" style="font-style:italic;">d</span><span class="font50" style="font-style:italic;">„</span><span class="font53">( </span><span class="font53" style="font-style:italic;">y</span><span class="font53">) 6, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(5.1)</span></p>
<p><span class="font53">where the </span><span class="font53" style="font-style:italic;">min</span><span class="font53"> in the equation is taken over all of </span><span class="font53" style="font-style:italic;">x</span><span class="font53">’s neighbors. The BellmanFord equation is rather intuitive. Indeed, after traveling from </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> to </span><span class="font53" style="font-style:italic;">v</span><span class="font53">, if we then take the least-cost path from </span><span class="font53" style="font-style:italic;">v</span><span class="font53"> to </span><span class="font53" style="font-style:italic;">y</span><span class="font53">, the path cost will be </span><span class="font53" style="font-style:italic;">c(x, v</span><span class="font53">) </span><span class="font55">+ </span><span class="font53" style="font-style:italic;">d<sub>v</sub></span><span class="font53">(</span><span class="font53" style="font-style:italic;">y</span><span class="font53">). Since we must begin by traveling to some neighbor </span><span class="font53" style="font-style:italic;">v</span><span class="font53">, the least cost from </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> to </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> is the minimum of </span><span class="font53" style="font-style:italic;">c(x, v</span><span class="font53">) </span><span class="font55">+ </span><span class="font53" style="font-style:italic;">d<sub>v</sub>(y)</span><span class="font53"> taken over all neighbors </span><span class="font53" style="font-style:italic;">v</span><span class="font53">.</span></p>
<p><span class="font53">But for those who might be skeptical about the validity of the equation, let’s check it for source node </span><span class="font53" style="font-style:italic;">u</span><span class="font53"> and destination node </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> in Figure 5.3. The source node </span><span class="font53" style="font-style:italic;">u </span><span class="font53">has three neighbors: nodes </span><span class="font53" style="font-style:italic;">v</span><span class="font53">, </span><span class="font53" style="font-style:italic;">x,</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">w.</span><span class="font53"> By walking along various paths in the graph, it is easy to see that </span><span class="font53" style="font-style:italic;">d<sub>v</sub>(z) =</span><span class="font53"> 5, </span><span class="font53" style="font-style:italic;">d<sub>x</sub>(z) =</span><span class="font53"> 3, and </span><span class="font53" style="font-style:italic;">d<sub>w</sub>(z) =</span><span class="font53"> 3. Plugging these values into Equation 5.1, along with the costs </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(</span><span class="font53" style="font-style:italic;">u</span><span class="font53">, </span><span class="font53" style="font-style:italic;">v</span><span class="font53">) </span><span class="font54">= </span><span class="font53">2, </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(</span><span class="font53" style="font-style:italic;">u</span><span class="font53">, </span><span class="font53" style="font-style:italic;">x</span><span class="font53">) </span><span class="font54">= </span><span class="font53">1, and </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(</span><span class="font53" style="font-style:italic;">u</span><span class="font53">, </span><span class="font53" style="font-style:italic;">w</span><span class="font53">) </span><span class="font54">= </span><span class="font53">5, gives </span><span class="font53" style="font-style:italic;">d<sub>u</sub>(z) =</span><span class="font53"> min {2 </span><span class="font55">+ </span><span class="font53">5, 5 </span><span class="font55">+ </span><span class="font53">3, 1 </span><span class="font55">+ </span><span class="font53">3 } </span><span class="font54">= </span><span class="font53">4, which is obviously true and which is exactly what the Dijskstra algorithm gave us for the same network. This quick verification should help relieve any skepticism you may have.</span></p>
<p><span class="font53">The Bellman-Ford equation is not just an intellectual curiosity. It actually has significant practical importance: the solution to the Bellman-Ford equation provides the entries in node </span><span class="font53" style="font-style:italic;">x</span><span class="font53">’s forwarding table. To see this, let </span><span class="font53" style="font-style:italic;">v*</span><span class="font53"> be any neighboring node that achieves the minimum in Equation 5.1. Then, if node </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> wants to send a packet to node </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> along a least-cost path, it should first forward the packet to node </span><span class="font53" style="font-style:italic;">v*</span><span class="font53">. Thus, node </span><span class="font53" style="font-style:italic;">x</span><span class="font53">’s forwarding table would specify node </span><span class="font53" style="font-style:italic;">v*</span><span class="font53"> as the next-hop router for the ultimate destination </span><span class="font53" style="font-style:italic;">y</span><span class="font53">. Another important practical contribution of the Bellman-Ford equation is that it suggests the form of the neighbor-to-neighbor communication that will take place in the DV algorithm.</span></p>
<p><a name="bookmark359"></a><span class="font53">The basic idea is as follows. Each node </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> begins with </span><span class="font53" style="font-style:italic;">D<sub>x</sub></span><span class="font53">(</span><span class="font53" style="font-style:italic;">y</span><span class="font53">), an estimate of the cost of the least-cost path from itself to node </span><span class="font53" style="font-style:italic;">y</span><span class="font53">, for all nodes, </span><span class="font53" style="font-style:italic;">y</span><span class="font53">, in </span><span class="font53" style="font-style:italic;">N.</span><span class="font53"> Let </span><span class="font53" style="font-weight:bold;font-style:italic;">D</span><span class="font53" style="font-style:italic;"><sub>x</sub> =</span><span class="font53"> [</span><span class="font53" style="font-style:italic;">D<sub>x</sub></span><span class="font53">(</span><span class="font53" style="font-style:italic;">y</span><span class="font53">): </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> in </span><span class="font53" style="font-style:italic;">N</span><span class="font53">] be node </span><span class="font53" style="font-style:italic;">x</span><span class="font53">’s distance vector, which is the vector of cost estimates from </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> to all other nodes, </span><span class="font53" style="font-style:italic;">y</span><span class="font53">, in </span><span class="font53" style="font-style:italic;">N.</span><span class="font53"> With the DV algorithm, each node </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> maintains the following routing information:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;For each neighbor </span><span class="font53" style="font-style:italic;">v,</span><span class="font53"> the cost </span><span class="font53" style="font-style:italic;">c(x,v)</span><span class="font53"> from </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> to directly attached neighbor, </span><span class="font53" style="font-style:italic;">v</span></p></li>
<li>
<p><span class="font53" style="font-style:italic;">•</span><span class="font53"> &nbsp;Node </span><span class="font53" style="font-style:italic;">x</span><span class="font53">’s distance vector, that is, </span><span class="font53" style="font-weight:bold;font-style:italic;">D</span><span class="font53" style="font-style:italic;"><sub>x</sub> = [D<sub>x</sub>(y): y</span><span class="font53"> in </span><span class="font53" style="font-style:italic;">A</span><span class="font53">], containing </span><span class="font53" style="font-style:italic;">x</span><span class="font53">’s estimate of its cost to all destinations, </span><span class="font53" style="font-style:italic;">y</span><span class="font53">, in </span><span class="font53" style="font-style:italic;">N</span></p></li>
<li>
<p><span class="font53">• &nbsp;The distance vectors of each of its neighbors, that is, </span><span class="font53" style="font-weight:bold;font-style:italic;">D</span><span class="font53" style="font-style:italic;"><sub>v</sub> =</span><span class="font53"> [</span><span class="font53" style="font-style:italic;">D<sub>v</sub></span><span class="font53">(</span><span class="font53" style="font-style:italic;">y</span><span class="font53">): </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> in </span><span class="font53" style="font-style:italic;">N</span><span class="font53">] for each neighbor </span><span class="font53" style="font-style:italic;">v</span><span class="font53"> of </span><span class="font53" style="font-style:italic;">x</span></p></li></ul>
<p><span class="font53">In the distributed, asynchronous algorithm, from time to time, each node sends a copy of its distance vector to each of its neighbors. When a node </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> receives a new distance vector from any of its neighbors </span><span class="font53" style="font-style:italic;">w,</span><span class="font53"> it saves </span><span class="font53" style="font-style:italic;">w</span><span class="font53">’s distance vector, and then uses the Bellman-Ford equation to update its own distance vector as follows:</span></p>
<p><span class="font53" style="font-style:italic;">D<sub>x</sub>(y) =</span><span class="font53"> min</span><span class="font53" style="font-style:italic;"><sub>v</sub></span><span class="font53"> { </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(</span><span class="font53" style="font-style:italic;">x</span><span class="font53">, </span><span class="font53" style="font-style:italic;">v</span><span class="font53">) </span><span class="font55">+ </span><span class="font53" style="font-style:italic;">D<sub>v</sub>(y)</span><span class="font53">} for each node </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> in </span><span class="font53" style="font-style:italic;">N</span></p>
<p><span class="font53">If node </span><span class="font53" style="font-style:italic;">x</span><span class="font53">’s distance vector has changed as a result of this update step, node </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> will then send its updated distance vector to each of its neighbors, which can in turn update their own distance vectors. Miraculously enough, as long as all the nodes continue to exchange their distance vectors in an asynchronous fashion, each cost estimate </span><span class="font53" style="font-style:italic;">D<sub>x</sub>(y)</span><span class="font53"> converges to </span><span class="font53" style="font-style:italic;">d<sub>x</sub>(y),</span><span class="font53"> the actual cost of the least-cost path from node </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> to node </span><span class="font53" style="font-style:italic;">y </span><span class="font53">[Bertsekas 1991]!</span></p>
<p><span class="font22" style="font-weight:bold;">Distance-Vector (DV) Algorithm</span></p>
<p><span class="font53">At each node, </span><span class="font53" style="font-style:italic;">x</span><span class="font53">:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font36">1 &nbsp;&nbsp;</span><span class="font53" style="font-weight:bold;">Initialization:</span></p></li>
<li>
<p><span class="font36">2 &nbsp;&nbsp;&nbsp;for all destinations y in N:</span></p></li>
<li>
<p><span class="font36">3 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;D (y)= c(x,y)/* if y is not a neighbor then c(x,y)= “ */</span></p></li>
<li>
<p><span class="font36">4 &nbsp;&nbsp;&nbsp;for each neighbor w</span></p></li>
<li>
<p><span class="font36">5 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;D (y) = ? for all destinations y in N</span></p></li>
<li>
<p><span class="font36">6 &nbsp;&nbsp;&nbsp;for each neighbor w</span></p></li>
<li>
<p><span class="font36">7 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;send distance vector </span><span class="font53" style="font-weight:bold;">D </span><span class="font36">= [D (y): y in N] to w</span></p></li></ul>
<p><span class="font36">8</span></p>
<ul style="list-style:none;"><li>
<p><span class="font36">9 &nbsp;</span><span class="font53" style="font-weight:bold;">loop</span></p></li>
<li>
<p><span class="font36">10 &nbsp;&nbsp;&nbsp;</span><span class="font53" style="font-weight:bold;">wait </span><span class="font36">(until I see a link cost change to some neighbor w or</span></p></li>
<li>
<p><span class="font36">11 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;until I receive a distance vector from some neighbor w)</span></p></li></ul>
<p><span class="font36">12</span></p>
<ul style="list-style:none;"><li>
<p><span class="font36">13 &nbsp;&nbsp;&nbsp;for each y in N:</span></p></li>
<li>
<p><span class="font36">14 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;D<sub>x</sub>(y) = min<sub>v</sub>{c(x,v) + D<sub>v</sub>(y)}</span></p></li></ul>
<p><span class="font36">15</span></p>
<ul style="list-style:none;"><li>
<p><span class="font36">16 </span><span class="font53" style="font-weight:bold;">if </span><span class="font36">D (y) changed for any destination y</span></p></li>
<li>
<p><span class="font36">17 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;send distance vector </span><span class="font53" style="font-weight:bold;">D</span><span class="font36"><sub>x</sub> = [D<sub>x</sub>(y): y in N] to all neighbors</span></p></li></ul>
<p><span class="font36">18</span></p>
<p><span class="font36">19 </span><span class="font53" style="font-weight:bold;">forever</span></p>
<p><span class="font53">In the DV algorithm, a node </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> updates its distance-vector estimate when it either sees a cost change in one of its directly attached links or receives a distance-vector update from some neighbor. But to update its own forwarding table for a given destination </span><span class="font53" style="font-style:italic;">y,</span><span class="font53"> what node </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> really needs to know is not the shortest-path distance to </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> but instead the neighboring node </span><span class="font53" style="font-style:italic;">v*</span><span class="font53">(</span><span class="font53" style="font-style:italic;">y</span><span class="font53">) that is the next-hop router along the shortest path to </span><span class="font53" style="font-style:italic;">y</span><span class="font53">. As you might expect, the next-hop router </span><span class="font53" style="font-style:italic;">v*</span><span class="font53">(</span><span class="font53" style="font-style:italic;">y</span><span class="font53">) is the neighbor </span><span class="font53" style="font-style:italic;">v</span><span class="font53"> that achieves the minimum in Line 14 of the DV algorithm. (If there are multiple neighbors </span><span class="font53" style="font-style:italic;">v</span><span class="font53"> that achieve the minimum, then </span><span class="font53" style="font-style:italic;">v*</span><span class="font53">(</span><span class="font53" style="font-style:italic;">y</span><span class="font53">) can be any of the minimizing neighbors.) Thus, in Lines 13-14, for each destination </span><span class="font53" style="font-style:italic;">y</span><span class="font53">, node </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> also determines </span><span class="font53" style="font-style:italic;">v*</span><span class="font53">(</span><span class="font53" style="font-style:italic;">y</span><span class="font53">) and updates its forwarding table for destination </span><span class="font53" style="font-style:italic;">y</span><span class="font53">.</span></p>
<p><span class="font53">Recall that the LS algorithm is a centralized algorithm in the sense that it requires each node to first obtain a complete map of the network before running the Dijkstra algorithm. The DV algorithm is </span><span class="font53" style="font-style:italic;">decentralized</span><span class="font53"> and does not use such global information. Indeed, the only information a node will have is the costs of the links to its directly attached neighbors and information it receives from these neighbors. Each node waits for an update from any neighbor (Lines 10-11), calculates its new distance vector when receiving an update (Line 14), and distributes its new distance vector to its neighbors (Lines 16-17). DV-like algorithms are used in many routing protocols in practice, including the Internet’s RIP and BGP, ISO IDRP, Novell IPX, and the original ARPAnet.</span></p>
<p><span class="font53">Figure 5.6 illustrates the operation of the DV algorithm for the simple three-node network shown at the top of the figure. The operation of the algorithm is illustrated in a synchronous manner, where all nodes simultaneously receive distance vectors from their neighbors, compute their new distance vectors, and inform their neighbors if their distance vectors have changed. After studying this example, you should convince yourself that the algorithm operates correctly in an asynchronous manner as well, with node computations and update generation/reception occurring at any time.</span></p>
<p><span class="font53">The leftmost column of the figure displays three initial </span><span class="font53" style="font-weight:bold;">routing tables </span><span class="font53">for each of the three nodes. For example, the table in the upper-left corner is node </span><span class="font53" style="font-style:italic;">x</span><span class="font53">’s initial routing table. Within a specific routing table, each row is a distance vector— specifically, each node’s routing table includes its own distance vector and that of each of its neighbors. Thus, the first row in node </span><span class="font53" style="font-style:italic;">x</span><span class="font53">’s initial routing table is </span><span class="font53" style="font-weight:bold;font-style:italic;">D</span><span class="font53" style="font-style:italic;"><sub>x</sub> =</span><span class="font53"> [</span><span class="font53" style="font-style:italic;">D<sub>x</sub></span><span class="font53">(</span><span class="font53" style="font-style:italic;">x</span><span class="font53">), </span><span class="font53" style="font-style:italic;">D<sub>x</sub>(y), D<sub>x</sub></span><span class="font53">(</span><span class="font53" style="font-style:italic;">z</span><span class="font53">)] </span><span class="font54">= </span><span class="font53">[0, 2, 7]. The second and third rows in this table are the most recently received distance vectors from nodes </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">z,</span><span class="font53"> respectively. Because at initialization node </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> has not received anything from node </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> or </span><span class="font53" style="font-style:italic;">z</span><span class="font53">, the entries in the second and third rows are initialized to infinity.</span></p>
<p><span class="font53">After initialization, each node sends its distance vector to each of its two neighbors. This is illustrated in Figure 5.6 by the arrows from the first column of tables to the second column of tables. For example, node </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> sends its distance vector </span><span class="font53" style="font-weight:bold;font-style:italic;">D</span><span class="font53" style="font-style:italic;"><sub>x</sub></span><span class="font54"> = </span><span class="font53">[0, 2, 7] to both nodes </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">z</span><span class="font53">. After receiving the updates, each node recomputes its own distance vector. For example, node </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> computes</span></p>
<p><span class="font53" style="font-style:italic;">D</span><span class="font50" style="font-style:italic;">J</span><span class="font53" style="font-style:italic;">x)</span><span class="font54"> = </span><span class="font53">0</span></p>
<p><span class="font53" style="font-style:italic;">D</span><span class="font50" style="font-style:italic;">x</span><span class="font53" style="font-style:italic;">(y)</span><span class="font54"> = </span><span class="font53">min {</span><span class="font53" style="font-style:italic;">c(x,y)</span><span class="font55"> + </span><span class="font53" style="font-style:italic;">D</span><span class="font50" style="font-style:italic;">y</span><span class="font53" style="font-style:italic;">(y), c(x,z)</span><span class="font55"> + </span><span class="font53" style="font-style:italic;">D<sub>z</sub>(y)</span><span class="font53">} </span><span class="font54">= </span><span class="font53">min {2 </span><span class="font55">+ </span><span class="font53">0, 7 </span><span class="font55">+ </span><span class="font53">1} </span><span class="font54">= </span><span class="font53">2</span></p>
<p><span class="font53" style="font-style:italic;">D<sub>x</sub>(z) =</span><span class="font53"> min {</span><span class="font53" style="font-style:italic;">c(x,y)</span><span class="font55"> + </span><span class="font53" style="font-style:italic;">D</span><span class="font50" style="font-style:italic;">y</span><span class="font53" style="font-style:italic;">(z), c(x,z)</span><span class="font55"> + </span><span class="font53" style="font-style:italic;">D<sub>z</sub>(z)</span><span class="font53">} </span><span class="font54">= </span><span class="font53">min {2 </span><span class="font55">+ </span><span class="font53">1, 7 </span><span class="font55">+ </span><span class="font53">0} </span><span class="font54">= </span><span class="font53">3</span></p>
<p><span class="font53">The second column therefore displays, for each node, the node’s new distance vector along with distance vectors just received from its neighbors. Note, for example, that</span></p>
<div><img src="networking_files/networking-378.jpg" alt="" style="width:131pt;height:45pt;">
</div><br clear="all">
<p><span class="font4" style="font-weight:bold;">Node x table</span></p>
<div>
<p><span class="font4">z</span></p>
<p><span class="font4">z</span></p>
<p><span class="font4" style="font-weight:bold;">Node y</span></p>
<p><span class="font4">x</span></p>
<p><span class="font52">E <sup>y</sup></span></p>
<p><span class="font4">x</span></p>
<p><span class="font52">E <sup>y</sup></span></p>
<table border="1">
<tr><td>
<p><span class="font4">0</span></p></td><td colspan="2">
<p><span class="font4">2 7</span></p></td></tr>
<tr><td>
<p><span class="font4">'</span></p></td><td>
<p><span class="font4">'</span></p></td><td>
<p><span class="font4">'</span></p></td></tr>
<tr><td>
<p><span class="font4">'</span></p></td><td>
<p><span class="font4">'</span></p></td><td>
<p><span class="font4">'</span></p></td></tr>
<tr><td colspan="3" style="vertical-align:bottom;">
<p><span class="font4" style="font-weight:bold;">ble</span></p></td></tr>
<tr><td colspan="3" style="vertical-align:bottom;">
<p><span class="font4">cost to</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">x</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">y</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">z</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font4">'</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">'</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">'</span></p></td></tr>
<tr><td>
<p><span class="font4">2</span></p></td><td>
<p><span class="font4">0</span></p></td><td>
<p><span class="font4">1</span></p></td></tr>
<tr><td>
<p><span class="font4">'</span></p></td><td>
<p><span class="font4">'</span></p></td><td>
<p><span class="font4">'</span></p></td></tr>
</table>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Node z table</span></p>
</div><br clear="all">
<div>
<p><span class="font4">cost to</span></p>
<p><span class="font4">z</span></p>
<p><span class="font4">x</span></p>
<p><span class="font4">y</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font4">x</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">y</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">z</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font4">'</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">'</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">'</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font4">'</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">'</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">'</span></p></td></tr>
<tr><td>
<p><span class="font4">7</span></p></td><td>
<p><span class="font4">1</span></p></td><td>
<p><span class="font4">0</span></p></td></tr>
</table>
</div><br clear="all">
<div>
<p><span class="font4">cost to</span></p>
<p><span class="font4">x y z</span></p>
<table border="1">
<tr><td></td><td style="vertical-align:bottom;">
<p><span class="font4">cost to</span></p>
<p><span class="font4">x y z</span></p></td></tr>
<tr><td>
<p><span class="font52">&quot;•o* from N *&lt; X</span></p></td><td>
<p><span class="font4">NJ /o\ —* O NJ </span><span class="font4" style="text-decoration:underline;">O —^</span><span class="font4">UD/ from</span></p></td></tr>
<tr><td></td><td></td></tr>
<tr><td></td><td style="vertical-align:bottom;">
<p><span class="font4">cost to</span></p>
<p><span class="font4">x y z | /V</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font52">x <sup>y </sup>z</span></p></td><td>
<p><span class="font4">0 2 <sup>7</sup> V</span></p>
<p><span class="font4">2 0 1 V|</span></p>
<p><span class="font4">7 1 0 A“</span></p></td></tr>
<tr><td></td><td></td></tr>
<tr><td></td><td style="vertical-align:bottom;">
<p><span class="font4">cost to</span></p>
<p><span class="font4">x y z / / ▼</span></p></td></tr>
<tr><td rowspan="2">
<p><span class="font52">X &gt;» N LUO J J.</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">0 2 7</span></p>
<p><span class="font4">2 0 1</span></p></td></tr>
<tr><td>
<p><span class="font4">3 1 0</span></p></td></tr>
<tr><td></td><td></td></tr>
</table>
<p><span class="font4">x</span></p>
<p><span class="font4">z</span></p>
<p><span class="font4">y</span></p>
</div><br clear="all">
<div>
<p><span class="font4">cost to</span></p>
<table border="1">
<tr><td></td><td style="vertical-align:bottom;">
<p><span class="font4">x</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">y</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">z</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">x</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">3</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font52"><sup>y</sup></span></p></td><td style="vertical-align:middle;">
<p><span class="font4">2</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">1</span></p></td></tr>
<tr><td>
<p><span class="font4">z</span></p></td><td>
<p><span class="font4">3</span></p></td><td>
<p><span class="font4">1</span></p></td><td>
<p><span class="font4">0</span></p></td></tr>
</table>
</div><br clear="all">
<div>
<p><span class="font4">cost to</span></p>
</div><br clear="all">
<div>
<p><span class="font4">cost to</span></p>
<table border="1">
<tr><td></td><td style="vertical-align:bottom;">
<p><span class="font4">x</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">y</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">z</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">x</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">3</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font52"><sup>y</sup></span></p></td><td style="vertical-align:middle;">
<p><span class="font4">2</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">1</span></p></td></tr>
<tr><td>
<p><span class="font4">z</span></p></td><td>
<p><span class="font4">3</span></p></td><td>
<p><span class="font4">1</span></p></td><td>
<p><span class="font4">0</span></p></td></tr>
</table>
</div><br clear="all">
<p><span class="font4">Time</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 5.6 </span><span class="font50">♦ </span><span class="font5">Distance-vector (DV) algorithm in operation </span><span class="font53">node </span><span class="font53" style="font-style:italic;">x</span><span class="font53">’s estimate for the least cost to node </span><span class="font53" style="font-style:italic;">z, D<sub>x</sub>(z),</span><span class="font53"> has changed from 7 to 3. Also note that for node </span><span class="font53" style="font-style:italic;">x,</span><span class="font53"> neighboring node </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> achieves the minimum in line 14 of the DV algorithm; thus, at this stage of the algorithm, we have at node </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> that </span><span class="font53" style="font-style:italic;">v</span><span class="font53">*(</span><span class="font53" style="font-style:italic;">y</span><span class="font53">) </span><span class="font54">= </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">v</span><span class="font53">*(</span><span class="font53" style="font-style:italic;">z</span><span class="font53">) </span><span class="font54">= </span><span class="font53" style="font-style:italic;">y</span><span class="font53">.</span></p>
<p><span class="font53">After the nodes recompute their distance vectors, they again send their updated distance vectors to their neighbors (if there has been a change). This is illustrated in Figure 5.6 by the arrows from the second column of tables to the third column of tables. Note that only nodes </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> send updates: node </span><span class="font53" style="font-style:italic;">y</span><span class="font53">’s distance vector didn’t change so node </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> doesn’t send an update. After receiving the updates, the nodes then recompute their distance vectors and update their routing tables, which are shown in the third column.</span></p>
<p><span class="font53">The process of receiving updated distance vectors from neighbors, recomputing routing table entries, and informing neighbors of changed costs of the least-cost path to a destination continues until no update messages are sent. At this point, since no update messages are sent, no further routing table calculations will occur and the algorithm will enter a quiescent state; that is, all nodes will be performing the wait in Lines 10-11 of the DV algorithm. The algorithm remains in the quiescent state until a link cost changes, as discussed next.</span></p>
<p><span class="font22" style="font-weight:bold;">Distance-Vector Algorithm: Link-Cost Changes and Link Failure</span></p>
<p><span class="font53">When a node running the DV algorithm detects a change in the link cost from itself to a neighbor (Lines 10-11), it updates its distance vector (Lines 13-14) and, if there’s a change in the cost of the least-cost path, informs its neighbors (Lines 16-17) of its new distance vector. Figure 5.7(a) illustrates a scenario where the link cost from </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> to </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> changes from 4 to 1. We focus here only on </span><span class="font53" style="font-style:italic;">y</span><span class="font53">’ and </span><span class="font53" style="font-style:italic;">z</span><span class="font53">’s distance table entries to destination </span><span class="font53" style="font-style:italic;">x</span><span class="font53">. The DV algorithm causes the following sequence of events to occur:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;At time </span><span class="font53" style="font-style:italic;">t<sub>0</sub>, y</span><span class="font53"> detects the link-cost change (the cost has changed from 4 to 1), updates its distance vector, and informs its neighbors of this change since its distance vector has changed.</span></p></li>
<li>
<p><span class="font53">• &nbsp;At time </span><span class="font53" style="font-style:italic;">t</span><span class="font53"><sub>1</sub>, </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> receives the update from </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> and updates its table. It computes a new least cost to </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> (it has decreased from a cost of 5 to a cost of 2) and sends its new distance vector to its neighbors.</span></p></li>
<li>
<p><span class="font53">• &nbsp;At time </span><span class="font53" style="font-style:italic;">t</span><span class="font53"><sub>2</sub>, </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> receives </span><span class="font53" style="font-style:italic;">z</span><span class="font53">’s update and updates its distance table. </span><span class="font53" style="font-style:italic;">y</span><span class="font53">’s least costs do not change and hence </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> does not send any message to </span><span class="font53" style="font-style:italic;">z</span><span class="font53">. The algorithm comes to a quiescent state.</span></p></li></ul>
<p><span class="font53">Thus, only two iterations are required for the DV algorithm to reach a quiescent state. The good news about the decreased cost between </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> has propagated quickly through the network.</span></p>
<div><img src="networking_files/networking-379.jpg" alt="" style="width:140pt;height:75pt;">
<p><span class="font5" style="font-weight:bold;">a.</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 5.7 </span><span class="font50">♦ </span><span class="font5">Changes in link cost</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-380.jpg" alt="" style="width:140pt;height:75pt;">
<p><span class="font5" style="font-weight:bold;">b.</span></p>
</div><br clear="all">
<p><span class="font53">Let’s now consider what can happen when a link cost </span><span class="font53" style="font-style:italic;">increases.</span><span class="font53"> Suppose that the link cost between </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> increases from 4 to 60, as shown in Figure 5.7(b).</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">1. Before the link cost changes, </span><span class="font53" style="font-style:italic;">D<sub>y</sub>(x) =</span><span class="font53"> 4, </span><span class="font53" style="font-style:italic;">D<sub>y</sub>(z) =</span><span class="font53"> 1, </span><span class="font53" style="font-style:italic;">D<sub>z</sub>(y) =</span><span class="font53"> 1, and </span><span class="font53" style="font-style:italic;">D<sub>z</sub>(x) =</span><span class="font53"> 5. At time </span><span class="font53" style="font-style:italic;">t<sub>0</sub>, y</span><span class="font53"> detects the link-cost change (the cost has changed from 4 to 60). </span><span class="font53" style="font-style:italic;">y </span><span class="font53">computes its new minimum-cost path to </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> to have a cost of</span></p></li></ul>
<p><span class="font53" style="font-style:italic;">D<sub>y</sub>(x) =</span><span class="font53"> min {</span><span class="font53" style="font-style:italic;">c</span><span class="font53">(</span><span class="font53" style="font-style:italic;">y</span><span class="font53">,</span><span class="font53" style="font-style:italic;">x</span><span class="font53">) </span><span class="font55">+ </span><span class="font53" style="font-style:italic;">D<sub>x</sub></span><span class="font53">(</span><span class="font53" style="font-style:italic;">x</span><span class="font53">), </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(</span><span class="font53" style="font-style:italic;">y</span><span class="font53">,</span><span class="font53" style="font-style:italic;">z</span><span class="font53">) </span><span class="font55">+ </span><span class="font53" style="font-style:italic;">D<sub>z</sub>(x)</span><span class="font53">} </span><span class="font54">= </span><span class="font53">min {60 </span><span class="font55">+ </span><span class="font53">0, 1 </span><span class="font55">+ </span><span class="font53">5 } </span><span class="font54">= </span><span class="font53">6</span></p>
<p><span class="font53">Of course, with our global view of the network, we can see that this new cost via </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> is </span><span class="font53" style="font-style:italic;">wrong.</span><span class="font53"> But the only information node </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> has is that its direct cost to </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> is 60 and that </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> has last told </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> that </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> could get to </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> with a cost of 5. So in order to get to </span><span class="font53" style="font-style:italic;">x, y</span><span class="font53"> would now route through </span><span class="font53" style="font-style:italic;">z</span><span class="font53">, fully expecting that </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> will be able to get to </span><span class="font53" style="font-style:italic;">x </span><span class="font53">with a cost of 5. As of </span><span class="font53" style="font-style:italic;">t</span><span class="font53"><sub>1</sub> we have a </span><span class="font53" style="font-weight:bold;">routing loop—</span><span class="font53">in order to get to </span><span class="font53" style="font-style:italic;">x, y</span><span class="font53"> routes through </span><span class="font53" style="font-style:italic;">z</span><span class="font53">, and </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> routes through </span><span class="font53" style="font-style:italic;">y</span><span class="font53">. A routing loop is like a black hole—a packet destined for </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> arriving at </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> or </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> as of </span><span class="font53" style="font-style:italic;">t</span><span class="font53"><sub>1</sub> will bounce back and forth between these two nodes forever (or until the forwarding tables are changed).</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">2. Since node </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> has computed a new minimum cost to </span><span class="font53" style="font-style:italic;">x</span><span class="font53">, it informs </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> of its new distance vector at time </span><span class="font53" style="font-style:italic;">t</span><span class="font53"><sub>1</sub>.</span></p></li>
<li>
<p><span class="font53">3. Sometime after </span><span class="font53" style="font-style:italic;">t</span><span class="font53"><sub>1</sub>, </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> receives </span><span class="font53" style="font-style:italic;">y</span><span class="font53">’s new distance vector, which indicates that </span><span class="font53" style="font-style:italic;">y</span><span class="font53">’s minimum cost to </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> is 6. </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> knows it can get to </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> with a cost of 1 and hence computes a new least cost to </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> of </span><span class="font53" style="font-style:italic;">D<sub>z</sub></span><span class="font53">(</span><span class="font53" style="font-style:italic;">x</span><span class="font53">) </span><span class="font54">= </span><span class="font53">min {50 </span><span class="font55">+ </span><span class="font53">0,1 </span><span class="font55">+ </span><span class="font53">6} </span><span class="font54">= </span><span class="font53">7. Since </span><span class="font53" style="font-style:italic;">z</span><span class="font53">’s least cost to </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> has increased, it then informs </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> of its new distance vector at </span><span class="font53" style="font-style:italic;">t</span><span class="font53"><sub>2</sub>.</span></p></li>
<li>
<p><span class="font53">4. In a similar manner, after receiving </span><span class="font53" style="font-style:italic;">z</span><span class="font53">’s new distance vector, </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> determines </span><span class="font53" style="font-style:italic;">D<sub>y</sub>(x) =</span><span class="font53"> 8 and sends </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> its distance vector. </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> then determines </span><span class="font53" style="font-style:italic;">D<sub>z</sub>(x) =</span><span class="font53"> 9 and sends </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> its distance vector, and so on.</span></p></li></ul>
<p><span class="font53">How long will the process continue? You should convince yourself that the loop will persist for 44 iterations (message exchanges between </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">z</span><span class="font53">)—until </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> eventually computes the cost of its path via </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> to be greater than 50. At this point, </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> will (finally!) determine that its least-cost path to </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> is via its direct connection to </span><span class="font53" style="font-style:italic;">x</span><span class="font53">. </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> will then route to </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> via </span><span class="font53" style="font-style:italic;">z.</span><span class="font53"> The result of the bad news about the increase in link cost has indeed traveled slowly! What would have happened if the link cost </span><span class="font53" style="font-style:italic;">c(y, x</span><span class="font53">) had changed from 4 to 10,000 and the cost </span><span class="font53" style="font-style:italic;">c(z, x)</span><span class="font53"> had been 9,999? Because of such scenarios, the problem we have seen is sometimes referred to as the count-to-infinity problem.</span></p>
<p><span class="font22" style="font-weight:bold;">Distance-Vector Algorithm: Adding Poisoned Reverse</span></p>
<p><span class="font53">The specific looping scenario just described can be avoided using a technique known as </span><span class="font53" style="font-style:italic;">poisoned reverse.</span><span class="font53"> The idea is simple—if </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> routes through </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> to get to destination </span><span class="font53" style="font-style:italic;">x</span><span class="font53">, then </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> will advertise to </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> that its distance to </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> is infinity, that is, </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> will advertise to </span><span class="font53" style="font-style:italic;">y </span><span class="font53">that </span><span class="font53" style="font-style:italic;">D<sub>z</sub>(x) = &amp;</span><span class="font53">&nbsp;(even though </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> knows </span><span class="font53" style="font-style:italic;">D<sub>z</sub>(x) =</span><span class="font53"> 5 in truth). </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> will continue telling this little white lie to </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> as long as it routes to </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> via </span><span class="font53" style="font-style:italic;">y</span><span class="font53">. Since </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> believes that </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> has no path to </span><span class="font53" style="font-style:italic;">x, y</span><span class="font53"> will never attempt to route to </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> via </span><span class="font53" style="font-style:italic;">z</span><span class="font53">, as long as </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> continues to route to </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> via </span><span class="font53" style="font-style:italic;">y </span><span class="font53">(and lies about doing so).</span></p>
<p><span class="font53">Let’s now see how poisoned reverse solves the particular looping problem we encountered before in Figure 5.5(b). As a result of the poisoned reverse, </span><span class="font53" style="font-style:italic;">y</span><span class="font53">’s distance table indicates </span><span class="font53" style="font-style:italic;">D<sub>z</sub>(x) =</span><span class="font53"> w. When the cost of the (</span><span class="font53" style="font-style:italic;">x</span><span class="font53">, </span><span class="font53" style="font-style:italic;">y</span><span class="font53">) link changes from 4 to 60 at time </span><span class="font53" style="font-style:italic;">t</span><span class="font49" style="font-style:italic;">0</span><span class="font53" style="font-style:italic;">, y</span><span class="font53"> updates its table and continues to route directly to </span><span class="font53" style="font-style:italic;">x</span><span class="font53">, albeit at a higher cost of 60, and informs </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> of its new cost to </span><span class="font53" style="font-style:italic;">x</span><span class="font53">, that is, </span><span class="font53" style="font-style:italic;">D<sub>y</sub></span><span class="font53">(</span><span class="font53" style="font-style:italic;">x</span><span class="font53">) </span><span class="font53" style="font-style:italic;">=</span><span class="font53"> 60. After receiving the update at </span><span class="font53" style="font-style:italic;">t</span><span class="font49" style="font-style:italic;">1</span><span class="font53" style="font-style:italic;">, z</span><span class="font53"> immediately shifts its route to </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> to be via the direct </span><span class="font53" style="font-style:italic;">(z, x)</span><span class="font53"> link at a cost of 50. Since this is a new least-cost path to </span><span class="font53" style="font-style:italic;">x</span><span class="font53">, and since the path no longer passes through </span><span class="font53" style="font-style:italic;">y, z</span><span class="font53"> now informs </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> that </span><span class="font53" style="font-style:italic;">D<sub>z</sub>(x) =</span><span class="font53"> 50 at </span><span class="font53" style="font-style:italic;">t</span><span class="font53"><sub>2</sub>. After receiving the update from </span><span class="font53" style="font-style:italic;">z, y</span><span class="font53"> updates its distance table with </span><span class="font53" style="font-style:italic;">D<sub>y</sub></span><span class="font53">(</span><span class="font53" style="font-style:italic;">x</span><span class="font53">) </span><span class="font53" style="font-style:italic;">=</span><span class="font53"> 51. Also, since </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> is now on </span><span class="font53" style="font-style:italic;">y</span><span class="font53">’s leastcost path to </span><span class="font53" style="font-style:italic;">x</span><span class="font53">, </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> poisons the reverse path from </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> to </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> by informing </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> at time </span><span class="font53" style="font-style:italic;">t</span><span class="font53"><sub>3</sub> that </span><span class="font53" style="font-style:italic;">D<sub>y</sub>(x) = ^</span><span class="font53"> (even though </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> knows that </span><span class="font53" style="font-style:italic;">D<sub>y</sub>(x) =</span><span class="font53"> 51 in truth).</span></p>
<p><span class="font53">Does poisoned reverse solve the general count-to-infinity problem? It does not. You should convince yourself that loops involving three or more nodes (rather than simply two immediately neighboring nodes) will not be detected by the poisoned reverse technique.</span></p>
<p><span class="font22" style="font-weight:bold;">A Comparison of LS and DV Routing Algorithms</span></p>
<p><span class="font53">The DV and LS algorithms take complementary approaches toward computing routing. In the DV algorithm, each node talks to </span><span class="font53" style="font-style:italic;">only</span><span class="font53"> its directly connected neighbors, but it provides its neighbors with least-cost estimates from itself to </span><span class="font53" style="font-style:italic;">all</span><span class="font53"> the nodes (that it knows about) in the network. The LS algorithm requires global information. Consequently, when implemented in each and every router, for example, as in Figures 4.2 and 5.1, each node would need to communicate with </span><span class="font53" style="font-style:italic;">all</span><span class="font53"> other nodes (via broadcast), but it tells them </span><span class="font53" style="font-style:italic;">only</span><span class="font53"> the costs of its directly connected links. Let’s conclude our study of LS and DV algorithms with a quick comparison of some of their attributes. Recall that </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> is the set of nodes (routers) and </span><span class="font53" style="font-style:italic;">E</span><span class="font53"> is the set of edges (links).</span></p>
<p><span class="font53">• </span><span class="font53" style="font-style:italic;">Message complexity.</span><span class="font53"> We have seen that LS requires each node to know the cost of each link in the network. This requires O(INI IEI) messages to be sent. Also, whenever a link cost changes, the new link cost must be sent to all nodes. The DV algorithm requires message exchanges between directly connected neighbors at each iteration. We have seen that the time needed for the algorithm to converge can depend on many factors. When link costs change, the DV algorithm will propagate the results of the changed link cost only if the new link cost results in a changed least-cost path for one of the nodes attached to that link.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Speed of convergence.</span><span class="font53"> We have seen that our implementation of LS is an O(|N|<sup>2</sup>) algorithm requiring O(|N| |E|)) messages. The DV algorithm can converge slowly and can have routing loops while the algorithm is converging. DV also suffers from the count-to-infinity problem.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Robustness.</span><span class="font53"> What can happen if a router fails, misbehaves, or is sabotaged? Under LS, a router could broadcast an incorrect cost for one of its attached links (but no others). A node could also corrupt or drop any packets it received as part of an LS broadcast. But an LS node is computing only its own forwarding tables; other nodes are performing similar calculations for themselves. This means route calculations are somewhat separated under LS, providing a degree of robustness. Under DV, a node can advertise incorrect least-cost paths to any or all destinations. (Indeed, in 1997, a malfunctioning router in a small ISP provided national backbone routers with erroneous routing information. This caused other routers to flood the malfunctioning router with traffic and caused large portions of the Internet to become disconnected for up to several hours [Neumann 1997].) More generally, we note that, at each iteration, a node’s calculation in DV is passed on to its neighbor and then indirectly to its neighbor’s neighbor on the next iteration. In this sense, an incorrect node calculation can be diffused through the entire network under DV.</span></p></li></ul>
<p><span class="font53">In the end, neither algorithm is an obvious winner over the other; indeed, both algorithms are used in the Internet.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">5.3 </span><span class="font24" style="font-weight:bold;">Intra-AS Routing in the Internet: OSPF</span></p></li></ul>
<p><span class="font53">In our study of routing algorithms so far, we’ve viewed the network simply as a collection of interconnected routers. One router was indistinguishable from another in the sense that all routers executed the same routing algorithm to compute routing paths through the entire network. In practice, this model and its view of a homogenous set of routers all executing the same routing algorithm is simplistic for two important reasons:</span></p>
<p><a name="bookmark360"></a><span class="font53">• </span><span class="font53" style="font-style:italic;">Scale.</span><span class="font53"> As the number of routers becomes large, the overhead involved in communicating, computing, and storing routing information becomes prohibitive. Today’s Internet consists of hundreds of millions of routers. Storing routing information for possible destinations at each of these routers would clearly require enormous amounts of memory. The overhead required to broadcast connectivity and link cost updates among all of the routers would be huge! A distance-vector algorithm that iterated among such a large number of routers would surely never converge. Clearly, something must be done to reduce the complexity of route computation in a network as large as the Internet.</span></p>
<p><span class="font53">• </span><span class="font53" style="font-style:italic;">Administrative autonomy.</span><span class="font53"> As described in Section 1.3, the Internet is a network of ISPs, with each ISP consisting of its own network of routers. An ISP generally desires to operate its network as it pleases (for example, to run whatever routing algorithm it chooses within its network) or to hide aspects of its network’s internal organization from the outside. Ideally, an organization should be able to operate and administer its network as it wishes, while still being able to connect its network to other outside networks.</span></p>
<p><span class="font53">Both of these problems can be solved by organizing routers into </span><span class="font53" style="font-weight:bold;">autonomous systems (ASs)</span><span class="font53">, with each AS consisting of a group of routers that are under the same administrative control. Often the routers in an ISP, and the links that interconnect them, constitute a single AS. Some ISPs, however, partition their network into multiple ASs. In particular, some tier-1 ISPs use one gigantic AS for their entire network, whereas others break up their ISP into tens of interconnected ASs. An autonomous system is identified by its globally unique autonomous system number (ASN) [RFC 1930]. AS numbers, like IP addresses, are assigned by ICANN regional registries [ICANN 2020].</span></p>
<p><span class="font53">Routers within the same AS all run the same routing algorithm and have information about each other. The routing algorithm running within an autonomous system is called an </span><span class="font53" style="font-weight:bold;">intra-autonomous system routing protocol</span><span class="font53">.</span></p>
<p><span class="font22" style="font-weight:bold;">Open Shortest Path First (OSPF)</span></p>
<p><span class="font53">OSPF routing and its closely related cousin, IS-IS, are widely used for intra-AS routing in the Internet. The Open in OSPF indicates that the routing protocol specification is publicly available (for example, as opposed to Cisco’s EIGRP protocol, which was only recently became open [Savage 2015], after roughly 20 years as a Cisco-proprietary protocol). The most recent version of OSPF, version 2, is defined in [RFC 2328], a public document.</span></p>
<p><span class="font53">OSPF is a link-state protocol that uses flooding of link-state information and a Dijkstra’s least-cost path algorithm. With OSPF, each router constructs a complete topological map (that is, a graph) of the entire autonomous system. Each router then locally runs Dijkstra’s shortest-path algorithm to determine a shortest-path tree to all </span><span class="font53" style="font-style:italic;">subnets,</span><span class="font53"> with itself as the root node. Individual link costs are configured by the network administrator (see sidebar, Principles and Practice:</span></p>
<div><img src="networking_files/networking-381.jpg" alt="" style="width:131pt;height:21pt;">
<p><span class="font4" style="font-weight:bold;">SETTING OSPF LINK WEIGHTS</span></p>
</div><br clear="all">
<div>
<p><span class="font23" style="font-weight:bold;">PRINCIPLES IN PRACTICE</span></p>
</div><br clear="all">
<p><span class="font4">Our discussion of link-state routing has implicitly assumed that link weights are set, a routing algorithm such as OSPF is run, and traffic flows according to the routing tables computed by the LS algorithm. In terms of cause and effect, the link weights are given (i.e., they come first) and result (via Dijkstra’s algorithm) in routing paths that minimize overall cost. In this viewpoint, link weights reflect the cost of using a link (for example, if link weights are inversely proportional to capacity, then the use of high-capacity links would have smaller weight and thus be more attractive from a routing standpoint) and Dijsktra’s algorithm serves to minimize overall cost.</span></p>
<p><span class="font4">In practice, the cause and effect relationship between link weights and routing paths may be reversed, with network operators configuring link weights in order to obtain routing paths that achieve certain traffic engineering goals [Fortz 2000, Fortz 2002]. For example, suppose a network operator has an estimate of traffic flow entering the network at each ingress point and destined for each egress point. The operator may then want to put in place a specific routing of ingress-to-egress flows that minimizes the maximum utilization over all of the network’s links. But with a routing algorithm such as OSPF, the operator’s main “knobs” for tuning the routing of flows through the network are the link weights. Thus, in order to achieve the goal of minimizing the maximum link utilization, the operator must find the set of link weights that achieves this goal. This is a reversal of the cause and effect relationship — the desired routing of flows is known, and the OSPF link weights must be found such that the OSPF routing algorithm results in this desired routing of flows.</span></p>
<p><span class="font53">Setting OSPF Weights). The administrator might choose to set all link costs to 1, thus achieving minimum-hop routing, or might choose to set the link weights to be inversely proportional to link capacity in order to discourage traffic from using low-bandwidth links. OSPF does not mandate a policy for how link weights are set (that is the job of the network administrator), but instead provides the mechanisms (protocol) for determining least-cost path routing for the given set of link weights.</span></p>
<p><span class="font53">With OSPF, a router broadcasts routing information to </span><span class="font53" style="font-style:italic;">all</span><span class="font53"> other routers in the autonomous system, not just to its neighboring routers. A router broadcasts link-state information whenever there is a change in a link’s state (for example, a change in cost or a change in up/down status). It also broadcasts a link’s state periodically (at least once every 30 minutes), even if the link’s state has not changed. RFC 2328 notes that “this periodic updating of link state advertisements adds robustness to the link state algorithm.” OSPF advertisements are contained in OSPF messages that are carried directly by IP, with an upper-layer protocol of 89 for OSPF. Thus, the OSPF protocol must itself implement functionality such as reliable message transfer and link-state broadcast. The OSPF protocol also checks that links are operational (via a HELLO message that is sent to an attached neighbor) and allows an OSPF router to obtain a neighboring router’s database of network-wide link state.</span></p>
<p><span class="font53">Some of the advances embodied in OSPF include the following:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Security.</span><span class="font53"> Exchanges between OSPF routers (for example, link-state updates) can be authenticated. With authentication, only trusted routers can participate in the OSPF protocol within an AS, thus preventing malicious intruders (or networking students taking their newfound knowledge out for a joyride) from injecting incorrect information into router tables. By default, OSPF packets between routers are not authenticated and could be forged. Two types of authentication can be configured—simple and MD5 (see Chapter 8 for a discussion on MD5 and authentication in general). With simple authentication, the same password is configured on each router. When a router sends an OSPF packet, it includes the password in plaintext. Clearly, simple authentication is not very secure. MD5 authentication is based on shared secret keys that are configured in all the routers. For each OSPF packet that it sends, the router computes the MD5 hash of the content of the OSPF packet appended with the secret key. (See the discussion of message authentication codes in Chapter 8.) Then the router includes the resulting hash value in the OSPF packet. The receiving router, using the preconfigured secret key, will compute an MD5 hash of the packet and compare it with the hash value that the packet carries, thus verifying the packet’s authenticity. Sequence numbers are also used with MD5 authentication to protect against replay attacks.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Multiple same-cost paths.</span><span class="font53"> When multiple paths to a destination have the same cost, OSPF allows multiple paths to be used (that is, a single path need not be chosen for carrying all traffic when multiple equal-cost paths exist).</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Integrated support for unicast and multicast routing.</span><span class="font53"> Multicast OSPF (MOSPF) [RFC 1584] provides simple extensions to OSPF to provide for multicast routing. MOSPF uses the existing OSPF link database and adds a new type of link-state advertisement to the existing OSPF link-state broadcast mechanism.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Support for hierarchy within a single AS.</span><span class="font53"> An OSPF autonomous system can be configured hierarchically into areas. Each area runs its own OSPF link-state routing algorithm, with each router in an area broadcasting its link state to all other routers in that area. Within each area, one or more area border routers are responsible for routing packets outside the area. Lastly, exactly one OSPF area in the AS is configured to be the backbone area. The primary role of the backbone area is to route traffic between the other areas in the AS. The backbone always contains all area border routers in the AS and may contain non-border routers as well. Inter-area routing within the AS requires that the packet be first routed to an area border router (intra-area routing), then routed through the backbone to the area border router that is in the destination area, and then routed to the final destination.</span></p></li></ul>
<p><span class="font53">OSPF is a relatively complex protocol, and our coverage here has been necessarily brief; [Huitema 1998; Moy 1998; RFC 2328] provide additional details.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">5.4 </span><span class="font24" style="font-weight:bold;">Routing Among the ISPs: BGP</span></p>
<div>
<p><span class="font16" style="font-weight:bold;">D</span></p>
<p><span class="font2" style="font-weight:bold;">VideoNote</span></p>
<p><span class="font1" style="font-weight:bold;">Gluing the Internet</span></p>
<p><span class="font1" style="font-weight:bold;">Together: BGP</span></p>
</div><br clear="all"></li></ul>
<p><span class="font53">We just learned that OSPF is an example of an intra-AS routing protocol. When routing a packet between a source and destination within the same AS, the route the packet follows is entirely determined by the intra-AS routing protocol. However, to route a packet across multiple ASs, say from a smartphone in Timbuktu to a server in a datacenter in Silicon Valley, we need an </span><span class="font53" style="font-weight:bold;">inter-autonomous system routing protocol</span><span class="font53">. Since an inter-AS routing protocol involves coordination among multiple ASs, communicating ASs must run the same inter-AS routing protocol. In fact, in the Internet, all ASs run the same inter-AS routing protocol, called the Border Gateway Protocol, more commonly known as </span><span class="font53" style="font-weight:bold;">BGP </span><span class="font53">[RFC 4271; Stewart 1999].</span></p>
<p><span class="font53">BGP is arguably the most important of all the Internet protocols (the only other contender would be the IP protocol that we studied in Section 4.3), as it is the protocol that glues the thousands of ISPs in the Internet together. As we will soon see, BGP is a decentralized and asynchronous protocol in the vein of distance-vector routing described in Section 5.2.2. Although BGP is a complex and challenging protocol, to understand the Internet on a deep level, we need to become familiar with its underpinnings and operation. The time we devote to learning BGP will be well worth the effort.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">5.4.1 </span><span class="font23" style="font-weight:bold;">The Role of BGP</span></p></li></ul>
<p><span class="font53">To understand the responsibilities of BGP, consider an AS and an arbitrary router in that AS. Recall that every router has a forwarding table, which plays the central role in the process of forwarding arriving packets to outbound router links. As we have learned, for destinations that are within the same AS, the entries in the router’s forwarding table are determined by the AS’s intra-AS routing protocol. But what about destinations that are outside of the AS? This is precisely where BGP comes to the rescue.</span></p>
<p><a name="bookmark361"></a><span class="font53">In BGP, packets are not routed to a specific destination address, but instead to CIDRized prefixes, with each prefix representing a subnet or a collection of subnets.</span></p>
<p><span class="font53">In the world of BGP, a destination may take the form 138.16.68/22, which for this example includes 1,024 IP addresses. Thus, a router’s forwarding table will have entries of the form (</span><span class="font53" style="font-style:italic;">x</span><span class="font53">, </span><span class="font53" style="font-style:italic;">I),</span><span class="font53"> where </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> is a prefix (such as 138.16.68/22) and </span><span class="font53" style="font-style:italic;">I</span><span class="font53"> is an interface number for one of the router’s interfaces.</span></p>
<p><span class="font53">As an inter-AS routing protocol, BGP provides each router a means to:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">1. &nbsp;</span><span class="font53" style="font-style:italic;">Obtain prefix reachability information from neighboring ASs.</span><span class="font53"> In particular, BGP allows each subnet to advertise its existence to the rest of the Internet. A subnet screams, “I exist and I am here,” and BGP makes sure that all the routers in the Internet know about this subnet. If it weren’t for BGP, each subnet would be an isolated island—alone, unknown and unreachable by the rest of the Internet.</span></p></li>
<li>
<p><span class="font53">2. </span><span class="font53" style="font-style:italic;">Determine the “best” routes to the prefixes.</span><span class="font53"> A router may learn about two or more different routes to a specific prefix. To determine the best route, the router will locally run a BGP route-selection procedure (using the prefix reachability information it obtained via neighboring routers). The best route will be determined based on policy as well as the reachability information.</span></p></li></ul>
<p><span class="font53">Let us now delve into how BGP carries out these two tasks.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">5.4.2 </span><span class="font23" style="font-weight:bold;">Advertising BGP Route Information</span></p></li></ul>
<p><span class="font53">Consider the network shown in Figure 5.8. As we can see, this simple network has three autonomous systems: AS1, AS2, and AS3. As shown, AS3 includes a subnet with prefix x. For each AS, each router is either a </span><span class="font53" style="font-weight:bold;">gateway router </span><span class="font53">or an </span><span class="font53" style="font-weight:bold;">internal router</span><span class="font53">. A gateway router is a router on the edge of an AS that directly connects to one or more routers in other ASs. An </span><span class="font53" style="font-weight:bold;">internal router </span><span class="font53">connects only to hosts and routers within its own AS. In AS1, for example, router 1c is a gateway router; routers 1a, 1b, and 1d are internal routers.</span></p>
<p><span class="font53">Let’s consider the task of advertising reachability information for prefix x to all of the routers shown in Figure 5.8. At a high level, this is straightforward. First, AS3 sends a BGP message to AS2, saying that x exists and is in AS3; let’s denote this message as “AS3 x”. Then AS2 sends a BGP message to AS1, saying that x exists and that you can get to x by first passing through AS2 and then going to AS3; let’s denote that message as “AS2 AS3 x”. In this manner, each of the autonomous systems will not only learn about the existence of x, but also learn about a path of autonomous systems that leads to x.</span></p>
<p><a name="bookmark362"></a><span class="font53">Although the discussion in the above paragraph about advertising BGP reachability information should get the general idea across, it is not precise in the sense that autonomous systems do not actually send messages to each other, but instead routers do. To understand this, let’s now re-examine the example in Figure 5.8. In BGP,</span></p><img src="networking_files/networking-382.jpg" alt="" style="width:355pt;height:109pt;">
<p><span class="font4" style="font-weight:bold;">AS1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;AS3</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 5.8 </span><span class="font50">♦ </span><span class="font5">Network with three autonomous systems. AS3 includes a subnet with prefix x</span></p>
<p><span class="font53">pairs of routers exchange routing information over semi-permanent TCP connections using port 179. Each such TCP connection, along with all the BGP messages sent over the connection, is called a </span><span class="font53" style="font-weight:bold;">BGP connection</span><span class="font53">. Furthermore, a BGP connection that spans two ASs is called an </span><span class="font53" style="font-weight:bold;">external BGP (eBGP) </span><span class="font53">connection, and a BGP session between routers in the same AS is called an </span><span class="font53" style="font-weight:bold;">internal BGP (iBGP) </span><span class="font53">connection. Examples of BGP connections for the network in Figure 5.8 are shown in Figure 5.9. There is typically one eBGP connection for each link that directly connects gateway routers in different ASs; thus, in Figure 5.9, there is an eBGP connection between gateway routers 1c and 2a and an eBGP connection between gateway routers 2c and 3 a.</span></p>
<p><span class="font53">There are also iBGP connections between routers within each of the ASs. In particular, Figure 5.9 displays a common configuration of one BGP connection for each pair of routers internal to an AS, creating a mesh of TCP connections within each AS. In Figure 5.9, the eBGP connections are shown with the long dashes; the iBGP connections are shown with the short dashes. Note that iBGP connections do not always correspond to physical links.</span></p>
<p><span class="font53">In order to propagate the reachability information, both iBGP and eBGP sessions are used. Consider again advertising the reachability information for prefix x to all routers in AS1 and AS2. In this process, gateway router 3a first sends an eBGP message “AS3 x” to gateway router 2c. Gateway router 2c then sends the iBGP message “AS3 x” to all of the other routers in AS2, including to gateway router 2a. Gateway router 2a then sends the eBGP message “AS2 AS3 x” to gateway router 1c. Finally, gateway router 1c uses iBGP to send the</span></p>
<div><img src="networking_files/networking-383.jpg" alt="" style="width:240pt;height:109pt;">
<p><span class="font4" style="font-weight:bold;">AS1</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-384.jpg" alt="" style="width:120pt;height:74pt;">
<p><span class="font4" style="font-weight:bold;">AS3</span></p>
</div><br clear="all">
<p><span class="font4">Key:</span></p>
<p><span class="font41">---eBGP</span></p>
<p><span class="font41">------iBGP</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 5.9 </span><span class="font50">♦ </span><span class="font5">eBGP and iBGP connections</span></p>
<p><span class="font53">message “AS2 AS3 x” to all the routers in AS1. After this process is complete, each router in AS1 and AS2 is aware of the existence of x and is also aware of an AS path that leads to x.</span></p>
<p><span class="font53">Of course, in a real network, from a given router there may be many different paths to a given destination, each through a different sequence of ASs. For example, consider the network in Figure 5.10, which is the original network in Figure 5.8, with an additional physical link from router 1d to router 3d. In this case, there are two paths from AS1 to x: the path “AS2 AS3 x” via router 1c; and the new path “AS3 x” via the router 1d.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">5.4.3 </span><span class="font23" style="font-weight:bold;">Determining the Best Routes</span></p></li></ul>
<p><span class="font53">As we have just learned, there may be many paths from a given router to a destination subnet. In fact, in the Internet, routers often receive reachability information about dozens of different possible paths. How does a router choose among these paths (and then configure its forwarding table accordingly)?</span></p>
<p><a name="bookmark363"></a><span class="font53">Before addressing this critical question, we need to introduce a little more BGP terminology. When a router advertises a prefix across a BGP connection, it includes with the prefix several </span><span class="font53" style="font-weight:bold;">BGP attributes</span><span class="font53">. In BGP jargon, a prefix along with its attributes is called a </span><span class="font53" style="font-weight:bold;">route</span><span class="font53">. Two of the more important attributes are AS-PATH and NEXT-HOP. The AS-PATH attribute contains the list of ASs through which the</span></p><img src="networking_files/networking-385.jpg" alt="" style="width:355pt;height:134pt;">
<p><span class="font7" style="font-weight:bold;">Figure 5.10 </span><span class="font50">♦ </span><span class="font5">Network augmented with peering link between AS1 and AS3</span></p>
<p><span class="font53">advertisement has passed, as we’ve seen in our examples above. To generate the AS-PATH value, when a prefix is passed to an AS, the AS adds its ASN to the existing list in the AS-PATH. For example, in Figure 5.10, there are two routes from AS1 to subnet x: one which uses the AS-PATH “AS2 AS3”; and another that uses the AS-PATH “A3”. BGP routers also use the AS-PATH attribute to detect and prevent looping advertisements; specifically, if a router sees that its own AS is contained in the path list, it will reject the advertisement.</span></p>
<p><span class="font53">Providing the critical link between the inter-AS and intra-AS routing protocols, the NEXT-HOP attribute has a subtle but important use. The NEXT-HOP is the </span><span class="font53" style="font-style:italic;">IP address of the router interface that begins the AS-PATH.</span><span class="font53"> To gain insight into this attribute, let’s again refer to Figure 5.10. As indicated in Figure 5.10, the NEXTHOP attribute for the route “AS2 AS3 x” from AS1 to x that passes through AS2 is the IP address of the left interface on router 2a. The NEXT-HOP attribute for the route “AS3 x” from AS1 to x that bypasses AS2 is the IP address of the leftmost interface of router 3d. In summary, in this toy example, each router in AS1 becomes aware of two BGP routes to prefix x:</span></p>
<p><span class="font53">IP address of leftmost interface for router 2a; AS2 AS3; x IP address of leftmost interface of router 3d; AS3; x</span></p>
<p><span class="font53">Here, each BGP route is written as a list with three components: NEXT-HOP; AS-PATH; destination prefix. In practice, a BGP route includes additional attributes, which we will ignore for the time being. Note that the NEXT-HOP attribute is an IP address of a router that does </span><span class="font53" style="font-style:italic;">not</span><span class="font53"> belong to AS1; however, the subnet that contains this IP address directly attaches to AS1.</span></p>
<p><span class="font22" style="font-weight:bold;">Hot Potato Routing</span></p>
<p><span class="font53">We are now </span><span class="font53" style="font-style:italic;">finally</span><span class="font53"> in position to talk about BGP routing algorithms in a precise manner. We will begin with one of the simplest routing algorithms, namely, </span><span class="font53" style="font-weight:bold;">hot potato routing</span><span class="font53">.</span></p>
<p><span class="font53">Consider router 1b in the network in Figure 5.10. As just described, this router will learn about two possible BGP routes to prefix x. In hot potato routing, the route chosen (from among all possible routes) is that route with the least cost to the NEXTHOP router beginning that route. In this example, router 1b will consult its intra-AS routing information to find the least-cost intra-AS path to NEXT-HOP router 2a and the least-cost intra-AS path to NEXT-HOP router 3d, and then select the route with the smallest of these least-cost paths. For example, suppose that cost is defined as the number of links traversed. Then the least cost from router 1b to router 2a is 2, the least cost from router 1b to router 2d is 3, and router 2a would therefore be selected. Router 1b would then consult its forwarding table (configured by its intra-AS algorithm) and find the interface </span><span class="font53" style="font-style:italic;">I</span><span class="font53"> that is on the least-cost path to router 2a. It then adds </span><span class="font53" style="font-style:italic;">(x, I)</span><span class="font53"> to its forwarding table.</span></p>
<p><span class="font53">The steps for adding an outside-AS prefix in a router’s forwarding table for hot potato routing are summarized in Figure 5.11. It is important to note that when adding an outside-AS prefix into a forwarding table, both the inter-AS routing protocol (BGP) and the intra-AS routing protocol (e.g., OSPF) are used.</span></p>
<p><span class="font53">The idea behind hot-potato routing is for router 1b to get packets out of its AS as quickly as possible (more specifically, with the least cost possible) without worrying about the cost of the remaining portions of the path outside of its AS to the destination. In the name “hot potato routing,” a packet is analogous to a hot potato that is burning in your hands. Because it is burning hot, you want to pass it off to another person (another AS) as quickly as possible. Hot potato routing is thus</span></p>
<p><span class="font4">Learn from inter-AS protocol that subnet x is reachable via multiple gateways. </span><span class="font53">a selfish algorithm—it tries to reduce the cost in its own AS while ignoring the other components of the end-to-end costs outside its AS. Note that with hot potato routing, two routers in the same AS may choose two different AS paths to the same prefix. For example, we just saw that router 1b would send packets through AS2 to reach x. However, router 1d would bypass AS2 and send packets directly to AS3 to reach x.</span></p>
<div><img src="networking_files/networking-386.jpg" alt="" style="width:319pt;height:69pt;">
<p><span class="font7" style="font-weight:bold;">Figure 5.11 </span><span class="font50">♦ </span><span class="font5">Steps in adding outside-AS destination in a router's forwarding table</span></p>
</div><br clear="all">
<p><span class="font22" style="font-weight:bold;">Route-Selection Algorithm</span></p>
<p><span class="font53">In practice, BGP uses an algorithm that is more complicated than hot potato routing, but nevertheless incorporates hot potato routing. For any given destination prefix, the input into BGP’s route-selection algorithm is the set of all routes to that prefix that have been learned and accepted by the router. If there is only one such route, then BGP obviously selects that route. If there are two or more routes to the same prefix, then BGP sequentially invokes the following elimination rules until one route remains:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">1. A route is assigned a </span><span class="font53" style="font-weight:bold;">local preference </span><span class="font53">value as one of its attributes (in addition to the AS-PATH and NEXT-HOP attributes). The local preference of a route could have been set by the router or could have been learned from another router in the same AS. The value of the local preference attribute is a policy decision that is left entirely up to the AS’s network administrator. (We will shortly discuss BGP policy issues in some detail.) The routes with the highest local preference values are selected.</span></p></li>
<li>
<p><span class="font53">2. From the remaining routes (all with the same highest local preference value), the route with the shortest AS-PATH is selected. If this rule were the only rule for route selection, then BGP would be using a DV algorithm for path determination, where the distance metric uses the number of AS hops rather than the number of router hops.</span></p></li>
<li>
<p><span class="font53">3. From the remaining routes (all with the same highest local preference value and the same AS-PATH length), hot potato routing is used, that is, the route with the closest NEXT-HOP router is selected.</span></p></li>
<li>
<p><span class="font53">4. If more than one route still remains, the router uses BGP identifiers to select the route; see [Stewart 1999].</span></p></li></ul>
<p><span class="font53">As an example, let’s again consider router 1b in Figure 5.10. Recall that there are exactly two BGP routes to prefix x, one that passes through AS2 and one that bypasses AS2. Also recall that if hot potato routing on its own were used, then BGP would route packets through AS2 to prefix x. But in the above route-selection algorithm, rule 2 is applied before rule 3, causing BGP to select the route that bypasses AS2, since that route has a shorter AS PATH. So we see that with the above routeselection algorithm, BGP is no longer a selfish algorithm—it first looks for routes with short AS paths (thereby likely reducing end-to-end delay).</span></p>
<p><span class="font53">As noted above, BGP is the </span><span class="font53" style="font-style:italic;">de facto</span><span class="font53"> standard for in ter-AS routing for the Internet. To see the contents of various BGP routing tables (large!) extracted from routers in tier-1 ISPs, see </span><a href="http://www.routeviews.org"><span class="font53">http://www.routeviews.org</span></a><span class="font53">. BGP routing tables often contain over half a million routes (that is, prefixes and corresponding attributes). Statistics about the size and characteristics of BGP routing tables are presented in [Huston 2019b].</span></p>
<p><span class="font56" style="font-weight:bold;">5.4.4 </span><span class="font23" style="font-weight:bold;">IP-Anycast</span></p>
<p><span class="font53">In addition to being the Internet’s inter-AS routing protocol, BGP is often used to implement the IP-anycast service [RFC 1546, RFC 7094], which is commonly used in DNS. To motivate IP-anycast, consider that in many applications, we are interested in (1) replicating the same content on different servers in many different dispersed geographical locations, and (2) having each user access the content from the server that is closest. For example, a CDN may replicate videos and other objects on servers in different countries. Similarly, the DNS system can replicate DNS records on DNS servers throughout the world. When a user wants to access this replicated content, it is desirable to point the user to the “nearest” server with the replicated content. BGP’s route-selection algorithm provides an easy and natural mechanism for doing so.</span></p>
<p><span class="font53">To make our discussion concrete, let’s describe how a CDN might use IP-anycast. As shown in Figure 5.12, during the IP-anycast configuration stage, the CDN company assigns the </span><span class="font53" style="font-style:italic;">same</span><span class="font53"> IP address to each of its servers, and uses standard BGP to advertise this IP address from each of the servers. When a BGP router receives multiple route advertisements for this IP address, it treats these advertisements as providing different paths to the same physical location (when, in fact, the advertisements are for different paths to different physical locations). When configuring its routing table, each router will locally use the BGP route-selection algorithm to pick the “best” (for example, closest, as determined by AS-hop counts) route to that IP address. For example, if one BGP route (corresponding to one location) is only one AS hop away from the router, and all other BGP routes (corresponding to other locations) are two or more AS hops away, then the BGP router would choose to route packets to the location that is one hop away. After this initial BGP address-advertisement phase, the CDN can do its main job of distributing content. When a client requests the video, the CDN returns to the client the common IP address used by the geographically dispersed servers, no matter where the client is located. When the client sends a request to that IP address, Internet routers then forward the request packet to the “closest” server, as defined by the BGP route-selection algorithm.</span></p>
<p><a name="bookmark364"></a><span class="font53">Although the above CDN example nicely illustrates how IP-anycast can be used, in practice, CDNs generally choose not to use IP-anycast because BGP routing changes can result in different packets of the same TCP connection arriving at different instances of the Web server. But IP-anycast is extensively used by the DNS system to direct DNS queries to the closest root DNS server. Recall from Section 2.4, there are currently 13 IP addresses for root DNS servers. But corresponding to each of these addresses, there are multiple DNS root servers, with some of these addresses having</span></p><img src="networking_files/networking-387.jpg" alt="" style="width:379pt;height:252pt;">
<p><span class="font4" style="font-weight:bold;">AS4</span></p>
<p><span class="font4" style="font-weight:bold;">AS3</span></p>
<p><span class="font4" style="font-weight:bold;">AS1</span></p>
<p><span class="font4" style="font-weight:bold;">AS2</span></p>
<p><span class="font4">CDN Server A</span></p>
<p><span class="font4">CDN Server B</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 5.12 </span><span class="font50">♦ </span><span class="font5">Using IP-anycast to bring users to the closest CDN server</span></p>
<p><span class="font4">Advertise</span></p>
<p><span class="font4">212.21.21.21</span></p>
<p><span class="font4">Receive BGP advertisements for 212.21.21.21 from AS1 and from AS4. Forward toward Server B since it is closer.</span></p>
<p><span class="font4">Advertise</span></p>
<p><span class="font4">212.21.21.21</span></p>
<p><span class="font53">over 100 DNS root servers scattered over all corners of the world. When a DNS query is sent to one of these 13 IP addresses, IP anycast is used to route the query to the nearest of the DNS root servers that is responsible for that address. [Li 2018] presents recent measurements illustrating Internet anycast, use, performance, and challenges.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">5.4.5 </span><span class="font23" style="font-weight:bold;">Routing Policy</span></p></li></ul>
<p><span class="font53">When a router selects a route to a destination, the AS routing policy can trump all other considerations, such as shortest AS path or hot potato routing. Indeed, in the route-selection algorithm, routes are first selected according to the local-preference attribute, whose value is fixed by the policy of the local AS.</span></p>
<p><a name="bookmark365"></a><span class="font53">Let’s illustrate some of the basic concepts of BGP routing policy with a simple example. Figure 5.13 shows six interconnected autonomous systems: A, B, C, W, X, and Y. It is important to note that A, B, C, W, X, and Y are ASs, not routers. Let’s</span></p>
<div><img src="networking_files/networking-388.jpg" alt="" style="width:167pt;height:81pt;">
<p><span class="font7" style="font-weight:bold;">Figure 5.13 </span><span class="font50">♦ </span><span class="font5">A simple BGP policy scenario</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Key:</span></p>
</div><br clear="all">
<p><span class="font41">Provider</span></p>
<p><span class="font41">network</span></p>
<p><span class="font41">Customer</span></p>
<p><span class="font41">network</span></p>
<p><span class="font53">assume that autonomous systems W, X, and Y are access ISPs and that A, B, and C are backbone provider networks. We’ll also assume that A, B, and C, directly send traffic to each other, and provide full BGP information to their customer networks. All traffic entering an ISP access network must be destined for that network, and all traffic leaving an ISP access network must have originated in that network. W and Y are clearly access ISPs. X is a </span><span class="font53" style="font-weight:bold;">multi-homed access ISP</span><span class="font53">, since it is connected to the rest of the network via two different providers (a scenario that is becoming increasingly common in practice). However, like W and Y, X itself must be the source/destination of all traffic leaving/entering X. But how will this stub network behavior be implemented and enforced? How will X be prevented from forwarding traffic between B and C? This can easily be accomplished by controlling the manner in which BGP routes are advertised. In particular, X will function as an access ISP network if it advertises (to its neighbors B and C) that it has no paths to any other destinations except itself. That is, even though X may know of a path, say XCY, that reaches network Y, it will not advertise this path to B. Since B is unaware that X has a path to Y, B would never forward traffic destined to Y (or C) via X. This simple example illustrates how a selective route advertisement policy can be used to implement customer/provider routing relationships.</span></p>
<p><span class="font53">Let’s next focus on a provider network, say AS B. Suppose that B has learned (from A) that A has a path AW to W. B can thus install the route AW into its routing information base. Clearly, B also wants to advertise the path BAW to its customer, X, so that X knows that it can route to W via B. But should B advertise the path BAW to C? If it does so, then C could route traffic to W via BAW. If A, B, and C are all backbone providers, than B might rightly feel that it should not have to shoulder the burden (and cost!) of carrying transit traffic between A and C. B might rightly feel that it is A’s and C’s job (and cost!) to make sure that C can route to/from A’s customers via a direct connection between A and C. There are currently no official standards that govern how backbone ISPs route among themselves. However, a rule of thumb followed by commercial ISPs is that any traffic flowing across an ISP’s backbone network must have either a source or a destination (or both) in a network that is a customer of that ISP; otherwise the traffic would be getting a free ride on the ISP’s network. Individual peering agreements (that would govern questions such</span></p>
<div><img src="networking_files/networking-389.jpg" alt="" style="width:131pt;height:21pt;">
</div><br clear="all">
<div>
<p><span class="font23" style="font-weight:bold;">PRINCIPLES IN PRACTICE</span></p>
</div><br clear="all">
<p><span class="font4" style="font-weight:bold;">WHY ARE THERE DIFFERENT INTER-AS AND INTRA-AS ROUTING PROTOCOLS?</span></p>
<p><span class="font4">Having now studied the details of specific inter-AS and intra-AS routing protocols deployed in today’s Internet, let’s conclude by considering perhaps the most fundamental question we could ask about these protocols in the first place (hopefully, you have been wondering this all along, and have not lost the forest for the trees!): Why are different inter-AS and intra-AS routing protocols used?</span></p>
<p><span class="font4">The answer to this question gets at the heart of the differences between the goals of routing within an AS and among ASs:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;&nbsp;</span><span class="font4" style="font-style:italic;">Policy.</span><span class="font4"> Among ASs, policy issues dominate. It may well be important that traffic originating in a given AS not be able to pass through another specific AS. Similarly, a given AS may well want to control what transit traffic it carries between other ASs. We have seen that BGP carries path attributes and provides for controlled distribution of routing information so that such policy-based routing decisions can be made. Within an AS, everything is nominally under the same administrative control, and thus policy issues play a much less important role in choosing routes within the AS.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font4" style="font-style:italic;">Scale.</span><span class="font4"> The ability of a routing algorithm and its data structures to scale to handle routing to/among large numbers of networks is a critical issue in inter-AS routing. Within an AS, scalability is less of a concern. For one thing, if a single ISP becomes too large, it is always possible to divide it into two ASs and perform inter-AS routing between the two new ASs. (Recall that OSPF allows such a hierarchy to be built by splitting an AS into areas.)</span></p></li>
<li>
<p><span class="font53">• &nbsp;&nbsp;</span><span class="font4" style="font-style:italic;">Performance.</span><span class="font4"> Because inter-AS routing is so policy oriented, the quality (for example, performance) of the routes used is often of secondary concern (that is, a longer or more costly route that satisfies certain policy criteria may well be taken over a route that is shorter but does not meet that criteria). Indeed, we saw that among ASs, there is not even the notion of cost (other than AS hop count) associated with routes. Within a single AS, however, such policy concerns are of less importance, allowing routing to focus more on the level of performance realized on a route.</span></p></li></ul>
<p><span class="font53">as those raised above) are typically negotiated between pairs of ISPs and are often confidential; [Huston 1999a; Huston 2012] provide an interesting discussion of peering agreements. For a detailed description of how routing policy reflects commercial relationships among ISPs, see [Gao 2001; Dmitiropoulos 2007]. For a discussion of BGP routing polices from an ISP standpoint, see [Caesar 2005b].</span></p>
<p><span class="font53">This completes our brief introduction to BGP. Understanding BGP is important because it plays a central role in the Internet. We encourage you to see the references [Stewart 1999; Huston 2019a; Labovitz 1997; Halabi 2000; Huitema 1998; Gao 2001; Feamster 2004; Caesar 2005b; Li 2007] to learn more about BGP.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">5.4.6 </span><span class="font23" style="font-weight:bold;">Putting the Pieces Together: Obtaining</span></p></li></ul>
<p><span class="font23" style="font-weight:bold;">Internet Presence</span></p>
<p><span class="font53">Although this subsection is not about BGP </span><span class="font53" style="font-style:italic;">per se,</span><span class="font53"> it brings together many of the protocols and concepts we’ve seen thus far, including IP addressing, DNS, and BGP.</span></p>
<p><span class="font53">Suppose you have just created a small company that has a number of servers, including a public Web server that describes your company’s products and services, a mail server from which your employees obtain their e-mail messages, and a DNS server. Naturally, you would like the entire world to be able to visit your Web site in order to learn about your exciting products and services. Moreover, you would like your employees to be able to send and receive e-mail to potential customers throughout the world.</span></p>
<p><span class="font53">To meet these goals, you first need to obtain Internet connectivity, which is done by contracting with, and connecting to, a local ISP. Your company will have a gateway router, which will be connected to a router in your local ISP. This connection might be a DSL connection through the existing telephone infrastructure, a leased line to the ISP’s router, or one of the many other access solutions described in Chapter 1. Your local ISP will also provide you with an IP address range, for example, a /24 address range consisting of 256 addresses. Once you have your physical connectivity and your IP address range, you will assign one of the IP addresses (in your address range) to your Web server, one to your mail server, one to your DNS server, one to your gateway router, and other IP addresses to other servers and networking devices in your company’s network.</span></p>
<p><span class="font53">In addition to contracting with an ISP, you will also need to contract with an Internet registrar to obtain a domain name for your company, as described in Chapter 2. For example, if your company’s name is, say, Xanadu Inc., you will naturally try to obtain the domain name</span><a href="http://xanadu.com"><span class="font53"> xanadu.com</span></a><span class="font53">. Your company must also obtain presence in the DNS system. Specifically, because outsiders will want to contact your DNS server to obtain the IP addresses of your servers, you will also need to provide your registrar with the IP address of your DNS server. Your registrar will then put an entry for your DNS server (domain name and corresponding IP address) in the .com top-level-domain servers, as described in Chapter 2. After this step is completed, any user who knows your domain name (e.g.,</span><a href="http://xanadu.com"><span class="font53"> xanadu.com)</span></a><span class="font53"> will be able to obtain the IP address of your DNS server via the DNS system.</span></p>
<p><a name="bookmark366"></a><span class="font53">So that people can discover the IP addresses of your Web server, in your DNS server you will need to include entries that map the host name of your Web server (e.g., </span><a href="http://www.xanadu.com"><span class="font53">www.xanadu.com)</span></a><span class="font53"> to its IP address. You will want to have similar entries for other publicly available servers in your company, including your mail server. In this manner, if Alice wants to browse your Web server, the DNS system will contact your DNS server, find the IP address of your Web server, and give it to Alice. Alice can then establish a TCP connection directly with your Web server.</span></p>
<p><span class="font53">However, there still remains one other necessary and crucial step to allow outsiders from around the world to access your Web server. Consider what happens when Alice, who knows the IP address of your Web server, sends an IP datagram (e.g., a TCP SYN segment) to that IP address. This datagram will be routed through the Internet, visiting a series of routers in many different ASs, and eventually reach your Web server. When any one of the routers receives the datagram, it is going to look for an entry in its forwarding table to determine on which outgoing port it should forward the datagram. Therefore, each of the routers needs to know about the existence of your company’s /24 prefix (or some aggregate entry). How does a router become aware of your company’s prefix? As we have just seen, it becomes aware of it from BGP! Specifically, when your company contracts with a local ISP and gets assigned a prefix (i.e., an address range), your local ISP will use BGP to advertise your prefix to the ISPs to which it connects. Those ISPs will then, in turn, use BGP to propagate the advertisement. Eventually, all Internet routers will know about your prefix (or about some aggregate that includes your prefix) and thus be able to appropriately forward datagrams destined to your Web and mail servers.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">5.5 </span><span class="font24" style="font-weight:bold;">The SDN Control Plane</span></p></li></ul>
<p><span class="font53">In this section, we’ll dive into the SDN control plane—the network-wide logic that controls packet forwarding among a network’s SDN-enabled devices, as well as the configuration and management of these devices and their services. Our study here builds on our earlier discussion of generalized SDN forwarding in Section 4.4, so you might want to first review that section, as well as Section 5.1 of this chapter, before continuing on. As in Section 4.4, we’ll again adopt the terminology used in the SDN literature and refer to the network’s forwarding devices as “packet switches” (or just switches, with “packet” being understood), since forwarding decisions can be made on the basis of network-layer source/destination addresses, link-layer source/destina-tion addresses, as well as many other values in transport-, network-, and link-layer packet-header fields.</span></p>
<p><span class="font53">Four key characteristics of an SDN architecture can be identified [Kreutz 2015]:</span></p>
<p><a name="bookmark367"></a><span class="font53">• </span><span class="font53" style="font-style:italic;">Flow-based forwarding.</span><span class="font53"> Packet forwarding by SDN-controlled switches can be based on any number of header field values in the transport-layer, network-layer, or link-layer header. We saw in Section 4.4 that the OpenFlowl.0 abstraction allows forwarding based on eleven different header field values. This contrasts sharply with the traditional approach to router-based forwarding that we studied in Sections 5.2-5.4, where forwarding of IP datagrams was based solely on a datagram’s destination IP address. Recall from Figure 5.2 that packet forwarding rules are specified in a switch’s flow table; it is the job of the SDN control plane to compute, manage and install flow table entries in all of the network’s switches.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Separation of data plane and control plane.</span><span class="font53"> This separation is shown clearly in Figures 5.2 and 5.14. The data plane consists of the network’s switches— relatively simple (but fast) devices that execute the “match plus action” rules in their flow tables. The control plane consists of servers and software that determine and manage the switches’ flow tables.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Network control functions: external to data-plane switches.</span><span class="font53"> Given that the “S” in SDN is for “software,” it’s perhaps not surprising that the SDN control plane is implemented in software. Unlike traditional routers, however, this software executes on servers that are both distinct and remote from the network’s switches. As shown in Figure 5.14, the control plane itself consists of two components—an SDN controller (or network operating system [Gude 2008]) and a set of network-control applications. The controller maintains accurate network state information (e.g., the state of remote links, switches, and hosts); provides this information to the networkcontrol applications running in the control plane; and provides the means through which these applications can monitor, program, and control the underlying network devices. Although the controller in Figure 5.14 is shown as a single central server, in practice the controller is only logically centralized; it is typically implemented on several servers that provide coordinated, scalable performance and high availability.</span></p></li>
<li>
<p><span class="font53">• </span><span class="font53" style="font-style:italic;">A programmable network.</span><span class="font53"> The network is programmable through the networkcontrol applications running in the control plane. These applications represent the “brains” of the SDN control plane, using the APIs provided by the SDN controller to specify and control the data plane in the network devices. For example, a routing network-control application might determine the end-end paths between sources and destinations (for example, by executing Dijkstra’s algorithm using the nodestate and link-state information maintained by the SDN controller). Another network application might perform access control, that is, determine which packets are to be blocked at a switch, as in our third example in Section 4.4.3. Yet another application might have switches forward packets in a manner that performs server load balancing (the second example we considered in Section 4.4.3).</span></p></li></ul>
<p><span class="font53">From this discussion, we can see that SDN represents a significant “unbundling” of network functionality—data plane switches, SDN controllers, and network-control applications are separate entities that may each be provided by different vendors and organizations. This contrasts with the pre-SDN model in which a switch/router (together with its embedded control plane software and protocol implementations) was monolithic, vertically integrated, and sold by a single vendor. This unbundling</span></p>
<div><img src="networking_files/networking-390.jpg" alt="" style="width:102pt;height:68pt;">
<p><span class="font4" style="font-weight:bold;">Control</span></p>
<p><span class="font4" style="font-weight:bold;">plane</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Network-control Applications</span></p><img src="networking_files/networking-391.jpg" alt="" style="width:127pt;height:68pt;">
</div><br clear="all">
<div>
<p><span class="font4">Northbound</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Data plane</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-392.jpg" alt="" style="width:20pt;height:39pt;">
</div><br clear="all">
<div>
<p><span class="font4">API</span></p>
</div><br clear="all">
<div>
<p><span class="font4">SDN Controller (network operating system)</span></p><img src="networking_files/networking-393.jpg" alt="" style="width:186pt;height:89pt;">
</div><br clear="all">
<div>
<p><span class="font4">Southbound</span></p>
<p><span class="font4">API</span></p>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 5.14 </span><span class="font50">♦ </span><span class="font5">Components of the SDN architecture: SDN-controlled switches, the SDN controller, network-control applications</span></p>
<p><span class="font53">of network functionality in SDN has been likened to the earlier evolution from mainframe computers (where hardware, system software, and applications were provided by a single vendor) to personal computers (with their separate hardware, operating systems, and applications). The unbundling of computing hardware, system software, and applications has led to a rich, open ecosystem driven by innovation in all three of these areas; one hope for SDN is that it will continue to drive and enable such rich innovation.</span></p>
<p><span class="font53">Given our understanding of the SDN architecture of Figure 5.14, many questions naturally arise. How and where are the flow tables actually computed? How are these tables updated in response to events at SDN-controlled devices (e.g., an attached link going up/down)? And how are the flow table entries at multiple switches coordinated in such a way as to result in orchestrated and consistent network-wide functionality (e.g., end-to-end paths for forwarding packets from sources to destinations, or coordinated distributed firewalls)? It is the role of the SDN control plane to provide these, and many other, capabilities.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">5.5.1 </span><span class="font23" style="font-weight:bold;">The SDN Control Plane: SDN Controller and SDN Network-control Applications</span></p></li></ul>
<p><span class="font53">Let’s begin our discussion of the SDN control plane in the abstract, by considering the generic capabilities that the control plane must provide. As we’ll see, this abstract, “first principles” approach will lead us to an overall architecture that reflects how SDN control planes have been implemented in practice.</span></p>
<p><span class="font53">As noted above, the SDN control plane divides broadly into two components— the SDN controller and the SDN network-control applications. Let’s explore the controller first. Many SDN controllers have been developed since the earliest SDN controller [Gude 2008]; see [Kreutz 2015] for an extremely thorough survey. Figure 5.15 provides a more detailed view of a generic SDN controller. A controller’s functionality can be broadly organized into three layers. Let’s consider these layers in an uncharacteristically bottom-up fashion:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• </span><span class="font53" style="font-style:italic;">A communication layer: communicating between the SDN controller and controlled network devices.</span><span class="font53"> Clearly, if an SDN controller is going to control the operation of a remote SDN-enabled switch, host, or other device, a protocol is needed to transfer information between the controller and that device. In addition, a device must be able to communicate locally-observed events to the controller (for example, a message indicating that an attached link has gone up or down, that a device has just joined the network, or a heartbeat indicating that a device is up and operational). These events provide the SDN controller with an up-to-date view of the network’s state. This protocol constitutes the lowest layer of the controller architecture, as shown in Figure 5.15. The communication between the controller and the controlled devices cross what has come to be known as the controller’s “southbound” interface. In Section 5.5.2, we’ll study OpenFlow—a specific protocol that provides this communication functionality. OpenFlow is implemented in most, if not all, SDN controllers.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">A network-wide state-management layer.</span><span class="font53"> The ultimate control decisions made by the SDN control plane—for example, configuring flow tables in all switches to achieve the desired end-end forwarding, to implement load balancing, or to implement a particular firewalling capability—will require that the controller have up-to-date information about state of the networks’ hosts, links, switches, and other SDN-controlled devices. A switch’s flow table contains counters whose values might also be profitably used by network-control applications; these values should thus be available to the applications. Since the ultimate aim of the control plane is to determine flow tables for the various controlled devices, a controller might also maintain a copy of these tables. These pieces of information all constitute examples of the network-wide “state” maintained by the SDN controller.</span></p></li>
<li>
<p><a name="bookmark368"></a><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">The interface to the network-control application layer.</span><span class="font53"> The controller interacts with network-control applications through its “northbound” interface. This API</span></p>
<div><img src="networking_files/networking-394.jpg" alt="" style="width:228pt;height:106pt;">
<p><span class="font4" style="font-weight:bold;">Northbound API</span></p>
<p><span class="font4">Network-wide distributed, robust state management</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Statistics</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Flow tables</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">SDN Controller</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Link-state info</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Host info</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Switch info</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Communication to/from controlled devices</span></p>
</div><br clear="all">
<div>
<p><span class="font4">OpenFlow</span></p>
</div><br clear="all">
<div>
<p><span class="font4">SNMP</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-395.jpg" alt="" style="width:113pt;height:55pt;">
<p><span class="font7" style="font-weight:bold;">Figure 5.15 </span><span class="font50">♦ </span><span class="font5">Components of an SDN controller</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Southbound API</span></p>
</div><br clear="all"></li></ul>
<p><span class="font53">allows network-control applications to read/write network state and flow tables within the state-management layer. Applications can register to be notified when state-change events occur, so that they can take actions in response to network event notifications sent from SDN-controlled devices. Different types of APIs may be provided; we’ll see that two popular SDN controllers communicate with their applications using a REST [Fielding 2000] request-response interface.</span></p>
<p><span class="font53">We have noted several times that an SDN controller can be considered to be “logically centralized,” that is, that the controller may be viewed externally (for example, from the point of view of SDN-controlled devices and external network-control applications) as a single, monolithic service. However, these services and the databases used to hold state information are implemented in practice by a </span><span class="font53" style="font-style:italic;">distributed </span><span class="font53">set of servers for fault tolerance, high availability, or for performance reasons. With controller functions being implemented by a </span><span class="font53" style="font-style:italic;">set</span><span class="font53"> of servers, the semantics of the controller’s internal operations (e.g., maintaining logical time ordering of events, consistency, consensus, and more) must be considered [Panda 2013]. Such concerns are common across many different distributed systems; see [Lamport 1989, Lampson 1996] for elegant solutions to these challenges. Modern controllers such as OpenDaylight [OpenDaylight 2020] and ONOS [ONOS 2020] (see sidebar) have placed considerable emphasis on architecting a logically centralized but physically distributed controller platform that provides scalable services and high availability to the controlled devices and network-control applications alike.</span></p>
<p><span class="font53">The architecture depicted in Figure 5.15 closely resembles the architecture of the originally proposed NOX controller in 2008 [Gude 2008], as well as that of today’s OpenDaylight [OpenDaylight 2020] and ONOS [ONOS 2020] SDN controllers (see sidebar). We’ll cover an example of controller operation in Section 5.5.3. First, however, let’s examine the OpenFlow protocol, the earliest and now one of several protocols that can be used for communication between an SDN controller and a controlled device, which lies in the controller’s communication layer.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">5.5.2 </span><span class="font23" style="font-weight:bold;">OpenFlow Protocol</span></p></li></ul>
<p><span class="font53">The OpenFlow protocol [OpenFlow 2009, ONF 2020] operates between an SDN controller and an SDN-controlled switch or other device implementing the OpenFlow API that we studied earlier in Section 4.4. The OpenFlow protocol operates over TCP, with a default port number of 6653.</span></p>
<p><span class="font53">Among the important messages flowing from the controller to the controlled switch are the following:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Configuration.</span><span class="font53"> This message allows the controller to query and set a switch’s configuration parameters.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Modify-State.</span><span class="font53"> This message is used by a controller to add/delete or modify entries in the switch’s flow table, and to set switch port properties.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Read-State.</span><span class="font53"> This message is used by a controller to collect statistics and counter values from the switch’s flow table and ports.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Send-Packet.</span><span class="font53"> This message is used by the controller to send a specific packet out of a specified port at the controlled switch. The message itself contains the packet to be sent in its payload.</span></p></li></ul>
<p><span class="font53">Among the messages flowing from the SDN-controlled switch to the controller are the following:</span></p>
<ul style="list-style:none;"><li>
<p><a name="bookmark369"></a><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Flow-Removed.</span><span class="font53"> This message informs the controller that a flow table entry has been removed, for example by a timeout or as the result of a received </span><span class="font53" style="font-style:italic;">modify-state</span><span class="font53"> message.</span></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Port-status.</span><span class="font53"> This message is used by a switch to inform the controller of a change in port status.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Packet-in.</span><span class="font53"> Recall from Section 4.4 that a packet arriving at a switch port and not matching any flow table entry is sent to the controller for additional processing. Matched packets may also be sent to the controller, as an action to be taken on a match. The </span><span class="font53" style="font-style:italic;">packet-in</span><span class="font53"> message is used to send such packets to the controller.</span></p></li></ul>
<p><span class="font53">Additional OpenFlow messages are defined in [OpenFlow 2009, ONF 2020].</span></p>
<div><img src="networking_files/networking-396.jpg" alt="" style="width:132pt;height:22pt;">
</div><br clear="all">
<div>
<p><span class="font23" style="font-weight:bold;">PRINCIPLES IN PRACTICE</span></p>
</div><br clear="all">
<p><span class="font4" style="font-weight:bold;">GOOGLE'S SOFTWARE-DEFINED GLOBAL NETWORK</span></p>
<p><span class="font4">Recall from the case study in Section 2.6 that Google deploys a dedicated wide-area network (WAN) that interconnects its data centers and server clusters (in IXPs and ISPs). This network, called B4, has a Google-designed SDN control plane built on OpenFlow. Google’s network is able to drive WAN links at near 70% utilization over the long run (a two to three fold increase over typical link utilizations) and split application flows among multiple paths based on application priority and existing flow demands [Jain 2013].</span></p>
<p><span class="font4">The Google B4 network is particularly it well-suited for SDN: </span><span class="font4" style="font-style:italic;">(i)</span><span class="font4"> Google controls all devices from the edge servers in IXPs and ISPs to routers in their network core; </span><span class="font4" style="font-style:italic;">(ii)</span><span class="font4"> the most bandwidth-intensive applications are large-scale data copies between sites that can defer to higher-priority interactive applications during times of resource congestion; </span><span class="font4" style="font-style:italic;">(iii)</span><span class="font4"> with only a few dozen data centers being connected, centralized control is feasible.</span></p>
<p><span class="font4">Google’s B4 network uses custom-built switches, each implementing a slightly extended version of OpenFlow, with a local Open Flow Agent (OFA) that is similar in spirit to the control agent we encountered in Figure 5.2. Each OFA in turn connects to an Open Flow Controller (OFC) in the network control server (NCS), using a separate “out of band” network, distinct from the network that carries data-center traffic between data centers. The OFC thus provides the services used by the NCS to communicate with its controlled switches, similar in spirit to the lowest layer in the SDN architecture shown in Figure 5.15. In B4, the OFC also performs state management functions, keeping node and link status in a Network Information Base (NIB). Google’s implementation of the OFC is based on the ONIX SDN controller [Koponen 2010]. Two routing protocols, BGP (for routing between the data centers) and IS-IS (a close relative of OSPF, for routing within a data center), are implemented. Paxos [Chandra 2007] is used to execute hot replicas of NCS components to protect against failure.</span></p>
<p><span class="font4">A traffic engineering network-control application, sitting logically above the set of network control servers, interacts with these servers to provide global, network-wide bandwidth provisioning for groups of application flows. With B4, SDN made an important leap forward into the operational networks of a global network provider. See [Jain 2013; Hong 2018] for a detailed description of B4.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">5.5.3 </span><span class="font23" style="font-weight:bold;">Data and Control Plane Interaction: An Example</span></p></li></ul>
<p><span class="font53">In order to solidify our understanding of the interaction between SDN-controlled switches and the SDN controller, let’s consider the example shown in Figure 5.16, in which Dijkstra’s algorithm (which we studied in Section 5.2) is used to determine shortest path routes. The SDN scenario in Figure 5.16 has two important differences from the earlier per-router-control scenario of Sections 5.2.1 and 5.3, where Dijkstra’s algorithm was implemented in each and every router and link-state updates were flooded among all network routers:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;Dijkstra’s algorithm is executed as a separate application, outside of the packet switches.</span></p></li>
<li>
<p><span class="font53">• &nbsp;Packet switches send link updates to the SDN controller and not to each other.</span></p></li></ul>
<p><span class="font53">In this example, let’s assume that the link between switch s1 and s2 goes down; that shortest path routing is implemented, and consequently and that incoming and outgoing flow forwarding rules at s1, s3, and s4 are affected, but that s2’s</span></p>
<p><span class="font4">Dijkstra’s link-state Routing </span><span class="font53">operation is unchanged. Let’s also assume that OpenFlow is used as the communication layer protocol, and that the control plane performs no other function other than link-state routing.</span></p>
<div>
<p><span class="font4">Network graph</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-397.jpg" alt="" style="width:37pt;height:22pt;">
</div><br clear="all">
<div><img src="networking_files/networking-398.jpg" alt="" style="width:17pt;height:32pt;">
</div><br clear="all">
<div><img src="networking_files/networking-399.jpg" alt="" style="width:17pt;height:27pt;">
</div><br clear="all">
<div>
<p><span class="font4">RESTful API</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Intent</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Statistics</span></p>
<p><span class="font4">Host info</span></p>
<p><span class="font4">OpenFlow</span></p>
<p><span class="font4">Flow tables</span></p>
<p><span class="font4">Link-state info</span></p><img src="networking_files/networking-400.jpg" alt="" style="width:150pt;height:139pt;">
<p><a name="bookmark370"></a><span class="font7" style="font-weight:bold;">Figure 5.16 </span><span class="font50">♦ </span><span class="font5">SDN controller scenario: Link-state change</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Switch info</span></p>
</div><br clear="all">
<div>
<p><span class="font4">SNMP</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<p><span class="font53">1. Switch s1, experiencing a link failure between itself and s2, notifies the SDN controller of the link-state change using the OpenFlow </span><span class="font53" style="font-style:italic;">port-status</span><span class="font53"> message.</span></p></li>
<li>
<p><span class="font53">2. The SDN controller receives the OpenFlow message indicating the link-state change, and notifies the link-state manager, which updates a link-state database.</span></p></li>
<li>
<p><span class="font53">3. The network-control application that implements Dijkstra’s link-state routing has previously registered to be notified when link state changes. That application receives the notification of the link-state change.</span></p></li>
<li>
<p><span class="font53">4. The link-state routing application interacts with the link-state manager to get updated link state; it might also consult other components in the state-management layer. It then computes the new least-cost paths.</span></p></li>
<li>
<p><span class="font53">5. The link-state routing application then interacts with the flow table manager, which determines the flow tables to be updated.</span></p></li>
<li>
<p><span class="font53">6. The flow table manager then uses the OpenFlow protocol to update flow table entries at affected switches—s1 (which will now route packets destined to s2 via s4), s2 (which will now begin receiving packets from s1 via intermediate switch s4), and s4 (which must now forward packets from s1 destined to s2).</span></p></li></ul>
<p><span class="font53">This example is simple but illustrates how the SDN control plane provides controlplane services (in this case, network-layer routing) that had been previously implemented with per-router control exercised in each and every network router. One can now easily appreciate how an SDN-enabled ISP could easily switch from least-cost path routing to a more hand-tailored approach to routing. Indeed, since the controller can tailor the flow tables as it pleases, it can implement </span><span class="font53" style="font-style:italic;">any</span><span class="font53"> form of forwarding that it pleases—simply by changing its application-control software. This ease of change should be contrasted to the case of a traditional per-router control plane, where software in all routers (which might be provided to the ISP by multiple independent vendors) must be changed.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">5.5.4 </span><span class="font23" style="font-weight:bold;">SDN: Past and Future</span></p></li></ul>
<p><a name="bookmark371"></a><span class="font53">Although the intense interest in SDN is a relatively recent phenomenon, the technical roots of SDN, and the separation of the data and control planes in particular, go back considerably further. In 2004, [Feamster 2004, Lakshman 2004, RFC 3746] all argued for the separation of the network’s data and control planes. [van der Merwe 1998] describes a control framework for ATM networks [Black 1995] with multiple controllers, each controlling a number of ATM switches. The Ethane project [Casado 2007] pioneered the notion of a network of simple flow-based Ethernet switches with match-plus-action flow tables, a centralized controller that managed flow admission and routing, and the forwarding of unmatched packets from the switch to the controller. A network of more than 300 Ethane switches was operational in 2007. Ethane quickly evolved into the OpenFlow project, and the rest (as the saying goes) is history!</span></p>
<p><span class="font53">Numerous research efforts are aimed at developing future SDN architectures and capabilities. As we have seen, the SDN revolution is leading to the disruptive replacement of dedicated monolithic switches and routers (with both data and control planes) by simple commodity switching hardware and a sophisticated software control plane. A generalization of SDN known as network functions virtualization (NFV) (which we discussed earlier in Section 4.5) similarly aims at disruptive replacement of sophisticated middleboxes (such as middleboxes with dedicated hardware and proprietary software for media caching/service) with simple commodity servers, switching, and storage. A second area of important research seeks to extend SDN concepts from the intra-AS setting to the inter-AS setting [Gupta 2014].</span></p>
<div><img src="networking_files/networking-401.jpg" alt="" style="width:132pt;height:22pt;">
</div><br clear="all">
<div>
<p><span class="font23" style="font-weight:bold;">PRINCIPLES IN PRACTICE</span></p>
</div><br clear="all">
<p><span class="font4" style="font-weight:bold;">SDN CONTROLLER CASE STUDIES: THE OPENDAYLIGHT</span></p>
<p><span class="font4" style="font-weight:bold;">AND ONOS CONTROLLERS</span></p>
<p><span class="font4">In the earliest days of SDN, there was a single SDN protocol (OpenFlow [McKeown 2008; OpenFlow 2009]) and a single SDN controller (NOX [Gude 2008]). Since then, the number of SDN controllers in particular has grown significantly [Kreutz 2015]. Some SDN controllers are company-specific and proprietary, particularly when used to control internal proprietary networks (e.g., within or among a company’s data centers). But many more controllers are open-source and implemented in a variety of programming languages [Erickson 2013]. Most recently, the OpenDaylight controller [OpenDaylight 2020] and the ONOS controller [ONOS 2020] have found considerable industry support. They are both open-source and are being developed in partnership with the Linux Foundation.</span></p>
<p><span class="font4" style="font-weight:bold;">The OpenDaylight Controller</span></p>
<p><span class="font4">Figure 5.17 presents a simplified view of the OpenDaylight (ODL) controller platform [OpenDaylight 2020, Eckel 2017].</span></p>
<p><span class="font4">ODL’s Basic Network Functions are at the heart of the controller, and correspond closely to the network-wide state management capabilities that we encountered in Figure 5.15. The Service Abstraction Layer (SAL) is the controller’s nerve center, allowing controller components and applications to invoke each other’s services, access configuration and operational data, and to subscribe to events they generate. The SAL also provides a uniform abstract interface to specific protocols operating between the ODL controller and the controlled devices. These protocols include OpenFlow (which we covered in Section 4.5),</span></p>
<div>
<p><span class="font4">Traffic Engineering</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-402.jpg" alt="" style="width:64pt;height:32pt;">
<p><span class="font4">Firewalling</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-403.jpg" alt="" style="width:64pt;height:32pt;">
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Network Orchestrations and Applications</span></p>
</div><br clear="all">
<div>
<p><span class="font4">REST/RESTCONF/NETCONF APIs</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Northbound APIs</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Enhanced</span></p>
<p><span class="font4">Services</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Basic Network Functions</span></p>
</div><br clear="all">
<div>
<p><span class="font4">AAA</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Topology Processing</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Switch mgr.</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Stats mgr.</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Device Discovery</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Forwarding rules mgr.</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Host Tracker</span></p>
</div><br clear="all">
<div>
<table border="1">
<tr><td></td><td style="vertical-align:bottom;">
<p><span class="font4">config. and operational data store</span></p></td><td>
<p><span class="font4">^</span><span class="font4" style="text-decoration:underline;">messaging</span><span class="font4">^</span></p></td></tr>
</table>
</div><br clear="all">
<div>
<table border="1">
<tr><td>
<p><span class="font4">Openflow</span></p></td><td></td><td>
<p><span class="font4">NETCONF</span></p></td><td></td><td>
<p><span class="font4">SNMP</span></p></td><td></td><td>
<p><span class="font4">OVSDB</span></p></td></tr>
</table>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Service Abstraction Layer (SAL)</span></p>
<p><span class="font4" style="font-weight:bold;">Southbound APIs and Protocols Plugins</span></p>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 5.17 </span><span class="font50">♦ </span><span class="font5">A simplified view of the OpenDaylight controller</span></p>
<p><span class="font4">and the Simple Network Management Protocol (SNMP) and the Network Configuration (NETCONF) protocol, both of which we'll cover in Section 5.7. The Open vSwitch Database Management Protocol (OVSDB) is used to manage data center switching, an important application area for SDN technology. We'll introduce data center networking in Chapter 6.</span></p>
<p><span class="font4">Network Orchestrations and Applications determine how data-plane forwarding and other services, such as firewalling and load balancing, are accomplished in the controlled devices. ODL provides two ways in which applications can interoperate with native controller services (and hence devices) and with each other. In the API-Driven (AD-SAL) approach, shown in Figure 5.17, applications communicate with controller modules using a REST request-response API running over HTTP. Initial releases of the OpenDaylight controller provided only the AD-SAL. As ODL became increasingly used for network configuration and management, later ODL releases introduced a Model-Driven (MD-SAL) approach. Here, the YANG data modeling language [RFC 6020] defines models of device, protocol, and network configuration and operational state data. Devices are then configured and managed by manipulating this data using the NETCONF protocol.</span></p>
<div>
<p><span class="font4" style="font-weight:bold;">Network control apps</span></p>
<p><span class="font4" style="font-weight:bold;">Northbound abstractions, protocols</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-404.jpg" alt="" style="width:160pt;height:32pt;">
</div><br clear="all">
<div>
<table border="1">
<tr><td></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font4">REST API &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Intent</span></p></td></tr>
</table>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">ONOS distributed core</span></p>
</div><br clear="all">
<div>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font4">Hosts</span></p></td><td></td><td style="vertical-align:middle;">
<p><span class="font4">Paths</span></p></td><td></td><td style="vertical-align:middle;">
<p><span class="font4">Flow rules</span></p></td></tr>
<tr><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font4">Devices</span></p></td><td></td><td style="vertical-align:middle;">
<p><span class="font4">Links</span></p></td><td></td><td style="vertical-align:middle;">
<p><span class="font4">Statistics</span></p></td></tr>
</table>
</div><br clear="all">
<div>
<p><span class="font4">Topology</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Southbound abstractions, protocols</span></p>
</div><br clear="all">
<div>
<table border="1">
<tr><td colspan="3"></td><td colspan="2"></td><td colspan="2"></td><td colspan="2"></td><td colspan="2"></td></tr>
<tr><td></td><td>
<p><span class="font4">Device</span></p></td><td></td><td>
<p><span class="font4">Link</span></p></td><td></td><td>
<p><span class="font4">Host</span></p></td><td></td><td>
<p><span class="font4">Flow</span></p></td><td></td><td>
<p><span class="font4">Packet</span></p></td><td></td></tr>
</table>
</div><br clear="all">
<div>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font4">OpenFlow</span></p></td><td></td><td style="vertical-align:middle;">
<p><span class="font4">Netconf</span></p></td><td></td><td style="vertical-align:middle;">
<p><span class="font4">OVSDB</span></p></td></tr>
</table>
</div><br clear="all">
<div><img src="networking_files/networking-405.jpg" alt="" style="width:110pt;height:53pt;">
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 5.18 </span><span class="font50">♦ </span><span class="font5">ONOS controller architecture</span></p>
<p><span class="font4" style="font-weight:bold;">The ONOS Controller</span></p>
<p><span class="font4">Figure 5.18 presents a simplified view of the ONOS controller ONOS 2020]. Similar to the canonical controller in Figure 5.15, three layers can be identified in the ONOS controller:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font4" style="font-style:italic;">Northbound abstractions and protocols.</span><span class="font4"> A unique feature of ONOS is its intent framework, which allows an application to request a high-level service (e.g., to setup a connection between host A and Host B, or conversely to not allow Host A and host</span></p></li></ul>
<p><span class="font4">B to communicate) without having to know the details of how this service is performed. State information is provided to network-control applications across the northbound API either synchronously (via query) or asynchronously (via listener callbacks, e.g., when network state changes).</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font4" style="font-style:italic;">Distributed core.</span><span class="font4"> The state of the network's links, hosts, and devices is maintained in ONOS's distributed core. ONOS is deployed as a service on a set of interconnected servers, with each server running an identical copy of the ONOS software; an increased number of servers offers an increased service capacity. The ONOS core provides the mechanisms for service replication and coordination among instances, providing the applications above and the network devices below with the abstraction of logically centralized core services.</span></p></li></ul>
<p><span class="font53">• </span><span class="font4" style="font-style:italic;">Southbound abstractions and protocols.</span><span class="font4"> The southbound abstractions mask the heterogeneity of the underlying hosts, links, switches, and protocols, allowing the distributed core to be both device and protocol agnostic. Because of this abstraction, the southbound interface below the distributed core is logically higher than in our canonical controller in Figure 5.14 or the ODL controller in Figure 5.17.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">5.6 </span><span class="font24" style="font-weight:bold;">ICMP: The Internet Control Message Protocol</span></p></li></ul>
<p><span class="font53">The Internet Control Message Protocol (ICMP), specified in [RFC 792], is used by hosts and routers to communicate network-layer information to each other. The most typical use of ICMP is for error reporting. For example, when running an HTTP session, you may have encountered an error message such as “Destination network unreachable.” This message had its origins in ICMP. At some point, an IP router was unable to find a path to the host specified in your HTTP request. That router created and sent an ICMP message to your host indicating the error.</span></p>
<p><span class="font53">ICMP is often considered part of IP, but architecturally it lies just above IP, as ICMP messages are carried inside IP datagrams. That is, ICMP messages are carried as IP payload, just as TCP or UDP segments are carried as IP payload. Similarly, when a host receives an IP datagram with ICMP specified as the upper-layer protocol (an upper-layer protocol number of 1), it demultiplexes the datagram’s contents to ICMP, just as it would demultiplex a datagram’s content to TCP or UDP.</span></p>
<p><span class="font53">ICMP messages have a type and a code field, and contain the header and the first 8 bytes of the IP datagram that caused the ICMP message to be generated in the first place (so that the sender can determine the datagram that caused the error). Selected ICMP message types are shown in Figure 5.19. Note that ICMP messages are used not only for signaling error conditions.</span></p>
<p><span class="font53">The well-known ping program sends an ICMP type 8 code 0 message to the specified host. The destination host, seeing the echo request, sends back a type 0 code 0 ICMP echo reply. Most TCP/IP implementations support the ping server directly in the operating system; that is, the server is not a process. Chapter 11 of [Stevens 1990] provides the source code for the ping client program. Note that the client program needs to be able to instruct the operating system to generate an ICMP message of type 8 code 0.</span></p>
<p><a name="bookmark372"></a><span class="font53">Another interesting ICMP message is the source quench message. This message is seldom used in practice. Its original purpose was to perform congestion control—to allow a congested router to send an ICMP source quench message to a host to force</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font6">ICMP Type</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Code</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Description</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">echo reply (to ping)</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">destination network unreachable</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">destination host unreachable</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">destination protocol unreachable</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">destination port unreachable</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">6</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">destination network unknown</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">7</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">destination host unknown</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">source quench (congestion control)</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">8</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">echo request</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">9</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">router advertisement</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">10</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">router discovery</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">11</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">TTL expired</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">12</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">IP header bad</span></p></td></tr>
</table>
<p><span class="font7" style="font-weight:bold;">Figure 5.19 </span><span class="font50">♦ </span><span class="font5">ICMP message types</span></p>
<p><span class="font53">that host to reduce its transmission rate. We have seen in Chapter 3 that TCP has its own congestion-control mechanism that operates at the transport layer, and that Explicit Congestion Notification bits can be used by network-later devices to signal congestion.</span></p>
<p><span class="font53">In Chapter 1, we introduced the Traceroute program, which allows us to trace a route from a host to any other host in the world. Interestingly, Traceroute is implemented with ICMP messages. To determine the names and addresses of the routers between source and destination, Traceroute in the source sends a series of ordinary IP datagrams to the destination. Each of these datagrams carries a UDP segment with an unlikely UDP port number. The first of these datagrams has a TTL of 1, the second of 2, the third of 3, and so on. The source also starts timers for each of the datagrams. When the </span><span class="font53" style="font-style:italic;">n</span><span class="font53">th datagram arrives at the </span><span class="font53" style="font-style:italic;">n</span><span class="font53">th router, the </span><span class="font53" style="font-style:italic;">n</span><span class="font53">th router observes that the TTL of the datagram has just expired. According to the rules of the IP protocol, the router discards the datagram and sends an ICMP warning message to the source (type 11 code 0). This warning message includes the name of the router and its IP address. When this ICMP message arrives back at the source, the source obtains the round-trip time from the timer and the name and IP address of the </span><span class="font53" style="font-style:italic;">n</span><span class="font53">th router from the ICMP message.</span></p>
<p><span class="font53">How does a Traceroute source know when to stop sending UDP segments? Recall that the source increments the TTL field for each datagram it sends. Thus, one of the datagrams will eventually make it all the way to the destination host. Because this datagram contains a UDP segment with an unlikely port number, the destination host sends a port unreachable ICMP message (type 3 code 3) back to the source. When the source host receives this particular ICMP message, it knows it does not need to send additional probe packets. (The standard Traceroute program actually sends sets of three packets with the same TTL; thus, the Traceroute output provides three results for each TTL.)</span></p>
<p><span class="font53">In this manner, the source host learns the number and the identities of routers that lie between it and the destination host and the round-trip time between the two hosts. Note that the Traceroute client program must be able to instruct the operating system to generate UDP datagrams with specific TTL values and must also be able to be notified by its operating system when ICMP messages arrive. Now that you understand how Traceroute works, you may want to go back and play with it some more.</span></p>
<p><span class="font53">A new version of ICMP has been defined for IPv6 in RFC 4443. In addition to reorganizing the existing ICMP type and code definitions, ICMPv6 also added new types and codes required by the new IPv6 functionality. These include the “Packet Too Big” type and an “unrecognized IPv6 options” error code.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">5.7 </span><span class="font24" style="font-weight:bold;">Network Management and SNMP, NETCONF/YANG</span></p></li></ul>
<p><span class="font53">Having now made our way to the end of our study of the network layer, with only the link-layer before us, we’re well aware that a network consists of many complex, interacting pieces of hardware and software—from the links, switches, routers, hosts, and other devices that comprise the physical components of the network to the many protocols that control and coordinate these devices. When hundreds or thousands of such components are brought together by an organization to form a network, the job of the network administrator to keep the network “up and running” is surely a challenge. We saw in Section 5.5 that the logically centralized controller can help with this process in an SDN context. But the challenge of network management has been around long before SDN, with a rich set of network management tools and approaches that help the network administrator monitor, manage, and control the network. We’ll study these tools and techniques in this section, as well as new tools and techniques that have co-evolved along with SDN.</span></p>
<p><span class="font53">An often-asked question is “What is network management?” A well-conceived, single-sentence (albeit a rather long run-on sentence) definition of network management from [Saydam 1996] is:</span></p>
<p><span class="font53" style="font-style:italic;">Network management includes the deployment, integration, and coordination of the hardware, software, and human elements to monitor, test, poll, configure, analyze, evaluate, and control the network and element resources to meet the real-time, operational performance, and Quality of Service requirements at a reasonable cost.</span></p>
<p><a name="bookmark373"></a><span class="font53">Given this broad definition, we’ll cover only the rudiments of network management in this section—the architecture, protocols, and data used by a network administrator in performing their task. We’ll not cover the administrator’s decisionmaking processes, where topics such as fault identification [Labovitz 1997; Steinder 2002; Feamster 2005; Wu 2005; Teixeira 2006], anomaly detection [Lakhina 2005; Barford 2009], network design/engineering to meet contracted Service Level Agreements (SLA’s) [Huston 1999a], and more come into consideration. Our focus is thus purposefully narrow; the interested reader should consult these references, the excellent overviews in [Subramanian 2000; Schonwalder 2010; Claise 2019], and the more detailed treatment of network management available on the Web site for this text.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">5.7.1 </span><span class="font23" style="font-weight:bold;">The Network Management Framework</span></p></li></ul>
<p><span class="font53">Figure 5.20 shows the key components of network management:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Managing server.</span><span class="font53"> The managing server is an application, typically with </span><span class="font53" style="font-weight:bold;">network managers </span><span class="font53">(humans) in the loop, running in a centralized network management station in the network operations center (NOC). The managing server is the locus of activity for network management: it controls the collection, processing, analysis, and dispatching of network management information and commands. It is here that actions are initiated to configure, monitor, and control the network’s managed devices. In practice, a network may have several such managing servers.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Managed device.</span><span class="font53"> A managed device is a piece of network equipment (including its software) that resides on a managed network. A managed device might be a host, router, switch, middlebox, modem, thermometer, or other network-connected device. The device itself will have many manageable components (e.g., a network interface is but one component of a host or router), and configuration parameters for these hardware and software components (e.g., an intra-AS routing protocol, such as OSPF).</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Data.</span><span class="font53"> Each managed device will have data, also known as “state,” associated with it. There are several different types of data. </span><span class="font53" style="font-weight:bold;">Configuration data </span><span class="font53">is device information explicitly configured by the network manager, for example, a manager-assigned/ configured IP address or interface speed for a device interface. </span><span class="font53" style="font-weight:bold;">Operational data </span><span class="font53">is information that the device acquires as it operates, for example, the list of immediate neighbors in OSPF protocol. </span><span class="font53" style="font-weight:bold;">Device statistics </span><span class="font53">are status indicators and counts that are updated as the device operators (e.g., the number of dropped packets on an interface, or the device’s cooling fan speed). The network manager can query remote device data, and in some cases, control the remote device by writing device data values, as discussed below. As shown in Figure 5.17, the managing server also maintains its own copy of configuration, operational and statistics data from its managed devices as well as network-wide data (e.g., the network’s topology).</span></p></li>
<li>
<p><a name="bookmark374"></a><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Network management agent.</span><span class="font53"> The network management agent is a software process running in the managed device that communicates with the managing server, taking local actions at the managed device under the command and control of the managing server. The network management agent is similar to the routing agent that we saw in Figure 5.2.</span></p>
<div>
<p><span class="font4">Network managers</span></p><img src="networking_files/networking-406.jpg" alt="" style="width:47pt;height:70pt;">
<p><span class="font4">Managing server/controller</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Agent Device data</span></p>
<p><span class="font4">config. and operational data store</span></p><img src="networking_files/networking-407.jpg" alt="" style="width:256pt;height:258pt;">
<p><span class="font4">Agent Device</span></p>
<p><span class="font4">Agent Device</span></p>
<p><span class="font4">data</span></p>
<p><span class="font4">Agent Device</span></p>
<p><span class="font4">data</span></p>
<p><span class="font4">Agent Device</span></p>
<p><span class="font4">data</span></p>
<p><span class="font4">Key:</span></p>
<p><span class="font4">Managed device</span></p>
<p><span class="font4">Managed device</span></p>
<p><span class="font4">◄ ► Controller-to-device protocol</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 5.20 </span><span class="font50">♦ </span><span class="font5">Elements of network management</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-408.jpg" alt="" style="width:117pt;height:44pt;">
<p><span class="font4">Managed device</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Managed device</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Managed device</span></p>
</div><br clear="all"></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Network management protocol.</span><span class="font53"> The final component of a network management framework is the network management protocol. This protocol runs between the managing server and the managed devices, allowing the managing server to query the status of managed devices and take actions at these devices via its agents. Agents can use the network management protocol to inform the managing server of exceptional events (e.g., component failures or violation of performance thresholds). It’s important to note that the network management protocol does not itself manage the network. Instead, it provides capabilities that network managers can use to manage (“monitor, test, poll, configure, analyze, evaluate, and control”) the network. This is a subtle, but important, distinction.</span></p></li></ul>
<p><span class="font53">In practice, there are three commonly used ways in a network operator can manage the network, using the components described above:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">CLI.</span><span class="font53"> A network operator may issue direct </span><span class="font53" style="font-weight:bold;">Command Line Interface (CLI) </span><span class="font53">commands to the device. These commands can be typed directly on a managed device’s console (if the operator is physically present at the device), or over a Telnet or secure shell (SSH) connection, possibly via scripting, between the managing server/controller and the managed device. CLI commands are vendor-and device-specific and can be rather arcane. While seasoned network wizards may be able to use CLI to flawlessly configure network devices, CLI use is prone to errors, and it is difficult to automate or efficiently scale for large networks. Consumer-oriented network devices, such as your wireless home router, may export a management menu that you (the network manager!) can access via HTTP to configure that device. While this approach may work well for single, simple devices and is less error-prone than CLI, it also doesn’t scale to larger-sized networks.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">SNMP/MIB.</span><span class="font53"> In this approach, the network operator can query/set the data contained in a device’s </span><span class="font53" style="font-weight:bold;">Management Information Base (MIB) </span><span class="font53">objects using the </span><span class="font53" style="font-weight:bold;">Simple Network Management Protocol (SNMP)</span><span class="font53">. Some MIBs are device- and vendor-specific, while other MIBs (e.g., the number of IP datagrams discarded at a router due to errors in an IP datagram header, or the number of UDP segments received at a host) are device-agnostic, providing abstraction and generality. A network operator would most typically use this approach to query and monitor operational state and device statistics, and then use CLI to actively control/configure the device. We note, importantly, that both approaches manage devices </span><span class="font53" style="font-style:italic;">individually. </span><span class="font53">We’ll cover the SNMP and MIBs, which have been in use since the late 1980s, in Section 5.7.2 below. A network-management workshop convened by the Internet Architecture Board in 2002 [RFC 3535] noted not only the value of the SNMP/ MIB approach for device monitoring but also noted its shortcomings, particularly for device configuration and network management at scale. This gave rise to the most recent approach for network management, using NETCONF and YANG.</span></p></li>
<li>
<p><span class="font53">• </span><span class="font53" style="font-style:italic;">NETCONF/YANG.</span><span class="font53"> The NETCONF/YANG approach takes a more abstract, network-wide, and holistic view toward network management, with a much stronger emphasis on configuration management, including specifying correctness constraints and providing atomic management operations over multiple controlled devices. </span><span class="font53" style="font-weight:bold;">YANG </span><span class="font53">[RFC 6020] is a data modeling language used to model configuration and operational data. The </span><span class="font53" style="font-weight:bold;">NETCONF </span><span class="font53">protocol [RFC 6241] is used to communicate YANG-compatible actions and data to/from/among remote devices. We briefly encountered NETCONF and YANG in our case study of OpenDaylight Controller in Figure 5.17 and will study them in Section 5.7.3 below.</span></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">5.7.2 </span><span class="font23" style="font-weight:bold;">The Simple Network Management Protocol (SNMP) and the Management Information Base (MIB)</span></p></li></ul>
<p><a name="bookmark375"></a><span class="font53">The </span><span class="font53" style="font-weight:bold;">Simple Network Management Protocol </span><span class="font53">version 3 (SNMPv3) [RFC 3410] is an application-layer protocol used to convey network-management control and information messages between a managing server and an agent executing on behalf of that managing server. The most common usage of SNMP is in a request-response mode in which an SNMP managing server sends a request to an SNMP agent, who</span></p>
<p><span class="font53">receives the request, performs some action, and sends a reply to the request. Typically, a request will be used to query (retrieve) or modify (set) MIB object values associated with a managed device. A second common usage of SNMP is for an agent to send an unsolicited message, known as a trap message, to a managing server. Trap messages are used to notify a managing server of an exceptional situation (e.g., a link interface going up or down) that has resulted in changes to MIB object values.</span></p>
<p><span class="font53">MIB objects are specified in a data description language known as SMI (Structure of Management Information) [RFC 2578; RFC 2579; RFC 2580], a rather oddly named component of the network management framework whose name gives no hint of its functionality. A formal definition language is used to ensure that the syntax and semantics of the network management data are well defined and unambiguous. Related MIB objects are gathered into MIB modules. As of late 2019, there are more than 400 MIB-related RFCs and a much larger number of vendor-specific (private) MIB modules.</span></p>
<p><span class="font53">SNMPv3 defines seven types of messages, known generically as protocol data units—PDUs—as shown in Table 5.2 and described below. The format of the PDU is shown in Figure 5.21.</span></p>
<p><span class="font53">• The </span><span class="font36">GetRequest</span><span class="font53">, </span><span class="font36">GetNextRequest, </span><span class="font53">and </span><span class="font36">GetBulkRequest </span><span class="font53">PDUs are all sent from a managing server to an agent to request the value of one or more</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font6">SNMPv3 PDU Type</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Sender-receiver</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Description</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font36">GetRequest</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">manager-to-agent</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">get value of one or more MIB object instances</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font36">GetNextRequest</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">manager-to-agent</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">get value of next MIB object instance in list or table</span></p></td></tr>
<tr><td>
<p><span class="font36">GetBulkRequest</span></p></td><td>
<p><span class="font6">manager-to-agent</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">get values in large block of data, for example, values in a large table</span></p></td></tr>
<tr><td>
<p><span class="font36">InformRequest</span></p></td><td>
<p><span class="font6">manager-to-manager</span></p></td><td>
<p><span class="font6">inform remote managing entity of MIB values remote to its access</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font36">SetRequest</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">manager-to-agent</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">set value of one or more MIB object instances</span></p></td></tr>
<tr><td>
<p><span class="font36">Response</span></p></td><td>
<p><span class="font6">agent-to-manager or manager-to-manager</span></p></td><td>
<p><span class="font6">generated in response to</span></p>
<p><span class="font36">GetRequest,</span></p>
<p><span class="font36">GetNextRequest,</span></p>
<p><span class="font36">GetBulkRequest,</span></p>
<p><span class="font36">SetRequest PDU, </span><span class="font6">or </span><span class="font36">InformRequest</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font36">SNMPv2-Trap</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">agent-to-manager</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">inform manager of an exceptional event #</span></p></td></tr>
</table>
<p><span class="font7" style="font-weight:bold;">Table 5.2 </span><span class="font50">♦ </span><span class="font5">SNMPv3 PDU types</span></p>
<p><span class="font4">Get/set header</span></p>
<p><span class="font4">Variables to get/set</span></p>
<table border="1">
<tr><td colspan="4"></td><td colspan="4"></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font4">PDU type (0-3)</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Request Id</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Error Status (0-5)</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Error</span></p>
<p><span class="font4">Index</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Name</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Value</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Name</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Value</span></p></td></tr>
</table>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font4">PDU Type (4)</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Enterprise</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Agent Addr</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Trap Type (0-7)</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Specific code</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Time stamp</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Name</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Value</span></p></td></tr>
<tr><td colspan="6"></td><td colspan="2"></td></tr>
</table>
<p><span class="font4">Trap header</span></p>
<p><span class="font4">Trap information _</span></p>
<div>
<p><span class="font53">r</span></p>
</div><br clear="all">
<p><span class="font4">SNMP PDU</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 5.21 </span><span class="font50">♦ </span><span class="font5">SNMP PDU format</span></p>
<p><span class="font53">MIB objects at the agent’s managed device. The MIB objects whose values are being requested are specified in the variable binding portion of the PDU. </span><span class="font36">GetRequest</span><span class="font53">, </span><span class="font36">GetNextRequest</span><span class="font53">, and </span><span class="font36">GetBulkRequest </span><span class="font53">differ in the granularity of their data requests. </span><span class="font36">GetRequest </span><span class="font53">can request an arbitrary set of MIB values; multiple </span><span class="font36">GetNextRequest</span><span class="font53">s can be used to sequence through a list or table of MIB objects; </span><span class="font36">GetBulkRequest </span><span class="font53">allows a large block of data to be returned, avoiding the overhead incurred if multiple </span><span class="font36">GetRequest </span><span class="font53">or </span><span class="font36">GetNextRequest </span><span class="font53">messages were to be sent. In all three cases, the agent responds with a </span><span class="font36">Response PDU </span><span class="font53">containing the object identifiers and their associated values.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;The </span><span class="font36">SetRequest </span><span class="font53">PDU is used by a managing server to set the value of one or more MIB objects in a managed device. An agent replies with a </span><span class="font36">Response </span><span class="font53">PDU with the “noError” error status to confirm that the value has indeed been set.</span></p></li>
<li>
<p><span class="font53">• &nbsp;The </span><span class="font36">InformRequest </span><span class="font53">PDU is used by a managing server to notify another managing server of MIB information that is remote to the receiving server.</span></p></li>
<li>
<p><span class="font53">• &nbsp;The </span><span class="font36">Response PDU </span><span class="font53">is typically sent from a managed device to the managing server in response to a request message from that server, returning the requested information.</span></p></li>
<li>
<p><span class="font53">• &nbsp;The final type of SNMPv3 PDU is the trap message. Trap messages are generated asynchronously; that is, they are not generated in response to a received request but rather in response to an event for which the managing server requires notification. RFC 3418 defines well-known trap types that include a cold or warm start by a device, a link going up or down, the loss of a neighbor, or an authentication failure event. A received trap request has no required response from a managing server.</span></p></li></ul>
<p><span class="font53">Given the request-response nature of SNMP, it is worth noting here that although SNMP PDUs can be carried via many different transport protocols, the SNMP PDU is typically carried in the payload of a UDP datagram. Indeed, RFC 3417 states that UDP is “the preferred transport mapping.” However, since UDP is an unreliable transport protocol, there is no guarantee that a request, or its response, will be received at the intended destination. The request ID field of the PDU (see Figure 5.21) is used by the managing server to number its requests to an agent; the agent’s response takes its request ID from that of the received request. Thus, the request ID field can be used by the managing server to detect lost requests or replies. It is up to the managing server to decide whether to retransmit a request if no corresponding response is received after a given amount of time. In particular, the SNMP standard does not mandate any particular procedure for retransmission, or even if retransmission is to be done in the first place. It only requires that the managing server “needs to act responsibly in respect to the frequency and duration of retransmissions.” This, of course, leads one to wonder how a “responsible” protocol should act!</span></p>
<p><span class="font53">SNMP has evolved through three versions. The designers of SNMPv3 have said that “SNMPv3 can be thought of as SNMPv2 with additional security and administration capabilities” [RFC 3410]. Certainly, there are changes in SNMPv3 over SNMPv2, but nowhere are those changes more evident than in the area of administration and security. The central role of security in SNMPv3 was particularly important, since the lack of adequate security resulted in SNMP being used primarily for monitoring rather than control (for example, </span><span class="font36">SetRequest </span><span class="font53">is rarely used in SNMPv1). Once again, we see that security—a topic we’ll cover in detail in Chapter 8 — is of critical concern, but once again a concern whose importance had been realized perhaps a bit late and only then “added on.”</span></p>
<p><span class="font22" style="font-weight:bold;">The Management Information Base (MIB)</span></p>
<p><span class="font53">We learned earlier that a managed device’s operational state data (and to some extent its configuration data) in the SNMP/MIB approach to network management are represented as objects that are gathered together into an MIB for that device. An MIB object might be a counter, such as the number of IP datagrams discarded at a router due to errors in an IP datagram header; or the number of carrier sense errors in an Ethernet interface card; descriptive information such as the version of the software running on a DNS server; status information such as whether a particular device is functioning correctly; or protocol-specific information such as a routing path to a destination. Related MIB objects are gathered into MIB modules. There are over 400 MIB modules defined in various IETC RFC’s; there are many more device- and vendor-specific MIBs. [RFC 4293] specifies the MIB module that defines managed objects (including ipSystemStatsInDelivers) for managing implementations of the Internet Protocol (IP) and its associated Internet Control Message Protocol (ICMP). [RFC 4022] specifies the MIB module for TCP, and [RFC 4113] specifies the MIB module for UDP.</span></p>
<p><span class="font53">While MIB-related RFCs make for rather tedious and dry reading, it is nonetheless instructive (i.e., like eating vegetables, it is “good for you”) to consider an example of a MIB object, The </span><span class="font36">ipSystem-StatsInDelivers </span><span class="font53">object-type definition from [RFC 4293] defines a 32-bit read-only counter that keeps track of the number of IP datagrams that were received at the managed device and were successfully delivered to an upper-layer protocol. In the example below, Counter32 is one of the basic data types defined in the SMI.</span></p>
<p><span class="font53">i</span><span class="font36">pSystemStatsInDelivers OBJECT-TYPE</span></p>
<p><span class="font36">SYNTAX Counter32</span></p>
<p><span class="font36">MAX-ACCESS read-only</span></p>
<p><span class="font36">STATUS current</span></p>
<p><span class="font36">DESCRIPTION</span></p>
<p><span class="font36">&quot;The total number of datagrams successfully delivered to IPuser-protocols (including ICMP).</span></p>
<p><span class="font36">When tracking interface statistics, the counter of the interface to which these datagrams were addressed is incremented. This interface might not be the same as the input interface for some of the datagrams.</span></p>
<p><span class="font36">Discontinuities in the value of this counter can occur at re-initialization of the management system, and at other times as indicated by the value of ipSystemStatsDiscontinuityTime.”</span></p>
<p><span class="font36">::= { ipSystemStatsEntry 18 }</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">5.7.3 </span><span class="font23" style="font-weight:bold;">The Network Configuration Protocol (NETCONF) and YANG</span></p></li></ul>
<p><a name="bookmark157"></a><span class="font53">The NETCONF protocol operates between the managing server and the managed network devices, providing messaging to </span><span class="font53" style="font-style:italic;">(i)</span><span class="font53"> retrieve, set, and modify configuration data at managed devices; </span><span class="font53" style="font-style:italic;">(ii)</span><span class="font53"> to query operational data and statistics at managed devices; and </span><span class="font53" style="font-style:italic;">(iii)</span><span class="font53"> to subscribe to notifications generated by managed devices. The managing server actively controls a managed device by sending it configurations, which are specified in a structured XML document, and activating a configuration at the managed device. NETCONF uses a remote procedure call (RPC) paradigm, where protocol messages are also encoded in XML and exchanged between the managing server and a managed device over a secure, connection-oriented session such as the TLS (Transport Layer Security) protocol (discussed in Chapter 8) over TCP.</span></p>
<div><img src="networking_files/networking-409.jpg" alt="" style="width:234pt;height:115pt;">
<p><span class="font4">———■ &lt;rpc&gt; — &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font4" style="text-decoration:underline;"><sub>r</sub></span></p>
<p><span class="font4">— &lt;rpc-reply&gt; &quot;</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-410.jpg" alt="" style="width:37pt;height:21pt;">
</div><br clear="all">
<p><span class="font4">' &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;rpc&gt; —</span><span class="font4" style="text-decoration:underline;">—</span></p>
<p><span class="font4">&lt;rpc-reply&gt;</span></p>
<p><span class="font4">&lt;notification&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;’</span></p>
<p><span class="font4">' &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;rpc&gt; ——</span></p>
<p><span class="font4">&lt;rpc-reply&gt;</span></p>
<p><span class="font4">Session close: &lt;close-session&gt; -----------------------------►</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 5.22 </span><span class="font50">♦ </span><span class="font5">NETCONF session between managing server/controller and managed device</span></p>
<p><span class="font53">Figure 5.22 shows an example NETCONF session. First, the managing server establishes a secure connection to the managed device. (In NETCONF parlance, the managing server is actually referred to as the “client” and the managed device as the “server,” since the managing server establishes the connection to the managed device. But we’ll ignore that here for consistency with the longer-standing networkmanagement server/client terminology shown in Figure 5.20.) Once a secure connection has been established, the managing server and the managed device exchange &lt;hello&gt; messages, declaring their “capabilities”—NETCONF functionality that supplements the base NETCONF specification in [RFC 6241]. Interactions between the managing server and managed device take the form of a remote procedure call, using the &lt;rpc&gt; and &lt;rpc-response&gt; messages. These messages are used to retrieve, set, query and modify device configurations, operational data and statistics, and to subscribe to device notifications. Device notifications themselves are proactively sent from managed device to the managing server using NETCONF &lt;notification&gt; messages. A session is closed with the &lt;session-close message&gt;.</span></p>
<p><span class="font53">Table 5.3 shows a number of the important NETCONF operations that a managing server can perform at a managed device. As in the case of SNMP, we see operations for retrieving operational state data (&lt;get&gt;), and for event notification. However, the &lt;get-config&gt;, &lt;edit-config&gt;, &lt;lock&gt; and &lt;unlock&gt; operation demonstrate NETCONF’s particular emphasis on device configuration. Using the basic operations shown in Table 5.3, it is also possible to create a </span><span class="font53" style="font-style:italic;">set</span><span class="font53"> of more sophisticated network management transactions that either complete atomically (i.e., as a group) and successfully on a </span><span class="font53" style="font-style:italic;">set</span><span class="font53"> of devices, or are fully reversed and leave the devices in their pre-transaction state. Such multi-device transactions—“enabl[ing] operators to concentrate on the </span><span class="font53" style="font-style:italic;">configuration</span><span class="font53"> of the network as a whole rather than individual devices” was an important operator requirement put forth in [RFC 3535].</span></p>
<p><span class="font53">A full description of NETCONF is beyond our scope here; [RFC 6241, RFC 5277, Claise 2019; Schonwalder 2010] provide more in-depth coverage.</span></p>
<p><span class="font53">But since this is the first time we’ve seen protocol messages formatted as an XML document (rather than the traditional message with header fields and message body, e.g., as shown in Figure 5.21 for the SNMP PDU), let’s conclude our brief study of NETCONF with two examples.</span></p>
<p><span class="font53">In the first example, the XML document sent from the managing server to the managed device is a NETCONF &lt;get&gt; command requesting all device configuration</span></p>
<table border="1">
<tr><td>
<p><span class="font6">NETCONF Operation</span></p></td><td>
<p><span class="font6">Description</span></p></td></tr>
<tr><td>
<p><span class="font6">&lt;get-config&gt;</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Retrieve all or part of a given configuration. A device may have multiple configurations. There is always a </span><span class="font36">running / </span><span class="font6">configuration that describes the devices current (running) configuration.</span></p></td></tr>
<tr><td>
<p><span class="font6">&lt;get&gt;</span></p>
<p><span class="font6">&lt;edit-config&gt;</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Retrieve all or part of both configuration state and operational state data.</span></p>
<p><span class="font6">Change all or part of a specified configuration at the managed device. If the running/configuration is specified, then the device's current (running) configuration will be changed. If the managed device was able to satisfy the request, an &lt;rpc-reply&gt; is sent containing an &lt;ok&gt; element; otherwise &lt;rpc-error&gt; response is returned. On error, the device's configuration state can be roll-ed-back to its previous state.</span></p></td></tr>
<tr><td>
<p><span class="font6">&lt;lock&gt;, &lt;unlock&gt;</span></p></td><td>
<p><span class="font6">The &lt;lock&gt; (&lt;unlock&gt;) operation allows the managing server to lock (unlock) the entire configuration datastore system of a managed device. Locks are intended to be short-lived and allow a client to make a change without fear of interaction with other NETCONF, SNMP, or CLIs commands from other sources.</span></p></td></tr>
<tr><td>
<p><span class="font6">&lt;create-subscription&gt; , &lt;notification&gt;</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">This operation initiates an event notification subscription that will send asynchronous event &lt;notification&gt; for specified events of interest from the managed device to the managing server, until the subscription is terminated.</span></p></td></tr>
</table>
<p><span class="font53">and operational data. With this command, the server can learn about the device’s configuration.</span></p>
<p><span class="font36">01 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></p>
<p><span class="font36">02 &lt;rpc message-id=&quot;101&quot;</span></p>
<p><span class="font36">03 xmlns=&quot;urn:ietf:params:xml:ns:netconf:base:1.0&quot;&gt;</span></p>
<p><span class="font36">04 &lt;get/&gt;</span></p>
<p><span class="font36">05 &lt;/rpc&gt;</span></p>
<p><span class="font53">Although few people can completely parse XML directly, we see that the NET-CONF command is relatively human-readable, and is much more reminiscent of HTTP and HTML than the protocol message formats that we saw for SNMP PDU format in Figure 5.21. The RPC message itself spans lines 02-05 (we have added line numbers here for pedagogical purposes). The RPC has a message ID value of 101, declared in line 02, and contains a single NETCONF &lt;get&gt; command. The reply from the device contains a matching ID number (101), and all of the device’s configuration data (in XML format, of course), starting in line 04, ultimately with a closing &lt;/rpc-reply&gt;.</span></p>
<p><span class="font36">01 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></p>
<p><span class="font36">02 &lt;rpc-reply message-id=&quot;101&quot;</span></p>
<p><span class="font36">03 xmlns=&quot;urn:ietf:params:xml:ns:netconf:base:1.0&quot;&gt;</span></p>
<p><span class="font36">04 &nbsp;&lt;!-- . . . all configuration data returned... --&gt;</span></p>
<p><span class="font36">&lt;/rpc-reply&gt;</span></p>
<p><span class="font53">In the second example below, adapted from [RFC 6241], the XML document sent from the managing server to the managed device sets the Maximum Transmission Unit (MTU) of an interface named “Ethernet0/0” to 1500 bytes:</span></p>
<p><span class="font36">01 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></p>
<p><span class="font36">02 &lt;rpc message-id=&quot;101&quot;</span></p>
<p><span class="font36">03 xmlns=&quot;urn:ietf:params:xml:ns:netconf:base:1.0&quot;&gt;</span></p>
<p><span class="font36">04 &lt;edit-config&gt;</span></p>
<p><span class="font36">05 &nbsp;&nbsp;&nbsp;&nbsp;&lt;target&gt;</span></p>
<p><span class="font36">06 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;running/&gt;</span></p>
<p><span class="font36">07 &nbsp;&nbsp;&nbsp;&nbsp;&lt;/target&gt;</span></p>
<p><span class="font36">08 &nbsp;&nbsp;&nbsp;&nbsp;&lt;config&gt;</span></p>
<p><span class="font36">09 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;top xmlns=&quot;</span><a href="http://example.com/schema/1.2/config"><span class="font36">http://example.com/schema/</span></a></p>
<p><a href="http://example.com/schema/1.2/config"><span class="font36">1.2/config</span></a><span class="font36">&quot;&gt;</span></p>
<ul style="list-style:none;"><li>
<p><span class="font36">10 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;interface&gt;</span></p></li>
<li>
<p><span class="font36">11 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;name&gt;Ethernet0/0&lt;/name&gt;</span></p></li>
<li>
<p><span class="font36">12 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;mtu&gt;1500&lt;/mtu&gt;</span></p></li>
<li>
<p><span class="font36">13 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;/interface&gt;</span></p></li>
<li>
<p><span class="font36">14 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;/top&gt;</span></p></li>
<li>
<p><span class="font36">15 &nbsp;&nbsp;&nbsp;&nbsp;&lt;/config&gt;</span></p></li>
<li>
<p><span class="font36">16 &nbsp;&nbsp;&lt;/edit-config&gt;</span></p></li>
<li>
<p><span class="font36">17 &lt;/rpc&gt;</span></p></li></ul>
<p><span class="font53">The RPC message itself spans lines 02-17, has a message ID value of 101, and contains a single NETCONF &lt;edit-config&gt; command, spanning lines 04-15. Line 06 indicates that the running device configuration at the managed device will be changed. Lines 11 and 12 specify the MTU size to be set of the Ethernet0/0 interface.</span></p>
<p><span class="font53">Once the managed device has changed the interface’s MTU size in the configuration, it responds back to the managing server with an OK reply (line 04 below), again within an XML document:</span></p>
<p><span class="font36">01 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></p>
<p><span class="font36">02 &lt;rpc-reply message-id=&quot;101&quot;</span></p>
<p><span class="font36">03 xmlns=&quot;urn:ietf:params:xml:ns:netconf:base:1.0&quot;&gt;</span></p>
<p><span class="font36">04 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;ok/&gt;</span></p>
<p><span class="font36">05 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;/rpc-reply&gt;</span></p>
<p><span class="font22" style="font-weight:bold;">YANG</span></p>
<p><span class="font53">YANG is the data modeling language used to precisely specify the structure, syntax, and semantics of network management data used by NETCONF, in much the same way that the SMI is used to specify MIBs in SNMP. All YANG definitions are contained in modules, and an XML document describing a device and its capabilities can be generated from a YANG module.</span></p>
<p><span class="font53">YANG features a small set of built-in data types (as in the case of SMI) and also allows data modelers to express constraints that must be satisfied by a valid NET-CONF configuration—a powerful aid in helping ensure that NETCONF configurations satisfy specified correctness and consistency constraints. YANG is also used to specify NETCONF notifications.</span></p>
<p><span class="font53">A fuller discussion of YANG is beyond our scope here. For more information, we refer the interested reader to the excellent book [Claise 2019].</span></p>
<p><span class="font59" style="font-weight:bold;">5.8 </span><span class="font24" style="font-weight:bold;">Summary</span></p>
<p><span class="font53">We have now completed our two-chapter journey into the network core—a journey that began with our study of the network layer’s data plane in Chapter 4 and finished here with our study of the network layer’s control plane. We learned that the control plane is the network-wide logic that controls not only how a datagram is forwarded among routers along an end-to-end path from the source host to the destination host, but also how network-layer components and services are configured and managed.</span></p>
<p><a name="bookmark376"></a><span class="font53">We learned that there are two broad approaches towards building a control plane: traditional </span><span class="font53" style="font-style:italic;">per-router control</span><span class="font53"> (where a routing algorithm runs in each and every router and the routing component in the router communicates with the routing components in other routers) and </span><span class="font53" style="font-style:italic;">software-defined networking</span><span class="font53"> (SDN) control (where a logically centralized controller computes and distributes the forwarding tables to be used by each and every router). We studied two fundamental routing algorithms for computing least cost paths in a graph—link-state routing and distance-vector routing—in Section 5.2; these algorithms find application in both per-router control and in SDN control. These algorithms are the basis for two widely deployed Internet routing protocols, OSPF and BGP, that we covered in Sections 5.3 and 5.4. We covered the SDN approach to the network-layer control plane in Section 5.5, investigating SDN network-control applications, the SDN controller, and the OpenFlow protocol for communicating between the controller and SDN-controlled devices. In Sections 5.6 and 5.7, we covered some of the nuts and bolts of managing an IP network: ICMP (the Internet Control Message Protocol) and network management using SNMP and NETCONF/YANG.</span></p>
<p><span class="font53">Having completed our study of the network layer, our journey now takes us one step further down the protocol stack, namely, to the link layer. Like the network layer, the link layer is part of each and every network-connected device. But we will see in the next chapter that the link layer has the much more localized task of moving packets between nodes on the same link or LAN. Although this task may appear on the surface to be rather simple compared with that of the network layer’s tasks, we will see that the link layer involves a number of important and fascinating issues that can keep us busy for a long time.</span></p>
<p><span class="font24" style="font-weight:bold;">Homework Problems and Questions</span></p>
<p><span class="font23" style="font-weight:bold;">Chapter 5 Review Questions</span></p>
<p><span class="font43" style="font-weight:bold;">SECTION 5.1</span></p>
<p><span class="font53">R1. What is meant by a control plane that is based on per-router control? In such cases, when we say the network control and data planes are implemented “monolithically,” what do we mean?</span></p>
<p><span class="font53">R2. What is meant by a control plane that is based on logically centralized control? In such cases, are the data plane and the control plane implemented within the same device or in separate devices? Explain.</span></p>
<p><span class="font43" style="font-weight:bold;">SECTION 5.2</span></p>
<p><span class="font53">R3. Compare and contrast the properties of a centralized and a distributed routing algorithm. Give an example of a routing protocol that takes a centralized and a decentralized approach.</span></p>
<p><span class="font53">R4. Compare and contrast static and dynamic routing algorithms.</span></p>
<p><span class="font53">R5. What is the “count to infinity” problem in distance vector routing?</span></p>
<p><span class="font53">R6. How is a least cost path calculated in a decentralized routing algorithm?</span></p>
<p><span class="font43" style="font-weight:bold;">SECTIONS 5.3-5.4</span></p>
<p><span class="font53">R7. Why are different inter-AS and intra-AS protocols used in the Internet?</span></p>
<p><a name="bookmark377"></a><span class="font53">R8. True or false: When an OSPF route sends its link state information, it is sent only to those nodes directly attached neighbors. Explain.</span></p>
<p><span class="font53">R9. What is meant by an </span><span class="font53" style="font-style:italic;">area</span><span class="font53"> in an OSPF autonomous system? Why was the concept of an area introduced?</span></p>
<p><span class="font53">R10. Define and contrast the following terms: </span><span class="font53" style="font-style:italic;">subnet, prefix,</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">BGP route.</span></p>
<p><span class="font53">R11. How does BGP use the NEXT-HOP attribute? How does it use the AS-PATH attribute?</span></p>
<p><span class="font53">R12. Describe how a network administrator of an upper-tier ISP can implement policy when configuring BGP.</span></p>
<p><span class="font53">R13. True or false: When a BGP router receives an advertised path from its neighbor, it must add its own identity to the received path and then send that new path on to all of its neighbors. Explain.</span></p>
<p><span class="font43" style="font-weight:bold;">SECTION 5.5</span></p>
<p><span class="font53">R14. Describe the main role of the communication layer, the network-wide statemanagement layer, and the network-control application layer in an SDN controller.</span></p>
<p><span class="font53">R15. Suppose you wanted to implement a new routing protocol in the SDN control plane. At which layer would you implement that protocol? Explain.</span></p>
<p><span class="font53">R16. What types of messages flow across an SDN controller’s northbound and southbound APIs? Who is the recipient of these messages sent from the controller across the southbound interface, and who sends messages to the controller across the northbound interface?</span></p>
<p><span class="font53">R17. Describe the purpose of two types of OpenFlow messages (of your choosing) that are sent from a controlled device to the controller. Describe the purpose of two types of Openflow messages (of your choosing) that are send from the controller to a controlled device.</span></p>
<p><span class="font53">R18. What is the purpose of the service abstraction layer in the OpenDaylight SDN controller?</span></p>
<p><span class="font43" style="font-weight:bold;">SECTIONS 5.6-5.7</span></p>
<p><span class="font53">R19. Names four different types of ICMP messages</span></p>
<p><span class="font53">R20. What two types of ICMP messages are received at the sending host executing the </span><span class="font53" style="font-style:italic;">Traceroute</span><span class="font53"> program?</span></p>
<p><span class="font53">R21. Define the following terms in the context of SNMP: </span><span class="font53" style="font-style:italic;">managing server, managed device, network management agent and MIB.</span></p>
<p><span class="font53">R22. What are the purposes of the SNMP </span><span class="font53" style="font-style:italic;">GetRequest</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">SetRequest</span><span class="font53"> messages?</span></p>
<p><span class="font53">R23. What is the purpose of the SNMP trap message?</span></p>
<p><span class="font24" style="font-weight:bold;">Problems</span></p>
<p><span class="font53">P1. Consider the figure below.</span></p>
<div><img src="networking_files/networking-411.jpg" alt="" style="width:170pt;height:100pt;">
</div><br clear="all">
<p><span class="font53">Enumerate all paths from </span><span class="font53" style="font-style:italic;">A</span><span class="font53"> to </span><span class="font53" style="font-style:italic;">D</span><span class="font53"> that do not contain any loops</span></p>
<p><span class="font53">P2. Repeat Problem P1 for paths from </span><span class="font53" style="font-style:italic;">C</span><span class="font53"> to </span><span class="font53" style="font-style:italic;">D</span><span class="font53">, </span><span class="font53" style="font-style:italic;">B</span><span class="font53"> to </span><span class="font53" style="font-style:italic;">F,</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">C</span><span class="font53"> to </span><span class="font53" style="font-style:italic;">F.</span></p>
<p><span class="font53">P3. Consider the following network. With the indicated link costs, use Dijkstra’s shortest-path algorithm to compute the shortest path from </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> to all network nodes. Show how the algorithm works by computing a table similar to Table 5.1.</span></p>
<div><img src="networking_files/networking-412.jpg" alt="" style="width:180pt;height:165pt;">
</div><br clear="all">
<p><span class="font16" style="font-weight:bold;">D</span></p>
<p><span class="font2" style="font-weight:bold;">VideoNote</span></p>
<p><span class="font1" style="font-weight:bold;">Dijkstra’s algorithm: discussion and example</span></p>
<p><span class="font53">P4. Consider the network shown in Problem P3. Using Dijkstra’s algorithm, and showing your work using a table similar to Table 5.1, do the following:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Compute the shortest path from </span><span class="font53" style="font-style:italic;">t</span><span class="font53"> to all network nodes.</span></p></li>
<li>
<p><span class="font53">b. Compute the shortest path from </span><span class="font53" style="font-style:italic;">u</span><span class="font53"> to all network nodes.</span></p></li>
<li>
<p><span class="font53">c. Compute the shortest path from </span><span class="font53" style="font-style:italic;">v</span><span class="font53"> to all network nodes.</span></p></li>
<li>
<p><span class="font53">d. Compute the shortest path from </span><span class="font53" style="font-style:italic;">w</span><span class="font53"> to all network nodes.</span></p></li>
<li>
<p><span class="font53">e. Compute the shortest path from </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> to all network nodes.</span></p></li>
<li>
<p><span class="font53">f. Compute the shortest path from </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> to all network nodes.</span></p></li></ul>
<p><span class="font53">P5. Consider the network shown below. Assume that each node initially knows the costs to each of its neighbors. Consider the distance-vector algorithm and show the distance table entries at node </span><span class="font53" style="font-style:italic;">z.</span></p><img src="networking_files/networking-413.jpg" alt="" style="width:128pt;height:77pt;">
<p><span class="font53">P6. Consider a general topology (that is, not the specific network shown above) and a synchronous version of the distance-vector algorithm. Suppose that at each iteration, a node exchanges its distance vectors with its neighbors and receives their distance vectors. Assuming that the algorithm begins with each node knowing only the costs to its immediate neighbors, what is the maximum number of iterations required before the distributed algorithm converges? Justify your answer.</span></p>
<p><span class="font53">P7. Consider the network fragment shown below. </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> has only two attached neighbors, </span><span class="font53" style="font-style:italic;">w</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">y. w</span><span class="font53"> has a minimum-cost path to destination </span><span class="font53" style="font-style:italic;">u</span><span class="font53"> (illustrated with the dotted line through the remaining network) of 9, and </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> has a minimum-cost path to </span><span class="font53" style="font-style:italic;">u</span><span class="font53"> of 11. The complete paths from </span><span class="font53" style="font-style:italic;">w</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> to </span><span class="font53" style="font-style:italic;">u</span><span class="font53"> (and between </span><span class="font53" style="font-style:italic;">w</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">y</span><span class="font53">) are pictured with dotted lines, as they are irrelevant to the solution.</span></p><img src="networking_files/networking-414.jpg" alt="" style="width:170pt;height:73pt;">
<ul style="list-style:none;"><li>
<p><span class="font53">a. Give </span><span class="font53" style="font-style:italic;">x</span><span class="font53">’s distance vector for destinations </span><span class="font53" style="font-style:italic;">w</span><span class="font53">, </span><span class="font53" style="font-style:italic;">y</span><span class="font53">, and </span><span class="font53" style="font-style:italic;">u</span><span class="font53">.</span></p></li>
<li>
<p><span class="font53">b. Give a link-cost change for either </span><span class="font53" style="font-style:italic;">c(x,w)</span><span class="font53"> or </span><span class="font53" style="font-style:italic;">c(x,y)</span><span class="font53"> such that </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> will inform its neighbors of a new minimum-cost path to </span><span class="font53" style="font-style:italic;">u</span><span class="font53"> as a result of executing the distance-vector algorithm.</span></p></li>
<li>
<p><span class="font53">c. Give a link-cost change for either </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(</span><span class="font53" style="font-style:italic;">x</span><span class="font53">,</span><span class="font52">w</span><span class="font53">) or </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(</span><span class="font53" style="font-style:italic;">x</span><span class="font53">,</span><span class="font53" style="font-style:italic;">y</span><span class="font53">) such that </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> will </span><span class="font53" style="font-style:italic;">not </span><span class="font53">inform its neighbors of a new minimum-cost path to </span><span class="font53" style="font-style:italic;">u</span><span class="font53"> as a result of executing the distance-vector algorithm.</span></p></li></ul>
<p><span class="font53">P8. Consider the three-node topology shown in Figure 5.6. Rather than having the link costs shown in Figure 5.6, the link costs are </span><span class="font53" style="font-style:italic;">c(x,y) =</span><span class="font53"> 3, </span><span class="font53" style="font-style:italic;">c(y,z)</span><span class="font54"> = </span><span class="font53">6, </span><span class="font53" style="font-style:italic;">c(z,x) =</span><span class="font53"> 4. Compute the distance tables after the initialization step and after each iteration of a synchronous version of the distance-vector algorithm (as we did in our earlier discussion of Figure 5.6).</span></p>
<p><span class="font53">P9. Can the </span><span class="font53" style="font-style:italic;">poisoned reverse</span><span class="font53"> solve the general count-to-infinity problem? Justify your answer.</span></p>
<p><span class="font53">P10. Argue that for the distance-vector algorithm in Figure 5.6, each value in the distance vector </span><span class="font53" style="font-style:italic;">D(x)</span><span class="font53"> is non-increasing and will eventually stabilize in a finite number of steps.</span></p>
<p><span class="font53">P11. Consider Figure 5.7. Suppose there is another router </span><span class="font53" style="font-style:italic;">w,</span><span class="font53"> connected to router </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">z.</span><span class="font53"> The costs of all links are given as follows: </span><span class="font53" style="font-style:italic;">c(x,y) =</span><span class="font53"> 4, </span><span class="font53" style="font-style:italic;">c(x,z)</span><span class="font54"> = </span><span class="font53">50, </span><span class="font53" style="font-style:italic;">c(y,w) =</span><span class="font53"> 1, </span><span class="font53" style="font-style:italic;">c(z,w) =</span><span class="font53"> 1, </span><span class="font53" style="font-style:italic;">c(y,z) =</span><span class="font53"> 3. Suppose that poisoned reverse is used in the distance-vector routing algorithm.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. When the distance vector routing is stabilized, router </span><span class="font53" style="font-style:italic;">w</span><span class="font53">, </span><span class="font53" style="font-style:italic;">y</span><span class="font53">, and </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> inform their distances to </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> to each other. What distance values do they tell each other?</span></p></li>
<li>
<p><span class="font53">b. Now suppose that the link cost between </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> increases to 60. Will there be a count-to-infinity problem even if poisoned reverse is used? Why or why not? If there is a count-to-infinity problem, then how many iterations are needed for the distance-vector routing to reach a stable state again? Justify your answer.</span></p></li>
<li>
<p><span class="font53">c. How do you modify </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(</span><span class="font53" style="font-style:italic;">y,z</span><span class="font53">) such that there is no count-to-infinity problem at all if </span><span class="font53" style="font-style:italic;">c(y,x)</span><span class="font53"> changes from 4 to 60?</span></p></li></ul>
<p><span class="font53">P12. What is the message complexity of LS routing algorithm?</span></p>
<p><span class="font53">P13. Will a BGP router always choose the loop-free route with the shortest ASpath length? Justify your answer.</span></p>
<p><span class="font53">P14. Consider the network shown below. Suppose AS3 and AS2 are running OSPF for their intra-AS routing protocol. Suppose AS1 and AS4 are running RIP for their intra-AS routing protocol. Suppose eBGP and iBGP are used for the inter-AS routing protocol. Initially suppose there is </span><span class="font53" style="font-style:italic;">no</span><span class="font53"> physical link between AS2 and AS4.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Router 3c learns about prefix </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> from which routing protocol: OSPF, RIP, eBGP, or iBGP?</span></p></li>
<li>
<p><span class="font53">b. Router 3a learns about </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> from which routing protocol?</span></p></li>
<li>
<p><span class="font53">c. Router 1c learns about </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> from which routing protocol?</span></p></li>
<li>
<p><span class="font53">d. Router 1d learns about </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> from which routing protocol?</span></p><img src="networking_files/networking-415.jpg" alt="" style="width:295pt;height:144pt;"></li></ul>
<p><span class="font53">P15. Referring to the previous problem, once router 1d learns about </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> it will put an entry (</span><span class="font53" style="font-style:italic;">x</span><span class="font53">, </span><span class="font53" style="font-style:italic;">I)</span><span class="font53"> in its forwarding table.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Will </span><span class="font53" style="font-style:italic;">I</span><span class="font53"> be equal to </span><span class="font53" style="font-style:italic;">I</span><span class="font53"><sub>1</sub> or </span><span class="font53" style="font-style:italic;">I</span><span class="font49" style="font-style:italic;">2</span><span class="font53"> for this entry? Explain why in one sentence.</span></p></li>
<li>
<p><span class="font53">b. Now suppose that there is a physical link between AS2 and AS4, shown by the dotted line. Suppose router 1d learns that </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> is accessible via AS2 as well as via AS3. Will </span><span class="font53" style="font-style:italic;">I</span><span class="font53"> be set to </span><span class="font53" style="font-style:italic;">I</span><span class="font53"><sub>1</sub> or </span><span class="font53" style="font-style:italic;">I</span><span class="font53"><sub>2</sub>? Explain why in one sentence.</span></p></li>
<li>
<p><span class="font53">c. Now suppose there is another AS, called AS5, which lies on the path between AS2 and AS4 (not shown in diagram). Suppose router 1d learns that </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> is accessible via AS2 AS5 AS4 as well as via AS3 AS4. Will </span><span class="font53" style="font-style:italic;">I</span><span class="font53"> be set to </span><span class="font53" style="font-style:italic;">I</span><span class="font53"><sub>1</sub> or </span><span class="font53" style="font-style:italic;">I</span><span class="font53"><sub>2</sub>? Explain why in one sentence.</span></p></li></ul>
<p><span class="font53">P16. Consider the following network. ISP B provides national backbone service to regional ISP A. ISP C provides national backbone service to regional ISP D. Each ISP consists of one AS. B and C peer with each other in two places using BGP. Consider traffic going from A to D. B would prefer to hand that traffic over to C on the West Coast (so that C would have to absorb the cost of carrying the traffic cross-country), while C would prefer to get the traffic via its East Coast peering point with B (so that B would have carried the traffic across the country). What BGP mechanism might C use, so that B would hand over A-to-D traffic at its East Coast peering point? To answer this question, you will need to dig into the BGP specification.</span></p><img src="networking_files/networking-416.jpg" alt="" style="width:275pt;height:181pt;">
<p><span class="font53">P17. In Figure 5.13, consider the path information that reaches stub networks W, X, and Y. Based on the information available at W and X, what are their respective views of the network topology? Justify your answer. The topology view at Y is shown below.</span></p>
<p><span class="font4">X</span></p>
<div><img src="networking_files/networking-417.jpg" alt="" style="width:35pt;height:34pt;">
</div><br clear="all">
<p><span class="font4">•^^^^Stub network </span><span class="font9"><sup>C</sup> </span><span class="font4">Y’s view of the topology</span></p>
<p><span class="font4">Y</span></p>
<p><span class="font53">P18. Consider Figure 5.13. B would never forward traffic destined to Y via X based on BGP routing. But there are some very popular applications for which data packets go to X first and then flow to Y. Identify one such application, and describe how data packets follow a path not given by BGP routing.</span></p>
<p><span class="font53">P19. In Figure 5.13, suppose that there is another stub network V that is a customer of ISP A. Suppose that B and C have a peering relationship, and A is a customer of both B and C. Suppose that A would like to have the traffic destined to W to come from B only, and the traffic destined to V from either B or C. How should A advertise its routes to B and C? What AS routes does C receive?</span></p>
<p><span class="font53">P20. Suppose ASs X and Z are not directly connected but instead are connected by AS Y. Further suppose that X has a peering agreement with Y, and that Y has a peering agreement with Z. Finally, suppose that Z wants to transit all of Y’s traffic but does not want to transit X’s traffic. Does BGP allow Z to implement this policy?</span></p>
<p><span class="font53">P21. Consider the two ways in which communication occurs between a managing entity and a managed device: request-response mode and trapping. What are the pros and cons of these two approaches, in terms of (1) overhead, (2) notification time when exceptional events occur, and (3) robustness with respect to lost messages between the managing entity and the device?</span></p>
<p><span class="font53">P22. In Section 5.7, we saw that it was preferable to transport SNMP messages in unreliable UDP datagrams. Why do you think the designers of SNMP chose UDP rather than TCP as the transport protocol of choice for SNMP?</span></p>
<p><span class="font24" style="font-weight:bold;">Socket Programming Assignment 5: ICMP Ping</span></p>
<p><a name="bookmark378"></a><span class="font53">At the end of Chapter 2, there are four socket programming assignments. Here you will find a fifth assignment which employs ICMP, a protocol discussed in this chapter.</span></p>
<p><span class="font53">Ping is a popular networking application used to test from a remote location whether a particular host is up and reachable. It is also often used to measure latency between the client host and the target host. It works by sending ICMP “echo request” packets (i.e., ping packets) to the target host and listening for ICMP “echo response” replies (i.e., pong packets). Ping measures the RRT, records packet loss, and calculates a statistical summary of multiple ping-pong exchanges (the minimum, mean, max, and standard deviation of the round-trip times).</span></p>
<p><span class="font53">In this lab, you will write your own Ping application in Python. Your application will use ICMP. But in order to keep your program simple, you will not exactly follow the official specification in RFC 1739. Note that you will only need to write the client side of the program, as the functionality needed on the server side is built into almost all operating systems. You can find full details of this assignment, as well as important snippets of the Python code, at the Web site </span><a href="http://www.pearsonglobaleditions.com"><span class="font53">http://www.pearsonglobaleditions.com</span></a><span class="font53">.</span></p>
<p><span class="font24" style="font-weight:bold;">Programming Assignment: Routing</span></p>
<p><span class="font53">In this programming assignment, you will be writing a “distributed” set of procedures that implements a distributed asynchronous distance-vector routing for the network shown below.</span></p>
<p><span class="font53">You are to write the following routines that will “execute” asynchronously within the emulated environment provided for this assignment. For node 0, you will write the routines:</span></p><img src="networking_files/networking-418.jpg" alt="" style="width:86pt;height:77pt;">
<p><a name="bookmark379"></a><span class="font53">• </span><span class="font53" style="font-style:italic;">rtinit0().</span><span class="font53"> This routine will be called once at the beginning of the emulation. </span><span class="font53" style="font-style:italic;">rtinit0()</span><span class="font53"> has no arguments. It should initialize your distance table in node 0 to reflect the direct costs of 1, 3, and 7 to nodes 1, 2, and 3, respectively. In the figure above, all links are bidirectional and the costs in both directions are identical. After initializing the distance table and any other data structures needed by your node 0 routines, it should then send its directly connected neighbors (in this case, 1, 2, and 3) the cost of its minimum-cost paths to all other network nodes.</span></p>
<p><span class="font53">This minimum-cost information is sent to neighboring nodes in a routing update packet by calling the routine </span><span class="font53" style="font-style:italic;">tolayer2(),</span><span class="font53"> as described in the full assignment. The format of the routing update packet is also described in the full assignment.</span></p>
<p><span class="font53">• </span><span class="font53" style="font-style:italic;">rtupdate0(struct rtpkt *rcvdpkt).</span><span class="font53"> This routine will be called when node 0 receives a routing packet that was sent to it by one of its directly connected neighbors. The parameter </span><span class="font53" style="font-style:italic;">*rcvdpkt</span><span class="font53"> is a pointer to the packet that was received. </span><span class="font53" style="font-style:italic;">rtupdate0() </span><span class="font53">is the “heart” of the distance-vector algorithm. The values it receives in a routing update packet from some other node </span><span class="font53" style="font-style:italic;">i</span><span class="font53"> contain </span><span class="font53" style="font-style:italic;">i’s</span><span class="font53"> current shortest-path costs to all other network nodes. </span><span class="font53" style="font-style:italic;">rtupdate0()</span><span class="font53"> uses these received values to update its own distance table (as specified by the distance-vector algorithm). If its own minimum cost to another node changes as a result of the update, node 0 informs its directly connected neighbors of this change in minimum cost by sending them a routing packet. Recall that in the distance-vector algorithm, only directly connected nodes will exchange routing packets. Thus, nodes 1 and 2 will communicate with each other, but nodes 1 and 3 will not communicate with each other.</span></p>
<p><span class="font53">Similar routines are defined for nodes 1, 2, and 3. Thus, you will write eight procedures in all: </span><span class="font53" style="font-style:italic;">rtinit0(), rtinit1(), rtinit2(), rtinit3(), rtupdate0(), rtupdate1(), rtup-date2(),</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">rtupdate3().</span><span class="font53"> These routines will together implement a distributed, asynchronous computation of the distance tables for the topology and costs shown in the figure on the preceding page.</span></p>
<p><span class="font53">You can find the full details of the programming assignment, as well as C code that you will need to create the simulated hardware/software environment, at </span><a href="http://www.pearsonglobaleditions.com"><span class="font53">http://</span></a><span class="font53"> </span><a href="http://www.pearsonglobaleditions.com"><span class="font53">www.pearsonglobaleditions.com</span></a><span class="font53">. A Java version of the assignment is also available.</span></p>
<p><span class="font24" style="font-weight:bold;">Wireshark Lab: ICMP</span></p>
<p><a name="bookmark380"></a><span class="font53">In the Web site for this textbook, </span><a href="http://www.pearsonglobaleditions.com"><span class="font53">www.pearsonglobaleditions.com</span></a><span class="font53">, you’ll find a Wireshark lab assignment that examines the use of the ICMP protocol in the ping and traceroute commands.</span></p>
<p><span class="font23" style="font-weight:bold;">AN INTERVIEW WITH...</span></p>
<p><span class="font11" style="font-weight:bold;">Jennifer Rexford</span></p>
<div><img src="networking_files/networking-419.jpg" alt="" style="width:97pt;height:109pt;">
</div><br clear="all">
<p><span class="font46">Jennifer Rexford is a Professor in the Computer Science department at Princeton University. Her research has the broad goal of making computer networks easier to design and manage, with particular emphasis on programmable neworks. From 1996-2004, she was a member of the Network Management and Performance department at AT&amp;T Labs-Research. While at AT&amp;T, she designed techniques and tools for network measurement, traffic engineering, and router configuration that were deployed in AT&amp;T’s backbone network. Jennifer is co-author of the book “Web Protocols and Practice: Networking Protocols, Caching, and Traffic Measurement,” published by Addison-Wesley in May 2001. She served as the chair of ACM SIGCOMM from 2003 to 2007. She received her BSE degree in electrical engineering from Princeton University in 1991, and her PhD degree in electrical engineering and computer science from the University of Michigan in 1996. Jennifer was the 2004 winner of ACM’s Grace Murray Hopper Award for outstanding young computer professional, the ACM Athena Lecturer Award (2016), the NCWIT Harrold and Notkin Research and Graduate Mentoring Award (2017), the ACM SIGCOMM award for lifetime contributions (2018), and the IEEE Internet Award (2019). She is an ACM Fellow (2008), an IEEE Fellow (2018), and the National Academy of Engineering (2014).</span></p>
<p><span class="font4" style="font-weight:bold;">Please describe one or two of the most exciting projects you have worked on during your career. What were the biggest challenges?</span></p>
<p><span class="font52">When I was a researcher at AT&amp;T, a group of us designed a new way to manage routing in Internet Service Provider backbone networks. Traditionally, network operators configure each router individually, and these routers run distributed protocols to compute paths through the network. We believed that network management would be simpler and more flexible if network operators could exercise direct control over how routers forward traffic based on a network-wide view of the topology and traffic. The Routing Control Platform (RCP) we designed and built could compute the routes for all of AT&amp;T’s backbone on a single commodity computer, and could control legacy routers without modification. To me, this project was exciting because we had a provocative idea, a working system, and ultimately a real deployment in an operational network. Fast forward a few years, and software-defined networking (SDN) has become a mainstream technology, and standard protocols (like standard protocols (like OpenFlow) and languages (like P4) have made it much easier to tell the underlying switches what to do.</span></p>
<p><span class="font4" style="font-weight:bold;">How do you think software-defined networking should evolve in the future?</span></p>
<p><span class="font52">In a major break from the past, the software controlling network devices can be created by many different programmers, not just at companies selling network equipment. Yet, unlike the applications running on a server or a smart phone, SDN applications must work together to handle the same traffic. Network operators do not want to perform load balancing on some traffic and routing on other traffic; instead, they want to perform load balancing and routing, together, on the same traffic. Future SDN platforms should offer good programming abstractions for composing independently written multiple applications together. More broadly, good programming abstractions can make it easier to create applications, without having to worry about low-level details like flow table entries, traffic counters, bit patterns in packet headers, and so on. Also, while an SDN controller is logically centralized, the network still consists of a distributed collection of devices. Future programmable networks should offer good abstractions for updating a distributed set of devices, so network administrators can reason about what happens to packets in flight while the devices are updated. Programming abstractions for programmable network is an exciting area for interdisciplinary research between computer networking, distributed systems, and programming languages, with a real chance for practical impact in the years ahead.</span></p>
<p><span class="font4" style="font-weight:bold;">Where do you see the future of networking and the Internet?</span></p>
<p><span class="font52">Networking is an exciting field because the applications and the underlying technologies change all the time. We are always reinventing ourselves! Who would have predicted even ten years ago the dominance of smart phones, allowing mobile users to access existing applications as well as new location-based services? The emergence of cloud computing is fundamentally changing the relationship between users and the applications they run, and networked sensors and actuators (the “Internet of Things”) are enabling a wealth of new applications (and security vulnerabilities!). The pace of innovation is truly inspiring.</span></p>
<p><span class="font52">The underlying network is a crucial component in all of these innovations. Yet, the network is notoriously “in the way”—limiting performance, compromising reliability, constraining applications, and complicating the deployment and management of services. We should strive to make the network of the future as invisible as the air we breathe, so it never stands in the way of new ideas and valuable services. To do this, we need to raise the level of abstraction above individual network devices and protocols (and their attendant acronyms!), so we can reason about the network and the user’s high-level goals as a whole.</span></p>
<p><span class="font4" style="font-weight:bold;">What people inspired you professionally?</span></p>
<p><span class="font52">I’ve long been inspired by Sally Floyd who worked for many years at the International Computer Science Institute. Her research was always purposeful, focusing on the important challenges facing the Internet. She dug deeply into hard questions until she understood the problem and the space of solutions completely, and she devoted serious energy into “making things happen,” such as pushing her ideas into protocol standards and network equipment. Also, she gave back to the community, through professional service in numerous standards and research organizations and by creating tools (such as the widely used ns-2 and ns-3 simulators) that enable other researchers to succeed. She retired in 2009, and passed away in 2019, but her influence on the field will be felt for years to come.</span></p>
<p><span class="font4" style="font-weight:bold;">What are your recommendations for students who want careers in computer science and networking?</span></p>
<p><span class="font52">Networking is an inherently interdisciplinary field. Applying techniques from other discipline’s breakthroughs in networking come from such diverse areas as queuing theory, game theory, control theory, distributed systems, network optimization, programming languages, machine learning, algorithms, data structures, and so on. I think that becoming conversant in a related field, or collaborating closely with experts in those fields, is a wonderful way to put networking on a stronger foundation, so we can learn how to build networks that are worthy of society’s trust. Beyond the theoretical disciplines, networking is exciting because we create real artifacts that real people use. Mastering how to design and build systems—by gaining experience in operating systems, computer architecture, and so on—is another fantastic way to amplify your knowledge of networking to help make the world a better place.</span></p><img src="networking_files/networking-420.jpg" alt="" style="width:531pt;height:153pt;">
<h1><a name="bookmark6"></a><span class="font27" style="font-weight:bold;">The Link Layer and LANs</span></h1>
<p><span class="font53">In the previous two chapters, we learned that the network layer provides a communication service between </span><span class="font53" style="font-style:italic;">any</span><span class="font53"> two network hosts. Between the two hosts, datagrams travel over a series of communication links, some wired and some wireless, starting at the source host, passing through a series of packet switches (switches and routers) and ending at the destination host. As we continue down the protocol stack, from the network layer to the link layer, we naturally wonder how packets are sent across the </span><span class="font53" style="font-style:italic;">individual links</span><span class="font53"> that make up the end-to-end communication path. How are the network-layer datagrams encapsulated in the link-layer frames for transmission over a single link? Are different link-layer protocols used in the different links along the communication path? How are transmission conflicts in broadcast links resolved? Is there addressing at the link layer and, if so, how does the link-layer addressing operate with the network-layer addressing we learned about in Chapter 4? And what exactly is the difference between a switch and a router? We’ll answer these and other important questions in this chapter.</span></p>
<p><a name="bookmark381"></a><span class="font53">In discussing the link layer, we’ll see that there are two fundamentally different types of link-layer channels. The first type are broadcast channels, which connect multiple hosts in wireless LANs, in satellite networks, and in hybrid fiber-coaxial cable (HFC) access networks. Since many hosts are connected to the same broadcast communication channel, a so-called medium access protocol is needed to coordinate frame transmission. In some cases, a central controller may be used to coordinate transmissions; in other cases, the hosts themselves coordinate transmissions. The second type of link-layer channel is the point-to-point communication link, such as that often found between two routers connected by a long-distance link, or between a user’s office computer and the nearby Ethernet switch to which it is connected. Coordinating access to a point-to-point link is simpler; the reference material on this book’s Web site has a detailed discussion of the Point-to-Point Protocol (PPP), which is used in settings ranging from dial-up service over a telephone line to high-speed point-to-point frame transport over fiber-optic links.</span></p>
<p><span class="font53">We’ll explore several important link-layer concepts and technologies in this chapter. We’ll dive deeper into error detection and correction, a topic we touched on briefly in Chapter 3. We’ll consider multiple access networks and switched LANs, including Ethernet—by far the most prevalent wired LAN technology. We’ll also look at virtual LANs, and data center networks. Although WiFi, and more generally wireless LANs, are link-layer topics, we’ll postpone our study of these important topics until Chapter 7.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">6.1 </span><span class="font24" style="font-weight:bold;">Introduction to the Link Layer</span></p></li></ul>
<p><span class="font53">Let’s begin with some important terminology. We’ll find it convenient in this chapter to refer to any device that runs a link-layer (i.e., layer 2) protocol as a </span><span class="font53" style="font-weight:bold;">node</span><span class="font53">. Nodes include hosts, routers, switches, and WiFi access points (discussed in Chapter 7). We will also refer to the communication channels that connect adjacent nodes along the communication path as </span><span class="font53" style="font-weight:bold;">links</span><span class="font53">. In order for a datagram to be transferred from source host to destination host, it must be moved over each of the </span><span class="font53" style="font-style:italic;">individual links </span><span class="font53">in the end-to-end path. As an example, in the company network shown at the bottom of Figure 6.1, consider sending a datagram from one of the wireless hosts to one of the servers. This datagram will actually pass through six links: a WiFi link between sending host and WiFi access point, an Ethernet link between the access point and a link-layer switch; a link between the link-layer switch and the router, a link between the two routers; an Ethernet link between the router and a link-layer switch; and finally an Ethernet link between the switch and the server. Over a given link, a transmitting node encapsulates the datagram in a </span><span class="font53" style="font-weight:bold;">link-layer frame </span><span class="font53">and transmits the frame into the link.</span></p>
<p><a name="bookmark382"></a><span class="font53">In order to gain further insight into the link layer and how it relates to the network layer, let’s consider a transportation analogy. Consider a travel agent who is planning a trip for a tourist traveling from Princeton, New Jersey, to Lausanne, Switzerland. The travel agent decides that it is most convenient for the tourist to take a limousine from Princeton to JFK airport, then a plane from JFK airport to Geneva’s airport, and finally a train from Geneva’s airport to Lausanne’s train station. Once</span></p><img src="networking_files/networking-421.jpg" alt="" style="width:326pt;height:377pt;">
<p><span class="font7" style="font-weight:bold;">Figure 6.1 </span><span class="font50">♦ </span><span class="font5">Six link-layer hops between wireless host and server</span></p>
<p><span class="font53">the travel agent makes the three reservations, it is the responsibility of the Princeton limousine company to get the tourist from Princeton to JFK; it is the responsibility of the airline company to get the tourist from JFK to Geneva; and it is the responsibility of the Swiss train service to get the tourist from Geneva to Lausanne. Each of the three segments of the trip is “direct” between two “adjacent” locations. Note that the three transportation segments are managed by different companies and use entirely different transportation modes (limousine, plane, and train). Although the transportation modes are different, they each provide the basic service of moving passengers from one location to an adjacent location. In this transportation analogy, the tourist is a datagram, each transportation segment is a link, the transportation mode is a linklayer protocol, and the travel agent is a routing protocol.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">6.1.1 </span><span class="font23" style="font-weight:bold;">The Services Provided by the Link Layer</span></p></li></ul>
<p><span class="font53">Although the basic service of any link layer is to move a datagram from one node to an adjacent node over a single communication link, the details of the provided service can vary from one link-layer protocol to the next. Possible services that can be offered by a link-layer protocol include:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Framing.</span><span class="font53"> Almost all link-layer protocols encapsulate each network-layer datagram within a link-layer frame before transmission over the link. A frame consists of a data field, in which the network-layer datagram is inserted, and a number of header fields. The structure of the frame is specified by the link-layer protocol. We’ll see several different frame formats when we examine specific link-layer protocols in the second half of this chapter.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Link access.</span><span class="font53"> A medium access control (MAC) protocol specifies the rules by which a frame is transmitted onto the link. For point-to-point links that have a single sender at one end of the link and a single receiver at the other end of the link, the MAC protocol is simple (or nonexistent)—the sender can send a frame whenever the link is idle. The more interesting case is when multiple nodes share a single broadcast link—the so-called multiple access problem. Here, the MAC protocol serves to coordinate the frame transmissions of the many nodes.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Reliable delivery.</span><span class="font53"> When a link-layer protocol provides reliable delivery service, it guarantees to move each network-layer datagram across the link without error. Recall that certain transport-layer protocols (such as TCP) also provide a reliable delivery service. Similar to a transport-layer reliable delivery service, a link-layer reliable delivery service can be achieved with acknowledgments and retransmissions (see Section 3.4). A link-layer reliable delivery service is often used for links that are prone to high error rates, such as a wireless link, with the goal of correcting an error locally—on the link where the error occurs—rather than forcing an end-to-end retransmission of the data by a transport- or application-layer protocol. However, link-layer reliable delivery can be considered an unnecessary overhead for low bit-error links, including fiber, coax, and many twisted-pair copper links. For this reason, many wired link-layer protocols do not provide a reliable delivery service.</span></p></li>
<li>
<p><a name="bookmark383"></a><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Error detection and correction.</span><span class="font53"> The link-layer hardware in a receiving node can incorrectly decide that a bit in a frame is zero when it was transmitted as a one, and vice versa. Such bit errors are introduced by signal attenuation and electromagnetic noise. Because there is no need to forward a datagram that has an error, many link-layer protocols provide a mechanism to detect such bit errors. This is done by having the transmitting node include error-detection bits in the frame, and having the receiving node perform an error check. Recall from Chapters 3 and 4 that the Internet’s transport layer and network layer also provide a limited form of error detection—the Internet checksum. Error detection in the link layer is usually more sophisticated and is implemented in hardware. Error correction is similar to error detection, except that a receiver not only detects when bit errors have occurred in the frame but also determines exactly where in the frame the errors have occurred (and then corrects these errors).</span></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">6.1.2 </span><span class="font23" style="font-weight:bold;">Where Is the Link Layer Implemented?</span></p></li></ul>
<p><span class="font53">Before diving into our detailed study of the link layer, let’s conclude this introduction by considering the question of where the link layer is implemented. Is a host’s link layer implemented in hardware or software? Is it implemented on a separate card or chip, and how does it interface with the rest of a host’s hardware and operating system components?</span></p>
<p><span class="font53">Figure 6.2 shows a typical host architecture. The Ethernet capabilities are either integrated into the motherboard chipset or implemented via a low-cost dedicated Ethernet chip. For the most part, the link layer is implemented on a chip called the </span><span class="font53" style="font-weight:bold;">network adapter</span><span class="font53">, also sometimes known as a </span><span class="font53" style="font-weight:bold;">network interface controller (NIC)</span><span class="font53">. The network adapter implements many link layer services including framing, link access, error detection, and so on. Thus, much of a link-layer controller’s functionality is implemented in hardware. For example, Intel’s 700 series adapters [Intel 2020] implements the Ethernet protocols we’ll study in Section 6.5; the Atheros AR5006 [Atheros 2020] controller implements the 802.11 WiFi protocols we’ll study in Chapter 7.</span></p>
<p><span class="font53">On the sending side, the controller takes a datagram that has been created and stored in host memory by the higher layers of the protocol stack, encapsulates the datagram in a link-layer frame (filling in the frame’s various fields), and then transmits the frame into the communication link, following the link-access protocol. On the receiving side, a controller receives the entire frame, and extracts the networklayer datagram. If the link layer performs error detection, then it is the sending controller that sets the error-detection bits in the frame header and it is the receiving controller that performs error detection.</span></p>
<p><a name="bookmark384"></a><span class="font53">Figure 6.2 shows that while most of the link layer is implemented in hardware, part of the link layer is implemented in software that runs on the host’s CPU. The software components of the link layer implement higher-level link-layer functionality such as assembling link-layer addressing information and activating the</span></p>
<div><img src="networking_files/networking-422.jpg" alt="" style="width:57pt;height:138pt;">
</div><br clear="all">
<div>
<p><span class="font4">Host</span></p><img src="networking_files/networking-423.jpg" alt="" style="width:130pt;height:199pt;">
<p><span class="font4">Motherboard bus</span></p>
<p><span class="font4">Network adapter</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 6.2 </span><span class="font50">♦ </span><span class="font5">Network adapter: Its relationship to other host components and to protocol stack functionality</span></p>
</div><br clear="all">
<p><span class="font53">controller hardware. On the receiving side, link-layer software responds to controller interrupts (for example, due to the receipt of one or more frames), handling error conditions and passing a datagram up to the network layer. Thus, the link layer is a combination of hardware and software—the place in the protocol stack where software meets hardware. [Intel 2020] provides a readable overview (as well as a detailed description) of the XL710 controller from a software-programming point of view.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">6.2 </span><span class="font24" style="font-weight:bold;">Error-Detection and -Correction Techniques</span></p></li></ul>
<p><a name="bookmark385"></a><span class="font53">In the previous section, we noted that </span><span class="font53" style="font-weight:bold;">bit-level error detection and correction— </span><span class="font53">detecting and correcting the corruption of bits in a link-layer frame sent from one node to another physically connected neighboring node—are two services often provided by the link layer. We saw in Chapter 3 that error-detection and -correction services are also often offered at the transport layer as well. In this section, we’ll examine a few of the simplest techniques that can be used to detect and, in some cases, correct such bit errors. A full treatment of the theory and implementation of this topic is itself the topic of many textbooks (e.g., [Schwartz 1980] or [Bertsekas 1991]), and our treatment here is necessarily brief. Our goal here is to develop an intuitive feel for the capabilities that error-detection and -correction techniques provide and to see how a few simple techniques work and are used in practice in the link layer.</span></p>
<p><span class="font53">Figure 6.3 illustrates the setting for our study. At the sending node, data, </span><span class="font53" style="font-style:italic;">D,</span><span class="font53"> to be protected against bit errors is augmented with error-detection and -correction bits </span><span class="font53" style="font-style:italic;">(EDC).</span><span class="font53"> Typically, the data to be protected includes not only the datagram passed down from the network layer for transmission across the link, but also link-level addressing information, sequence numbers, and other fields in the link frame header. Both </span><span class="font53" style="font-style:italic;">D</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">EDC</span><span class="font53"> are sent to the receiving node in a link-level frame. At the receiving node, a sequence of bits, </span><span class="font53" style="font-style:italic;">D'</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">EDC'</span><span class="font53"> is received. Note that </span><span class="font53" style="font-style:italic;">D'</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">EDC'</span><span class="font53"> may differ from the original </span><span class="font53" style="font-style:italic;">D</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">EDC</span><span class="font53"> as a result of in-transit bit flips.</span></p>
<p><span class="font53">The receiver’s challenge is to determine whether or not </span><span class="font53" style="font-style:italic;">D</span><span class="font54">' </span><span class="font53">is the same as the original </span><span class="font53" style="font-style:italic;">D</span><span class="font53">, given that it has only received </span><span class="font53" style="font-style:italic;">D '</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">EDC '</span><span class="font53">. The exact wording of the receiver’s decision in Figure 6.3 (we ask whether an error is detected, not whether an error has occurred!) is important. Error-detection and -correction techniques allow the receiver to sometimes, </span><span class="font53" style="font-style:italic;">but not always,</span><span class="font53"> detect that bit errors have occurred. Even with the use of error-detection bits there still may be </span><span class="font53" style="font-weight:bold;">undetected bit errors</span><span class="font53">; that is, the receiver may be unaware that the received information contains bit errors. As a</span></p>
<p><span class="font25">t</span></p>
<p><span class="font4">Datagram &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Datagram</span></p><img src="networking_files/networking-424.jpg" alt="" style="width:335pt;height:156pt;">
<p><span class="font4">Bit error-prone link</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 6.3 </span><span class="font50">♦ </span><span class="font5">Error-detection and -correction scenario</span></p>
<p><span class="font53">consequence, the receiver might deliver a corrupted datagram to the network layer, or be unaware that the contents of a field in the frame’s header has been corrupted. We thus want to choose an error-detection scheme that keeps the probability of such occurrences small. Generally, more sophisticated error-detection and -correction techniques (that is, those that have a smaller probability of allowing undetected bit errors) incur a larger overhead—more computation is needed to compute and transmit a larger number of error-detection and -correction bits.</span></p>
<p><span class="font53">Let’s now examine three techniques for detecting errors in the transmitted data— parity checks (to illustrate the basic ideas behind error detection and correction), checksumming methods (which are more typically used in the transport layer), and cyclic redundancy checks (which are more typically used in the link layer in an adapter).</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">6.2.1 </span><span class="font23" style="font-weight:bold;">Parity Checks</span></p></li></ul>
<p><span class="font53">Perhaps the simplest form of error detection is the use of a single </span><span class="font53" style="font-weight:bold;">parity bit</span><span class="font53">. Suppose that the information to be sent, </span><span class="font53" style="font-style:italic;">D</span><span class="font53"> in Figure 6.4, has </span><span class="font53" style="font-style:italic;">d</span><span class="font53"> bits. In an even parity scheme, the sender simply includes one additional bit and chooses its value such that the total number of 1s in the </span><span class="font53" style="font-style:italic;">d</span><span class="font55"> + </span><span class="font53">1 bits (the original information plus a parity bit) is even. For odd parity schemes, the parity bit value is chosen such that there is an odd number of 1s. Figure 6.4 illustrates an even parity scheme, with the single parity bit being stored in a separate field.</span></p>
<p><span class="font53">Receiver operation is also simple with a single parity bit. The receiver need only count the number of 1s in the received </span><span class="font53" style="font-style:italic;">d</span><span class="font55"> + </span><span class="font53">1 bits. If an odd number of 1-valued bits are found with an even parity scheme, the receiver knows that at least one bit error has occurred. More precisely, it knows that some </span><span class="font53" style="font-style:italic;">odd</span><span class="font53"> number of bit errors have occurred.</span></p>
<p><span class="font53">But what happens if an even number of bit errors occur? You should convince yourself that this would result in an undetected error. If the probability of bit errors is small and errors can be assumed to occur independently from one bit to the next, the probability of multiple bit errors in a packet would be extremely small. In this case, a single parity bit might suffice. However, measurements have shown that, rather than occurring independently, errors are often clustered together in “bursts.” Under burst error conditions, the probability of undetected errors in a frame protected by single-bit parity can approach 50 percent [Spragins 1991]. Clearly, a more robust error-detection scheme is needed (and, fortunately, is used in practice!). But before examining error-detection schemes that are used in practice, let’s consider a simple</span></p>
<p><span class="font4">Parity </span><span class="font4" style="font-style:italic;">d</span><span class="font4"> data bits &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bit</span></p>
<p><span class="font5">0111000110101011 &nbsp;1 </span><span class="font53">generalization of one-bit parity that will provide us with insight into error-correction techniques.</span></p>
<p><span class="font53">Figure 6.5 shows a two-dimensional generalization of the single-bit parity scheme. Here, the </span><span class="font53" style="font-style:italic;">d</span><span class="font53"> bits in </span><span class="font53" style="font-style:italic;">D</span><span class="font53"> are divided into </span><span class="font53" style="font-style:italic;">i</span><span class="font53"> rows and </span><span class="font53" style="font-style:italic;">j</span><span class="font53"> columns. A parity value is computed for each row and for each column. The resulting </span><span class="font53" style="font-style:italic;">i</span><span class="font55"> + </span><span class="font53" style="font-style:italic;">j</span><span class="font55"> + </span><span class="font53">1 parity bits comprise the link-layer frame’s error-detection bits.</span></p>
<p><span class="font53">Suppose now that a single bit error occurs in the original </span><span class="font53" style="font-style:italic;">d</span><span class="font53"> bits of information. With this </span><span class="font53" style="font-weight:bold;">two-dimensional parity </span><span class="font53">scheme, the parity of both the column and the row containing the flipped bit will be in error. The receiver can thus not only </span><span class="font53" style="font-style:italic;">detect</span><span class="font53"> the fact that a single bit error has occurred, but can use the column and row indices of the column and row with parity errors to actually identify the bit that was corrupted and </span><span class="font53" style="font-style:italic;">correct</span><span class="font53"> that error! Figure 6.5 shows an example in which the 1-valued bit in position (2,2) is corrupted and switched to a 0—an error that is both detectable and correctable at the receiver. Although our discussion has focused on the original </span><span class="font53" style="font-style:italic;">d</span><span class="font53"> bits of information, a single error in the parity bits themselves is also detectable and correctable. Two-dimensional parity can also detect (but not correct!) any combination of two errors in a packet. Other properties of the two-dimensional parity scheme are explored in the problems at the end of the chapter.</span></p>
<p><span class="font4">Row parity</span></p>
<table border="1">
<tr><td></td><td>
<p><span class="font50" style="font-style:italic;"><sup>d</sup>1,1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font4" style="font-style:italic;">■ ■</span></p></td><td>
<p><span class="font4" style="font-style:italic;">■ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font50" style="font-style:italic;"><sup>d</sup></span><span class="font50">1, </span><span class="font50" style="font-style:italic;">j</span></p></td><td>
<p><span class="font50" style="font-style:italic;"><sup>d</sup>1,j+1</span></p></td></tr>
<tr><td rowspan="2">
<p><span class="font4">Column parity</span></p></td><td style="vertical-align:bottom;">
<p><span class="font50" style="font-style:italic;"><sup>d</sup></span><span class="font50">2,1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font4" style="font-style:italic;">■ ■</span></p>
<p><span class="font4" style="font-style:italic;">■■■ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;■■</span></p></td><td style="vertical-align:bottom;">
<ul style="list-style:none;"><li>
<p><span class="font4" style="font-style:italic;">■ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font50" style="font-style:italic;"><sup>d</sup>2,j</span></p></li>
<li>
<p><span class="font4" style="font-style:italic;">■ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;■ ■ ■</span></p></li></ul></td><td style="vertical-align:bottom;">
<p><span class="font50" style="font-style:italic;"><sup>d</sup>2,j+1</span></p>
<p><span class="font4" style="font-style:italic;">■■■</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font50" style="font-style:italic;"><sup>d</sup>i,1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font4" style="font-style:italic;">■ ■</span></p></td><td style="vertical-align:middle;">
<p><span class="font4" style="font-style:italic;">d</span></p>
<p><span class="font50" style="font-style:italic;"><sup>■</sup> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;i</span><span class="font50">, </span><span class="font50" style="font-style:italic;">j</span></p></td><td style="vertical-align:middle;">
<p><span class="font50" style="font-style:italic;"><sup>d</sup>i, j</span><span class="font50">+1</span></p></td></tr>
<tr><td></td><td style="vertical-align:bottom;">
<p><span class="font50" style="font-style:italic;">' <sup>d</sup>i+1,1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font4" style="font-style:italic;">■ ■</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4" style="font-style:italic;">■ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font50" style="font-style:italic;"><sup>d</sup>i</span><span class="font50">+1, </span><span class="font50" style="font-style:italic;">j</span></p></td><td style="vertical-align:bottom;">
<p><span class="font50" style="font-style:italic;"><sup>d</sup>i</span><span class="font50">+1, </span><span class="font50" style="font-style:italic;">j</span><span class="font50">+1</span></p></td></tr>
</table>
<p><span class="font4" style="font-weight:bold;">No errors</span></p>
<div>
<p><span class="font4" style="font-weight:bold;">Correctable single-bit error</span></p><img src="networking_files/networking-425.jpg" alt="" style="width:79pt;height:76pt;">
<p><span class="font4">Parity error</span></p>
<p><span class="font4">Parity error</span></p>
</div><br clear="all">
<p><a href="#bookmark386"><span class="font5">1 &nbsp;&nbsp;0 &nbsp;1 &nbsp;&nbsp;0 &nbsp;1</span></a></p>
<p><a href="#bookmark387"><span class="font5">1 &nbsp;&nbsp;1 &nbsp;&nbsp;1 &nbsp;&nbsp;1 &nbsp;&nbsp;0</span></a></p>
<p><a href="#bookmark388"><span class="font5">0 &nbsp;1 &nbsp;&nbsp;1 &nbsp;&nbsp;1 &nbsp;&nbsp;0</span></a></p>
<p><a href="#bookmark389"><span class="font5">0 &nbsp;0 &nbsp;1 &nbsp;0 &nbsp;1</span></a></p>
<p><span class="font53">The ability of the receiver to both detect and correct errors is known as </span><span class="font53" style="font-weight:bold;">forward error correction (FEC)</span><span class="font53">. These techniques are commonly used in audio storage and playback devices such as audio CDs. In a network setting, FEC techniques can be used by themselves, or in conjunction with link-layer ARQ techniques similar to those we examined in Chapter 3. FEC techniques are valuable because they can decrease the number of sender retransmissions required. Perhaps more important, they allow for immediate correction of errors at the receiver. This avoids having to wait for the round-trip propagation delay needed for the sender to receive a NAK packet and for the retransmitted packet to propagate back to the receiver—a potentially important advantage for real-time network applications [Rubenstein 1998] or links (such as deep-space links) with long propagation delays. Research examining the use of FEC in error-control protocols includes [Biersack 1992; Nonnenmacher 1998; Byers 1998; Shacham 1990].</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">6.2.2 </span><span class="font23" style="font-weight:bold;">Checksumming Methods</span></p></li></ul>
<p><span class="font53">In checksumming techniques, the </span><span class="font53" style="font-style:italic;">d</span><span class="font53"> bits of data in Figure 6.4 are treated as a sequence of </span><span class="font53" style="font-style:italic;">k</span><span class="font53">-bit integers. One simple checksumming method is to simply sum these </span><span class="font53" style="font-style:italic;">k</span><span class="font53">-bit integers and use the resulting sum as the error-detection bits. The </span><span class="font53" style="font-weight:bold;">Internet checksum </span><span class="font53">is based on this approach—bytes of data are treated as 16-bit integers and summed. The 1s complement of this sum then forms the Internet checksum that is carried in the segment header. As discussed in Section 3.3, the receiver checks the checksum by taking the 1s complement of the sum of the received data (including the checksum) and checking whether the result is all 0 bits. If any of the bits are 1, an error is indicated. RFC 1071 discusses the Internet checksum algorithm and its implementation in detail. In the TCP and UDP protocols, the Internet checksum is computed over all fields (header and data fields included). In IP, the checksum is computed over the IP header (since the UDP or TCP segment has its own checksum). In other protocols, for example, XTP [Strayer 1992], one checksum is computed over the header and another checksum is computed over the entire packet.</span></p>
<p><a name="bookmark390"></a><span class="font53">Checksumming methods require relatively little packet overhead. For example, the checksums in TCP and UDP use only 16 bits. However, they provide relatively weak protection against errors as compared with cyclic redundancy check, which is discussed below and which is often used in the link layer. A natural question at this point is, Why is checksumming used at the transport layer and cyclic redundancy check used at the link layer? Recall that the transport layer is typically implemented in software in a host as part of the host’s operating system. Because transport-layer error detection is implemented in software, it is important to have a simple and fast error-detection scheme such as checksumming. On the other hand, error detection at the link layer is implemented in dedicated hardware in adapters, which can rapidly perform the more complex CRC operations. Feldmeier [Feldmeier 1995] presents fast software implementation techniques for not only weighted checksum codes, but CRC (see below) and other codes as well.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">6.2.3 </span><span class="font23" style="font-weight:bold;">Cyclic Redundancy Check (CRC)</span></p></li></ul>
<p><span class="font53">An error-detection technique used widely in today’s computer networks is based on </span><span class="font53" style="font-weight:bold;">cyclic redundancy check (CRC) codes</span><span class="font53">. CRC codes are also known as </span><span class="font53" style="font-weight:bold;">polynomial codes</span><span class="font53">, since it is possible to view the bit string to be sent as a polynomial whose coefficients are the 0 and 1 values in the bit string, with operations on the bit string interpreted as polynomial arithmetic.</span></p>
<p><span class="font53">CRC codes operate as follows. Consider the </span><span class="font53" style="font-style:italic;">d</span><span class="font53">-bit piece of data, </span><span class="font53" style="font-style:italic;">D,</span><span class="font53"> that the sending node wants to send to the receiving node. The sender and receiver must first agree on an </span><span class="font53" style="font-style:italic;">r</span><span class="font55"> + </span><span class="font53">1 bit pattern, known as a </span><span class="font53" style="font-weight:bold;">generator</span><span class="font53">, which we will denote as </span><span class="font53" style="font-style:italic;">G. </span><span class="font53">We will require that the most significant (leftmost) bit of </span><span class="font53" style="font-style:italic;">G</span><span class="font53"> be a 1. The key idea behind CRC codes is shown in Figure 6.6. For a given piece of data, </span><span class="font53" style="font-style:italic;">D</span><span class="font53">, the sender will choose </span><span class="font53" style="font-style:italic;">r</span><span class="font53"> additional bits, </span><span class="font53" style="font-style:italic;">R,</span><span class="font53"> and append them to </span><span class="font53" style="font-style:italic;">D</span><span class="font53"> such that the resulting </span><span class="font53" style="font-style:italic;">d</span><span class="font55"> + </span><span class="font53" style="font-style:italic;">r </span><span class="font53">bit pattern (interpreted as a binary number) is exactly divisible by </span><span class="font53" style="font-style:italic;">G</span><span class="font53"> (i.e., has no remainder) using modulo-2 arithmetic. The process of error checking with CRCs is thus simple: The receiver divides the </span><span class="font53" style="font-style:italic;">d</span><span class="font55"> + </span><span class="font53" style="font-style:italic;">r</span><span class="font53"> received bits by </span><span class="font53" style="font-style:italic;">G</span><span class="font53">. If the remainder is nonzero, the receiver knows that an error has occurred; otherwise the data is accepted as being correct.</span></p>
<p><span class="font53">All CRC calculations are done in modulo-2 arithmetic without carries in addition or borrows in subtraction. This means that addition and subtraction are identical, and both are equivalent to the bitwise exclusive-or (XOR) of the operands. Thus, for example,</span></p>
<p><span class="font36">1011 XOR 0101 = 1110</span></p>
<p><span class="font36">1001 XOR 1101 = 0100</span></p>
<p><span class="font53">Also, we similarly have</span></p>
<p><span class="font36">1011 - 0101 = 1110</span></p>
<p><span class="font36">1001 - 1101 = 0100</span></p>
<p><span class="font53">Multiplication and division are the same as in base-2 arithmetic, except that any required addition or subtraction is done without carries or borrows. As in regular</span></p>
<p><span class="font4" style="font-style:italic;">d</span><span class="font4"> bits &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font4" style="font-style:italic;">r</span><span class="font4"> bits</span></p>
<p><span class="font4" style="text-decoration:underline;">^1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<sup>1</sup></span></p>
<p><span class="font4" style="font-style:italic;">D:</span><span class="font4"> Data bits to be sent &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font4" style="font-style:italic;">R:</span><span class="font4"> CRC bits &nbsp;&nbsp;&nbsp;&nbsp;Bit pattern</span></p>
<p><span class="font4" style="font-style:italic;">D</span><span class="font50"> • </span><span class="font4" style="font-style:italic;">2<sup>r</sup></span><span class="font4"> XOR </span><span class="font4" style="font-style:italic;">R</span><span class="font4"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Mathematical formula</span></p>
<p><a name="bookmark391"></a><span class="font7" style="font-weight:bold;">Figure 6.6 </span><span class="font50">♦ </span><span class="font5">CRC </span><span class="font53">binary arithmetic, multiplication by </span><span class="font53" style="font-style:italic;">2<sup>k</sup></span><span class="font53"> left shifts a bit pattern by </span><span class="font53" style="font-style:italic;">k</span><span class="font53"> places. Thus, given </span><span class="font53" style="font-style:italic;">D</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">R,</span><span class="font53"> the quantity </span><span class="font53" style="font-style:italic;">D </span><span class="font60" style="font-style:italic;">• </span><span class="font53" style="font-style:italic;">2<sup>r</sup></span><span class="font53"> XOR </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> yields the </span><span class="font53" style="font-style:italic;">d</span><span class="font55"> + </span><span class="font53" style="font-style:italic;">r</span><span class="font53"> bit pattern shown in Figure 6.6. We’ll use this algebraic characterization of the </span><span class="font53" style="font-style:italic;">d</span><span class="font55"> + </span><span class="font53" style="font-style:italic;">r</span><span class="font53"> bit pattern from Figure 6.6 in our discussion below.</span></p>
<p><span class="font53">Let us now turn to the crucial question of how the sender computes </span><span class="font53" style="font-style:italic;">R</span><span class="font53">. Recall that we want to find </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> such that there is an </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> such that</span></p>
<p><span class="font53" style="font-style:italic;">D </span><span class="font60" style="font-style:italic;">• </span><span class="font53" style="font-style:italic;">2<sup>r</sup></span><span class="font53"> XOR </span><span class="font53" style="font-style:italic;">R = nG</span></p>
<p><span class="font53">That is, we want to choose </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> such that </span><span class="font53" style="font-style:italic;">G</span><span class="font53"> divides into </span><span class="font53" style="font-style:italic;">D </span><span class="font60" style="font-style:italic;">• </span><span class="font53" style="font-style:italic;">2<sup>r</sup></span><span class="font53"> XOR </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> without remainder. If we XOR (that is, add modulo-2, without carry) </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> to both sides of the above equation, we get</span></p>
<p><span class="font53" style="font-style:italic;">D </span><span class="font60" style="font-style:italic;">• </span><span class="font53" style="font-style:italic;">2<sup>r</sup> = nG</span><span class="font53"> XOR </span><span class="font53" style="font-style:italic;">R</span></p>
<p><span class="font53">This equation tells us that if we divide </span><span class="font53" style="font-style:italic;">D </span><span class="font10" style="font-style:italic;"><sup>•</sup></span><span class="font53"> 2</span><span class="font53" style="font-style:italic;"><sup>r</sup></span><span class="font53"> by </span><span class="font53" style="font-style:italic;">G</span><span class="font53">, the value of the remainder is precisely </span><span class="font53" style="font-style:italic;">R</span><span class="font53">. In other words, we can calculate </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> as</span></p>
<p><span class="font53" style="font-style:italic;">D </span><span class="font60" style="font-style:italic;">• </span><span class="font53" style="font-style:italic;">2<sup>r </sup>R =</span><span class="font53"> remainder----</span></p>
<p><span class="font53" style="font-style:italic;">G</span></p>
<p><span class="font53">Figure 6.7 illustrates this calculation for the case of </span><span class="font53" style="font-style:italic;">D =</span><span class="font53"> 101110, </span><span class="font53" style="font-style:italic;">d =</span><span class="font53"> 6, </span><span class="font53" style="font-style:italic;">G =</span><span class="font53"> 1001, and </span><span class="font53" style="font-style:italic;">r =</span><span class="font53"> 3. The 9 bits transmitted in this case are 101110011. You should check these calculations for yourself and also check that indeed </span><span class="font53" style="font-style:italic;">D </span><span class="font10" style="font-style:italic;"><sup>•</sup></span><span class="font53"> 2</span><span class="font53" style="font-style:italic;"><sup>r</sup> =</span><span class="font53"> 101011 </span><span class="font10" style="font-style:italic;"><sup>•</sup> </span><span class="font53" style="font-style:italic;">G</span><span class="font53"> XOR </span><span class="font53" style="font-style:italic;">R</span><span class="font53">.</span></p>
<p><span class="font4">1 0 1 0 1 1</span></p>
<p><span class="font4">) 1</span><span class="font4" style="text-decoration:underline;"> </span><span class="font4">0</span><span class="font4" style="text-decoration:underline;"> </span><span class="font4">1</span><span class="font4" style="text-decoration:underline;"> </span><span class="font4">1</span><span class="font4" style="text-decoration:underline;"> </span><span class="font4">1</span><span class="font4" style="text-decoration:underline;"> </span><span class="font4">0 0 0 0</span></p>
<p><span class="font4" style="text-decoration:underline;">1 0 0 1</span><span class="font4"> &nbsp;&nbsp;&nbsp;\</span></p>
<p><span class="font4">1 0 1 &nbsp;&nbsp;\</span></p>
<p><span class="font4" style="text-decoration:underline;">0 0 0</span><span class="font4"> </span><span class="font9"><sup>D</sup></span></p>
<p><span class="font4">1 0 1 0</span></p>
<p><span class="font4">1 0 0 1</span></p>
<p><span class="font4">1 1 0</span></p>
<p><a href="#bookmark392"><span class="font4" style="text-decoration:underline;">0 0</span></a></p>
<p><a href="#bookmark393"><span class="font4">1 &nbsp;1 &nbsp;0</span></a></p>
<p><a href="#bookmark394"><span class="font4">1 &nbsp;0 &nbsp;0</span></a></p>
<p><a href="#bookmark395"><span class="font4">1 &nbsp;0 &nbsp;1</span></a></p>
<p><a href="#bookmark396"><span class="font4" style="text-decoration:underline;">1 &nbsp;0 &nbsp;0</span></a></p>
<p><span class="font4" style="text-decoration:underline;">0 1 1</span></p>
<p><span class="font4">R</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 6.7 </span><span class="font50">♦ </span><span class="font5">A sample CRC calculation</span></p>
<p><span class="font53">International standards have been defined for 8-, 12-, 16-, and 32-bit generators, </span><span class="font53" style="font-style:italic;">G.</span><span class="font53"> The CRC-32 32-bit standard, which has been adopted in a number of link-level IEEE protocols, uses a generator of</span></p>
<p><span class="font53" style="font-style:italic;font-variant:small-caps;">G</span><span class="font38" style="font-variant:small-caps;"><sub>crc</sub></span><span class="font53" style="font-variant:small-caps;">.</span><span class="font38" style="font-variant:small-caps;"><sub>32</sub></span><span class="font54"> = </span><span class="font53">100000100110000010001110110110111</span></p>
<p><span class="font53">Each of the CRC standards can detect burst errors of fewer than </span><span class="font53" style="font-style:italic;">r</span><span class="font55"> + </span><span class="font53">1 bits. (This means that all consecutive bit errors of </span><span class="font53" style="font-style:italic;">r</span><span class="font53"> bits or fewer will be detected.) Furthermore, under appropriate assumptions, a burst of length greater than </span><span class="font53" style="font-style:italic;">r</span><span class="font55"> + </span><span class="font53">1 bits is detected with probability 1 </span><span class="font55">— </span><span class="font53">0.5</span><span class="font53" style="font-style:italic;"><sup>r</sup></span><span class="font53">. Also, each of the CRC standards can detect any odd number of bit errors. See [Williams 1993] for a discussion of implementing CRC checks. The theory behind CRC codes and even more powerful codes is beyond the scope of this text. The text [Schwartz 1980] provides an excellent introduction to this topic.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">6.3 </span><span class="font24" style="font-weight:bold;">Multiple Access Links and Protocols</span></p></li></ul>
<p><span class="font53">In the introduction to this chapter, we noted that there are two types of network links: point-to-point links and broadcast links. A </span><span class="font53" style="font-weight:bold;">point-to-point link </span><span class="font53">consists of a single sender at one end of the link and a single receiver at the other end of the link. Many link-layer protocols have been designed for point-to-point links; the point-to-point protocol (PPP) and high-level data link control (HDLC) are two such protocols. The second type of link, a </span><span class="font53" style="font-weight:bold;">broadcast link</span><span class="font53">, can have multiple sending and receiving nodes all connected to the same, single, shared broadcast channel. The term </span><span class="font53" style="font-style:italic;">broadcast</span><span class="font53"> is used here because when any one node transmits a frame, the channel broadcasts the frame and each of the other nodes receives a copy. Ethernet and wireless LANs are examples of broadcast link-layer technologies. In this section, we’ll take a step back from specific link-layer protocols and first examine a problem of central importance to the link layer: how to coordinate the access of multiple sending and receiving nodes to a shared broadcast channel—the </span><span class="font53" style="font-weight:bold;">multiple access problem</span><span class="font53">. Broadcast channels are often used in LANs, networks that are geographically concentrated in a single building (or on a corporate or university campus). Thus, we’ll look at how multiple access channels are used in LANs at the end of this section.</span></p>
<p><a name="bookmark397"></a><span class="font53">We are all familiar with the notion of broadcasting—television has been using it since its invention. But traditional television is a one-way broadcast (that is, one fixed node transmitting to many receiving nodes), while nodes on a computer network broadcast channel can both send and receive. Perhaps a more apt human analogy for a broadcast channel is a cocktail party, where many people gather in a large room (the air providing the broadcast medium) to talk and listen. A second good analogy is something many readers will be familiar with—a classroom—where teacher(s) and student(s) similarly share the same, single, broadcast medium. A central problem in both scenarios is that of determining who gets to talk (that is, transmit into the channel) and when. As humans, we’ve evolved an elaborate set of protocols for sharing the broadcast channel:</span></p>
<p><span class="font53">“Give everyone a chance to speak.”</span></p>
<p><span class="font53">“Don’t speak until you are spoken to.”</span></p>
<p><span class="font53">“Don’t monopolize the conversation.”</span></p>
<p><span class="font53">“Raise your hand if you have a question.”</span></p>
<p><span class="font53">“Don’t interrupt when someone is speaking.”</span></p>
<p><span class="font53">“Don’t fall asleep when someone is talking.”</span></p>
<p><span class="font53">Computer networks similarly have protocols—so-called </span><span class="font53" style="font-weight:bold;">multiple access protocols—</span><span class="font53">by which nodes regulate their transmission into the shared broadcast channel. As shown in Figure 6.8, multiple access protocols are needed in a wide variety of network settings, including both wired and wireless access networks, and satellite networks. Although technically each node accesses the broadcast channel through its adapter, in this section, we will refer to the </span><span class="font53" style="font-style:italic;">node</span><span class="font53"> as the sending and receiving device. In practice, hundreds or even thousands of nodes can directly communicate over a broadcast channel.</span></p>
<div>
<p><span class="font4" style="font-weight:bold;">Shared wire </span><span class="font4">(e.g., cable access network)</span></p>
<p><span class="font4" style="font-weight:bold;">Shared wireless</span></p>
<p><span class="font4">(e.g., WiFi)</span></p><img src="networking_files/networking-426.jpg" alt="" style="width:332pt;height:105pt;">
</div><br clear="all">
<div><img src="networking_files/networking-427.jpg" alt="" style="width:22pt;height:33pt;">
</div><br clear="all">
<div><img src="networking_files/networking-428.jpg" alt="" style="width:70pt;height:77pt;">
<p><span class="font7" style="font-weight:bold;">Figure 6.8 </span><span class="font50">♦ </span><span class="font5">Various multiple access channels</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-429.jpg" alt="" style="width:27pt;height:29pt;">
</div><br clear="all">
<div><img src="networking_files/networking-430.jpg" alt="" style="width:22pt;height:33pt;">
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Cocktail party</span></p><img src="networking_files/networking-431.jpg" alt="" style="width:112pt;height:89pt;">
</div><br clear="all">
<p><span class="font53">Because all nodes are capable of transmitting frames, more than two nodes can transmit frames at the same time. When this happens, all of the nodes receive multiple frames at the same time; that is, the transmitted frames </span><span class="font53" style="font-weight:bold;">collide </span><span class="font53">at all of the receivers. Typically, when there is a collision, none of the receiving nodes can make any sense of any of the frames that were transmitted; in a sense, the signals of the colliding frames become inextricably tangled together. Thus, all the frames involved in the collision are lost, and the broadcast channel is wasted during the collision interval. Clearly, if many nodes want to transmit frames frequently, many transmissions will result in collisions, and much of the bandwidth of the broadcast channel will be wasted.</span></p>
<p><span class="font53">In order to ensure that the broadcast channel performs useful work when multiple nodes are active, it is necessary to somehow coordinate the transmissions of the active nodes. This coordination job is the responsibility of the multiple access protocol. Over the past 40 years, thousands of papers and hundreds of PhD dissertations have been written on multiple access protocols; a comprehensive survey of the first 20 years of this body of work is [Rom 1990]. Furthermore, active research in multiple access protocols continues due to the continued emergence of new types of links, particularly new wireless links.</span></p>
<p><span class="font53">Over the years, dozens of multiple access protocols have been implemented in a variety of link-layer technologies. Nevertheless, we can classify just about any multiple access protocol as belonging to one of three categories: </span><span class="font53" style="font-weight:bold;">channel partitioning protocols</span><span class="font53">, </span><span class="font53" style="font-weight:bold;">random access protocols</span><span class="font53">, and </span><span class="font53" style="font-weight:bold;">taking-turns protocols</span><span class="font53">. We’ll cover these categories of multiple access protocols in the following three subsections.</span></p>
<p><span class="font53">Let’s conclude this overview by noting that, ideally, a multiple access protocol for a broadcast channel of rate </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> bits per second should have the following desirable characteristics:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">1. When only one node has data to send, that node has a throughput of </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> bps.</span></p></li>
<li>
<p><span class="font53">2. When </span><span class="font53" style="font-style:italic;">M</span><span class="font53"> nodes have data to send, each of these nodes has a throughput of </span><span class="font53" style="font-style:italic;">R/M </span><span class="font53">bps. This need not necessarily imply that each of the </span><span class="font53" style="font-style:italic;">M</span><span class="font53"> nodes always has an instantaneous rate of </span><span class="font53" style="font-style:italic;">R</span><span class="font53">/</span><span class="font53" style="font-style:italic;">M</span><span class="font53">, but rather that each node should have an average transmission rate of </span><span class="font53" style="font-style:italic;">R/M</span><span class="font53"> over some suitably defined interval of time.</span></p></li>
<li>
<p><span class="font53">3. The protocol is decentralized; that is, there is no master node that represents a single point of failure for the network.</span></p></li>
<li>
<p><span class="font53">4. The protocol is simple, so that it is inexpensive to implement.</span></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">6.3.1 </span><span class="font23" style="font-weight:bold;">Channel Partitioning Protocols</span></p></li></ul>
<p><a name="bookmark398"></a><span class="font53">Recall from our early discussion back in Section 1.3 that time-division multiplexing (TDM) and frequency-division multiplexing (FDM) are two techniques that can</span></p><img src="networking_files/networking-432.jpg" alt="" style="width:215pt;height:149pt;">
<p><span class="font4">Key:</span></p><img src="networking_files/networking-433.jpg" alt="" style="width:16pt;height:28pt;">
<p><span class="font41">All slots labeled “2” are dedicated to a specific sender-receiver pair.</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 6.9 </span><span class="font50">♦ </span><span class="font5">A four-node TDM and FDM example</span></p>
<p><span class="font53">be used to partition a broadcast channel’s bandwidth among all nodes sharing that channel. As an example, suppose the channel supports </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> nodes and that the transmission rate of the channel is </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> bps. TDM divides time into </span><span class="font53" style="font-weight:bold;">time frames </span><span class="font53">and further divides each time frame into </span><span class="font53" style="font-style:italic;">N</span><span class="font53" style="font-weight:bold;"> time slots</span><span class="font53">. (The TDM time frame should not be confused with the link-layer unit of data exchanged between sending and receiving adapters, which is also called a frame. In order to reduce confusion, in this subsection we’ll refer to the link-layer unit of data exchanged as a packet.) Each time slot is then assigned to one of the </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> nodes. Whenever a node has a packet to send, it transmits the packet’s bits during its assigned time slot in the revolving TDM frame. Typically, slot sizes are chosen so that a single packet can be transmitted during a slot time. Figure 6.9 shows a simple four-node TDM example. Returning to our cocktail party analogy, a TDM-regulated cocktail party would allow one partygoer to speak for a fixed period of time, then allow another partygoer to speak for the same amount of time, and so on. Once everyone had had a chance to talk, the pattern would repeat.</span></p>
<p><span class="font53">TDM is appealing because it eliminates collisions and is perfectly fair: Each node gets a dedicated transmission rate of </span><span class="font53" style="font-style:italic;">R/N</span><span class="font53"> bps during each frame time. However, it has two major drawbacks. First, a node is limited to an average rate of </span><span class="font53" style="font-style:italic;">R</span><span class="font53">/</span><span class="font53" style="font-style:italic;">N</span><span class="font53"> bps even when it is the only node with packets to send. A second drawback is that a node must always wait for its turn in the transmission sequence—again, even when it is the only node with a frame to send. Imagine the partygoer who is the only one with anything to say (and imagine that this is the even rarer circumstance where everyone wants to hear what that one person has to say). Clearly, TDM would be a poor choice for a multiple access protocol for this particular party.</span></p>
<p><span class="font53">While TDM shares the broadcast channel in time, FDM divides the </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> bps channel into different frequencies (each with a bandwidth of </span><span class="font53" style="font-style:italic;">R/N)</span><span class="font53"> and assigns each frequency to one of the </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> nodes. FDM thus creates </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> smaller channels of </span><span class="font53" style="font-style:italic;">R/N</span><span class="font53"> bps out of the single, larger </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> bps channel. FDM shares both the advantages and drawbacks of TDM. It avoids collisions and divides the bandwidth fairly among the </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> nodes. However, FDM also shares a principal disadvantage with TDM—a node is limited to a bandwidth of </span><span class="font53" style="font-style:italic;">R</span><span class="font53">/</span><span class="font53" style="font-style:italic;">N</span><span class="font53">, even when it is the only node with packets to send.</span></p>
<p><span class="font53">A third channel partitioning protocol is </span><span class="font53" style="font-weight:bold;">code division multiple access (CDMA)</span><span class="font53">. While TDM and FDM assign time slots and frequencies, respectively, to the nodes, CDMA assigns a different </span><span class="font53" style="font-style:italic;">code</span><span class="font53"> to each node. Each node then uses its unique code to encode the data bits it sends. If the codes are chosen carefully, CDMA networks have the wonderful property that different nodes can transmit </span><span class="font53" style="font-style:italic;">simultaneously</span><span class="font53"> and yet have their respective receivers correctly receive a sender’s encoded data bits (assuming the receiver knows the sender’s code) in spite of interfering transmissions by other nodes. CDMA has been used in military systems for some time (due to its anti-jamming properties) and now has widespread civilian use, particularly in cellular telephony. Because CDMA’s use is so tightly tied to wireless channels, we’ll save our discussion of the technical details of CDMA until Chapter 7. For now, it will suffice to know that CDMA codes, like time slots in TDM and frequencies in FDM, can be allocated to the multiple access channel users.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">6.3.2 </span><span class="font23" style="font-weight:bold;">Random Access Protocols</span></p></li></ul>
<p><span class="font53">The second broad class of multiple access protocols are random access protocols. In a random access protocol, a transmitting node always transmits at the full rate of the channel, namely, </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> bps. When there is a collision, each node involved in the collision repeatedly retransmits its frame (that is, packet) until its frame gets through without a collision. But when a node experiences a collision, it doesn’t necessarily retransmit the frame right away. </span><span class="font53" style="font-style:italic;">Instead it waits a random delay before retransmitting the frame.</span><span class="font53"> Each node involved in a collision chooses independent random delays. Because the random delays are independently chosen, it is possible that one of the nodes will pick a delay that is sufficiently less than the delays of the other colliding nodes and will therefore be able to sneak its frame into the channel without a collision.</span></p>
<p><a name="bookmark399"></a><span class="font53">There are dozens if not hundreds of random access protocols described in the literature [Rom 1990; Bertsekas 1991]. In this section we’ll describe a few of the most commonly used random access protocols—the ALOHA protocols [Abramson 1970; Abramson 1985; Abramson 2009] and the carrier sense multiple access (CSMA) protocols [Kleinrock 1975b]. Ethernet [Metcalfe 1976] is a popular and widely deployed CSMA protocol.</span></p>
<p><span class="font22" style="font-weight:bold;">Slotted ALOHA</span></p>
<p><span class="font53">Let’s begin our study of random access protocols with one of the simplest random access protocols, the slotted ALOHA protocol. In our description of slotted ALOHA, we assume the following:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;All frames consist of exactly </span><span class="font53" style="font-style:italic;">L</span><span class="font53"> bits.</span></p></li>
<li>
<p><span class="font53">• &nbsp;Time is divided into slots of size </span><span class="font53" style="font-style:italic;">L/R</span><span class="font53"> seconds (that is, a slot equals the time to transmit one frame).</span></p></li>
<li>
<p><span class="font53">• &nbsp;Nodes start to transmit frames only at the beginnings of slots.</span></p></li>
<li>
<p><span class="font53">• &nbsp;The nodes are synchronized so that each node knows when the slots begin.</span></p></li>
<li>
<p><span class="font53">• &nbsp;If two or more frames collide in a slot, then all the nodes detect the collision event before the slot ends.</span></p></li></ul>
<p><span class="font53">Let </span><span class="font53" style="font-style:italic;">p</span><span class="font53"> be a probability, that is, a number between 0 and 1. The operation of slotted ALOHA in each node is simple:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;When the node has a fresh frame to send, it waits until the beginning of the next slot and transmits the entire frame in the slot.</span></p></li>
<li>
<p><span class="font53">• &nbsp;If there isn’t a collision, the node has successfully transmitted its frame and thus need not consider retransmitting the frame. (The node can prepare a new frame for transmission, if it has one.)</span></p></li>
<li>
<p><span class="font53">• &nbsp;If there is a collision, the node detects the collision before the end of the slot. The node retransmits its frame in each subsequent slot with probability </span><span class="font53" style="font-style:italic;">p</span><span class="font53"> until the frame is transmitted without a collision.</span></p></li></ul>
<p><span class="font53">By retransmitting with probability </span><span class="font53" style="font-style:italic;">p</span><span class="font53">, we mean that the node effectively tosses a biased coin; the event heads corresponds to “retransmit,” which occurs with probability </span><span class="font53" style="font-style:italic;">p</span><span class="font53">. The event tails corresponds to “skip the slot and toss the coin again in the next slot”; this occurs with probability (1 </span><span class="font55">— </span><span class="font53" style="font-style:italic;">p</span><span class="font53">). All nodes involved in the collision toss their coins independently.</span></p>
<p><span class="font53">Slotted ALOHA would appear to have many advantages. Unlike channel partitioning, slotted ALOHA allows a node to transmit continuously at the full rate, </span><span class="font53" style="font-style:italic;">R</span><span class="font53">, when that node is the only active node. (A node is said to be active if it has frames to send.) Slotted ALOHA is also highly decentralized, because each node detects collisions and independently decides when to retransmit. (Slotted ALOHA does, however, require the slots to be synchronized in the nodes; shortly we’ll discuss an unslotted version of the ALOHA protocol, as well as CSMA protocols, none of which require such synchronization.) Slotted ALOHA is also an extremely simple protocol.</span></p>
<p><span class="font53">Slotted ALOHA works well when there is only one active node, but how efficient is it when there are multiple active nodes? There are two possible efficiency</span></p>
<div>
<p><span class="font4">Node 1</span></p>
</div><br clear="all">
<div>
<p><span class="font4">1</span></p>
<p><span class="font4">Node 2</span></p><img src="networking_files/networking-434.jpg" alt="" style="width:29pt;height:16pt;">
</div><br clear="all">
<div>
<p><span class="font4">Node 3</span></p><img src="networking_files/networking-435.jpg" alt="" style="width:29pt;height:15pt;">
</div><br clear="all">
<div><img src="networking_files/networking-436.jpg" alt="" style="width:29pt;height:15pt;">
</div><br clear="all">
<div><img src="networking_files/networking-437.jpg" alt="" style="width:33pt;height:20pt;">
</div><br clear="all">
<div>
<p><span class="font4">I C I E I C I S</span></p>
</div><br clear="all">
<p><span class="font4">........... &nbsp;&nbsp;&nbsp;&nbsp;Time</span></p>
<p><span class="font4">E I Cl El S I S I</span></p>
<p><span class="font4">Key:</span></p>
<p><span class="font41">C = Collision slot</span></p>
<p><span class="font41">E = Empty slot</span></p>
<p><span class="font41">S = Successful slot</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 6.10 </span><span class="font50">♦ </span><span class="font5">Nodes 1, 2, and 3 collide in the first slot. Node 2 finally succeeds in the fourth slot, node 1 in the eighth slot, and node 3 in the ninth slot</span></p>
<p><span class="font53">concerns here. First, as shown in Figure 6.10, when there are multiple active nodes, a certain fraction of the slots will have collisions and will therefore be “wasted.” The second concern is that another fraction of the slots will be </span><span class="font53" style="font-style:italic;">empty</span><span class="font53"> because all active nodes refrain from transmitting as a result of the probabilistic transmission policy. The only “unwasted” slots will be those in which exactly one node transmits. A slot in which exactly one node transmits is said to be a </span><span class="font53" style="font-weight:bold;">successful slot</span><span class="font53">. The </span><span class="font53" style="font-weight:bold;">efficiency </span><span class="font53">of a slotted multiple access protocol is defined to be the long-run fraction of successful slots in the case when there are a large number of active nodes, each always having a large number of frames to send. Note that if no form of access control were used, and each node were to immediately retransmit after each collision, the efficiency would be zero. Slotted ALOHA clearly increases the efficiency beyond zero, but by how much?</span></p>
<p><span class="font53">We now proceed to outline the derivation of the maximum efficiency of slotted ALOHA. To keep this derivation simple, let’s modify the protocol a little and assume that each node attempts to transmit a frame in each slot with probability </span><span class="font53" style="font-style:italic;">p</span><span class="font53">. (That is, we assume that each node always has a frame to send and that the node transmits with probability </span><span class="font53" style="font-style:italic;">p</span><span class="font53"> for a fresh frame as well as for a frame that has already suffered a collision.) Suppose there are </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> nodes. Then the probability that a given slot is a successful slot is the probability that one of the nodes transmits and that the remaining </span><span class="font53" style="font-style:italic;">N —</span><span class="font53"> 1 nodes do not transmit. The probability that a given node transmits is </span><span class="font53" style="font-style:italic;">p;</span><span class="font53"> the probability that the remaining nodes do not transmit is (1 </span><span class="font55">— </span><span class="font53" style="font-style:italic;">p)<sup>N</sup></span><span class="font4"><sup> — </sup></span><span class="font53"><sup>1</sup>. Therefore, the probability a given node has a success is </span><span class="font53" style="font-style:italic;">p</span><span class="font53">(1 </span><span class="font55">— </span><span class="font53" style="font-style:italic;">p)<sup>N</sup></span><span class="font4"><sup> — </sup></span><span class="font53"><sup>1</sup>. Because there are </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> nodes, the probability that any one of the </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> nodes has a success is </span><span class="font53" style="font-style:italic;">Np</span><span class="font53">(1 </span><span class="font55">— </span><span class="font53" style="font-style:italic;">p)<sup>N</sup></span><span class="font4"><sup> — </sup></span><span class="font53"><sup>1</sup>.</span></p>
<p><span class="font53">Thus, when there are </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> active nodes, the efficiency of slotted ALOHA is </span><span class="font53" style="font-style:italic;">Np(1 — p)<sup>N</sup></span><span class="font3">- </span><span class="font50">1</span><span class="font53">. To obtain the </span><span class="font53" style="font-style:italic;">maximum</span><span class="font53"> efficiency for </span><span class="font53" style="font-style:italic;">N</span><span class="font53">active nodes, we have to find the </span><span class="font53" style="font-style:italic;">p*</span><span class="font53"> that maximizes this expression. (See the homework problems for a general outline of this derivation.) And to obtain the maximum efficiency for a large number of active nodes, we take the limit of </span><span class="font53" style="font-style:italic;">Np</span><span class="font53">*(1 </span><span class="font55">— </span><span class="font53" style="font-style:italic;">p</span><span class="font53">*)</span><span class="font53" style="font-style:italic;"><sup>N</sup></span><span class="font4"><sup>— </sup></span><span class="font53"><sup>1</sup> as </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> approaches infinity. (Again, see the homework problems.) After performing these calculations, we’ll find that the maximum efficiency of the protocol is given by </span><span class="font53" style="font-style:italic;">1/e =</span><span class="font53"> 0.37. That is, when a large number of nodes have many frames to transmit, then (at best) only 37 percent of the slots do useful work. Thus, the effective transmission rate of the channel is not </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> bps but only 0.37 </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> bps! A similar analysis also shows that 37 percent of the slots go empty and 26 percent of slots have collisions. Imagine the poor network administrator who has purchased a 100-Mbps slotted ALOHA system, expecting to be able to use the network to transmit data among a large number of users at an aggregate rate of, say, 80 Mbps! Although the channel is capable of transmitting a given frame at the full channel rate of 100 Mbps, in the long run, the successful throughput of this channel will be less than 37 Mbps.</span></p>
<p><span class="font22" style="font-weight:bold;">ALOHA</span></p>
<p><span class="font53">The slotted ALOHA protocol required that all nodes synchronize their transmissions to start at the beginning of a slot. The first ALOHA protocol [Abramson 1970] was actually an unslotted, fully decentralized protocol. In pure ALOHA, when a frame first arrives (that is, a network-layer datagram is passed down from the network layer at the sending node), the node immediately transmits the frame in its entirety into the broadcast channel. If a transmitted frame experiences a collision with one or more other transmissions, the node will then immediately (after completely transmitting its collided frame) retransmit the frame with probability </span><span class="font53" style="font-style:italic;">p</span><span class="font53">. Otherwise, the node waits for a frame transmission time. After this wait, it then transmits the frame with probability </span><span class="font53" style="font-style:italic;">p</span><span class="font53">, or waits (remaining idle) for another frame time with probability 1 - </span><span class="font53" style="font-style:italic;">p</span><span class="font53">.</span></p>
<p><span class="font53">To determine the maximum efficiency of pure ALOHA, we focus on an individual node. We’ll make the same assumptions as in our slotted ALOHA analysis and take the frame transmission time to be the unit of time. At any given time, the probability that a node is transmitting a frame is</span><span class="font53" style="font-style:italic;">p</span><span class="font53">. Suppose this frame begins transmission at time </span><span class="font53" style="font-style:italic;">t</span><span class="font49" style="font-style:italic;">0</span><span class="font53" style="font-style:italic;">.</span><span class="font53"> As shown in Figure 6.11, in order for this frame to be successfully transmitted, no other nodes can begin their transmission in the interval of time [</span><span class="font53" style="font-style:italic;">t</span><span class="font50">0 </span><span class="font55">— </span><span class="font53">1, </span><span class="font53" style="font-style:italic;">t</span><span class="font50">0</span><span class="font53">]. Such a transmission would overlap with the beginning of the transmission of node </span><span class="font53" style="font-style:italic;">i</span><span class="font53">’s frame. The probability that all other nodes do not begin a transmission in this interval is (1 </span><span class="font55">— </span><span class="font53" style="font-style:italic;">p)<sup>N</sup></span><span class="font4"><sup> —</sup> </span><span class="font50">1</span><span class="font53">. Similarly, no other node can begin a transmission while node </span><span class="font53" style="font-style:italic;">i</span><span class="font53"> is transmitting, as such a transmission would overlap with the latter part of node </span><span class="font53" style="font-style:italic;">i</span><span class="font53">’s transmission. The probability that all other nodes do not begin a transmission in this interval is also (1 </span><span class="font55">— </span><span class="font53" style="font-style:italic;">p)<sup>N</sup></span><span class="font4"><sup> —</sup> </span><span class="font50">1</span><span class="font53">. Thus, the probability that a given node has a successful transmission is </span><span class="font53" style="font-style:italic;">p</span><span class="font53">( 1 </span><span class="font55">— </span><span class="font53" style="font-style:italic;">p</span><span class="font53">)<sup>2(</sup></span><span class="font53" style="font-style:italic;"><sup>N</sup></span><span class="font4"><sup> — </sup></span><span class="font53"><sup>1</sup></span><span class="font50">)</span><span class="font53">. By taking limits as in the slotted ALOHA case, we find that the maximum efficiency of the pure ALOHA protocol is only 1/(2</span><span class="font53" style="font-style:italic;">e</span><span class="font50">)—</span><span class="font53">exactly half that of slotted ALOHA. This then is the price to be paid for a fully decentralized ALOHA protocol.</span></p>
<div>
<p><span class="font4">Will overlap with start of </span><span class="font4" style="font-style:italic;">i</span><span class="font4">'s frame </span><span class="font4" style="font-style:italic;">_____________________________________________________________________________________________________________l________________________________________________________________________________________________</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Will overlap with end of </span><span class="font4" style="font-style:italic;">i</span><span class="font4">'s frame _____________________________________________________________________________________________________l__________________________________________________________________________________________________</span></p>
</div><br clear="all">
<p><span class="font4">Node i frame</span></p>
<div>
<p><span class="font4" style="font-style:italic;">t</span><span class="font50" style="font-style:italic;">o</span><span class="font4"> - 1</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-style:italic;">t</span><span class="font50" style="font-style:italic;">o</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-438.jpg" alt="" style="width:98pt;height:17pt;">
</div><br clear="all">
<div>
<p><span class="font50" style="font-style:italic;"><sup>t</sup>0</span><span class="font4"> + </span><span class="font9"><sup>1</sup></span></p>
</div><br clear="all">
<div>
<p><span class="font4">Time</span></p>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 6.11 </span><span class="font50">♦ </span><span class="font5">Interfering transmissions in pure ALOHA</span></p>
<p><span class="font22" style="font-weight:bold;">Carrier Sense Multiple Access (CSMA)</span></p>
<p><span class="font53">In both slotted and pure ALOHA, a node’s decision to transmit is made independently of the activity of the other nodes attached to the broadcast channel. In particular, a node neither pays attention to whether another node happens to be transmitting when it begins to transmit, nor stops transmitting if another node begins to interfere with its transmission. In our cocktail party analogy, ALOHA protocols are quite like a boorish partygoer who continues to chatter away regardless of whether other people are talking. As humans, we have human protocols that allow us not only to behave with more civility, but also to decrease the amount of time spent “colliding” with each other in conversation and, consequently, to increase the amount of data we exchange in our conversations. Specifically, there are two important rules for polite human conversation:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Listen before speaking.</span><span class="font53"> If someone else is speaking, wait until they are finished. In the networking world, this is called </span><span class="font53" style="font-weight:bold;">carrier sensing—</span><span class="font53">a node listens to the channel before transmitting. If a frame from another node is currently being transmitted into the channel, a node then waits until it detects no transmissions for a short amount of time and then begins transmission.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">If someone else begins talking at the same time, stop talking.</span><span class="font53"> In the networking world, this is called </span><span class="font53" style="font-weight:bold;">collision detection—</span><span class="font53">a transmitting node listens to the channel while it is transmitting. If it detects that another node is transmitting an interfering frame, it stops transmitting and waits a random amount of time before repeating the sense-and-transmit-when-idle cycle.</span></p></li></ul>
<p><span class="font53">These two rules are embodied in the family of </span><span class="font53" style="font-weight:bold;">carrier sense multiple access (CSMA) </span><span class="font53">and </span><span class="font53" style="font-weight:bold;">CSMA with collision detection (CSMA/CD) </span><span class="font53">protocols [Kleinrock 1975b; Metcalfe 1976; Lam 1980; Rom 1990]. Many variations on CSMA and</span></p>
<p><span class="font23" style="font-weight:bold;">CASE HISTORY</span></p>
<p><span class="font3">r**<sup>1</sup> v </span><span class="font53" style="font-style:italic;">ASh____________________________________________________</span></p>
<p><span class="font4" style="font-weight:bold;">NORM ABRAMSON AND ALOHANET</span></p>
<p><span class="font4">Norm Abramson, a PhD engineer, had a passion for surfing and an interest in packet switching. This combination of interests brought him to the University of Hawaii in 1969. Hawaii consists of many mountainous islands, making it difficult to install and operate land-based networks. When not surfing, Abramson thought about how to design a network that does packet switching over radio. The network he designed had one central host and several secondary nodes scattered over the Hawaiian Islands. The network had two channels, each using a different frequency band. The downlink channel broadcasted packets from the central host to the secondary hosts; and the upstream channel sent packets from the secondary hosts to the central host. In addition to sending informational packets, the central host also sent on the downstream channel an acknowledgment for each packet successfully received from the secondary hosts.</span></p>
<p><span class="font4">Because the secondary hosts transmitted packets in a decentralized fashion, collisions on the upstream channel inevitably occurred. This observation led Abramson to devise the pure ALOHA protocol, as described in this chapter. In 1970, with continued funding from ARPA, Abramson connected his ALOHAnet to the ARPAnet. Abramson’s work is important not only because it was the first example of a radio packet network, but also because it inspired Bob Metcalfe. A few years later, Metcalfe modified the ALOHA protocol to create the CSMA/CD protocol and the Ethernet LAN.</span></p>
<p><span class="font53">CSMA/CD have been proposed. Here, we’ll consider a few of the most important, and fundamental, characteristics of CSMA and CSMA/CD.</span></p>
<p><span class="font53">The first question that you might ask about CSMA is why, if all nodes perform carrier sensing, do collisions occur in the first place? After all, a node will refrain from transmitting whenever it senses that another node is transmitting. The answer to the question can best be illustrated using space-time diagrams [Molle 1987]. Figure 6.12 shows a space-time diagram of four nodes (A, B, C, D) attached to a linear broadcast bus. The horizontal axis shows the position of each node in space; the vertical axis represents time.</span></p>
<p><span class="font53">At time </span><span class="font53" style="font-style:italic;">t<sub>0</sub>,</span><span class="font53"> node B senses the channel is idle, as no other nodes are currently transmitting. Node B thus begins transmitting, with its bits propagating in both directions along the broadcast medium. The downward propagation of B’s bits in Figure 6.12 with increasing time indicates that a nonzero amount of time is needed for B’s bits actually to propagate (albeit at near the speed of light) along the broadcast medium. At time </span><span class="font53" style="font-style:italic;">t</span><span class="font50">1 </span><span class="font53">(</span><span class="font53" style="font-style:italic;">t</span><span class="font50">1 </span><span class="font55">7 </span><span class="font53" style="font-style:italic;">t</span><span class="font53"><sub>0</sub>), node D has a frame to send. Although node B is currently transmitting at time </span><span class="font53" style="font-style:italic;">t</span><span class="font50">1</span><span class="font53">, the bits being transmitted by B have yet to reach D, and thus D senses</span></p>
<div>
<p><span class="font4">Space</span></p>
<p><span class="font4" style="font-weight:bold;">A</span></p>
<p><span class="font4" style="font-weight:bold;">BCD</span></p>
<p><span class="font4" style="font-style:italic;">t</span><span class="font50">0</span></p><img src="networking_files/networking-439.jpg" alt="" style="width:241pt;height:250pt;">
<p><span class="font4" style="font-style:italic;">1</span><span class="font50">1</span></p>
</div><br clear="all">
<p><span class="font4">Time</span></p>
<div>
<p><span class="font4">Time</span></p>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 6.12 </span><span class="font50">♦ </span><span class="font5">Space-time diagram of two CSMA nodes with colliding transmissions</span></p>
<p><span class="font53">the channel idle at </span><span class="font53" style="font-style:italic;">t<sub>1</sub>.</span><span class="font53"> In accordance with the CSMA protocol, D thus begins transmitting its frame. A short time later, B’s transmission begins to interfere with D’s transmission at D. From Figure 6.12, it is evident that the end-to-end </span><span class="font53" style="font-weight:bold;">channel propagation delay </span><span class="font53">of a broadcast channel—the time it takes for a signal to propagate from one of the nodes to another—will play a crucial role in determining its performance. The longer this propagation delay, the larger the chance that a carrier-sensing node is not yet able to sense a transmission that has already begun at another node in the network.</span></p>
<p><span class="font22" style="font-weight:bold;">Carrier Sense Multiple Access with Collision Detection (CSMA/CD)</span></p>
<p><span class="font53">In Figure 6.12, nodes do not perform collision detection; both B and D continue to transmit their frames in their entirety even though a collision has occurred. When a node performs collision detection, it ceases transmission as soon as it detects a collision. Figure 6.13 shows the same scenario as in Figure 6.12, except that the two</span></p>
<div>
<p><span class="font4">Space</span></p>
<p><span class="font4" style="font-weight:bold;">A</span></p>
<p><span class="font4" style="font-weight:bold;">B</span></p>
<p><span class="font4" style="font-weight:bold;">D</span></p>
<p><span class="font4" style="font-style:italic;">t</span><span class="font50">0</span></p><img src="networking_files/networking-440.jpg" alt="" style="width:241pt;height:250pt;">
<p><span class="font4">Time</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 6.13 </span><span class="font50">♦ </span><span class="font5">CSMA with collision detection</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Time</span></p>
</div><br clear="all">
<p><span class="font53">nodes each abort their transmission a short time after detecting a collision. Clearly, adding collision detection to a multiple access protocol will help protocol performance by not transmitting a useless, damaged (by interference with a frame from another node) frame in its entirety.</span></p>
<p><span class="font53">Before analyzing the CSMA/CD protocol, let us now summarize its operation from the perspective of an adapter (in a node) attached to a broadcast channel:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">1. The adapter obtains a datagram from the network layer, prepares a link-layer frame, and puts the frame adapter buffer.</span></p></li>
<li>
<p><span class="font53">2. &nbsp;If the adapter senses that the channel is idle (that is, there is no signal energy entering the adapter from the channel), it starts to transmit the frame. If, on the other hand, the adapter senses that the channel is busy, it waits until it senses no signal energy and then starts to transmit the frame.</span></p></li>
<li>
<p><span class="font53">3. While transmitting, the adapter monitors for the presence of signal energy coming from other adapters using the broadcast channel.</span></p></li>
<li>
<p><span class="font53">4. If the adapter transmits the entire frame without detecting signal energy from other adapters, the adapter is finished with the frame. If, on the other hand, the adapter detects signal energy from other adapters while transmitting, it aborts the transmission (that is, it stops transmitting its frame).</span></p></li>
<li>
<p><span class="font53">5. After aborting, the adapter waits a random amount of time and then returns to step 2.</span></p></li></ul>
<p><span class="font53">The need to wait a random (rather than fixed) amount of time is hopefully clear—if two nodes transmitted frames at the same time and then both waited the same fixed amount of time, they’d continue colliding forever. But what is a good interval of time from which to choose the random backoff time? If the interval is large and the number of colliding nodes is small, nodes are likely to wait a large amount of time (with the channel remaining idle) before repeating the sense-and-transmit-when-idle step. On the other hand, if the interval is small and the number of colliding nodes is large, it’s likely that the chosen random values will be nearly the same, and transmitting nodes will again collide. What we’d like is an interval that is short when the number of colliding nodes is small, and long when the number of colliding nodes is large.</span></p>
<p><span class="font53">The </span><span class="font53" style="font-weight:bold;">binary exponential backoff </span><span class="font53">algorithm, used in Ethernet as well as in DOCSIS cable network multiple access protocols [DOCSIS 3.1 2014], elegantly solves this problem. Specifically, when transmitting a frame that has already experienced </span><span class="font53" style="font-style:italic;">n </span><span class="font53">collisions, a node chooses the value of </span><span class="font53" style="font-style:italic;">K</span><span class="font53"> at random from {0,1,2, . . . . 2</span><span class="font53" style="font-style:italic;"><sup>n</sup></span><span class="font55"> — </span><span class="font53">1}. Thus, the more collisions experienced by a frame, the larger the interval from which </span><span class="font53" style="font-style:italic;">K</span><span class="font53"> is chosen. For Ethernet, the actual amount of time a node waits is K </span><span class="font60">• </span><span class="font53">512 bit times (i.e., </span><span class="font53" style="font-style:italic;">K</span><span class="font53"> times the amount of time needed to send 512 bits into the Ethernet) and the maximum value that </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> can take is capped at 10.</span></p>
<p><span class="font53">Let’s look at an example. Suppose that a node attempts to transmit a frame for the first time and while transmitting it detects a collision. The node then chooses </span><span class="font53" style="font-style:italic;">K</span><span class="font54"> = </span><span class="font53">0 with probability 0.5 or chooses </span><span class="font53" style="font-style:italic;">K =</span><span class="font53"> 1 with probability 0.5. If the node chooses </span><span class="font53" style="font-style:italic;">K =</span><span class="font53"> 0, then it immediately begins sensing the channel. If the node chooses </span><span class="font53" style="font-style:italic;">K</span><span class="font54"> = </span><span class="font53">1, it waits 512 bit times (e.g., 5.12 microseconds for a 100 Mbps Ethernet) before beginning the sense-and-transmit-when-idle cycle. After a second collision, </span><span class="font53" style="font-style:italic;">K</span><span class="font53"> is chosen with equal probability from {0,1,2,3}. After three collisions, </span><span class="font53" style="font-style:italic;">K</span><span class="font53"> is chosen with equal probability from {0,1,2,3,4,5,6,7}. After 10 or more collisions, </span><span class="font53" style="font-style:italic;">K</span><span class="font53"> is chosen with equal probability from {0,1,2, . . . , 1023}. Thus, the size of the sets from which </span><span class="font53" style="font-style:italic;">K</span><span class="font53"> is chosen grows exponentially with the number of collisions; for this reason this algorithm is referred to as binary exponential backoff.</span></p>
<p><span class="font53">We also note here that each time a node prepares a new frame for transmission, it runs the CSMA/CD algorithm, not taking into account any collisions that may have occurred in the recent past. So it is possible that a node with a new frame will immediately be able to sneak in a successful transmission while several other nodes are in the exponential backoff state.</span></p>
<p><span class="font22" style="font-weight:bold;">CSMA/CD Efficiency</span></p>
<p><span class="font53">When only one node has a frame to send, the node can transmit at the full channel rate (e.g., for Ethernet typical rates are 10 Mbps, 100 Mbps, or 1 Gbps). However, if many nodes have frames to transmit, the effective transmission rate of the channel can be much less. We define the </span><span class="font53" style="font-weight:bold;">efficiency of CSMA/CD </span><span class="font53">to be the long-run fraction of time during which frames are being transmitted on the channel without collisions when there is a large number of active nodes, with each node having a large number of frames to send. In order to present a closed-form approximation of the efficiency of Ethernet, let </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>prop</sub> denote the maximum time it takes signal energy to propagate between any two adapters. Let </span><span class="font53" style="font-style:italic;">d</span><span class="font50">t</span><span class="font53"><sub>rans</sub> be the time to transmit a maximum-size frame (approximately 1.2 msecs for a 10 Mbps Ethernet). A derivation of the efficiency of CSMA/CD is beyond the scope of this book (see [Lam 1980] and [Bertsekas 1991]). Here we simply state the following approximation:</span></p>
<div>
<p><span class="font53">Efficiency </span><span class="font54">=</span></p>
</div><br clear="all">
<div>
<p><span class="font59"><sup>1</sup> </span><span class="font55">+ </span><span class="font59"><sup>5</sup></span><span class="font53" style="font-style:italic;"><sup>d</sup></span><span class="font50">p</span><span class="font53"><sub>r</sub></span><span class="font50">op </span><span class="font53">&gt;&nbsp;</span><span class="font53" style="font-style:italic;"><sup>d</sup></span><span class="font50">trans</span></p>
</div><br clear="all">
<p><span class="font53">We see from this formula that as </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>prop</sub> approaches 0, the efficiency approaches 1. This matches our intuition that if the propagation delay is zero, colliding nodes will abort immediately without wasting the channel. Also, as </span><span class="font53" style="font-style:italic;">d</span><span class="font50">t</span><span class="font53"><sub>rans</sub> becomes very large, efficiency approaches 1. This is also intuitive because when a frame grabs the channel, it will hold on to the channel for a very long time; thus, the channel will be doing productive work most of the time.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">6.3.3 </span><span class="font23" style="font-weight:bold;">Taking-Turns Protocols</span></p></li></ul>
<p><span class="font53">Recall that two desirable properties of a multiple access protocol are (1) when only one node is active, the active node has a throughput of </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> bps, and (2) when </span><span class="font53" style="font-style:italic;">M</span><span class="font53"> nodes are active, then each active node has a throughput of nearly </span><span class="font53" style="font-style:italic;">R/M</span><span class="font53"> bps. The ALOHA and CSMA protocols have this first property but not the second. This has motivated researchers to create another class of protocols—the </span><span class="font53" style="font-weight:bold;">taking-turns protocols</span><span class="font53">. As with random access protocols, there are dozens of taking-turns protocols, and each one of these protocols has many variations. We’ll discuss two of the more important protocols here. The first one is the </span><span class="font53" style="font-weight:bold;">polling protocol</span><span class="font53">. The polling protocol requires one of the nodes to be designated as a master node. The master node </span><span class="font53" style="font-weight:bold;">polls </span><span class="font53">each of the nodes in a round-robin fashion. In particular, the master node first sends a message to node 1, saying that it (node 1) can transmit up to some maximum number of frames. After node 1 transmits some frames, the master node tells node 2 it (node 2) can transmit up to the maximum number of frames. (The master node can determine when a node has finished sending its frames by observing the lack of a signal on the channel.) The procedure continues in this manner, with the master node polling each of the nodes in a cyclic manner.</span></p>
<p><a name="bookmark400"></a><span class="font53">The polling protocol eliminates the collisions and empty slots that plague random access protocols. This allows polling to achieve a much higher efficiency. But it also has a few drawbacks. The first drawback is that the protocol introduces a polling delay—the amount of time required to notify a node that it can transmit. If, for example, only one node is active, then the node will transmit at a rate less than </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> bps, as the master node must poll each of the inactive nodes in turn each time the active node has sent its maximum number of frames. The second drawback, which is potentially more serious, is that if the master node fails, the entire channel becomes inoperative. The Bluetooth protocol, which we will study in Section 6.3, is an example of a polling protocol.</span></p>
<p><span class="font53">The second taking-turns protocol is the </span><span class="font53" style="font-weight:bold;">token-passing protocol</span><span class="font53">. In this protocol there is no master node. A small, special-purpose frame known as a </span><span class="font53" style="font-weight:bold;">token </span><span class="font53">is exchanged among the nodes in some fixed order. For example, node 1 might always send the token to node 2, node 2 might always send the token to node 3, and node </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> might always send the token to node 1. When a node receives a token, it holds onto the token only if it has some frames to transmit; otherwise, it immediately forwards the token to the next node. If a node does have frames to transmit when it receives the token, it sends up to a maximum number of frames and then forwards the token to the next node. Token passing is decentralized and highly efficient. But it has its problems as well. For example, the failure of one node can crash the entire channel. Or if a node accidentally neglects to release the token, then some recovery procedure must be invoked to get the token back in circulation. Over the years many token-passing protocols have been developed, including the fiber distributed data interface (FDDI) protocol [Jain 1994] and the IEEE 802.5 token ring protocol [IEEE 802.5 2012], and each one had to address these as well as other sticky issues.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">6.3.4 </span><span class="font23" style="font-weight:bold;">DOCSIS: The Link-Layer Protocol for Cable Internet Access</span></p></li></ul>
<p><span class="font53">In the previous three subsections, we’ve learned about three broad classes of multiple access protocols: channel partitioning protocols, random access protocols, and taking turns protocols. A cable access network will make for an excellent case study here, as we’ll find aspects of </span><span class="font53" style="font-style:italic;">each</span><span class="font53"> of these three classes of multiple access protocols with the cable access network!</span></p>
<p><a name="bookmark401"></a><span class="font53">Recall from Section 1.2.1 that a cable access network typically connects several thousand residential cable modems to a cable modem termination system (CMTS) at the cable network headend. The Data-Over-Cable Service Interface Specifications (DOCSIS) [DOCSIS 3.1 2014; Hamzeh 2015] specifies the cable data network architecture and its protocols. DOCSIS uses FDM to divide the downstream (CMTS to modem) and upstream (modem to CMTS) network segments into multiple frequency channels. Each downstream channel is between 24 MHz and 192 MHz wide, with a maximum throughput of approximately 1.6 Gbps per channel; each upstream channel has channel widths ranging from 6.4 MHz to 96 MHz, with a maximum upstream throughput of approximately 1 Gbps. Each upstream and downstream</span></p>
<p><span class="font4">MAP frame for interval [</span><span class="font4" style="font-style:italic;">t</span><span class="font4"><sub>1</sub>,</span><span class="font4" style="font-style:italic;">t</span><span class="font4"><sub>2</sub>]</span></p>
<div><img src="networking_files/networking-441.jpg" alt="" style="width:70pt;height:65pt;">
<p><span class="font4" style="font-weight:bold;">Cable head end</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Upstream channel j</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Downstream channel i</span></p><img src="networking_files/networking-442.jpg" alt="" style="width:99pt;height:66pt;">
<p><span class="font4" style="font-weight:bold;">Residences with </span><span class="font4" style="font-style:italic;">^</span><span class="font50">2 </span><span class="font4" style="font-weight:bold;">cable modems</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Minislots containing minislot request frames</span></p>
</div><br clear="all">
<p><span class="font4">Assigned minislots containing cable modem upstream data frames</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 6.14 </span><span class="font50">♦ </span><span class="font5">Upstream and downstream channels between CMTS and cable modems</span></p>
<p><span class="font53">channel is a broadcast channel. Frames transmitted on the downstream channel by the CMTS are received by all cable modems receiving that channel; since there is just a single CMTS transmitting into the downstream channel, however, there is no multiple access problem. The upstream direction, however, is more interesting and technically challenging, since multiple cable modems share the same upstream channel (frequency) to the CMTS, and thus collisions can potentially occur.</span></p>
<p><span class="font53">As illustrated in Figure 6.14, each upstream channel is divided into intervals of time (TDM-like), each containing a sequence of mini-slots during which cable modems can transmit to the CMTS. The CMTS explicitly grants permission to individual cable modems to transmit during specific mini-slots. The CMTS accomplishes this by sending a control message known as a MAP message on a downstream channel to specify which cable modem (with data to send) can transmit during which mini-slot for the interval of time specified in the control message. Since mini-slots are explicitly allocated to cable modems, the CMTS can ensure there are no colliding transmissions during a mini-slot.</span></p>
<p><span class="font53">But how does the CMTS know which cable modems have data to send in the first place? This is accomplished by having cable modems send mini-slot-request frames to the CMTS during a special set of interval mini-slots that are dedicated for this purpose, as shown in Figure 6.14. These mini-slot-request frames are transmitted in a random access manner and so may collide with each other. A cable modem can neither sense whether the upstream channel is busy nor detect collisions. Instead, the cable modem infers that its mini-slot-request frame experienced a collision if it does not receive a response to the requested allocation in the next downstream control message. When a collision is inferred, a cable modem uses binary exponential backoff to defer the retransmission of its mini-slot-request frame to a future time slot. When there is little traffic on the upstream channel, a cable modem may actually transmit data frames during slots nominally assigned for mini-slot-request frames (and thus avoid having to wait for a mini-slot assignment).</span></p>
<p><span class="font53">A cable access network thus serves as a terrific example of multiple access protocols in action—FDM, TDM, random access, and centrally allocated time slots all within one network!</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">6.4 </span><span class="font24" style="font-weight:bold;">Switched Local Area Networks</span></p></li></ul>
<p><span class="font53">Having covered broadcast networks and multiple access protocols in the previous section, let’s turn our attention next to switched local networks. Figure 6.15 shows a switched local network connecting three departments, two servers and a router with four switches. Because these switches operate at the link layer, they switch link-layer frames (rather than network-layer datagrams), don’t recognize network-layer addresses, and don’t use routing algorithms like OSPF to determine paths through the network of layer-2 switches. Instead of using IP addresses, we will soon see that they use link-layer addresses to forward link-layer frames through the network of switches. We’ll begin our study of switched LANs by first covering linklayer addressing (Section 6.4.1). We then examine the celebrated Ethernet protocol (Section 6.4.2). After examining link-layer addressing and Ethernet, we’ll look at how link-layer switches operate (Section 6.4.3), and then see (Section 6.4.4) how these switches are often used to build large-scale LANs.</span></p>
<div>
<p><span class="font4">1 Gbps</span></p>
<p><span class="font4">To external internet</span></p>
<p><span class="font52">Web </span><span class="font4">server</span></p>
<p><span class="font4">Mail server</span></p>
<p><span class="font4">1 Gbps</span></p><img src="networking_files/networking-443.jpg" alt="" style="width:392pt;height:216pt;">
<p><span class="font4">Mixture of 10 Mbps,</span></p>
<p><span class="font4">100 Mbps, 1 Gbps,</span></p>
<p><span class="font4">Cat 5 cable</span></p>
<p><span class="font4">100 Mbps (fiber)</span></p>
<p><span class="font4" style="font-weight:bold;">Electrical Engineering</span></p>
<p><span class="font4" style="font-weight:bold;">Computer Science</span></p>
<p><span class="font4" style="font-weight:bold;">Computer Engineering</span></p>
<p><a name="bookmark402"></a><span class="font7" style="font-weight:bold;">Figure 6.15 </span><span class="font50">♦ </span><span class="font5">An institutional network connected together by four switches</span></p>
</div><br clear="all">
<div>
<p><span class="font4">100 Mbps (fiber)</span></p>
</div><br clear="all">
<div>
<p><span class="font4">100 Mbps (fiber)</span></p>
</div><br clear="all">
<div>
<p><span class="font4">1 Gbps</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">6.4.1 </span><span class="font23" style="font-weight:bold;">Link-Layer Addressing and ARP</span></p></li></ul>
<p><span class="font53">Hosts and routers have link-layer addresses. Now you might find this surprising, recalling from Chapter 4 that hosts and routers have network-layer addresses as well. You might be asking, why in the world do we need to have addresses at both the network and link layers? In addition to describing the syntax and function of the link-layer addresses, in this section we hope to shed some light on why the two layers of addresses are useful and, in fact, indispensable. We’ll also cover the Address Resolution Protocol (ARP), which provides a mechanism to translate IP addresses to link-layer addresses.</span></p>
<p><span class="font22" style="font-weight:bold;">MAC Addresses</span></p>
<p><span class="font53">In truth, it is not hosts and routers that have link-layer addresses but rather their adapters (that is, network interfaces) that have link-layer addresses. A host or router with multiple network interfaces will thus have multiple link-layer addresses associated with it, just as it would also have multiple IP addresses associated with it. It’s important to note, however, that link-layer switches do not have link-layer addresses associated with their interfaces that connect to hosts and routers. This is because the job of the link-layer switch is to carry datagrams between hosts and routers; a switch does this job transparently, that is, without the host or router having to explicitly address the frame to the intervening switch. This is illustrated in Figure 6.16. A linklayer address is variously called a </span><span class="font53" style="font-weight:bold;">LAN address</span><span class="font53">, a </span><span class="font53" style="font-weight:bold;">physical address</span><span class="font53">, or a </span><span class="font53" style="font-weight:bold;">MAC address</span><span class="font53">. Because MAC address seems to be the most popular term, we’ll henceforth refer to link-layer addresses as MAC addresses. For most LANs (including Ethernet and 802.11 wireless LANs), the MAC address is 6 bytes long, giving 2<sup>48</sup> possible MAC addresses. As shown in Figure 6.16, these 6-byte addresses are typically expressed in hexadecimal notation, with each byte of the address expressed as a pair of hexadecimal numbers. Although MAC addresses were designed to be permanent, it is now possible to change an adapter’s MAC address via software. For the rest of this section, however, we’ll assume that an adapter’s MAC address is fixed.</span></p>
<p><a name="bookmark403"></a><span class="font53">One interesting property of MAC addresses is that no two adapters have the same address. This might seem surprising given that adapters are manufactured in many countries by many companies. How does a company manufacturing adapters in Taiwan make sure that it is using different addresses from a company manufacturing</span></p>
<p><span class="font34">1A-23-F9-CD-06-9B</span></p><img src="networking_files/networking-444.jpg" alt="" style="width:82pt;height:39pt;">
<p><span class="font34">5C-66-AB-90-75-B1 &nbsp;&nbsp;88-B2-2F-54-1A-0F</span></p><img src="networking_files/networking-445.jpg" alt="" style="width:156pt;height:40pt;">
<p><span class="font34">49-BD-D2-C7-56-2A</span></p><img src="networking_files/networking-446.jpg" alt="" style="width:82pt;height:39pt;">
<p><span class="font7" style="font-weight:bold;">Figure 6.16 </span><span class="font50">♦ </span><span class="font5">Each interface connected to a LAN has a unique MAC address</span></p>
<p><span class="font53">adapters in Belgium? The answer is that the IEEE manages the MAC address space. In particular, when a company wants to manufacture adapters, it purchases a chunk of the address space consisting of 2<sup>24</sup> addresses for a nominal fee. IEEE allocates the chunk of 2<sup>24</sup> addresses by fixing the first 24 bits of a MAC address and letting the company create unique combinations of the last 24 bits for each adapter.</span></p>
<p><span class="font53">An adapter’s MAC address has a flat structure (as opposed to a hierarchical structure) and doesn’t change no matter where the adapter goes. A laptop with an Ethernet interface always has the same MAC address, no matter where the computer goes. A smartphone with an 802.11 interface always has the same MAC address, no matter where the smartphone goes. Recall that, in contrast, IP addresses have a hierarchical structure (that is, a network part and a host part), and a host’s IP addresses needs to be changed when the host moves, i.e., changes the network to which it is attached. An adapter’s MAC address is analogous to a person’s social security number, which also has a flat addressing structure and which doesn’t change no matter where the person goes. An IP address is analogous to a person’s postal address, which is hierarchical and which must be changed whenever a person moves. Just as a person may find it useful to have both a postal address and a social security number, it is useful for a host and router interfaces to have both a network-layer address and a MAC address.</span></p>
<p><span class="font53">When an adapter wants to send a frame to some destination adapter, the sending adapter inserts the destination adapter’s MAC address into the frame and then sends the frame into the LAN. As we will soon see, a switch occasionally broadcasts an incoming frame onto all of its interfaces. We’ll see in Chapter 7 that 802.11 also broadcasts frames. Thus, an adapter may receive a frame that isn’t addressed to it. Thus, when an adapter receives a frame, it will check to see whether the destination MAC address in the frame matches its own MAC address. If there is a match, the adapter extracts the enclosed datagram and passes the datagram up the protocol stack. If there isn’t a match, the adapter discards the frame, without passing the network-layer datagram up. Thus, the destination only will be interrupted when the frame is received.</span></p>
<p><span class="font53">However, sometimes a sending adapter </span><span class="font53" style="font-style:italic;">does</span><span class="font53"> want all the other adapters on the LAN to receive and </span><span class="font53" style="font-style:italic;">process</span><span class="font53"> the frame it is about to send. In this case, the sending adapter inserts a special MAC </span><span class="font53" style="font-weight:bold;">broadcast address </span><span class="font53">into the destination address field of the frame. For LANs that use 6-byte addresses (such as Ethernet and 802.11), the broadcast address is a string of 48 consecutive 1s (that is, FF-FF-FF-FF-FF-FF in hexadecimal notation).</span></p>
<p><span class="font22" style="font-weight:bold;">Address Resolution Protocol (ARP)</span></p>
<p><span class="font53">Because there are both network-layer addresses (for example, Internet IP addresses) and link-layer addresses (that is, MAC addresses), there is a need to translate between them. For the Internet, this is the job of the </span><span class="font53" style="font-weight:bold;">Address Resolution Protocol (ARP) </span><span class="font53">[RFC 826].</span></p>
<p><span class="font53">To understand the need for a protocol such as ARP, consider the network shown in Figure 6.17. In this simple example, each host and router has a single IP address and single MAC address. As usual, IP addresses are shown in dotted-decimal</span></p>
<div><img src="networking_files/networking-447.jpg" alt="" style="width:132pt;height:22pt;">
</div><br clear="all">
<div>
<p><span class="font23" style="font-weight:bold;">PRINCIPLES IN PRACTICE</span></p>
</div><br clear="all">
<p><span class="font4" style="font-weight:bold;">KEEPING THE LAYERS INDEPENDENT</span></p>
<p><span class="font4">There are several reasons why hosts and router interfaces have MAC addresses in addition to network-layer addresses. First, LANs are designed for arbitrary network-layer protocols, not just for IP and the Internet. If adapters were assigned IP addresses rather than “neutral” MAC addresses, then adapters would not easily be able to support other network-layer protocols (for example, IPX or DECnet). Second, if adapters were to use network-layer addresses instead of MAC addresses, the network-layer address would have to be stored in the adapter RAM and reconfigured every time the adapter was moved (or powered up). Another option is to not use any addresses in the adapters and have each adapter pass the data (typically, an IP datagram) of each frame it receives up the protocol stack. The network layer could then check for a matching network-layer address. One problem with this option is that the host would be interrupted by every frame sent on the LAN, including by frames that were destined for other hosts on the same broadcast LAN. In summary, in order for the layers to be largely independent building blocks in a network architecture, different layers need to have their own addressing scheme. We have now seen three types of addresses: host names for the application layer, IP addresses for the network layer, and MAC addresses for the link layer.</span></p>
<div>
<p><span class="font33">1A-23-F9-CD-06-9B</span></p>
</div><br clear="all">
<div>
<p><span class="font33">IP:222.222.222.220</span></p><img src="networking_files/networking-448.jpg" alt="" style="width:37pt;height:42pt;">
<p><span class="font4" style="font-weight:bold;">C</span></p>
</div><br clear="all">
<div>
<p><span class="font33">5C-66-AB-90-75-B1</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-449.jpg" alt="" style="width:35pt;height:39pt;">
</div><br clear="all">
<div><img src="networking_files/networking-450.jpg" alt="" style="width:25pt;height:16pt;">
</div><br clear="all">
<div>
<p><span class="font33">88-B2-2F-54-1A-0F</span></p><img src="networking_files/networking-451.jpg" alt="" style="width:86pt;height:30pt;">
</div><br clear="all">
<p><span class="font33">49-BD-D2-C7-56-2A</span></p>
<div><img src="networking_files/networking-452.jpg" alt="" style="width:40pt;height:39pt;">
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 6.17 </span><span class="font50">♦ </span><span class="font5">Each interface on a LAN has an IP address and a MAC address</span></p>
<p><span class="font53">notation and MAC addresses are shown in hexadecimal notation. For the purposes of this discussion, we will assume in this section that the switch broadcasts all frames; that is, whenever a switch receives a frame on one interface, it forwards the frame on all of its other interfaces. In the next section, we will provide a more accurate explanation of how switches operate.</span></p>
<p><span class="font53">Now suppose that the host with IP address 222.222.222.220 wants to send an IP datagram to host 222.222.222.222. In this example, both the source and destination are in the same subnet, in the addressing sense of Section 4.3.3. To send a datagram, the source must give its adapter not only the IP datagram but also the MAC address for destination 222.222.222.222. The sending adapter will then construct a link-layer frame containing the destination’s MAC address and send the frame into the LAN.</span></p>
<p><span class="font53">The important question addressed in this section is, How does the sending host determine the MAC address for the destination host with IP address 222.222.222.222? As you might have guessed, it uses ARP. An ARP module in the sending host takes any IP address on the same LAN as input, and returns the corresponding MAC address. In the example at hand, sending host 222.222.222.220 provides its ARP module the IP address 222.222.222.222, and the ARP module returns the corresponding MAC address 49-BD-D2-C7-56-2A.</span></p>
<p><span class="font53">So we see that ARP resolves an IP address to a MAC address. In many ways it is analogous to DNS (studied in Section 2.5), which resolves host names to IP addresses. However, one important difference between the two resolvers is that DNS resolves host names for hosts anywhere in the Internet, whereas ARP resolves IP addresses only for hosts and router interfaces on the same subnet. If a node in California were to try to use ARP to resolve the IP address for a node in Mississippi, ARP would return with an error.</span></p>
<table border="1">
<tr><td>
<p><span class="font6">IP Address</span></p></td><td>
<p><span class="font6">MAC Address</span></p></td><td>
<p><span class="font6">TTL</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">222.222.222.221</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">88-B2-2F-54-1A-0F</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">13:45:00</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">222.222.222.223</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">5C-66-AB-90-75-B1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">13:52:00</span></p></td></tr>
</table>
<p><span class="font7" style="font-weight:bold;">Figure 6.18 </span><span class="font50">♦ </span><span class="font5">A possible ARP table in 222.222.222.220</span></p>
<p><span class="font53">Now that we have explained what ARP does, let’s look at how it works. Each host and router has an </span><span class="font53" style="font-weight:bold;">ARP table </span><span class="font53">in its memory, which contains mappings of IP addresses to MAC addresses. Figure 6.18 shows what an ARP table in host 222.222.222.220 might look like. The ARP table also contains a time-to-live (TTL) value, which indicates when each mapping will be deleted from the table. Note that a table does not necessarily contain an entry for every host and router on the subnet; some may have never been entered into the table, and others may have expired. A typical expiration time for an entry is 20 minutes from when an entry is placed in an ARP table.</span></p>
<p><span class="font53">Now suppose that host 222.222.222.220 wants to send a datagram that is IP-addressed to another host or router on that subnet. The sending host needs to obtain the MAC address of the destination given the IP address. This task is easy if the sender’s ARP table has an entry for the destination node. But what if the ARP table doesn’t currently have an entry for the destination? In particular, suppose 222.222.222.220 wants to send a datagram to 222.222.222.222. In this case, the sender uses the ARP protocol to resolve the address. First, the sender constructs a special packet called an </span><span class="font53" style="font-weight:bold;">ARP packet</span><span class="font53">. An ARP packet has several fields, including the sending and receiving IP and MAC addresses. Both ARP query and response packets have the same format. The purpose of the ARP query packet is to query all the other hosts and routers on the subnet to determine the MAC address corresponding to the IP address that is being resolved.</span></p>
<p><span class="font53">Returning to our example, 222.222.222.220 passes an ARP query packet to the adapter along with an indication that the adapter should send the packet to the MAC broadcast address, namely, FF-FF-FF-FF-FF-FF. The adapter encapsulates the ARP packet in a link-layer frame, uses the broadcast address for the frame’s destination address, and transmits the frame into the subnet. Recalling our social security number/postal address analogy, an ARP query is equivalent to a person shouting out in a crowded room of cubicles in some company (say, AnyCorp): “What is the social security number of the person whose postal address is Cubicle 13, Room 112, AnyCorp, Palo Alto, California?” The frame containing the ARP query is received by all the other adapters on the subnet, and (because of the broadcast address) each adapter passes the ARP packet within the frame up to its ARP module. Each of these ARP modules checks to see if its IP address matches the destination IP address in the ARP packet. The one with a match sends back to the querying host a response ARP packet with the desired mapping. The querying host 222.222.222.220 can then update its ARP table and send its IP datagram, encapsulated in a link-layer frame whose destination MAC is that of the host or router responding to the earlier ARP query.</span></p>
<p><span class="font53">There are a couple of interesting things to note about the ARP protocol. First, the query ARP message is sent within a broadcast frame, whereas the response ARP message is sent within a standard frame. Before reading on you should think about why this is so. Second, ARP is plug-and-play; that is, an ARP table gets built automatically—it doesn’t have to be configured by a system administrator. And if a host becomes disconnected from the subnet, its entry is eventually deleted from the other ARP tables in the subnet.</span></p>
<p><span class="font53">Students often wonder if ARP is a link-layer protocol or a network-layer protocol. As we’ve seen, an ARP packet is encapsulated within a link-layer frame and thus lies architecturally above the link layer. However, an ARP packet has fields containing link-layer addresses and thus is arguably a link-layer protocol, but it also contains network-layer addresses and thus is also arguably a network-layer protocol. In the end, ARP is probably best considered a protocol that straddles the boundary between the link and network layers—not fitting neatly into the simple layered protocol stack we studied in Chapter 1. Such are the complexities of real-world protocols!</span></p>
<p><span class="font22" style="font-weight:bold;">Sending a Datagram off the Subnet</span></p>
<p><span class="font53">It should now be clear how ARP operates when a host wants to send a datagram to another host </span><span class="font53" style="font-style:italic;">on the same subnet.</span><span class="font53"> But now let’s look at the more complicated situation when a host on a subnet wants to send a network-layer datagram to a host </span><span class="font53" style="font-style:italic;">off the subnet</span><span class="font53"> (that is, across a router onto another subnet). Let’s discuss this issue in the context of Figure 6.19, which shows a simple network consisting of two subnets interconnected by a router.</span></p>
<p><span class="font53">There are several interesting things to note about Figure 6.19. Each host has exactly one IP address and one adapter. But, as discussed in Chapter 4, a router has an IP address for </span><span class="font53" style="font-style:italic;">each</span><span class="font53"> of its interfaces. For each router interface there is also an ARP module (in the router) and an adapter. Because the router in Figure 6.19 has two interfaces, it has two IP addresses, two ARP modules, and two adapters. Of course, each adapter in the network has its own MAC address.</span></p>
<div>
<p><span class="font33">74-29-9C-E8-FF-55</span></p>
</div><br clear="all">
<div>
<p><span class="font33">IP:111.111.111.111</span></p><img src="networking_files/networking-453.jpg" alt="" style="width:37pt;height:42pt;">
</div><br clear="all">
<div>
<p><span class="font33">88-B2-2F-54-1A-0F</span></p>
</div><br clear="all">
<div>
<p><span class="font33">IP:111.111.111.110</span></p>
</div><br clear="all">
<div>
<p><span class="font33">E6-E9-00-17-BB-4B</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-454.jpg" alt="" style="width:25pt;height:16pt;">
</div><br clear="all">
<div>
<p><span class="font33">CC-49-DE-D0-AB-7D</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-455.jpg" alt="" style="width:42pt;height:26pt;">
</div><br clear="all">
<div><img src="networking_files/networking-456.jpg" alt="" style="width:25pt;height:16pt;">
</div><br clear="all">
<div><img src="networking_files/networking-457.jpg" alt="" style="width:37pt;height:37pt;">
<p><span class="font33">IP:222.222.222.221</span></p>
</div><br clear="all">
<div>
<p><span class="font33">IP:111.111.111.112</span></p><img src="networking_files/networking-458.jpg" alt="" style="width:37pt;height:42pt;">
</div><br clear="all">
<div>
<p><span class="font33">1A-23-F9-CD-06-9B</span></p>
</div><br clear="all">
<div>
<p><span class="font33">49-BD-D2-C7-56-2A</span></p>
</div><br clear="all">
<div>
<p><span class="font33">IP:222.222.222.220</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-459.jpg" alt="" style="width:37pt;height:37pt;">
<p><span class="font33">IP:222.222.222.222</span></p>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 6.19 </span><span class="font50">♦ </span><span class="font5">Two subnets interconnected by a router</span></p>
<p><span class="font53">Also note that Subnet 1 has the network address 111.111.111/24 and that Subnet 2 has the network address 222.222.222/24. Thus, all of the interfaces connected to Subnet 1 have addresses of the form 111.111.111.xxx and all of the interfaces connected to Subnet 2 have addresses of the form 222.222.222.xxx.</span></p>
<p><span class="font53">Now let’s examine how a host on Subnet 1 would send a datagram to a host on Subnet 2. Specifically, suppose that host 111.111.111.111 wants to send an IP datagram to a host 222.222.222.222. The sending host passes the datagram to its adapter, as usual. But the sending host must also indicate to its adapter an appropriate destination MAC address. What MAC address should the adapter use? One might be tempted to guess that the appropriate MAC address is that of the adapter for host 222.222.222.222, namely, 49-BD-D2-C7-56-2A. This guess, however, would be wrong! If the sending adapter were to use that MAC address, then none of the adapters on Subnet 1 would bother to pass the IP datagram up to its network layer, since the frame’s destination address would not match the MAC address of any adapter on Subnet 1. The datagram would just die and go to datagram heaven.</span></p>
<p><span class="font53">If we look carefully at Figure 6.19, we see that in order for a datagram to go from 111.111.111.111 to a host on Subnet 2, the datagram must first be sent to the router interface 111.111.111.110, which is the IP address of the first-hop router on the path to the final destination. Thus, the appropriate MAC address for the frame is the address of the adapter for router interface 111.111.111.110, namely, E6-E9-00-17-BB-4B. How does the sending host acquire the MAC address for 111.111.111.110? By using ARP, of course! Once the sending adapter has this MAC address, it creates a frame (containing the datagram addressed to 222.222.222.222) and sends the frame into Subnet 1. The router adapter on Subnet 1 sees that the link-layer frame is addressed to it, and therefore passes the frame to the network layer of the router. Hooray—the IP datagram has successfully been moved from source host to the router! But we are not finished. We still have to move the datagram from the router to the destination. The router now has to determine the correct interface on which the datagram is to be forwarded. As discussed in Chapter 4, this is done by consulting a forwarding table in the router. The forwarding table tells the router that the datagram is to be forwarded via router interface 222.222.222.220. This interface then passes the datagram to its adapter, which encapsulates the datagram in a new frame and sends the frame into Subnet 2. This time, the destination MAC address of the frame is indeed the MAC address of the ultimate destination. And how does the router obtain this destination MAC address? From ARP, of course!</span></p>
<p><span class="font53">ARP for Ethernet is defined in RFC 826. A nice introduction to ARP is given in the TCP/IP tutorial, RFC 1180. We’ll explore ARP in more detail in the homework problems.</span></p>
<p><span class="font56" style="font-weight:bold;">6.4.2 </span><span class="font23" style="font-weight:bold;">Ethernet</span></p>
<p><a name="bookmark404"></a><span class="font53">Ethernet has pretty much taken over the wired LAN market. In the 1980s and the early 1990s, Ethernet faced many challenges from other LAN technologies, including token ring, FDDI, and ATM. Some of these other technologies succeeded in capturing a part of the LAN market for a few years. But since its invention in the mid-1970s, Ethernet has continued to evolve and grow and has held on to its dominant position. Today, Ethernet is by far the most prevalent wired LAN technology, and it is likely to remain so for the foreseeable future. One might say that Ethernet has been to local area networking what the Internet has been to global networking.</span></p>
<p><span class="font53">There are many reasons for Ethernet’s success. First, Ethernet was the first widely deployed high-speed LAN. Because it was deployed early, network administrators became intimately familiar with Ethernet—its wonders and its quirks—and were reluctant to switch over to other LAN technologies when they came on the scene. Second, token ring, FDDI, and ATM were more complex and expensive than Ethernet, which further discouraged network administrators from switching over. Third, the most compelling reason to switch to another LAN technology (such as FDDI or ATM) was usually the higher data rate of the new technology; however, Ethernet always fought back, producing versions that operated at equal data rates or higher. Switched Ethernet was also introduced in the early 1990s, which further increased its effective data rates. Finally, because Ethernet has been so popular, Ethernet hardware (in particular, adapters and switches) has become a commodity and is remarkably cheap.</span></p>
<p><span class="font53">The original Ethernet LAN was invented in the mid-1970s by Bob Metcalfe and David Boggs. The original Ethernet LAN used a coaxial bus to interconnect the nodes. Bus topologies for Ethernet actually persisted throughout the 1980s and into the mid-1990s. Ethernet with a bus topology is a broadcast LAN—all transmitted frames travel to and are processed by </span><span class="font53" style="font-style:italic;">all</span><span class="font53"> adapters connected to the bus. Recall that we covered Ethernet’s CSMA/CD multiple access protocol with binary exponential backoff in Section 6.3.2.</span></p>
<p><span class="font53">By the late 1990s, most companies and universities had replaced their LANs with Ethernet installations using a hub-based star topology. In such an installation the hosts (and routers) are directly connected to a hub with twisted-pair copper wire. A </span><span class="font53" style="font-weight:bold;">hub </span><span class="font53">is a physical-layer device that acts on individual bits rather than frames. When a bit, representing a zero or a one, arrives from one interface, the hub simply re-creates the bit, boosts its energy strength, and transmits the bit onto all the other interfaces. Thus, Ethernet with a hub-based star topology is also a broadcast LAN—whenever a hub receives a bit from one of its interfaces, it sends a copy out on all of its other interfaces. In particular, if a hub receives frames from two different interfaces at the same time, a collision occurs and the nodes that created the frames must retransmit.</span></p>
<p><span class="font53">In the early 2000s, Ethernet experienced yet another major evolutionary change. Ethernet installations continued to use a star topology, but the hub at the center was replaced with a </span><span class="font53" style="font-weight:bold;">switch</span><span class="font53">. We’ll be examining switched Ethernet in depth later in this chapter. For now, we only mention that a switch is not only “collision-less” but is also a bona-fide store-and-forward packet switch; but unlike routers, which operate up through layer 3, a switch operates only up through layer 2.</span></p>
<div>
<p><span class="font4">Preamble</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Dest. address</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Source address</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Data</span></p>
</div><br clear="all">
<div>
<p><span class="font4">CRC</span></p>
</div><br clear="all">
<p><span class="font4">Type</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 6.20 </span><span class="font50">♦ </span><span class="font5">Ethernet frame structure</span></p>
<p><span class="font22" style="font-weight:bold;">Ethernet Frame Structure</span></p>
<p><span class="font53">We can learn a lot about Ethernet by examining the Ethernet frame, which is shown in Figure 6.20. To give this discussion about Ethernet frames a tangible context, let’s consider sending an IP datagram from one host to another host, with both hosts on the same Ethernet LAN (for example, the Ethernet LAN in Figure 6.17.) (Although the payload of our Ethernet frame is an IP datagram, we note that an Ethernet frame can carry other network-layer packets as well.) Let the sending adapter, adapter A, have the MAC address AA-AA-AA-AA-AA-AA and the receiving adapter, adapter B, have the MAC address BB-BB-BB-BB-BB-BB. The sending adapter encapsulates the IP datagram within an Ethernet frame and passes the frame to the physical layer. The receiving adapter receives the frame from the physical layer, extracts the IP datagram, and passes the IP datagram to the network layer. In this context, let’s now examine the six fields of the Ethernet frame, as shown in Figure 6.20.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Data field (46 to 1,500 bytes).</span><span class="font53"> This field carries the IP datagram. The maximum transmission unit (MTU) of Ethernet is 1,500 bytes. This means that if the IP datagram exceeds 1,500 bytes, then the host has to fragment the datagram, as discussed in Section 4.3.2. The minimum size of the data field is 46 bytes. This means that if the IP datagram is less than 46 bytes, the data field has to be “stuffed” to fill it out to 46 bytes. When stuffing is used, the data passed to the network layer contains the stuffing as well as an IP datagram. The network layer uses the length field in the IP datagram header to remove the stuffing.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Destination address (6 bytes).</span><span class="font53"> This field contains the MAC address of the destination adapter, BB-BB-BB-BB-BB-BB. When adapter B receives an Ethernet frame whose destination address is either BB-BB-BB-BB-BB-BB or the MAC broadcast address, it passes the contents of the frame’s data field to the network layer; if it receives a frame with any other MAC address, it discards the frame.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Source address (6 bytes).</span><span class="font53"> This field contains the MAC address of the adapter that transmits the frame onto the LAN, in this example, AA-AA-AA-AA-AA-AA.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Type field (2 bytes).</span><span class="font53"> The type field permits Ethernet to multiplex network-layer protocols. To understand this, we need to keep in mind that hosts can use other network-layer protocols besides IP. In fact, a given host may support multiple network-layer protocols using different protocols for different applications. For this reason, when the Ethernet frame arrives at adapter B, adapter B needs to know to which network-layer protocol it should pass (that is, demultiplex) the contents of the data field. IP and other network-layer protocols (for example, Novell IPX or AppleTalk) each have their own, standardized type number. Furthermore, the ARP protocol (discussed in the previous section) has its own type number, and if the arriving frame contains an ARP packet (i.e., has a type field of 0806 hexadecimal), the ARP packet will be demultiplexed up to the ARP protocol. Note that the type field is analogous to the protocol field in the network-layer datagram and the port-number fields in the transport-layer segment; all of these fields serve to glue a protocol at one layer to a protocol at the layer above.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Cyclic redundancy check (CRC) (4 bytes).</span><span class="font53"> As discussed in Section 6.2.3, the purpose of the CRC field is to allow the receiving adapter, adapter B, to detect bit errors in the frame.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Preamble (8 bytes).</span><span class="font53"> The Ethernet frame begins with an 8-byte preamble field. Each of the first 7 bytes of the preamble has a value of 10101010; the last byte is 10101011. The first 7 bytes of the preamble serve to “wake up” the receiving adapters and to synchronize their clocks to that of the sender’s clock. Why should the clocks be out of synchronization? Keep in mind that adapter A aims to transmit the frame at 10 Mbps, 100 Mbps, or 1 Gbps, depending on the type of Ethernet LAN. However, because nothing is absolutely perfect, adapter A will not transmit the frame at exactly the target rate; there will always be some </span><span class="font53" style="font-style:italic;">drift </span><span class="font53">from the target rate, a drift which is not known </span><span class="font53" style="font-style:italic;">a priori</span><span class="font53"> by the other adapters on the LAN. A receiving adapter can lock onto adapter A’s clock simply by locking onto the bits in the first 7 bytes of the preamble. The last 2 bits of the eighth byte of the preamble (the first two consecutive 1s) alert adapter B that the “important stuff” is about to come.</span></p></li></ul>
<p><span class="font53">All of the Ethernet technologies provide connectionless service to the network layer. That is, when adapter A wants to send a datagram to adapter B, adapter A encapsulates the datagram in an Ethernet frame and sends the frame into the LAN, without first handshaking with adapter B. This layer-2 connectionless service is analogous to IP’s layer-3 datagram service and UDP’s layer-4 connectionless service.</span></p>
<p><span class="font53">Ethernet technologies provide an unreliable service to the network layer. Specifically, when adapter B receives a frame from adapter A, it runs the frame through a CRC check, but neither sends an acknowledgment when a frame passes the CRC check nor sends a negative acknowledgment when a frame fails the CRC check. When a frame fails the CRC check, adapter B simply discards the frame. Thus, adapter A has no idea whether its transmitted frame reached adapter B and passed the CRC check. This lack of reliable transport (at the link layer) helps to make Ethernet simple and cheap. But it also means that the stream of datagrams passed to the network layer can have gaps.</span></p>
<p><span class="font62" style="font-style:italic;">I*</span><span class="font58" style="font-weight:bold;"> <sup>CASE</sup> </span><span class="font59" style="font-weight:bold;font-variant:small-caps;">history</span></p>
<p><span class="font4" style="font-weight:bold;">BOB METCALFE AND ETHERNET</span></p>
<p><span class="font4">As a PhD student at Harvard University in the early 1970s, Bob Metcalfe worked on the ARPAnet at MIT. During his studies, he also became exposed to Abramson’s work on ALOHA and random access protocols. After completing his PhD and just before beginning a job at Xerox Palo Alto Research Center (Xerox PARC), he visited Abramson and his University of Hawaii colleagues for three months, getting a firsthand look at ALOHAnet. At Xerox PARC, Metcalfe became exposed to Alto computers, which in many ways were the forerunners of the personal computers of the 1980s. Metcalfe saw the need to network these computers in an inexpensive manner. So armed with his knowledge about ARPAnet, ALOHAnet, and random access protocols, Metcalfe—along with colleague David Boggs—invented Ethernet.</span></p>
<p><span class="font4">Metcalfe and Boggs’s original Ethernet ran at 2.94 Mbps and linked up to 256 hosts separated by up to one mile. Metcalfe and Boggs succeeded at getting most of the researchers at Xerox PARC to communicate through their Alto computers. Metcalfe then forged an alliance between Xerox, Digital, and Intel to establish Ethernet as a 10 Mbps Ethernet standard, ratified by the IEEE. Xerox did not show much interest in commercializing Ethernet. In 1979, Metcalfe formed his own company, 3Com, which developed and commercialized networking technology, including Ethernet technology. In particular, 3Com developed and marketed Ethernet cards in the early 1980s for the immensely popular IBM PCs.</span></p>
<p><span class="font53">If there are gaps due to discarded Ethernet frames, does the application at Host B see gaps as well? As we learned in Chapter 3, this depends on whether the application is using UDP or TCP. If the application is using UDP, then the application in Host B will indeed see gaps in the data. On the other hand, if the application is using TCP, then TCP in Host B will not acknowledge the data contained in discarded frames, causing TCP in Host A to retransmit. Note that when TCP retransmits data, the data will eventually return to the Ethernet adapter at which it was discarded. Thus, in this sense, Ethernet does retransmit data, although Ethernet is unaware of whether it is transmitting a brand-new datagram with brand-new data, or a datagram that contains data that has already been transmitted at least once.</span></p>
<p><span class="font22" style="font-weight:bold;">Ethernet Technologies</span></p>
<p><span class="font53">In our discussion above, we’ve referred to Ethernet as if it were a single protocol standard. But in fact, Ethernet comes in </span><span class="font53" style="font-style:italic;">many</span><span class="font53"> different flavors, with somewhat bewildering acronyms such as 10BASE-T, 10BASE-2, 100BASE-T, 1000BASE-LX, 10GBASE-T and 40GBASE-T. These and many other Ethernet technologies have been standardized over the years by the IEEE 802.3 CSMA/CD (Ethernet) working group [IEEE 802.3 2020]. While these acronyms may appear bewildering, there is actually considerable order here. The first part of the acronym refers to the speed of the standard: 10, 100, 1000, or 10G, for 10 Megabit (per second), 100 Megabit, Gigabit, 10 Gigabit and 40 Gigibit Ethernet, respectively. “BASE” refers to baseband Ethernet, meaning that the physical media only carries Ethernet traffic; almost all of the 802.3 standards are for baseband Ethernet. The final part of the acronym refers to the physical media itself; Ethernet is both a link-layer </span><span class="font53" style="font-style:italic;">and</span><span class="font53"> a physical-layer specification and is carried over a variety of physical media including coaxial cable, copper wire, and fiber. Generally, a “T” refers to twisted-pair copper wires.</span></p>
<p><span class="font53">Historically, an Ethernet was initially conceived of as a segment of coaxial cable. The early 10BASE-2 and 10BASE-5 standards specify 10 Mbps Ethernet over two types of coaxial cable, each limited in length to 500 meters. Longer runs could be obtained by using a </span><span class="font53" style="font-weight:bold;">repeater—</span><span class="font53">a physical-layer device that receives a signal on the input side, and regenerates the signal on the output side. A coaxial cable corresponds nicely to our view of Ethernet as a broadcast medium—all frames transmitted by one interface are received at other interfaces, and Ethernet’s CDMA/CD protocol nicely solves the multiple access problem. Nodes simply attach to the cable, and </span><span class="font53" style="font-style:italic;">voila,</span><span class="font53"> we have a local area network!</span></p>
<p><span class="font53">Ethernet has passed through a series of evolutionary steps over the years, and today’s Ethernet is very different from the original bus-topology designs using coaxial cable. In most installations today, nodes are connected to a switch via point-to-point segments made of twisted-pair copper wires or fiber-optic cables, as shown in Figures 6.15-6.17.</span></p>
<p><span class="font53">In the mid-1990s, Ethernet was standardized at 100 Mbps, 10 times faster than 10 Mbps Ethernet. The original Ethernet MAC protocol and frame format were preserved, but higher-speed physical layers were defined for copper wire (100BASE-T) and fiber (100BASE-FX, 100BASE-SX, 100BASE-BX). Figure 6.21 shows these different standards and the common Ethernet MAC protocol and frame format. 100 Mbps Ethernet is limited to a 100-meter distance over twisted pair, and to</span></p>
<div><img src="networking_files/networking-460.jpg" alt="" style="width:56pt;height:72pt;">
</div><br clear="all">
<div>
<p><span class="font4">MAC protocol and frame format</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font4">100BASE-TX</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">100BASE-T2</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">100BASE-FX</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font4">100BASE-T4</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">100BASE-SX</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">100BASE-BX</span></p></td></tr>
</table>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 6.21 </span><span class="font50">♦ </span><span class="font5">100 Mbps Ethernet standards: A common link layer, different physical layers </span><span class="font53">several kilometers over fiber, allowing Ethernet switches in different buildings to be connected.</span></p>
<p><span class="font53">Gigabit Ethernet is an extension to the highly successful 10 Mbps and 100 Mbps Ethernet standards. Offering a raw data rate of 40,000 Mbps, 40 Gigabit Ethernet maintains full compatibility with the huge installed base of Ethernet equipment. The standard for Gigabit Ethernet, referred to as IEEE 802.3z, does the following:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;Uses the standard Ethernet frame format (Figure 6.20) and is backward compatible with 10BASE-T and 100BASE-T technologies. This allows for easy integration of Gigabit Ethernet with the existing installed base of Ethernet equipment.</span></p></li>
<li>
<p><span class="font53">• &nbsp;Allows for point-to-point links as well as shared broadcast channels. Point-to-point links use switches while broadcast channels use hubs, as described earlier. In Gigabit Ethernet jargon, hubs are called </span><span class="font53" style="font-style:italic;">buffered distributors.</span></p></li>
<li>
<p><span class="font53">• &nbsp;Uses CSMA/CD for shared broadcast channels. In order to have acceptable efficiency, the maximum distance between nodes must be severely restricted.</span></p></li>
<li>
<p><span class="font53">• &nbsp;Allows for full-duplex operation at 40 Gbps in both directions for point-to-point channels.</span></p></li></ul>
<p><span class="font53">Initially operating over optical fiber, Gigabit Ethernet is now able to run over category 5 UTP cabling (for 1000BASE-T and 10GBASE-T).</span></p>
<p><span class="font53">Let’s conclude our discussion of Ethernet technology by posing a question that may have begun troubling you. In the days of bus topologies and hub-based star topologies, Ethernet was clearly a broadcast link (as defined in Section 6.3) in which frame collisions occurred when nodes transmitted at the same time. To deal with these collisions, the Ethernet standard included the CSMA/CD protocol, which is particularly effective for a wired broadcast LAN spanning a small geographical region. But if the prevalent use of Ethernet today is a switch-based star topology, using store-and-forward packet switching, is there really a need anymore for an Ethernet MAC protocol? As we’ll see shortly, a switch coordinates its transmissions and never forwards more than one frame onto the same interface at any time. Furthermore, modern switches are full-duplex, so that a switch and a node can each send frames to each other at the same time without interference. In other words, in a switch-based Ethernet LAN there are no collisions and, therefore, there is no need for a MAC protocol!</span></p>
<p><span class="font53">As we’ve seen, today’s Ethernets are </span><span class="font53" style="font-style:italic;">very</span><span class="font53"> different from the original Ethernet conceived by Metcalfe and Boggs more than 40 years ago—speeds have increased by three orders of magnitude, Ethernet frames are carried over a variety of media, switched-Ethernets have become dominant, and now even the MAC protocol is often unnecessary! Is all of this </span><span class="font53" style="font-style:italic;">really</span><span class="font53"> still Ethernet? The answer, of course, is “yes, by definition.” It is interesting to note, however, that through all of these changes, there has indeed been one enduring constant that has remained unchanged over 30 years— Ethernet’s frame format. Perhaps this then is the one true and timeless centerpiece of the Ethernet standard.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">6.4.3 </span><span class="font23" style="font-weight:bold;">Link-Layer Switches</span></p></li></ul>
<p><span class="font53">Up until this point, we have been purposefully vague about what a switch actually does and how it works. The role of the switch is to receive incoming link-layer frames and forward them onto outgoing links; we’ll study this forwarding function in detail in this subsection. We’ll see that the switch itself is </span><span class="font53" style="font-weight:bold;">transparent </span><span class="font53">to the hosts and routers in the subnet; that is, a host/router addresses a frame to another host/router (rather than addressing the frame to the switch) and happily sends the frame into the LAN, unaware that a switch will be receiving the frame and forwarding it. The rate at which frames arrive to any one of the switch’s output interfaces may temporarily exceed the link capacity of that interface. To accommodate this problem, switch output interfaces have buffers, in much the same way that router output interfaces have buffers for datagrams. Let’s now take a closer look at how switches operate.</span></p>
<p><span class="font22" style="font-weight:bold;">Forwarding and Filtering</span></p>
<p><span class="font53" style="font-weight:bold;">Filtering </span><span class="font53">is the switch function that determines whether a frame should be forwarded to some interface or should just be dropped. </span><span class="font53" style="font-weight:bold;">Forwarding </span><span class="font53">is the switch function that determines the interfaces to which a frame should be directed, and then moves the frame to those interfaces. Switch filtering and forwarding are done with a </span><span class="font53" style="font-weight:bold;">switch table</span><span class="font53">. The switch table contains entries for some, but not necessarily all, of the hosts and routers on a LAN. An entry in the switch table contains (1) a MAC address, (2) the switch interface that leads toward that MAC address, and (3) the time at which the entry was placed in the table. An example switch table for the uppermost switch in Figure 6.15 is shown in Figure 6.22. This description of frame forwarding may sound similar to our discussion of datagram forwarding</span></p>
<table border="1">
<tr><td>
<p><span class="font6">Address</span></p></td><td>
<p><span class="font6">Interface</span></p></td><td>
<p><span class="font6">Time</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">62-FE-F7-11-89-A3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">9:32</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">7C-BA-B2-B4-91-10</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">9:36</span></p></td></tr>
<tr><td colspan="3" style="vertical-align:bottom;">
<p><span class="font6">.... &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.... &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;....</span></p></td></tr>
</table>
<p><a name="bookmark405"></a><span class="font7" style="font-weight:bold;">Figure 6.22 </span><span class="font50">♦ </span><span class="font5">Portion of a switch table for the uppermost switch in Figure 6.15 </span><span class="font53">in Chapter 4. Indeed, in our discussion of generalized forwarding in Section 4.4, we learned that many modern packet switches can be configured to forward on the basis of layer-2 destination MAC addresses (i.e., function as a layer-2 switch) or layer-3 IP destination addresses (i.e., function as a layer-3 router). Nonetheless, we’ll make the important distinction that switches forward packets based on MAC addresses rather than on IP addresses. We will also see that a traditional (i.e., in a non-SDN context) switch table is constructed in a very different manner from a router’s forwarding table.</span></p>
<p><span class="font53">To understand how switch filtering and forwarding work, suppose a frame with destination address DD-DD-DD-DD-DD-DD arrives at the switch on interface </span><span class="font53" style="font-style:italic;">x. </span><span class="font53">The switch indexes its table with the MAC address DD-DD-DD-DD-DD-DD. There are three possible cases:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;There is no entry in the table for DD-DD-DD-DD-DD-DD. In this case, the switch forwards copies of the frame to the output buffers preceding </span><span class="font53" style="font-style:italic;">all</span><span class="font53"> interfaces except for interface </span><span class="font53" style="font-style:italic;">x</span><span class="font53">. In other words, if there is no entry for the destination address, the switch broadcasts the frame.</span></p></li>
<li>
<p><span class="font53">• &nbsp;There is an entry in the table, associating DD-DD-DD-DD-DD-DD with interface </span><span class="font53" style="font-style:italic;">x</span><span class="font53">. In this case, the frame is coming from a LAN segment that contains adapter DD-DD-DD-DD-DD-DD. There being no need to forward the frame to any of the other interfaces, the switch performs the filtering function by discarding the frame.</span></p></li>
<li>
<p><span class="font53">• &nbsp;There is an entry in the table, associating DD-DD-DD-DD-DD-DD with interface </span><span class="font53" style="font-style:italic;">y</span><span class="font54"> # </span><span class="font53" style="font-style:italic;">x</span><span class="font53">. In this case, the frame needs to be forwarded to the LAN segment attached to interface </span><span class="font53" style="font-style:italic;">y</span><span class="font53">. The switch performs its forwarding function by putting the frame in an output buffer that precedes interface </span><span class="font53" style="font-style:italic;">y</span><span class="font53">.</span></p></li></ul>
<p><span class="font53">Let’s walk through these rules for the uppermost switch in Figure 6.15 and its switch table in Figure 6.22. Suppose that a frame with destination address 62-FE-F7-11-89-A3 arrives at the switch from interface 1. The switch examines its table and sees that the destination is on the LAN segment connected to interface 1 (that is, Electrical Engineering). This means that the frame has already been broadcast on the LAN segment that contains the destination. The switch therefore filters (that is, discards) the frame. Now suppose a frame with the same destination address arrives from interface 2. The switch again examines its table and sees that the destination is in the direction of interface 1; it therefore forwards the frame to the output buffer preceding interface 1. It should be clear from this example that as long as the switch table is complete and accurate, the switch forwards frames toward destinations without any broadcasting.</span></p>
<p><span class="font53">In this sense, a switch is “smarter” than a hub. But how does this switch table get configured in the first place? Are there link-layer equivalents to network-layer routing protocols? Or must an overworked manager manually configure the switch table?</span></p>
<p><span class="font22" style="font-weight:bold;">Self-Learning</span></p>
<p><span class="font53">A switch has the wonderful property (particularly for the already-overworked network administrator) that its table is built automatically, dynamically, and autonomously— without any intervention from a network administrator or from a configuration protocol. In other words, switches are </span><span class="font53" style="font-weight:bold;">self-learning</span><span class="font53">. This capability is accomplished as follows:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">1. The switch table is initially empty.</span></p></li>
<li>
<p><span class="font53">2. For each incoming frame received on an interface, the switch stores in its table (1) the MAC address in the frame’s </span><span class="font53" style="font-style:italic;">source address field,</span><span class="font53"> (2) the interface from which the frame arrived, and (3) the current time. In this manner, the switch records in its table the LAN segment on which the sender resides. If every host in the LAN eventually sends a frame, then every host will eventually get recorded in the table.</span></p></li>
<li>
<p><span class="font53">3. The switch deletes an address in the table if no frames are received with that address as the source address after some period of time (the </span><span class="font53" style="font-weight:bold;">aging time</span><span class="font53">). In this manner, if a PC is replaced by another PC (with a different adapter), the MAC address of the original PC will eventually be purged from the switch table.</span></p></li></ul>
<p><span class="font53">Let’s walk through the self-learning property for the uppermost switch in Figure 6.15 and its corresponding switch table in Figure 6.22. Suppose at time 9:39 a frame with source address 01-12-23-34-45-56 arrives from interface 2. Suppose that this address is not in the switch table. Then the switch adds a new entry to the table, as shown in Figure 6.23.</span></p>
<p><span class="font53">Continuing with this same example, suppose that the aging time for this switch is 60 minutes, and no frames with source address 62-FE-F7-11-89-A3 arrive to the switch between 9:32 and 10:32. Then at time 10:32, the switch removes this address from its table.</span></p>
<table border="1">
<tr><td>
<p><span class="font6">Address</span></p></td><td>
<p><span class="font6">Interface</span></p></td><td>
<p><span class="font6">Time</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">01-12-23-34-45-56</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">9:39</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">62-FE-F7-11-89-A3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">9:32</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">7C-BA-B2-B4-91-10</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">9:36</span></p></td></tr>
</table>
<p><span class="font7" style="font-weight:bold;">Figure 6.23 </span><span class="font50">♦ </span><span class="font5">Switch learns about the location of an adapter with address 01-12-23-34-45-56</span></p>
<p><span class="font53">Switches are </span><span class="font53" style="font-weight:bold;">plug-and-play devices </span><span class="font53">because they require no intervention from a network administrator or user. A network administrator wanting to install a switch need do nothing more than connect the LAN segments to the switch interfaces. The administrator need not configure the switch tables at the time of installation or when a host is removed from one of the LAN segments. Switches are also full-duplex, meaning any switch interface can send and receive at the same time.</span></p>
<p><span class="font22" style="font-weight:bold;">Properties of Link-Layer Switching</span></p>
<p><span class="font53">Having described the basic operation of a link-layer switch, let’s now consider their features and properties. We can identify several advantages of using switches, rather than broadcast links such as buses or hub-based star topologies:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Elimination of collisions.</span><span class="font53"> In a LAN built from switches (and without hubs), there is no wasted bandwidth due to collisions! The switches buffer frames and never transmit more than one frame on a segment at any one time. As with a router, the maximum aggregate throughput of a switch is the sum of all the switch interface rates. Thus, switches provide a significant performance improvement over LANs with broadcast links.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Heterogeneous links.</span><span class="font53"> Because a switch isolates one link from another, the different links in the LAN can operate at different speeds and can run over different media. For example, the uppermost switch in Figure 6.15 might have three1 Gbps 1000BASE-T copper links, two 100 Mbps 100BASE-FX fiber links, and one 100BASE-T copper link. Thus, a switch is ideal for mixing legacy equipment with new equipment.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Management.</span><span class="font53"> In addition to providing enhanced security (see sidebar on Focus on Security), a switch also eases network management. For example, if an adapter malfunctions and continually sends Ethernet frames (called a jabbering adapter), a switch can detect the problem and internally disconnect the malfunctioning adapter. With this feature, the network administrator need not get out of bed and drive back to work in order to correct the problem. Similarly, a cable cut disconnects only that host that was using the cut cable to connect to the switch. In the days of coaxial cable, many a network manager spent hours “walking the line” (or more accurately, “crawling the floor”) to find the cable break that brought down the entire network. Switches also gather statistics on bandwidth usage, collision rates, and traffic types, and make this information available to the network manager. This information can be used to debug and correct problems, and to plan how the LAN should evolve in the future. Researchers are exploring adding yet more management functionality into Ethernet LANs in prototype deployments [Casado 2007; Koponen 2011].</span></p>
<div><img src="networking_files/networking-461.jpg" alt="" style="width:168pt;height:23pt;">
</div><br clear="all">
<div>
<p><span class="font23" style="font-weight:bold;">FOCUS ON SECURITY</span></p>
</div><br clear="all"></li></ul>
<p><span class="font4" style="font-weight:bold;">SNIFFING A SWITCHED LAN: SWITCH POISONING</span></p>
<p><span class="font4">When a host is connected to a switch, it typically only receives frames that are intended for it. For example, consider a switched LAN in Figure 6.17. When host A sends a frame to host B, and there is an entry for host B in the switch table, then the switch will forward the frame </span><span class="font4" style="font-style:italic;">only</span><span class="font4"> to host B. If host C happens to be running a sniffer, host C will not be able to sniff this A-to-B frame. Thus, in a switched-LAN environment (in contrast to a broadcast link environment such as 802.11 LANs or hub-based Ethernet LANs), it is more difficult for an attacker to sniff frames. </span><span class="font4" style="font-style:italic;">However, </span><span class="font4">because the switch broadcasts frames that have destination addresses that are not in the switch table, the sniffer at C can still sniff some frames that are not intended for C. Furthermore, a sniffer will be able sniff all Ethernet broadcast frames with broadcast destination address FF-FF-FF-FF-FF-FF. A well-known attack against a switch, called </span><span class="font5" style="font-weight:bold;">switch poisoning</span><span class="font4">, is to send tons of packets to the switch with many different bogus source MAC addresses, thereby filling the switch table with bogus entries and leaving no room for the MAC addresses of the legitimate hosts. This causes the switch to broadcast most frames, which can then be picked up by the sniffer [Skoudis 2006]. As this attack is rather involved even for a sophisticated attacker, switches are significantly less vulnerable to sniffing than are hubs and wireless LANs.</span></p>
<p><span class="font22" style="font-weight:bold;">Switches Versus Routers</span></p>
<p><span class="font53">As we learned in Chapter 4, routers are store-and-forward packet switches that forward packets using network-layer addresses. Although a switch is also a store-and-forward packet switch, it is fundamentally different from a router in that it forwards packets using MAC addresses. Whereas a router is a layer-3 packet switch, a switch is a layer-2 packet switch. Recall, however, that we learned in Section 4.4 that modern switches using the “match plus action” operation can be used to forward a layer-2 frame based on the frame's destination MAC address, as well as a layer-3 datagram using the datagram's destination IP address. Indeed, we saw that switches using the OpenFlow standard can perform generalized packet forwarding based on any of eleven different frame, datagram, and transport-layer header fields.</span></p>
<p><span class="font53">Even though switches and routers are fundamentally different, network administrators must often choose between them when installing an interconnection device. For example, for the network in Figure 6.15, the network administrator could just as easily have used a router instead of a switch to connect the department LANs, servers, and internet gateway router. Indeed, a router would permit interdepartmental communication without creating collisions. Given that both switches and routers are candidates for interconnection devices, what are the pros and cons of the two approaches?</span></p>
<p><span class="font4">Host</span></p>
<p><span class="font4">Host</span></p><img src="networking_files/networking-462.jpg" alt="" style="width:333pt;height:116pt;">
<p><span class="font7" style="font-weight:bold;">Figure 6.24 </span><span class="font50">♦ </span><span class="font5">Packet processing in switches, routers, and hosts</span></p>
<p><span class="font53">First consider the pros and cons of switches. As mentioned above, switches are plug-and-play, a property that is cherished by all the overworked network administrators of the world. Switches can also have relatively high filtering and forwarding rates—as shown in Figure 6.24, switches have to process frames only up through layer 2, whereas routers have to process datagrams up through layer 3. On the other hand, to prevent the cycling of broadcast frames, the active topology of a switched network is restricted to a spanning tree. Also, a large switched network would require large ARP tables in the hosts and routers and would generate substantial ARP traffic and processing. Furthermore, switches are susceptible to broadcast storms—if one host goes haywire and transmits an endless stream of Ethernet broadcast frames, the switches will forward all of these frames, causing the entire network to collapse.</span></p>
<p><span class="font53">Now consider the pros and cons of routers. Because network addressing is often hierarchical (and not flat, as is MAC addressing), packets do not normally cycle through routers even when the network has redundant paths. (However, packets can cycle when router tables are misconfigured; but as we learned in Chapter 4, IP uses a special datagram header field to limit the cycling.) Thus, packets are not restricted to a spanning tree and can use the best path between source and destination. Because routers do not have the spanning tree restriction, they have allowed the Internet to be built with a rich topology that includes, for example, multiple active links between Europe and North America. Another feature of routers is that they provide firewall protection against layer-2 broadcast storms. Perhaps the most significant drawback of routers, though, is that they are not plug-and-play—they and the hosts that connect to them need their IP addresses to be configured. Also, routers often have a larger per-packet processing time than switches, because they have to process up through the layer-3 fields. Finally, there are two different ways to pronounce the word </span><span class="font53" style="font-style:italic;">router, </span><span class="font53">either as “rootor” or as “rowter,” and people waste a lot of time arguing over the proper pronunciation [Perlman 1999].</span></p>
<p><span class="font53">Given that both switches and routers have their pros and cons (as summarized in Table 6.1), when should an institutional network (for example, a university campus</span></p>
<table border="1">
<tr><td></td><td style="vertical-align:bottom;">
<p><span class="font6">Hubs</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Routers</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Switches</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Traffic isolation</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">No</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Yes</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Yes</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Plug and play</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Yes</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">No</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Yes</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Optimal routing</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">No</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Yes</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">No</span></p></td></tr>
</table>
<p><span class="font7" style="font-weight:bold;">Table 6.1 </span><span class="font50">♦ </span><span class="font5">Comparison of the typical features of popular interconnection devices</span></p>
<p><span class="font53">network or a corporate campus network) use switches, and when should it use routers? Typically, small networks consisting of a few hundred hosts have a few LAN segments. Switches suffice for these small networks, as they localize traffic and increase aggregate throughput without requiring any configuration of IP addresses. But larger networks consisting of thousands of hosts typically include routers within the network (in addition to switches). The routers provide a more robust isolation of traffic, control broadcast storms, and use more “intelligent” routes among the hosts in the network.</span></p>
<p><span class="font53">For more discussion of the pros and cons of switched versus routed networks, as well as a discussion of how switched LAN technology can be extended to accommodate two orders of magnitude more hosts than today’s Ethernets, see [Meyers 2004; Kim 2008].</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">6.4.4 </span><span class="font23" style="font-weight:bold;">Virtual Local Area Networks (VLANs)</span></p></li></ul>
<p><span class="font53">In our earlier discussion of Figure 6.15, we noted that modern institutional LANs are often configured hierarchically, with each workgroup (department) having its own switched LAN connected to the switched LANs of other groups via a switch hierarchy. While such a configuration works well in an ideal world, the real world is often far from ideal. Three drawbacks can be identified in the configuration in Figure 6.15:</span></p>
<p><a name="bookmark406"></a><span class="font53">• </span><span class="font53" style="font-style:italic;">Lack of traffic isolation.</span><span class="font53"> Although the hierarchy localizes group traffic to within a single switch, broadcast traffic (e.g., frames carrying ARP and DHCP messages or frames whose destination has not yet been learned by a self-learning switch) must still traverse the entire institutional network. Limiting the scope of such broadcast traffic would improve LAN performance. Perhaps more importantly, it also may be desirable to limit LAN broadcast traffic for security/privacy reasons. For example, if one group contains the company’s executive management team and another group contains disgruntled employees running Wireshark packet sniffers, the network manager may well prefer that the executives’ traffic never even reaches employee hosts. This type of isolation could be provided by replacing the center switch in Figure 6.15 with a router. We’ll see shortly that this isolation also can be achieved via a switched (layer 2) solution.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Inefficient use of switches.</span><span class="font53"> If instead of three groups, the institution had 10 groups, then 10 first-level switches would be required. If each group were small, say less than 10 people, then a single 96-port switch would likely be large enough to accommodate everyone, but this single switch would not provide traffic isolation.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Managing users.</span><span class="font53"> If an employee moves between groups, the physical cabling must be changed to connect the employee to a different switch in Figure 6.15. Employees belonging to two groups make the problem even harder.</span></p></li></ul>
<p><span class="font53">Fortunately, each of these difficulties can be handled by a switch that supports </span><span class="font53" style="font-weight:bold;">virtual local area networks </span><span class="font53">(</span><span class="font53" style="font-weight:bold;">VLANs</span><span class="font53">). As the name suggests, a switch that supports VLANs allows multiple </span><span class="font53" style="font-style:italic;">virtual</span><span class="font53"> local area networks to be defined over a single </span><span class="font53" style="font-style:italic;">physical</span><span class="font53"> local area network infrastructure. Hosts within a VLAN communicate with each other as if they (and no other hosts) were connected to the switch. In a port-based VLAN, the switch’s ports (interfaces) are divided into groups by the network manager. Each group constitutes a VLAN, with the ports in each VLAN forming a broadcast domain (i.e., broadcast traffic from one port can only reach other ports in the group). Figure 6.25 shows a single switch with 16 ports. Ports 2 to 8 belong to the EE VLAN, while ports 9 to 15 belong to the CS VLAN (ports 1 and 16 are unassigned). This VLAN solves all of the difficulties noted above—EE and CS VLAN frames are isolated from each other, the two switches in Figure 6.15 have been replaced by a single switch, and if the user at switch port 8 joins the CS Department, the network operator simply reconfigures the VLAN software so that port 8 is now associated with the CS VLAN. One can easily imagine how the VLAN switch is configured and operates—the network manager declares a port to belong to a given VLAN (with undeclared ports belonging to a default VLAN) using switch management software, a table of port-to-VLAN mappings is maintained within the switch; and switch hardware only delivers frames between ports belonging to the same VLAN.</span></p>
<div><img src="networking_files/networking-463.jpg" alt="" style="width:224pt;height:118pt;">
<p><span class="font4">Electrical Engineering (VLAN ports 2-8)</span></p>
<p><span class="font4">Computer Science (VLAN ports 9-15)</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 6.25 </span><span class="font50">♦ </span><span class="font5">A single switch with two configured VLANs</span></p>
</div><br clear="all">
<div>
<table border="1">
<tr><td>
<p><span class="font3">1</span></p></td><td></td><td></td><td></td><td>
<p><span class="font3">9</span></p></td><td></td><td></td><td></td><td>
<p><span class="font3">15</span></p></td><td></td></tr>
<tr><td>
<p><span class="font3">2</span></p></td><td>
<p><span class="font3">4</span></p></td><td></td><td>
<p><span class="font3">8</span></p></td><td>
<p><span class="font3">10</span></p></td><td></td><td></td><td></td><td>
<p><span class="font3">16</span></p></td><td></td></tr>
<tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr>
</table>
</div><br clear="all">
<p><span class="font53">But by completely isolating the two VLANs, we have introduced a new difficulty! How can traffic from the EE Department be sent to the CS Department? One way to handle this would be to connect a VLAN switch port (e.g., port 1 in Figure 6.25) to an external router and configure that port to belong both the EE and CS VLANs. In this case, even though the EE and CS departments share the same physical switch, the logical configuration would look as if the EE and CS departments had separate switches connected via a router. An IP datagram going from the EE to the CS department would first cross the EE VLAN to reach the router and then be forwarded by the router back over the CS VLAN to the CS host. Fortunately, switch vendors make such configurations easy for the network manager by building a single device that contains both a VLAN switch </span><span class="font53" style="font-style:italic;">and</span><span class="font53"> a router, so a separate external router is not needed. A homework problem at the end of the chapter explores this scenario in more detail.</span></p>
<p><span class="font53">Returning again to Figure 6.15, let’s now suppose that rather than having a separate Computer Engineering department, some EE and CS faculty are housed in a separate building, where (of course!) they need network access, and (of course!) they’d like to be part of their department’s VLAN. Figure 6.26 shows a second 8-port switch, where the switch ports have been defined as belonging to the EE or the CS VLAN, as needed. But how should these two switches be interconnected? One easy solution would be to define a port belonging to the CS VLAN on each switch (similarly for the EE VLAN) and to connect these ports to each other, as shown in Figure 6.26(a). This solution doesn’t scale, however, since </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> VLANS would require </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> ports on each switch simply to interconnect the two switches.</span></p>
<p><span class="font53">A more scalable approach to interconnecting VLAN switches is known as </span><span class="font53" style="font-weight:bold;">VLAN trunking</span><span class="font53">. In the VLAN trunking approach shown in Figure 6.26(b), a special port on each switch (port 16 on the left switch and port 1 on the right switch) is configured as a trunk port to interconnect the two VLAN switches. The trunk port belongs to all VLANs, and frames sent to any VLAN are forwarded over the trunk link to the other switch. But this raises yet another question: How does a switch know that a frame arriving on a trunk port belongs to a particular VLAN? The IEEE has defined an extended Ethernet frame format, 802.1Q, for frames crossing a VLAN trunk. As shown in Figure 6.27, the 802.1Q frame consists of the standard Ethernet frame with a four-byte </span><span class="font53" style="font-weight:bold;">VLAN tag </span><span class="font53">added into the header that carries the identity of the VLAN to which the frame belongs. The VLAN tag is added into a frame by the switch at the sending side of a VLAN trunk, parsed, and removed by the switch at the receiving side of the trunk. The VLAN tag itself consists of a 2-byte Tag Protocol Identifier (TPID) field (with a fixed hexadecimal value of 81-00), a 2-byte Tag Control Information field that contains a 12-bit VLAN identifier field, and a 3-bit priority field that is similar in intent to the IP datagram TOS field.</span></p>
<div>
<p><span class="font4" style="font-weight:bold;">a.</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-464.jpg" alt="" style="width:363pt;height:81pt;">
</div><br clear="all">
<div><img src="networking_files/networking-465.jpg" alt="" style="width:63pt;height:37pt;">
<p><span class="font3">1</span></p>
</div><br clear="all">
<div>
<p><span class="font3">2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;8</span></p><img src="networking_files/networking-466.jpg" alt="" style="width:114pt;height:56pt;">
</div><br clear="all">
<div>
<p><span class="font4"><sup>9</sup> . &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font3">15, </span><span class="font4">Trunk</span></p><img src="networking_files/networking-467.jpg" alt="" style="width:315pt;height:115pt;">
</div><br clear="all">
<div>
<table border="1">
<tr><td>
<p><span class="font3" style="text-decoration:underline;">1</span></p></td><td>
<p><span class="font3">3</span></p></td><td>
<p><span class="font3">5</span></p></td><td>
<p><span class="font3">7</span></p></td></tr>
<tr><td>
<p><span class="font3">2^</span></p></td><td></td><td>
<p><span class="font3">6 <sup>x</sup></span></p></td><td>
<p><span class="font3">8 &nbsp;&nbsp;&nbsp;&nbsp;'</span></p></td></tr>
</table>
</div><br clear="all">
<div>
<p><span class="font4">Electrical Engineering (VLAN ports 2-8) </span><span class="font4" style="font-weight:bold;">b.</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Computer Science (VLAN ports 9-15)</span></p>
</div><br clear="all">
<p><span class="font4">Electrical Engineering Computer Science (VLAN ports 2, 3, 6) (VLAN ports 4, 5, 7)</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 6.26 </span><span class="font50">♦ </span><span class="font5">Connecting two VLAN switches with two VLANs: (a) two cables (b) trunked</span></p>
<div><img src="networking_files/networking-468.jpg" alt="" style="width:385pt;height:62pt;">
</div><br clear="all">
<p><span class="font4">Type</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font4">Preamble</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Dest. address</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Source address</span></p></td><td></td><td style="vertical-align:middle;">
<p><span class="font4">Data</span></p></td><td></td><td></td><td style="vertical-align:middle;">
<p><span class="font4">CRC</span></p></td></tr>
<tr><td colspan="3" style="vertical-align:bottom;">
<p><span class="font4">1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1</span></p></td><td colspan="5" style="vertical-align:bottom;">
<p><span class="font50">X.</span></p></td></tr>
</table>
<p><span class="font53">In this discussion, we’ve only briefly touched on VLANs and have focused on portbased VLANs. We should also mention that VLANs can be defined in several other ways. In MAC-based VLANs, the network manager specifies the set of MAC addresses that belong to each VLAN; whenever a device attaches to a port, the port is connected into the appropriate VLAN based on the MAC address of the device. VLANs can also be defined based on network-layer protocols (e.g., IPv4, IPv6, or Appletalk) and other criteria. It is also possible for VLANs to be extended across IP routers, allowing islands of LANs to be connected together to form a single VLAN that could span the globe [Yu 2011]. See the 802.1Q standard [IEEE 802.1q 2005] for more details.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">6.5 </span><span class="font24" style="font-weight:bold;">Link Virtualization: A Network as a Link Layer</span></p></li></ul>
<p><span class="font53">Because this chapter concerns link-layer protocols, and given that we’re now nearing the chapter’s end, let’s reflect on how our understanding of the term </span><span class="font53" style="font-style:italic;">link</span><span class="font53"> has evolved. We began this chapter by viewing the link as a physical wire connecting two communicating hosts. In studying multiple access protocols, we saw that multiple hosts could be connected by a shared wire and that the “wire” connecting the hosts could be radio spectra or other media. This led us to consider the link a bit more abstractly as a channel, rather than as a wire. In our study of Ethernet LANs (Figure 6.15), we saw that the interconnecting media could actually be a rather complex switched infrastructure. Throughout this evolution, however, the hosts themselves maintained the view that the interconnecting medium was simply a link-layer channel connecting two or more hosts. We saw, for example, that an Ethernet host can be blissfully unaware of whether it is connected to other LAN hosts by a single short LAN segment (Figure 6.17) or by a geographically dispersed switched LAN (Figure 6.15) or by a VLAN (Figure 6.26).</span></p>
<p><span class="font53">In the case of a dialup modem connection between two hosts, the link connecting the two hosts is actually the telephone network—a logically separate, global telecommunications network with its own switches, links, and protocol stacks for data transfer and signaling. From the Internet link-layer point of view, however, the dial-up connection through the telephone network is viewed as a simple “wire.” In this sense, the Internet virtualizes the telephone network, viewing the telephone network as a link-layer technology providing link-layer connectivity between two Internet hosts. You may recall from our discussion of overlay networks in Chapter 2 that an overlay network similarly views the Internet as a means for providing connectivity between overlay nodes, seeking to overlay the Internet in the same way that the Internet overlays the telephone network.</span></p>
<p><a name="bookmark407"></a><span class="font53">In this section, we’ll consider Multiprotocol Label Switching (MPLS) networks. Unlike the circuit-switched telephone network, MPLS is a packet-switched,</span></p>
<p><span class="font53">virtual-circuit network in its own right. It has its own packet formats and forwarding behaviors. Thus, from a pedagogical viewpoint, a discussion of MPLS fits well into a study of either the network layer or the link layer. From an Internet viewpoint, however, we can consider MPLS, like the telephone network and switched-Ethernets, as a link-layer technology that serves to interconnect IP devices. Thus, we’ll consider MPLS in our discussion of the link layer. Frame-relay and ATM networks can also be used to interconnect IP devices, though they represent a slightly older (but still deployed) technology and will not be covered here; see the very readable book [Goralski 1999] for details. Our treatment of MPLS will be necessarily brief, as entire books could be (and have been) written on these networks. We recommend [Davie 2000] for details on MPLS. We’ll focus here primarily on how MPLS servers interconnect to IP devices, although we’ll dive a bit deeper into the underlying technologies as well.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">6.5.1 </span><span class="font23" style="font-weight:bold;">Multiprotocol Label Switching (MPLS)</span></p></li></ul>
<p><span class="font53">Multiprotocol Label Switching (MPLS) evolved from a number of industry efforts in the mid-to-late 1990s to improve the forwarding speed of IP routers by adopting a key concept from the world of virtual-circuit networks: a fixed-length label. The goal was not to abandon the destination-based IP datagram-forwarding infrastructure for one based on fixed-length labels and virtual circuits, but to augment it by selectively labeling datagrams and allowing routers to forward datagrams based on fixed-length labels (rather than destination IP addresses) when possible. Importantly, these techniques work hand-in-hand with IP, using IP addressing and routing. The IETF unified these efforts in the MPLS protocol [RFC 3031, RFC 3032], effectively blending VC techniques into a routed datagram network.</span></p>
<p><span class="font53">Let’s begin our study of MPLS by considering the format of a link-layer frame that is handled by an MPLS-capable router. Figure 6.28 shows that a link-layer frame transmitted between MPLS-capable devices has a small MPLS header added between the layer-2 (e.g., Ethernet) header and layer-3 (i.e., IP) header. RFC 3032 defines the format of the MPLS header for such links; headers are defined for ATM and frame-relayed networks as well in other RFCs. Among the fields in the MPLS</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font4">PPP or Ethernet header</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">MPLS header</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">IP header</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Remainder of link-layer frame</span></p></td></tr>
</table>
<p><span class="font4">Label &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Exp S TTL</span></p>
<p><a name="bookmark408"></a><span class="font7" style="font-weight:bold;">Figure 6.28 </span><span class="font50">♦ </span><span class="font5">MPLS header: Located between link- and network-layer headers</span></p>
<p><span class="font53">header are the label, 3 bits reserved for experimental use, a single S bit, which is used to indicate the end of a series of “stacked” MPLS headers (an advanced topic that we’ll not cover here), and a time-to-live field.</span></p>
<p><span class="font53">It’s immediately evident from Figure 6.28 that an MPLS-enhanced frame can only be sent between routers that are both MPLS capable (since a non-MPLS-capable router would be quite confused when it found an MPLS header where it had expected to find the IP header!). An MPLS-capable router is often referred to as a </span><span class="font53" style="font-weight:bold;">label-switched router</span><span class="font53">, since it forwards an MPLS frame by looking up the MPLS label in its forwarding table and then immediately passing the datagram to the appropriate output interface. Thus, the MPLS-capable router need </span><span class="font53" style="font-style:italic;">not</span><span class="font53"> extract the destination IP address and perform a lookup of the longest prefix match in the forwarding table. But how does a router know if its neighbor is indeed MPLS capable, and how does a router know what label to associate with the given IP destination? To answer these questions, we’ll need to take a look at the interaction among a group of MPLS-capable routers.</span></p>
<p><span class="font53">In the example in Figure 6.29, routers R1 through R4 are MPLS capable. R5 and R6 are standard IP routers. R1 has advertised to R2 and R3 that it (R1) can route to destination A, and that a received frame with MPLS label 6 will be forwarded to destination A. Router R3 has advertised to router R4 that it can route to destinations A and D, and that incoming frames with MPLS labels 10 and 12, respectively, will be switched toward those destinations. Router R2 has also advertised to router R4 that it (R2) can reach destination A, and that a received frame with MPLS label 8 will be switched toward A. Note that router R4 is now in the interesting position of having two MPLS</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font4">in label</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">out label</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">dest</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">out interface</span></p></td></tr>
<tr><td></td><td style="vertical-align:bottom;">
<p><span class="font4">10</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">A</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0</span></p></td></tr>
<tr><td></td><td>
<p><span class="font4">12</span></p></td><td>
<p><span class="font4">D</span></p></td><td>
<p><span class="font4">0</span></p></td></tr>
<tr><td></td><td>
<p><span class="font4">8</span></p></td><td>
<p><span class="font4">A</span></p></td><td>
<p><span class="font4">1</span></p></td></tr>
</table>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font4">in label</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">out label</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">dest</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">out interface</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">10</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">6</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">A</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1</span></p></td></tr>
<tr><td>
<p><span class="font4">12</span></p></td><td>
<p><span class="font4">9</span></p></td><td>
<p><span class="font4">D</span></p></td><td>
<p><span class="font4">0</span></p></td></tr>
</table>
<div><img src="networking_files/networking-469.jpg" alt="" style="width:336pt;height:126pt;">
<p><span class="font7" style="font-weight:bold;">Figure 6.29 </span><span class="font50">♦ </span><span class="font5">MPLS-enhanced forwarding</span></p>
</div><br clear="all">
<p><span class="font53">paths to reach A: via interface 0 with outbound MPLS label 10, and via interface 1 with an MPLS label of 8. The broad picture painted in Figure 6.29 is that IP devices R5, R6, A, and D are connected together via an MPLS infrastructure (MPLS-capable routers R1, R2, R3, and R4) in much the same way that a switched LAN or an ATM network can connect together IP devices. And like a switched LAN or ATM network, the MPLS-capable routers R1 through R4 do so </span><span class="font53" style="font-style:italic;">without ever touching the IP header of a packet.</span></p>
<p><span class="font53">In our discussion above, we’ve not specified the specific protocol used to distribute labels among the MPLS-capable routers, as the details of this signaling are well beyond the scope of this book. We note, however, that the IETF working group on MPLS has specified in [RFC 3468] that an extension of the RSVP protocol, known as RSVP-TE [RFC 3209], will be the focus of its efforts for MPLS signaling. We’ve also not discussed how MPLS actually computes the paths for packets among MPLS capable routers, nor how it gathers link-state information (e.g., amount of link bandwidth unreserved by MPLS) to use in these path computations. Existing link-state routing algorithms (e.g., OSPF) have been extended to flood this information to MPLS-capable routers. Interestingly, the actual path computation algorithms are not standardized, and are currently vendor-specific.</span></p>
<p><span class="font53">Thus far, the emphasis of our discussion of MPLS has been on the fact that MPLS performs switching based on labels, without needing to consider the IP address of a packet. The true advantages of MPLS and the reason for current interest in MPLS, however, lie not in the potential increases in switching speeds, but rather in the new traffic management capabilities that MPLS enables. As noted above, R4 has </span><span class="font53" style="font-style:italic;">two</span><span class="font53"> MPLS paths to A. If forwarding were performed up at the IP layer on the basis of IP address, the IP routing protocols we studied in Chapter 5 would specify only a single, least-cost path to A. Thus, MPLS provides the ability to forward packets along routes that would not be possible using standard IP routing protocols. This is one simple form of </span><span class="font53" style="font-weight:bold;">traffic engineering </span><span class="font53">using MPLS [RFC 3346; RFC 3272; RFC 2702; Xiao 2000], in which a network operator can override normal IP routing and force some of the traffic headed toward a given destination along one path, and other traffic destined toward the same destination along another path (whether for policy, performance, or some other reason).</span></p>
<p><span class="font53">It is also possible to use MPLS for many other purposes as well. It can be used to perform fast restoration of MPLS forwarding paths, e.g., to reroute traffic over a precomputed failover path in response to link failure [Kar 2000; Huang 2002; RFC 3469]. Finally, we note that MPLS can, and has, been used to implement so-called </span><span class="font53" style="font-weight:bold;">virtual private networks </span><span class="font53">(VPNs). In implementing a VPN for a customer, an ISP uses its MPLS-enabled network to connect together the customer’s various networks. MPLS can be used to isolate both the resources and addressing used by the customer’s VPN from that of other users crossing the ISP’s network; see [DeClercq 2002] for details.</span></p>
<p><span class="font53">Our discussion of MPLS has been brief, and we encourage you to consult the references we’ve mentioned. We note that MPLS rose to prominence before the development of software-defined networking, which we studied in Chapter 5, and that many of MPLS’ traffic engineering capabilities can also be achieved via SDN and the generalized forwarding paradigm we studied in Chapter 4. Only the future will tell whether MPLS and SDN will continue to co-exist, or whether newer technologies (such as SDN) will eventually replace MPLS.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">6.6 </span><span class="font24" style="font-weight:bold;">Data Center Networking</span></p></li></ul>
<p><span class="font53">Internet companies such as Google, Microsoft, Amazon, and Alibaba have built massive data centers, each housing tens to hundreds of thousands of hosts. As briefly discussed in the sidebar in Section 1.2, data centers are not only connected to the Internet, but also internally include complex computer networks, called </span><span class="font53" style="font-weight:bold;">data center networks</span><span class="font53">, which interconnect their internal hosts. In this section, we provide a brief introduction to data center networking for cloud applications.</span></p>
<p><span class="font53">Broadly speaking, data centers serve three purposes. First, they provide content such as Web pages, search results, e-mail, or streaming video to users. Second, they serve as massively-parallel computing infrastructures for specific data processing tasks, such as distributed index computations for search engines. Third, they provide </span><span class="font53" style="font-weight:bold;">cloud computing </span><span class="font53">to other companies. Indeed, today a major trend in computing is for companies to use a cloud provider such as Amazon Web Services, Microsoft Azure, and Alibaba Cloud to handle essentially </span><span class="font53" style="font-style:italic;">all</span><span class="font53"> of their IT needs.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">6.6.1 </span><span class="font23" style="font-weight:bold;">Data Center Architectures</span></p></li></ul>
<p><span class="font53">Data center designs are carefully kept company secrets, as they often provide critical competitive advantages to leading cloud computing companies. The cost of a large data center is huge, exceeding $12 million per month for a 100,000 host data center in 2009 [Greenberg 2009a]. Of these costs, about 45 percent can be attributed to the hosts themselves (which need to be replaced every 3-4 years); 25 percent to infrastructure, including transformers, uninterruptable power supplies (UPS) systems, generators for long-term outages, and cooling systems; 15 percent for electric utility costs for the power draw; and 15 percent for networking, including network gear (switches, routers, and load balancers), external links, and transit traffic costs. (In these percentages, costs for equipment are amortized so that a common cost metric is applied for one-time purchases and ongoing expenses such as power.) While networking is not the largest cost, networking innovation is the key to reducing overall cost and maximizing performance [Greenberg 2009a].</span></p>
<p><a name="bookmark409"></a><span class="font53">The worker bees in a data center are the hosts. The hosts in data centers, called </span><span class="font53" style="font-weight:bold;">blades </span><span class="font53">and resembling pizza boxes, are generally commodity hosts that include CPU, memory, and disk storage. The hosts are stacked in racks, with each rack typically having 20 to 40 blades. At the top of each rack, there is a switch, aptly named the </span><span class="font53" style="font-weight:bold;">Top of Rack (TOR) switch</span><span class="font53">, that interconnects the hosts in the rack with each other and with other switches in the data center. Specifically, each host in the rack has a network interface that connects to its TOR switch, and each TOR switch has additional ports that can be connected to other switches. Today, hosts typically have 40 Gbps or 100 Gbps Ethernet connections to their TOR switches [FB 2019; Greenberg 2015; Roy 2015; Singh 2015]. Each host is also assigned its own data-centerinternal IP address.</span></p>
<p><span class="font4">Internet</span></p>
<p><span class="font4">Tier-2 switches</span></p>
<p><span class="font4">Access router</span></p>
<p><span class="font4">Load balancer</span></p><img src="networking_files/networking-470.jpg" alt="" style="width:377pt;height:216pt;">
<p><span class="font4">Tier-1 switches</span></p>
<p><span class="font4">TOR switches</span></p>
<p><span class="font4">Server racks</span></p>
<p><span class="font4">1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3 &nbsp;&nbsp;&nbsp;&nbsp;4 &nbsp;&nbsp;&nbsp;&nbsp;5 &nbsp;&nbsp;&nbsp;&nbsp;6 &nbsp;&nbsp;&nbsp;&nbsp;7 &nbsp;&nbsp;&nbsp;&nbsp;8</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 6.30 </span><span class="font50">♦ </span><span class="font5">A data center network with a hierarchical topology</span></p>
<p><span class="font53">The data center network supports two types of traffic: traffic flowing between external clients and internal hosts and traffic flowing between internal hosts. To handle flows between external clients and internal hosts, the data center network includes one or more </span><span class="font53" style="font-weight:bold;">border routers</span><span class="font53">, connecting the data center network to the public Internet. The data center network therefore interconnects the racks with each other and connects the racks to the border routers. Figure 6.30 shows an example of a data center network. </span><span class="font53" style="font-weight:bold;">Data center network design</span><span class="font53">, the art of designing the interconnection network and protocols that connect the racks with each other and with the border routers, has become an important branch of computer networking research in recent years. (See references in this section.)</span></p>
<p><span class="font22" style="font-weight:bold;">Load Balancing</span></p>
<p><span class="font53">A cloud data center, such as one operated by Google, Microsoft, Amazon, and Alibaba, provides many applications concurrently, such as search, e-mail, and video applications. To support requests from external clients, each application is associated with a publicly visible IP address to which clients send their requests and from which they receive responses. Inside the data center, the external requests are first directed to a load balancer whose job it is to distribute requests to the hosts, balancing the load across the hosts as a function of their current load [Patel 2013; Eisenbud 2016]. A large data center will often have several load balancers, each one devoted to a set of specific cloud applications. Such a load balancer is sometimes referred to as a “layer-4 switch” since it makes decisions based on the destination port number (layer 4) as well as destination IP address in the packet. Upon receiving a request for a particular application, the load balancer forwards it to one of the hosts that handles the application. (A host may then invoke the services of other hosts to help process the request.) The load balancer not only balances the work load across hosts, but also provides a NAT-like function, translating the public external IP address to the internal IP address of the appropriate host, and then translating back for packets traveling in the reverse direction back to the clients. This prevents clients from contacting hosts directly, which has the security benefit of hiding the internal network structure and preventing clients from directly interacting with the hosts.</span></p>
<p><span class="font22" style="font-weight:bold;">Hierarchical Architecture</span></p>
<p><span class="font53">For a small data center housing only a few thousand hosts, a simple network consisting of a border router, a load balancer, and a few tens of racks all interconnected by a single Ethernet switch could possibly suffice. But to scale to tens to hundreds of thousands of hosts, a data center often employs a hierarchy of routers and switches, such as the topology shown in Figure 6.30. At the top of the hierarchy, the border router connects to access routers (only two are shown in Figure 6.30, but there can be many more). Below each access router, there are three tiers of switches. Each access router connects to a top-tier switch, and each top-tier switch connects to multiple second-tier switches and a load balancer. Each second-tier switch in turn connects to multiple racks via the racks’ TOR switches (third-tier switches). All links typically use Ethernet for their link-layer and physical-layer protocols, with a mix of copper and fiber cabling. With such a hierarchical design, it is possible to scale a data center to hundreds of thousands of hosts.</span></p>
<p><span class="font53">Because it is critical for a cloud application provider to continually provide applications with high availability, data centers also include redundant network equipment and redundant links in their designs (not shown in Figure 6.30). For example, each TOR switch can connect to two tier-2 switches, and each access router, tier-1 switch, and tier-2 switch can be duplicated and integrated into the design [Cisco 2012; Greenberg 2009b]. In the hierarchical design in Figure 6.30, observe that the hosts below each access router form a single subnet. In order to localize ARP broadcast traffic, each of these subnets is further partitioned into smaller VLAN subnets, each comprising a few hundred hosts [Greenberg 2009a].</span></p>
<p><span class="font53">Although the conventional hierarchical architecture just described solves the problem of scale, it suffers from limited host-to-host capacity [Greenberg 2009b]. To understand this limitation, consider again Figure 6.30, and suppose each host connects to its TOR switch with a 10 Gbps link, whereas the links between switches are 100 Gbps Ethernet links. Two hosts in the same rack can always communicate at a full 10 Gbps, limited only by the rate of the hosts’ network interface controllers. However, if there are many simultaneous flows in the data center network, the maximum rate between two hosts in different racks can be much less. To gain insight into this issue, consider a traffic pattern consisting of 40 simultaneous flows between 40 pairs of hosts in different racks. Specifically, suppose each of 10 hosts in rack 1 in Figure 6.30 sends a flow to a corresponding host in rack 5. Similarly, there are ten simultaneous flows between pairs of hosts in racks 2 and 6, ten simultaneous flows between racks 3 and 7, and ten simultaneous flows between racks 4 and 8. If each flow evenly shares a link’s capacity with other flows traversing that link, then the 40 flows crossing the 100 Gbps A-to-B link (as well as the 100 Gbps B-to-C link) will each only receive 100 Gbps / 40 </span><span class="font55">= </span><span class="font53">2.5 Gbps, which is significantly less than the 10 Gbps network interface rate. The problem becomes even more acute for flows between hosts that need to travel higher up the hierarchy.</span></p>
<p><span class="font53">There are several possible solutions to this problem:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;One possible solution to this limitation is to deploy higher-rate switches and routers. But this would significantly increase the cost of the data center, because switches and routers with high port speeds are very expensive.</span></p></li>
<li>
<p><span class="font53">• &nbsp;A second solution to this problem, which can be adopted whenever possible, is to co-locate related services and data as close to one another as possible (e.g., in the same rack or in a nearby rack) [Roy 2015; Singh 2015] in order to minimize inter-rack communication via tier-2 or tier-1 switches. But this can only go so far, as a key requirement in data centers is flexibility in placement of computation and services [Greenberg 2009b; Farrington 2010]. For example, a large-scale Internet search engine may run on thousands of hosts spread across multiple racks with significant bandwidth requirements between all pairs of hosts. Similarly, a cloud computing service (such Amazon Web Services or Microsoft Azure) may wish to place the multiple virtual machines comprising a customer’s service on the physical hosts with the most capacity irrespective of their location in the data center. If these physical hosts are spread across multiple racks, network bottlenecks as described above may result in poor performance.</span></p></li>
<li>
<p><span class="font53">• &nbsp;A final piece of the solution is to provide increased connectivity between the TOR switches and tier-2 switches, and between tier-2 switches and tier-1 switches. For example, as shown in Figure 6.31, each TOR switch could be connected to two tier-2 switches, which then provide for multiple link- and switch-disjoint paths between racks. In Figure 6.31, there are four distinct paths between the first tier-2 switch and the second tier-2 switch, together providing an aggregate capacity of 400 Gbps between the first two tier-2 switches. Increasing the degree of connectivity between tiers has two significant benefits: there is both increased capacity and increased reliability (because of path diversity) between switches. In Facebook’s data center [FB 2014; FB 2019], each TOR is connected to four different tier-2 switches, and each tier-2 switch is connected to four different tier-1 switches.</span></p></li></ul><img src="networking_files/networking-471.jpg" alt="" style="width:430pt;height:140pt;">
<p><span class="font7" style="font-weight:bold;">Figure 6.31 </span><span class="font50">♦ </span><span class="font5">Highly interconnected data network topology</span></p>
<p><span class="font53">A direct consequence of the increased connectivity between tiers in data center networks is that multi-path routing can become a first-class citizen in these networks. Flows are by default multipath flows. A very simple scheme to achieve multi-path routing is Equal Cost Multi Path (ECMP) [RFC 2992], which performs a randomized next-hop selection along the switches between source and destination. Advanced schemes using finer-grained load balancing have also been proposed [Alizadeh 2014; Noormohammadpour 2018]. While these schemes perform multi-path routing at the flow level, there are also designs that route individual packets within a flow among multiple paths [He 2015; Raiciu 2010].</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">6.6.2 </span><span class="font23" style="font-weight:bold;">Trends in Data Center Networking</span></p></li></ul>
<p><span class="font53">Data center networking is evolving rapidly, with the trends being driven by cost reduction, virtualization, physical constraints, modularity, and customization.</span></p>
<p><span class="font22" style="font-weight:bold;">Cost Reduction</span></p>
<p><span class="font53">In order to reduce the cost of data centers, and at the same time improve their delay and throughput performance, as well as ease of expansion and deployment, Internet cloud giants are continually deploying new data center network designs. Although some of these designs are proprietary, others (e.g., [FB 2019]) are explicitly open or described in the open literature (e.g., [Greenberg 2009b; Singh 2015]). Many important trends can thus be identified.</span></p>
<p><a name="bookmark410"></a><span class="font53">Figure 6.31 illustrates one of the most important trends in data center networking—the emergence of a hierarchical, tiered network interconnecting the data center hosts. This hierarchy conceptually serves the same purpose as a single (very, very!), large crossbar switch that we studied in Section 4.2.2, allowing any host in the data center to communicate with any other host. But as we have seen, this tiered interconnection network has many advantages over a conceptual crossbar switch, including multiple paths from source to destination and the increased capacity (due to multipath routing) and reliability (due to multiple switch- and link-disjoint paths between any two hosts).</span></p>
<p><span class="font53">The data center interconnection network is comprised of a large number of smallsized switches. For example, in Google’s Jupiter datacenter fabric, one configuration has 48 links between the ToR switch and its servers below, and connections up to 8 tier-2 switches; a tier-2 switch has links to 256 ToR switches and links up to 16 tier-1 switches [Singh 2015]. In Facebook’s data center architecture, each ToR switch connects up to four different tier-2 switches (each in a different “spline plane”), and each tier-2 switch connects up to 4 of the 48 tier-1 switches in its spline plane; there are four spline planes. Tier-1 and tier-2 switches connect down to a larger, scalable number of tier-2 or ToR switches, respectively, below [FB 2019]. For some of the largest data center operators, these switches are being built in-house from commodity, off-the-shelf, merchant silicon [Greenberg 2009b; Roy 2015; Singh 2015] rather than being purchased from switch vendors.</span></p>
<p><span class="font53">A multi-switch layered (tiered, multistage) interconnection network such as that in Figure 6.31 and as implemented in the data center architectures discussed above is known as Clos networks, named after Charles Clos, who studied such networks [Clos 1953] in the context of telephony switching. Since then, a rich theory of Clos networks has been developed, finding additional use in data center networking and in multiprocessor interconnection networks.</span></p>
<p><span class="font22" style="font-weight:bold;">Centralized SDN Control and Management</span></p>
<p><span class="font53">Because a data center is managed by a single organization, it is perhaps natural that a number of the largest data center operators, including Google, Microsoft, and Facebook, are embracing the notion of SDN-like logically centralized control. Their architectures also reflect a clear separation of a data plane (comprised of relatively simple, commodity switches) and a software-based control plane, as we saw in Section 5.5. Due to the immense-scale of their data centers, automated configuration and operational state management, as we encountered in Section 5.7, are also crucial.</span></p>
<p><span class="font22" style="font-weight:bold;">Virtualization</span></p>
<p><span class="font53">Virtualization has been a driving force for much of the growth of cloud computing and data center networks more generally. Virtual Machines (VMs) decouple software running applications from the physical hardware. This decoupling also allows seamless migration of VMs between physical servers, which might be located on different racks. Standard Ethernet and IP protocols have limitations in enabling the movement of VMs while maintaining active network connections across servers. Since all data center networks are managed by a single administrative authority, an elegant solution to the problem is to treat the entire data center network as a single, flat, layer-2 network. Recall that in a typical Ethernet network, the ARP protocol maintains the binding between the IP address and hardware (MAC) address on an interface. To emulate the effect of having all hosts connect to a “single” switch, the ARP mechanism is modified to use a DNS style query system instead of a broadcast, and the directory maintains a mapping of the IP address assigned to a VM and which physical switch the VM is currently connected to in the data center network. Scalable schemes that implement this basic design have been proposed in [Mysore 2009; Greenberg 2009b] and have been successfully deployed in modern data centers.</span></p>
<p><span class="font22" style="font-weight:bold;">Physical Constraints</span></p>
<p><span class="font53">Unlike the wide area Internet, data center networks operate in environments that not only have very high capacity (40 Gbps and 100 Gbps links are now commonplace) but also have extremely low delays (microseconds). Consequently, buffer sizes are small and congestion control protocols such as TCP and its variants do not scale well in data centers. In data centers, congestion control protocols have to react fast and operate in extremely low loss regimes, as loss recovery and timeouts can lead to extreme inefficiency. Several approaches to tackle this issue have been proposed and deployed, ranging from data center-specific TCP variants [Alizadeh 2010] to implementing Remote Direct Memory Access (RDMA) technologies on standard Ethernet [Zhu 2015; Moshref 2016; Guo 2016]. Scheduling theory has also been applied to develop mechanisms that decouple flow scheduling from rate control, enabling very simple congestion control protocols while maintaining high utilization of the links [Alizadeh 2013; Hong 2012].</span></p>
<p><span class="font22" style="font-weight:bold;">Hardware Modularity and Customization</span></p>
<p><span class="font53">Another major trend is to employ shipping container-based modular data centers (MDCs) [YouTube 2009; Waldrop 2007]. In an MDC, a factory builds, within a standard 12-meter shipping container, a “mini data center” and ships the container to the data center location. Each container has up to a few thousand hosts, stacked in tens of racks, which are packed closely together. At the data center location, multiple containers are interconnected with each other and also with the Internet. Once a prefabricated container is deployed at a data center, it is often difficult to service. Thus, each container is designed for graceful performance degradation: as components (servers and switches) fail over time, the container continues to operate but with degraded performance. When many components have failed and performance has dropped below a threshold, the entire container is removed and replaced with a fresh one.</span></p>
<p><span class="font53">Building a data center out of containers creates new networking challenges. With an MDC, there are two types of networks: the container-internal networks within each of the containers and the core network connecting each container [Guo 2009; Farrington 2010]. Within each container, at the scale of up to a few thousand hosts, it is possible to build a fully connected network using inexpensive commodity Gigabit Ethernet switches. However, the design of the core network, interconnecting hundreds to thousands of containers while providing high host-to-host bandwidth across containers for typical workloads, remains a challenging problem. A hybrid electrical/optical switch architecture for interconnecting the containers is described in [Farrington 2010].</span></p>
<p><span class="font53">Another important trend is that large cloud providers are increasingly building or customizing just about everything that is in their data centers, including network adapters, switches routers, TORs, software, and networking protocols [Greenberg 2015; Singh 2015]. Another trend, pioneered by Amazon, is to improve reliability with “availability zones,” which essentially replicate distinct data centers in different nearby buildings. By having the buildings nearby (a few kilometers apart), transactional data can be synchronized across the data centers in the same availability zone while providing fault tolerance [Amazon 2014]. Many more innovations in data center design are likely to continue to come.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">6.7 </span><span class="font24" style="font-weight:bold;">Retrospective: A Day in the Life of a Web Page Request</span></p></li></ul>
<p><span class="font53">Now that we’ve covered the link layer in this chapter, and the network, transport and application layers in earlier chapters, our journey down the protocol stack is complete! In the very beginning of this book (Section 1.1), we wrote “much of this book is concerned with computer network protocols,” and in the first five chapters, we’ve certainly seen that this is indeed the case! Before heading into the topical chapters in second part of this book, we’d like to wrap up our journey down the protocol stack by taking an integrated, holistic view of the protocols we’ve learned about so far. One way then to take this “big picture” view is to identify the many (many!) protocols that are involved in satisfying even the simplest request: downloading a Web page. Figure 6.32 illustrates our setting: a student, Bob, connects a laptop to his school’s Ethernet switch and downloads a Web page (say the home page of </span><a href="http://www.google.com"><span class="font53">www.google.com</span></a><span class="font53">). As we now know, there’s a </span><span class="font53" style="font-style:italic;">lot</span><span class="font53"> going on “under the hood” to satisfy this seemingly simple request. A Wireshark lab at the end of this chapter examines trace files containing a number of the packets involved in similar scenarios in more detail.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">6.7.1 </span><span class="font23" style="font-weight:bold;">Getting Started: DHCP, UDP, IP, and Ethernet</span></p></li></ul>
<p><span class="font53">Let’s suppose that Bob boots up his laptop and then connects it to an Ethernet cable connected to the school’s Ethernet switch, which in turn is connected to the school’s router, as shown in Figure 6.32. The school’s router is connected to an ISP, in this example, </span><a href="http://comcast.net"><span class="font53">comcast.net.</span></a><span class="font53"> In this example,</span><a href="http://comcast.net"><span class="font53"> comcast.net </span></a><span class="font53">is providing the DNS service for the school; thus, the DNS server resides in the Comcast network rather than the school network. We’ll assume that the DHCP server is running within the router, as is often the case.</span></p>
<p><a name="bookmark411"></a><span class="font53">When Bob first connects his laptop to the network, he can’t do anything (e.g., download a Web page) without an IP address. Thus, the first network-related</span></p>
<div>
<p><span class="font4" style="font-weight:bold;">School network 68.80.2.0/24</span></p>
<p><a href="http://comcast.net"><span class="font4">comcast.net</span></a><span class="font4"> DNS server 68.87.71.226</span></p>
<p><span class="font4">00:16:D3:23:68:8A</span></p>
<p><span class="font4">68.85.2.101</span></p>
<p><span class="font4" style="font-weight:bold;">Comcast’s network 68.80.0.0/13</span></p><img src="networking_files/networking-472.jpg" alt="" style="width:306pt;height:211pt;">
<p><span class="font3">14-17</span></p>
<p><a href="http://www.google.com"><span class="font4">www.google.com</span></a></p>
<p><span class="font4">Web server 64.233.169.105</span></p>
<p><span class="font4">00:22:6B:45:1F:1B</span></p>
<p><span class="font4">68.85.2.1</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 6.32 </span><span class="font50">♦ </span><span class="font5">A day in the life of a Web page request: Network setting and actions</span></p>
</div><br clear="all">
<p><span class="font4" style="font-weight:bold;">Google’s network 64.233.160.0/19</span></p>
<p><span class="font53">action taken by Bob’s laptop is to run the DHCP protocol to obtain an IP address, as well as other information, from the local DHCP server:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">1. The operating system on Bob’s laptop creates a </span><span class="font53" style="font-weight:bold;">DHCP request message </span><span class="font53">(Section 4.3.3) and puts this message within a </span><span class="font53" style="font-weight:bold;">UDP segment </span><span class="font53">(Section 3.3) with destination port 67 (DHCP server) and source port 68 (DHCP client). The UDP segment is then placed within an </span><span class="font53" style="font-weight:bold;">IP datagram </span><span class="font53">(Section 4.3.1) with a broadcast IP destination address (255.255.255.255) and a source IP address of 0.0.0.0, since Bob’s laptop doesn’t yet have an IP address.</span></p></li>
<li>
<p><span class="font53">2. The IP datagram containing the DHCP request message is then placed within an </span><span class="font53" style="font-weight:bold;">Ethernet frame </span><span class="font53">(Section 6.4.2). The Ethernet frame has a destination MAC addresses of FF:FF:FF:FF:FF:FF so that the frame will be broadcast to all devices connected to the switch (hopefully including a DHCP server); the frame’s source MAC address is that of Bob’s laptop, 00:16:D3:23:68:8A.</span></p></li>
<li>
<p><span class="font53">3. The broadcast Ethernet frame containing the DHCP request is the first frame sent by Bob’s laptop to the Ethernet switch. The switch broadcasts the incoming frame on all outgoing ports, including the port connected to the router.</span></p></li>
<li>
<p><span class="font53">4. The router receives the broadcast Ethernet frame containing the DHCP request on its interface with MAC address 00:22:6B:45:1F:1B and the IP datagram</span></p></li></ul>
<p><span class="font53">is extracted from the Ethernet frame. The datagram’s broadcast IP destination address indicates that this IP datagram should be processed by upper layer protocols at this node, so the datagram’s payload (a UDP segment) is thus </span><span class="font53" style="font-weight:bold;">demultiplexed </span><span class="font53">(Section 3.2) up to UDP, and the DHCP request message is extracted from the UDP segment. The DHCP server now has the DHCP request message.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">5. Let’s suppose that the DHCP server running within the router can allocate IP addresses in the </span><span class="font53" style="font-weight:bold;">CIDR </span><span class="font53">(Section 4.3.3) block 68.85.2.0/24. In this example, all IP addresses used within the school are thus within Comcast’s address block. Let’s suppose the DHCP server allocates address 68.85.2.101 to Bob’s laptop. The DHCP server creates a </span><span class="font53" style="font-weight:bold;">DHCP ACK message </span><span class="font53">(Section 4.3.3) containing this IP address, as well as the IP address of the DNS server (68.87.71.226), the IP address for the default gateway router (68.85.2.1), and the subnet block (68.85.2.0/24) (equivalently, the “network mask”). The DHCP message is put inside a UDP segment, which is put inside an IP datagram, which is put inside an Ethernet frame. The Ethernet frame has a source MAC address of the router’s interface to the home network (00:22:6B:45:1F:1B) and a destination MAC address of Bob’s laptop (00:16:D3:23:68:8A).</span></p></li>
<li>
<p><span class="font53">6. The Ethernet frame containing the DHCP ACK is sent (unicast) by the router to the switch. Because the switch is </span><span class="font53" style="font-weight:bold;">self-learning </span><span class="font53">(Section 6.4.3) and previously received an Ethernet frame (containing the DHCP request) from Bob’s laptop, the switch knows to forward a frame addressed to 00:16:D3:23:68:8A only to the output port leading to Bob’s laptop.</span></p></li>
<li>
<p><span class="font53">7. Bob’s laptop receives the Ethernet frame containing the DHCP ACK, extracts the IP datagram from the Ethernet frame, extracts the UDP segment from the IP datagram, and extracts the DHCP ACK message from the UDP segment. Bob’s DHCP client then records its IP address and the IP address of its DNS server. It also installs the address of the default gateway into its </span><span class="font53" style="font-weight:bold;">IP forwarding table </span><span class="font53">(Section 4.1). Bob’s laptop will send all datagrams with destination address outside of its subnet 68.85.2.0/24 to the default gateway. At this point, Bob’s laptop has initialized its networking components and is ready to begin processing the Web page fetch. (Note that only the last two DHCP steps of the four presented in Chapter 4 are actually necessary.)</span></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">6.7.2 </span><span class="font23" style="font-weight:bold;">Still Getting Started: DNS and ARP</span></p></li></ul>
<p><a name="bookmark412"></a><span class="font53">When Bob types the URL for </span><a href="http://www.google.com"><span class="font53">www.google.com</span></a><span class="font53"> into his Web browser, he begins the long chain of events that will eventually result in Google’s home page being displayed by his Web browser. Bob’s Web browser begins the process by creating a </span><span class="font53" style="font-weight:bold;">TCP socket </span><span class="font53">(Section 2.7) that will be used to send the </span><span class="font53" style="font-weight:bold;">HTTP request </span><span class="font53">(Section 2.2) to </span><a href="http://www.google.com"><span class="font53">www.google.com</span></a><span class="font53">. In order to create the socket, Bob’s laptop will need to know the IP address of </span><a href="http://www.google.com"><span class="font53">www.google.com</span></a><span class="font53">. We learned in Section 2.5, that the </span><span class="font53" style="font-weight:bold;">DNS protocol </span><span class="font53">is used to provide this name-to-IP-address translation service.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">8. The operating system on Bob’s laptop thus creates a </span><span class="font53" style="font-weight:bold;">DNS query message </span><span class="font53">(Section 2.5.3), putting the string “</span><a href="http://www.google.com"><span class="font53">www.google.com”</span></a><span class="font53"> in the question section of the DNS message. This DNS message is then placed within a UDP segment with a destination port of 53 (DNS server). The UDP segment is then placed within an IP datagram with an IP destination address of 68.87.71.226 (the address of the DNS server returned in the DHCP ACK in step 5) and a source IP address of 68.85.2.101.</span></p></li>
<li>
<p><span class="font53">9. Bob’s laptop then places the datagram containing the DNS query message in an Ethernet frame. This frame will be sent (addressed, at the link layer) to the gateway router in Bob’s school’s network. However, even though Bob’s laptop knows the IP address of the school’s gateway router (68.85.2.1) via the DHCP ACK message in step 5 above, it doesn’t know the gateway router’s MAC address. In order to obtain the MAC address of the gateway router, Bob’s laptop will need to use the </span><span class="font53" style="font-weight:bold;">ARP protocol </span><span class="font53">(Section 6.4.1).</span></p></li>
<li>
<p><span class="font53">10. Bob’s laptop creates an </span><span class="font53" style="font-weight:bold;">ARP query </span><span class="font53">message with a target IP address of 68.85.2.1 (the default gateway), places the ARP message within an Ethernet frame with a broadcast destination address (FF:FF:FF:FF:FF:FF) and sends the Ethernet frame to the switch, which delivers the frame to all connected devices, including the gateway router.</span></p></li>
<li>
<p><span class="font53">11. The gateway router receives the frame containing the ARP query message on the interface to the school network, and finds that the target IP address of 68.85.2.1 in the ARP message matches the IP address of its interface. The gateway router thus prepares an </span><span class="font53" style="font-weight:bold;">ARP reply</span><span class="font53">, indicating that its MAC address of 00:22:6B:45:1F:1B corresponds to IP address 68.85.2.1. It places the ARP reply message in an Ethernet frame, with a destination address of 00:16:D3:23:68:8A (Bob’s laptop) and sends the frame to the switch, which delivers the frame to Bob’s laptop.</span></p></li>
<li>
<p><span class="font53">12. Bob’s laptop receives the frame containing the ARP reply message and extracts the MAC address of the gateway router (00:22:6B:45:1F:1B) from the ARP reply message.</span></p></li>
<li>
<p><span class="font53">13. Bob’s laptop can now </span><span class="font53" style="font-style:italic;">(finally!)</span><span class="font53"> address the Ethernet frame containing the DNS query to the gateway router’s MAC address. Note that the IP datagram in this frame has an IP destination address of 68.87.71.226 (the DNS server), while the frame has a destination address of 00:22:6B:45:1F:1B (the gateway router). Bob’s laptop sends this frame to the switch, which delivers the frame to the gateway router.</span></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">6.7.3 </span><span class="font23" style="font-weight:bold;">Still Getting Started: Intra-Domain Routing to the DNS Server</span></p></li></ul>
<ul style="list-style:none;"><li>
<p><a name="bookmark413"></a><span class="font53">14. The gateway router receives the frame and extracts the IP datagram containing the DNS query. The router looks up the destination address of this datagram (68.87.71.226) and determines from its forwarding table that the datagram should be sent to the leftmost router in the Comcast network in Figure 6.32. The IP datagram is placed inside a link-layer frame appropriate for the link connecting the school’s router to the leftmost Comcast router and the frame is sent over this link.</span></p></li>
<li>
<p><span class="font53">15. The leftmost router in the Comcast network receives the frame, extracts the IP datagram, examines the datagram’s destination address (68.87.71.226) and determines the outgoing interface on which to forward the datagram toward the DNS server from its forwarding table, which has been filled in by Comcast’s intra-domain protocol (such as </span><span class="font53" style="font-weight:bold;">RIP</span><span class="font53">, </span><span class="font53" style="font-weight:bold;">OSPF </span><span class="font53">or </span><span class="font53" style="font-weight:bold;">IS-IS</span><span class="font53">, Section 5.3) as well as the </span><span class="font53" style="font-weight:bold;">Internet’s inter-domain protocol</span><span class="font53">, </span><span class="font53" style="font-weight:bold;">BGP </span><span class="font53">(Section 5.4).</span></p></li>
<li>
<p><span class="font53">16. Eventually the IP datagram containing the DNS query arrives at the DNS server. The DNS server extracts the DNS query message, looks up the name </span><a href="http://www.google.com"><span class="font53">www.google.com</span></a><span class="font53"> in its DNS database (Section 2.5), and finds the </span><span class="font53" style="font-weight:bold;">DNS resource record </span><span class="font53">that contains the IP address (64.233.169.105) for </span><a href="http://www.google.com"><span class="font53">www.google.com.</span></a><span class="font53"> (assuming that it is currently cached in the DNS server). Recall that this cached data originated in the </span><span class="font53" style="font-weight:bold;">authoritative DNS server </span><span class="font53">(Section 2.5.2) for</span><a href="http://google.com"><span class="font53"> google.com</span></a><span class="font53">. The DNS server forms a </span><span class="font53" style="font-weight:bold;">DNS reply message </span><span class="font53">containing this hostname-to-IP-address mapping, and places the DNS reply message in a UDP segment, and the segment within an IP datagram addressed to Bob’s laptop (68.85.2.101). This datagram will be forwarded back through the Comcast network to the school’s router and from there, via the Ethernet switch to Bob’s laptop.</span></p></li>
<li>
<p><span class="font53">17. Bob’s laptop extracts the IP address of the server </span><a href="http://www.google.com"><span class="font53">www.google.com</span></a><span class="font53"> from the DNS message. </span><span class="font53" style="font-style:italic;">Finally,</span><span class="font53"> after a </span><span class="font53" style="font-style:italic;">lot</span><span class="font53"> of work, Bob’s laptop is now ready to contact the </span><a href="http://www.google.com"><span class="font53">www.google.com</span></a><span class="font53"> server!</span></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">6.7.4 </span><span class="font23" style="font-weight:bold;">Web Client-Server Interaction: TCP and HTTP</span></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font53">18. Now that Bob’s laptop has the IP address of </span><a href="http://www.google.com"><span class="font53">www.google.com</span></a><span class="font53">, it can create the </span><span class="font53" style="font-weight:bold;">TCP socket </span><span class="font53">(Section 2.7) that will be used to send the </span><span class="font53" style="font-weight:bold;">HTTP GET </span><span class="font53">message (Section 2.2.3) to </span><a href="http://www.google.com"><span class="font53">www.google.com</span></a><span class="font53">. When Bob creates the TCP socket, the TCP in Bob’s laptop must first perform a </span><span class="font53" style="font-weight:bold;">three-way handshake </span><span class="font53">(Section 3.5.6) with the TCP in </span><a href="http://www.google.com"><span class="font53">www.google.com</span></a><span class="font53">. Bob’s laptop thus first creates a </span><span class="font53" style="font-weight:bold;">TCP SYN </span><span class="font53">segment with destination port 80 (for HTTP), places the TCP segment inside an IP datagram with a destination IP address of 64.233.169.105 (</span><a href="http://www.google.com"><span class="font53">www.google.com)</span></a><span class="font53">, places the datagram inside a frame with a destination MAC address of 00:22:6B:45:1F:1B (the gateway router) and sends the frame to the switch.</span></p></li>
<li>
<p><a name="bookmark414"></a><span class="font53">19. The routers in the school network, Comcast’s network, and Google’s network forward the datagram containing the TCP SYN toward </span><a href="http://www.google.com"><span class="font53">www.google.com,</span></a><span class="font53"> using the forwarding table in each router, as in steps 14-16 above. Recall that the router forwarding table entries governing forwarding of packets over the inter-domain link between the Comcast and Google networks are determined by the </span><span class="font53" style="font-weight:bold;">BGP </span><span class="font53">protocol (Chapter 5).</span></p></li>
<li>
<p><span class="font53">20. Eventually, the datagram containing the TCP SYN arrives at </span><a href="http://www.google.com"><span class="font53">www.google.com</span></a><span class="font53">.</span></p></li></ul>
<p><span class="font53">The TCP SYN message is extracted from the datagram and demultiplexed to the welcome socket associated with port 80. A connection socket (Section 2.7) is created for the TCP connection between the Google HTTP server and Bob’s laptop. A TCP SYNACK (Section 3.5.6) segment is generated, placed inside a datagram addressed to Bob’s laptop, and finally placed inside a link-layer frame appropriate for the link connecting </span><a href="http://www.google.com"><span class="font53">www.google.com</span></a><span class="font53"> to its first-hop router.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">21. The datagram containing the TCP SYNACK segment is forwarded through the Google, Comcast, and school networks, eventually arriving at the Ethernet controller in Bob’s laptop. The datagram is demultiplexed within the operating system to the TCP socket created in step 18, which enters the connected state.</span></p></li>
<li>
<p><span class="font53">22. With the socket on Bob’s laptop now </span><span class="font53" style="font-style:italic;">(finally!)</span><span class="font53"> ready to send bytes to </span><a href="http://www.google.com"><span class="font53">www.google.com</span></a><span class="font53">, Bob’s browser creates the HTTP GET message (Section 2.2.3) containing the URL to be fetched. The HTTP GET message is then written into the socket, with the GET message becoming the payload of a TCP segment. The TCP segment is placed in a datagram and sent and delivered to </span><a href="http://www.google.com"><span class="font53">www.google.com</span></a><span class="font53"> as in steps 18-20 above.</span></p></li>
<li>
<p><span class="font53">23. The HTTP server at </span><a href="http://www.google.com"><span class="font53">www.google.com</span></a><span class="font53"> reads the HTTP GET message from the TCP socket, creates an </span><span class="font53" style="font-weight:bold;">HTTP response </span><span class="font53">message (Section 2.2), places the requested Web page content in the body of the HTTP response message, and sends the message into the TCP socket.</span></p></li>
<li>
<p><span class="font53">24. The datagram containing the HTTP reply message is forwarded through the Google, Comcast, and school networks, and arrives at Bob’s laptop. Bob’s Web browser program reads the HTTP response from the socket, extracts the html for the Web page from the body of the HTTP response, and finally </span><span class="font53" style="font-style:italic;">(finally!)</span><span class="font53"> displays the Web page!</span></p></li></ul>
<p><span class="font53">Our scenario above has covered a lot of networking ground! If you’ve understood most or all of the above example, then you’ve also covered a lot of ground since you first read Section 1.1, where we wrote “much of this book is concerned with computer network protocols” and you may have wondered what a protocol actually was! As detailed as the above example might seem, we’ve omitted a number of possible additional protocols (e.g., NAT running in the school’s gateway router, wireless access to the school’s network, security protocols for accessing the school network or encrypting segments or datagrams, network management protocols), and considerations (Web caching, the DNS hierarchy) that one would encounter in the public Internet. We’ll cover a number of these topics and more in the second part of this book.</span></p>
<p><span class="font53">Lastly, we note that our example above was an integrated and holistic, but also very “nuts and bolts,” view of many of the protocols that we’ve studied in the first part of this book. The example focused more on the “how” than the “why.” For a broader, more reflective view on the design of network protocols in general, you might want to re-read the “Architectural Principles of the Internet” in Section 4.5, and the references therein.</span></p>
<p><span class="font59" style="font-weight:bold;">6.8 </span><span class="font24" style="font-weight:bold;">Summary</span></p>
<p><span class="font53">In this chapter, we’ve examined the link layer—its services, the principles underlying its operation, and a number of important specific protocols that use these principles in implementing link-layer services.</span></p>
<p><span class="font53">We saw that the basic service of the link layer is to move a network-layer datagram from one node (host, switch, router, WiFi access point) to an adjacent node. We saw that all link-layer protocols operate by encapsulating a network-layer datagram within a link-layer frame before transmitting the frame over the link to the adjacent node. Beyond this common framing function, however, we learned that different link-layer protocols provide very different link access, delivery, and transmission services. These differences are due in part to the wide variety of link types over which link-layer protocols must operate. A simple point-to-point link has a single sender and receiver communicating over a single “wire.” A multiple access link is shared among many senders and receivers; consequently, the link-layer protocol for a multiple access channel has a protocol (its multiple access protocol) for coordinating link access. In the case of MPLS, the “link” connecting two adjacent nodes (for example, two IP routers that are adjacent in an IP sense—that they are next-hop IP routers toward some destination) may actually be a </span><span class="font53" style="font-style:italic;">network</span><span class="font53"> in and of itself. In one sense, the idea of a network being considered as a link should not seem odd. A telephone link connecting a home modem/computer to a remote modem/router, for example, is actually a path through a sophisticated and complex telephone </span><span class="font53" style="font-style:italic;">network.</span></p>
<p><a name="bookmark415"></a><span class="font53">Among the principles underlying link-layer communication, we examined errordetection and -correction techniques, multiple access protocols, link-layer addressing, virtualization (VLANs), and the construction of extended switched LANs and data center networks. Much of the focus today at the link layer is on these switched networks. In the case of error detection/correction, we examined how it is possible to add additional bits to a frame’s header in order to detect, and in some cases correct, bit-flip errors that might occur when the frame is transmitted over the link. We covered simple parity and checksumming schemes, as well as the more robust cyclic redundancy check. We then moved on to the topic of multiple access protocols. We identified and studied three broad approaches for coordinating access to a broadcast channel: channel partitioning approaches (TDM, FDM), random access approaches (the ALOHA protocols and CSMA protocols), and taking-turns approaches (polling and token passing). We studied the cable access network and found that it uses many of these multiple access methods. We saw that a consequence of having multiple nodes share a single broadcast channel was the need to provide node addresses at the link layer. We learned that link-layer addresses were quite different from network-layer addresses and that, in the case of the Internet, a special protocol (ARP—the Address Resolution Protocol) is used to translate between these two forms of addressing and studied the hugely successful Ethernet protocol in detail. We then examined how nodes sharing a broadcast channel form a LAN and how multiple LANs can be connected together to form larger LANs—all </span><span class="font53" style="font-style:italic;">without</span><span class="font53"> the intervention of network-layer routing to interconnect these local nodes. We also learned how multiple virtual LANs can be created on a single physical LAN infrastructure.</span></p>
<p><span class="font53">We ended our study of the link layer by focusing on how MPLS networks provide link-layer services when they interconnect IP routers and an overview of the network designs for today’s massive data centers. We wrapped up this chapter (and indeed the first five chapters) by identifying the many protocols that are needed to fetch a simple Web page. Having covered the link layer, </span><span class="font53" style="font-style:italic;">our journey down the protocol stack is now over!</span><span class="font53"> Certainly, the physical layer lies below the link layer, but the details of the physical layer are probably best left for another course (e.g., in communication theory, rather than computer networking). We have, however, touched upon several aspects of the physical layer in this chapter and in Chapter 1 (our discussion of physical media in Section 1.2). We’ll consider the physical layer again when we study wireless link characteristics in the next chapter.</span></p>
<p><span class="font53">Although our journey down the protocol stack is over, our study of computer networking is not yet at an end. In the following three chapters, we cover wireless networking, network security, and multimedia networking. These four topics do not fit conveniently into any one layer; indeed, each topic crosscuts many layers. Understanding these topics (billed as advanced topics in some networking texts) thus requires a firm foundation in all layers of the protocol stack—a foundation that our study of the link layer has now completed!</span></p>
<p><span class="font24" style="font-weight:bold;">Homework Problems and Questions</span></p>
<p><span class="font23" style="font-weight:bold;">Chapter 6 Review Questions</span></p>
<p><span class="font43" style="font-weight:bold;">SECTIONS 6.1-6.2</span></p>
<p><span class="font53">R1. What is framing in link layer?</span></p>
<p><span class="font53">R2. If all the links in the Internet were to provide reliable delivery service, would the TCP reliable delivery service be redundant? Why or why not?</span></p>
<p><span class="font53">R3. Name three error-detection strategies employed by link layer.</span></p>
<p><span class="font43" style="font-weight:bold;">SECTION 6.3</span></p>
<p><span class="font53">R4. Suppose two nodes start to transmit at the same time a packet of length </span><span class="font53" style="font-style:italic;">L </span><span class="font53">over a broadcast channel of rate </span><span class="font53" style="font-style:italic;">R.</span><span class="font53"> Denote the propagation delay between the two nodes as </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>prop</sub>. Will there be a collision if </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>prop</sub> </span><span class="font55">&lt;&nbsp;</span><span class="font53" style="font-style:italic;">L/R?</span><span class="font53"> Why or why not?</span></p>
<p><a name="bookmark416"></a><span class="font53">R5. In Section 6.3, we listed four desirable characteristics of a broadcast channel. Which of these characteristics does slotted ALOHA have? Which of these characteristics does token passing have?</span></p>
<p><span class="font53">R6. In CSMA/CD, after the fifth collision, what is the probability that a node chooses </span><span class="font53" style="font-style:italic;">K =</span><span class="font53"> 4? The result </span><span class="font53" style="font-style:italic;">K =</span><span class="font53"> 4 corresponds to a delay of how many seconds on a 10 Mbps Ethernet?</span></p>
<p><span class="font53">R7. While TDM and FDM assign time slots and frequencies, CDMA assigns a different code to each node. Explain the basic principle in which CDMA works.</span></p>
<p><span class="font53">R8. Why does collision occur in CSMA, if all nodes perform carrier sensing before transmission?</span></p>
<p><span class="font43" style="font-weight:bold;">SECTION 6.4</span></p>
<p><span class="font53">R9. How big is the MAC address space? The IPv4 address space? The IPv6 address space?</span></p>
<p><span class="font53">R10. Suppose nodes A, B, and C each attach to the same broadcast LAN (through their adapters). If A sends thousands of IP datagrams to B with each encapsulating frame addressed to the MAC address of B, will C’s adapter process these frames? If so, will C’s adapter pass the IP datagrams in these frames to the network layer C? How would your answers change if A sends frames with the MAC broadcast address?</span></p>
<p><span class="font53">R11. IEEE manages the MAC address space, allocating chunks of it to companies manufacturing network adapters. The first half of the bits of the addresses in these chunks are fixed, ensuring that the address space is unique. How long will a chunk last for a company manufacturing 1,000,000 network adapters per year?</span></p>
<p><span class="font53">R12. For the network in Figure 6.19, the router has two ARP modules, each with its own ARP table. Is it possible that the same MAC address appears in both tables?</span></p>
<p><span class="font53">R13. What is a hub used for?</span></p>
<p><span class="font53">R14. Consider Figure 6.15. How many subnetworks are there, in the addressing sense of Section 4.3?</span></p>
<p><span class="font53">R15. Each host and router has an ARP table in its memory. What are the contents of this table?</span></p>
<p><span class="font53">R16. The Ethernet frame begins with an 8-byte preamble field. The purpose of the first 7 bytes is to “wake up” the receiving adapters and to synchronize their clocks to that of the sender’s clock. What are the contents of the 8 bytes? What is the purpose of the last byte?</span></p>
<p><span class="font24" style="font-weight:bold;">Problems</span></p>
<p><span class="font53">P1. Suppose the information content of a packet is the bit pattern 1010 0111 0101 1001 and an even parity scheme is being used. What would the value of the field containing the parity bits be for the case of a two-dimensional parity scheme? Your answer should be such that a minimum-length checksum field is used.</span></p>
<p><span class="font53">P2. For the two-dimensional parity check matrix below, show that:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. a single-bit error that can be corrected.</span></p></li>
<li>
<p><span class="font53">b. a double-bit error that can be detected, but not corrected.</span></p></li></ul>
<p><span class="font53">0101</span></p>
<p><span class="font53">1010</span></p>
<p><span class="font53">0101</span></p>
<p><span class="font53">1010</span></p>
<p><span class="font53">P3. Suppose the information portion of a packet contains six bytes consisting of the 8-bit unsigned binary ASCII representation of string “CHKSUM”; compute the Internet checksum for this data.</span></p>
<p><span class="font53">P4. Compute the Internet checksum for each of the following:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. the binary representation of the numbers 1 through 6.</span></p></li>
<li>
<p><span class="font53">b. the ASCII representation of the letters C through H (uppercase).</span></p></li>
<li>
<p><span class="font53">c. the ASCII representation of the letters c through h (lowercase).</span></p></li></ul>
<p><span class="font53">P5. Consider the generator, G </span><span class="font54">= </span><span class="font53">1001, and suppose that D has the value 11000111010. What is the value of R?</span></p>
<p><span class="font53">P6. Rework the previous problem, but suppose that D has the value</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. 01101010101.</span></p></li>
<li>
<p><span class="font53">b. 11111010101.</span></p></li>
<li>
<p><span class="font53">c. 10001100001.</span></p></li></ul>
<p><span class="font53">P7. In this problem, we explore some of the properties of the CRC. For the generator G (</span><span class="font54">= </span><span class="font53">1001) given in Section 6.2.3, answer the following questions.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Why can it detect any single bit error in data D?</span></p></li>
<li>
<p><span class="font53">b. Can the above G detect any odd number of bit errors? Why?</span></p></li></ul>
<p><span class="font53">P8. In Section 6.3, we provided an outline of the derivation of the efficiency of slotted ALOHA. In this problem we’ll complete the derivation.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Recall that when there are </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> active nodes, the efficiency of slotted ALOHA is </span><span class="font53" style="font-style:italic;">Np(1 — p)<sup>N</sup></span><span class="font51" style="font-style:italic;"><sup>—</sup></span><span class="font53" style="font-style:italic;"><sup>1</sup>.</span><span class="font53"> Find the value of </span><span class="font53" style="font-style:italic;">p</span><span class="font53"> that maximizes this expression.</span></p></li>
<li>
<p><span class="font53">b. Using the value of </span><span class="font53" style="font-style:italic;">p</span><span class="font53"> found in (a), find the efficiency of slotted ALOHA by letting </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> approach infinity. </span><span class="font53" style="font-style:italic;">Hint:</span><span class="font53"> (1 </span><span class="font55">— </span><span class="font53" style="font-variant:small-caps;">1/</span><span class="font53" style="font-style:italic;font-variant:small-caps;">N</span><span class="font53" style="font-variant:small-caps;">)</span><span class="font11" style="font-style:italic;font-variant:small-caps;"><sup>n</sup></span><span class="font53"> approaches </span><span class="font53" style="font-style:italic;">1/e</span><span class="font53"> as </span><span class="font53" style="font-style:italic;">N </span><span class="font53">approaches infinity.</span></p></li></ul>
<p><span class="font53">P9. Show that the maximum efficiency of pure ALOHA is 1/(2</span><span class="font53" style="font-style:italic;">e</span><span class="font53">). </span><span class="font53" style="font-style:italic;">Note:</span><span class="font53"> This problem is easy if you have completed the problem above!</span></p>
<p><span class="font53">P10. Consider two nodes, A and B, that use the slotted ALOHA protocol to contend for a channel. Suppose node A has more data to transmit than node B, and node A’s retransmission probability </span><span class="font53" style="font-style:italic;">p<sub>A</sub></span><span class="font53"> is greater than node B’s retransmission probability, </span><span class="font53" style="font-style:italic;">p<sub>B</sub>.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Provide a formula for node A’s average throughput. What is the total efficiency of the protocol with these two nodes?</span></p></li>
<li>
<p><span class="font53">b. If </span><span class="font53" style="font-style:italic;">p<sub>A</sub> = 2p<sub>B</sub>,</span><span class="font53"> is node A’s average throughput twice as large as that of node B? Why or why not? If not, how can you choose </span><span class="font53" style="font-style:italic;">p<sub>A</sub></span><span class="font53"> and </span><span class="font53" style="font-style:italic;">p<sub>B</sub></span><span class="font53"> to make that happen?</span></p></li>
<li>
<p><span class="font53">c. In general, suppose there are </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> nodes, among which node A has retransmission probability </span><span class="font53" style="font-style:italic;">2p</span><span class="font53"> and all other nodes have retransmission probability </span><span class="font53" style="font-style:italic;">p.</span><span class="font53"> Provide expressions to compute the average throughputs of node A and of any other node.</span></p></li></ul>
<p><span class="font53">P11. Suppose four active nodes—nodes A, B, C and D—are competing for access to a channel using slotted ALOHA. Assume each node has an infinite number of packets to send. Each node attempts to transmit in each slot with probability </span><span class="font53" style="font-style:italic;">p</span><span class="font53">. The first slot is numbered slot 1, the second slot is numbered slot 2, and so on.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. What is the probability that node A succeeds for the first time in slot 4?</span></p></li>
<li>
<p><span class="font53">b. What is the probability that some node (either A, B, C or D) succeeds in slot 5?</span></p></li>
<li>
<p><span class="font53">c. What is the probability that the first success occurs in slot 4?</span></p></li>
<li>
<p><span class="font53">d. What is the efficiency of this four-node system?</span></p></li></ul>
<p><span class="font53">P12. Graph the efficiency of slotted ALOHA and pure ALOHA as a function of </span><span class="font53" style="font-style:italic;">p</span><span class="font53"> for the following values of </span><span class="font53" style="font-style:italic;">N</span><span class="font53">:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. </span><span class="font53" style="font-style:italic;">N</span><span class="font54"> = </span><span class="font53">10.</span></p></li>
<li>
<p><span class="font53">b. </span><span class="font53" style="font-style:italic;">N =</span><span class="font53"> 30.</span></p></li>
<li>
<p><span class="font53">c. </span><span class="font53" style="font-style:italic;">N</span><span class="font54"> = </span><span class="font53">50.</span></p></li></ul>
<p><span class="font53">P13. Consider a broadcast channel with </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> nodes and a transmission rate of </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> bps. Suppose the broadcast channel uses polling (with an additional polling node) for multiple access. Suppose the amount of time from when a node completes transmission until the subsequent node is permitted to transmit (that is, the polling delay) is </span><span class="font53" style="font-style:italic;">d</span><span class="font53"><sub>poll</sub>. Suppose that within a polling round, a given node is allowed to transmit at most </span><span class="font53" style="font-style:italic;">Q</span><span class="font53"> bits. What is the maximum throughput of the broadcast channel?</span></p>
<p><span class="font53">P14. Consider three LANs interconnected by two routers, as shown in Figure 6.33.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Assign IP addresses to all of the interfaces. For Subnet 1 use addresses of the form 192.168.1.xxx; for Subnet 2 uses addresses of the form 192.168.2.xxx; and for Subnet 3 use addresses of the form 192.168.3.xxx.</span></p></li>
<li>
<p><span class="font53">b. Assign MAC addresses to all of the adapters.</span></p></li></ul><img src="networking_files/networking-473.jpg" alt="" style="width:268pt;height:201pt;">
<p><span class="font7" style="font-weight:bold;">Figure 6.33 </span><span class="font50">♦ </span><span class="font5">Three subnets, interconnected by routers</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">c. Consider sending an IP datagram from Host E to Host B. Suppose all of the ARP tables are up to date. Enumerate all the steps, as done for the single-router example in Section 6.4.1.</span></p></li>
<li>
<p><span class="font53">d. Repeat (c), now assuming that the ARP table in the sending host is empty (and the other tables are up to date).</span></p></li></ul>
<p><span class="font53">P15. Consider Figure 6.33. Now we replace the router between subnets 1 and 2 with a switch S1, and label the router between subnets 2 and 3 as R1.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Consider sending an IP datagram from Host E to Host F. Will Host E ask router R1 to help forward the datagram? Why? In the Ethernet frame containing the IP datagram, what are the source and destination IP and MAC addresses?</span></p></li>
<li>
<p><span class="font53">b. Suppose E would like to send an IP datagram to B, and assume that E’s ARP cache does not contain B’s MAC address. Will E perform an ARP query to find B’s MAC address? Why? In the Ethernet frame (containing the IP datagram destined to B) that is delivered to router R1, what are the source and destination IP and MAC addresses?</span></p></li>
<li>
<p><span class="font53">c. Suppose Host A would like to send an IP datagram to Host B, and neither A’s ARP cache contains B’s MAC address nor does B’s ARP cache contain A’s MAC address. Further suppose that the switch S1’s forwarding table contains entries for Host B and router R1 only. Thus, A will broadcast an ARP request message. What actions will switch S1 perform once it receives the ARP request message? Will router R1 also receive this ARP request message? If so, will R1 forward the message to Subnet 3? Once Host B receives this ARP request message, it will send back to Host A an ARP response message. But will it send an ARP query message to ask for A’s MAC address? Why? What will switch S1 do once it receives an ARP response message from Host B?</span></p></li></ul>
<p><span class="font53">P16. Consider the previous problem, but suppose now that the router between subnets 2 and 3 is replaced by a switch. Answer questions (a)-(c) in the previous problem in this new context.</span></p>
<p><span class="font53">P17. Recall that with the CSMA/CD protocol, the network adapter waits </span><span class="font53" style="font-style:italic;">K </span><span class="font60" style="font-style:italic;">•</span><span class="font53"> 512 bit times after a collision, where </span><span class="font53" style="font-style:italic;">K</span><span class="font53"> is drawn randomly. For </span><span class="font53" style="font-style:italic;">K =</span><span class="font53"> 115, how long does the adapter wait until returning to Step 2 for:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. a 10 Mbps broadcast channel?</span></p></li>
<li>
<p><span class="font53">b. a 100 Mbps broadcast channel?</span></p></li></ul>
<p><span class="font53">P18. Suppose nodes A and B are on the same 12 Mbps broadcast channel, and the propagation delay between the two nodes is 316 bit times. Suppose CSMA/ CD and Ethernet packets are used for this broadcast channel. Suppose node A begins transmitting a frame and, before it finishes, node B begins transmitting a frame. Can A finish transmitting before it detects that B has transmitted? Why or why not? If the answer is yes, then A incorrectly believes that its frame was successful transmitted without a collision. </span><span class="font53" style="font-style:italic;">Hint:</span><span class="font53"> Suppose at time </span><span class="font53" style="font-style:italic;">t =</span><span class="font53"> 0 bits, A begins transmitting a frame. In the worst case, Atransmits a minimum-sized frame of 512 </span><span class="font55">+ </span><span class="font53">64 bit times. So A would finish transmitting the frame at </span><span class="font53" style="font-style:italic;">t =</span><span class="font53"> 512 </span><span class="font55">+ </span><span class="font53">64 bit times. Thus, the answer is no, if B’s signal reaches A before bit time </span><span class="font53" style="font-style:italic;">t =</span><span class="font53"> 512 </span><span class="font55">+ </span><span class="font53">64 bits. In the worst case, when does B’s signal reach A?</span></p>
<p><span class="font53">P19. Suppose nodes A and B are on the same 10 Mbps broadcast channel, and the propagation delay between the two nodes is 245 bit times. Suppose A and B send Ethernet frames at the same time, the frames collide, and then A and B choose different values of </span><span class="font53" style="font-style:italic;">K</span><span class="font53"> in the CSMA/CD algorithm. Assuming no other nodes are active, can the retransmissions from A and B collide? For our purposes, it suffices to work out the following example. Suppose A and B begin transmission at </span><span class="font53" style="font-style:italic;">t =</span><span class="font53"> 0 bit times. They both detect collisions at </span><span class="font53" style="font-style:italic;">t =</span><span class="font53"> 245 t bit times. Suppose </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">A </span><span class="font53" style="font-style:italic;">=</span><span class="font53"> 0 and </span><span class="font53" style="font-style:italic;">K<sub>B</sub> =</span><span class="font53"> 1. At what time does B schedule its retransmission? At what time does A begin transmission? </span><span class="font53" style="font-style:italic;">(Note: </span><span class="font53">The nodes must wait for an idle channel after returning to Step 2—see protocol.) At what time does A’s signal reach B? Does B refrain from transmitting at its scheduled time?</span></p>
<p><span class="font53">P20. In this problem, you will derive the efficiency of a CSMA/CD-like multiple access protocol. In this protocol, time is slotted and all adapters are synchronized to the slots. Unlike slotted ALOHA, however, the length of a slot (in seconds) is much less than a frame time (the time to transmit a frame). Let </span><span class="font53" style="font-style:italic;">S </span><span class="font53">be the length of a slot. Suppose all frames are of constant length </span><span class="font53" style="font-style:italic;">L = kRS, </span><span class="font53">where </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> is the transmission rate of the channel and </span><span class="font53" style="font-style:italic;">k</span><span class="font53"> is a large integer.</span></p>
<p><span class="font53">Suppose there are </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> nodes, each with an infinite number of frames to send. We also assume that </span><span class="font53" style="font-style:italic;">d<sub>prop</sub></span><span class="font55"> &lt;&nbsp;</span><span class="font53" style="font-style:italic;">S,</span><span class="font53"> so that all nodes can detect a collision before the end of a slot time. The protocol is as follows:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;If, for a given slot, no node has possession of the channel, all nodes contend for the channel; in particular, each node transmits in the slot with probability </span><span class="font53" style="font-style:italic;">p.</span><span class="font53"> If exactly one node transmits in the slot, that node takes possession of the channel for the subsequent </span><span class="font53" style="font-style:italic;">k —</span><span class="font53"> 1 slots and transmits its entire frame.</span></p></li>
<li>
<p><span class="font53">• &nbsp;If some node has possession of the channel, all other nodes refrain from transmitting until the node that possesses the channel has finished transmitting its frame. Once this node has transmitted its frame, all nodes contend for the channel.</span></p></li></ul>
<p><span class="font53">Note that the channel alternates between two states: the productive state, which lasts exactly </span><span class="font53" style="font-style:italic;">k</span><span class="font53"> slots, and the nonproductive state, which lasts for a random number of slots. Clearly, the channel efficiency is the ratio of </span><span class="font53" style="font-style:italic;">k</span><span class="font53">/(</span><span class="font53" style="font-style:italic;">k</span><span class="font55"> + </span><span class="font53" style="font-style:italic;">x), </span><span class="font53">where </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> is the expected number of consecutive unproductive slots.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. For fixed </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">p</span><span class="font53">, determine the efficiency of this protocol.</span></p></li>
<li>
<p><span class="font53">b. For fixed </span><span class="font53" style="font-style:italic;">N</span><span class="font53">, determine the </span><span class="font53" style="font-style:italic;">p</span><span class="font53"> that maximizes the efficiency.</span></p></li>
<li>
<p><span class="font53">c. Using the </span><span class="font53" style="font-style:italic;">p</span><span class="font53"> (which is a function of </span><span class="font53" style="font-style:italic;">N)</span><span class="font53"> found in (b), determine the efficiency as </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> approaches infinity.</span></p></li>
<li>
<p><span class="font53">d. Show that this efficiency approaches 1 as the frame length becomes large.</span></p></li></ul>
<p><span class="font53">P21. Consider Figure 6.33 in problem P14. Provide MAC addresses and IP addresses for the interfaces at Host A, both routers, and Host F. Suppose Host A sends a datagram to Host F. Give the source and destination MAC addresses in the frame encapsulating this IP datagram as the frame is transmitted </span><span class="font53" style="font-style:italic;">(i)</span><span class="font53"> from A to the left router, </span><span class="font53" style="font-style:italic;">(ii)</span><span class="font53"> from the left router to the right router, </span><span class="font53" style="font-style:italic;">(iii)</span><span class="font53"> from the right router to F. Also give the source and destination IP addresses in the IP datagram encapsulated within the frame at each of these points in time.</span></p>
<p><span class="font53">P22. Suppose now that the leftmost router in Figure 6.33 is replaced by a switch. Hosts A, B, C, and D and the right router are all star-connected into this switch. Give the source and destination MAC addresses in the frame encapsulating this IP datagram as the frame is transmitted </span><span class="font53" style="font-style:italic;">(i)</span><span class="font53"> from A to the switch, </span><span class="font53" style="font-style:italic;">(ii)</span><span class="font53"> from the switch to the right router, </span><span class="font53" style="font-style:italic;">(iii)</span><span class="font53"> from the right router to F. Also give the source and destination IP addresses in the IP datagram encapsulated within the frame at each of these points in time.</span></p>
<p><span class="font53">P23. Consider Figure 5.15. Suppose that all links are 120 Mbps. What is the maximum total aggregate throughput that can be achieved among 12 hosts (4 in each department) and 2 servers in this network? You can assume that any host or server can send to any other host or server. Why?</span></p>
<p><span class="font53">P24. Suppose the three departmental switches in Figure 5.15 are replaced by hubs. All links are 120 Mbps. Now answer the questions posed in Problem P23.</span></p>
<p><span class="font53">P25. Suppose that </span><span class="font53" style="font-style:italic;">all</span><span class="font53"> the switches in Figure 5.15 are replaced by hubs. All links are 120 Mbps. Now answer the questions posed in Problem P23.</span></p>
<p><span class="font53">P26. Let’s consider the operation of a learning switch in the context of a network in which 6 nodes labeled A through F are star connected into an Ethernet switch. Suppose that </span><span class="font53" style="font-style:italic;">(i)</span><span class="font53"> B sends a frame to E, </span><span class="font53" style="font-style:italic;">(ii)</span><span class="font53"> E replies with a frame to B, </span><span class="font53" style="font-style:italic;">(iii)</span><span class="font53"> A sends a frame to B, </span><span class="font53" style="font-style:italic;">(iv)</span><span class="font53"> B replies with a frame to A. The switch table is initially empty. Show the state of the switch table before and after each of these events. For each of these events, identify the link(s) on which the transmitted frame will be forwarded, and briefly justify your answers.</span></p>
<p><span class="font53">P27. In this problem, we explore the use of small packets for Voice-over-IP applications. One of the drawbacks of a small packet size is that a large fraction of link bandwidth is consumed by overhead bytes. To this end, suppose that the packet consists of </span><span class="font53" style="font-style:italic;">P</span><span class="font53"> bytes and 5 bytes of header.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Consider sending a digitally encoded voice source directly. Suppose the source is encoded at a constant rate of 128 kbps. Assume each packet is entirely filled before the source sends the packet into the network. The time required to fill a packet is the </span><span class="font53" style="font-weight:bold;">packetization delay</span><span class="font53">. In terms of </span><span class="font53" style="font-style:italic;">L, </span><span class="font53">determine the packetization delay in milliseconds.</span></p></li>
<li>
<p><span class="font53">b. Packetization delays greater than 20 msec can cause a noticeable and unpleasant echo. Determine the packetization delay for </span><span class="font53" style="font-style:italic;">L =</span><span class="font53"> 1,500 bytes (roughly corresponding to a maximum-sized Ethernet packet) and for</span></p></li></ul>
<p><span class="font53" style="font-style:italic;">L =</span><span class="font53"> 50 (corresponding to an ATM packet).</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">c. Calculate the store-and-forward delay at a single switch for a link rate of </span><span class="font53" style="font-style:italic;">R =</span><span class="font53"> 622 Mbps for </span><span class="font53" style="font-style:italic;">L =</span><span class="font53"> 1,500 bytes, and for </span><span class="font53" style="font-style:italic;">L =</span><span class="font53"> 50 bytes.</span></p></li>
<li>
<p><span class="font53">d. Comment on the advantages of using a small packet size.</span></p></li></ul>
<p><span class="font53">P28. Consider the single switch VLAN in Figure 6.25, and assume an external router is connected to switch port 1. Assign IP addresses to the EE and CS hosts and router interface. Trace the steps taken at both the network layer and the link layer to transfer an IP datagram from an EE host to a CS host </span><span class="font53" style="font-style:italic;">(Hint:</span><span class="font53"> Reread the discussion of Figure 6.19 in the text).</span></p>
<p><span class="font53">P29. Consider the MPLS network shown in Figure 6.29, and suppose that routers R5 and R6 are now MPLS enabled. Suppose that we want to perform traffic engineering so that packets from R6 destined for A are switched to A via R6-R4-R3-R1, and packets from R5 destined for A are switched via R5-R4-R2-R1. Show the MPLS tables in R5 and R6, as well as the modified table in R4, that would make this possible.</span></p>
<p><span class="font53">P30. Consider again the same scenario as in the previous problem, but suppose that packets from R6 destined for D are switched via R6-R4-R3, while packets from R5 destined to D are switched via R4-R2-R1-R3. Show the MPLS tables in all routers that would make this possible.</span></p>
<p><span class="font53">P31. In this problem, you will put together much of what you have learned about Internet protocols. Suppose you walk into a room, connect to Ethernet, and want to download a Web page. What are all the protocol steps that take place, starting from powering on your PC to getting the Web page? Assume there is nothing in our DNS or browser caches when you power on your PC.</span></p>
<p><span class="font53" style="font-style:italic;">(Hint:</span><span class="font53"> The steps include the use of Ethernet, DHCP, ARP, DNS, TCP, and HTTP protocols.) Explicitly indicate in your steps how you obtain the IP and MAC addresses of a gateway router.</span></p>
<p><span class="font53">P32. Consider the data center network with hierarchical topology in Figure 6.30. Suppose now there are 80 pairs of flows, with ten flows between the first and ninth rack, ten flows between the second and tenth rack, and so on. Further suppose that all links in the network are 10 Gbps, except for the links between hosts and TOR switches, which are 1 Gbps.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Each flow has the same data rate; determine the maximum rate of a flow.</span></p></li>
<li>
<p><span class="font53">b. For the same traffic pattern, determine the maximum rate of a flow for the highly interconnected topology in Figure 6.31.</span></p></li>
<li>
<p><span class="font53">c. Now suppose there is a similar traffic pattern, but involving 20 hosts on each rack and 160 pairs of flows. Determine the maximum flow rates for the two topologies.</span></p></li></ul>
<p><span class="font53">P33. Consider the hierarchical network in Figure 6.30 and suppose that the data center needs to support e-mail and video distribution among other applications. Suppose four racks of servers are reserved for e-mail and four racks are reserved for video. For each of the applications, all four racks must lie below a single tier-2 switch since the tier-2 to tier-1 links do not have sufficient bandwidth to support the intra-application traffic. For the e-mail application, suppose that for 99.9 percent of the time only three racks are used, and that the video application has identical usage patterns.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. For what fraction of time does the e-mail application need to use a fourth rack? How about for the video application?</span></p></li>
<li>
<p><span class="font53">b. Assuming e-mail usage and video usage are independent, for what fraction of time do (equivalently, what is the probability that) both applications need their fourth rack?</span></p></li>
<li>
<p><span class="font53">c. Suppose that it is acceptable for an application to have a shortage of servers for 0.001 percent of time or less (causing rare periods of performance degradation for users). Discuss how the topology in Figure 6.31 can be used so that only seven racks are collectively assigned to the two applications (assuming that the topology can support all the traffic).</span></p></li></ul>
<p><span class="font24" style="font-weight:bold;">Wireshark Labs: 802.11 Ethernet</span></p>
<p><a name="bookmark417"></a><span class="font53">At the Companion Website for this textbook, </span><a href="http://www.pearsonglobaleditions.com"><span class="font53">http://www.pearsonglobaleditions.com</span></a><span class="font53">, you’ll find a Wireshark lab that examines the operation of the IEEE 802.3 protocol and the Wireshark frame format. A second Wireshark lab examines packet traces taken in a home network scenario.</span></p>
<p><span class="font23" style="font-weight:bold;">AN INTERVIEW WITH...</span></p>
<p><span class="font11" style="font-weight:bold;">Albert Greenberg</span></p>
<div><img src="networking_files/networking-474.jpg" alt="" style="width:86pt;height:110pt;">
</div><br clear="all">
<p><span class="font46">Albert Greenberg is Microsoft Corporate Vice President for Azure Networking. He leads development for the Azure Networking team, which is responsible for networking R&amp;D at Microsoft - within and across data centers and edge sites; global terrestrial and subsea networks; optical networking; FPGA and SmartNIC offloads; access and hybrid cloud networking; host networking and network virtualization; application load balancers and network virtual appliances; network services and analytics; security services; container networking; content distribution networks; edge networking including application acceleration and 5G, and first party networks. To meet the challenges of agility and quality that comes with cloud scale, his team has developed and embraced custom hardware, machine learning, and open source. Albert moved to Microsoft in 2007 to innovate on Cloud and bring networking to the host (network virtualization), ideas that appeared, among many, in his VL2 paper, and which underly Cloud networking today.</span></p>
<p><span class="font46">Prior to joining Microsoft, Albert worked at Bell Labs and AT&amp;T Labs as an AT&amp;T Fellow. He helped build the systems and tools that run AT&amp;T's networks, and pioneered the architecture and systems at the foundations of software-defined networking. He holds an AB in Mathematics from Dartmouth College and a PhD in Computer Science from the University of Washington.</span></p>
<p><span class="font46">Albert is a member of the National Academy of Engineering, and an ACM Fellow. He has received the IEEE Koji Kobayashi Computer and Communication Award, ACM Sigcomm Award, and ACM Sigcomm and Sigmetrics Test of Time paper awards. Albert and wife Kathryn are proud parents of four daughters. He grew up in New Orleans. While the Seattle Seahawks are his team, he cannot shake his fondness for the Saints.</span></p>
<p><span class="font4" style="font-weight:bold;">What brought you to specialize in networking?</span></p>
<p><span class="font52">I’ve always liked solving real-world problems, and also liked mathematics. I’ve found that the field of networking has lots of room and scope to do both. That mix was very appealing to me. While working on a PhD at the University of Washington, I benefited from the influence of Ed Lazowska on the systems side, and Richard Ladner and Martin Tompa on the mathematical and theoretical side. One of my MS course projects was to get two machines from the </span><span class="font52" style="font-style:italic;">same</span><span class="font52"> vendor to talk to each other. Now it seems you can’t </span><span class="font52" style="font-style:italic;">stop </span><span class="font52">machines from communicating!</span></p>
<p><span class="font4" style="font-weight:bold;">Do you have any advice for students entering the networking/Internet field?</span></p>
<p><span class="font52">The face of networking is changing. It’s becoming a very diverse, inclusive and open environment. I mean that in two ways. First, we will see far much more diversity among our network developers and researchers, including women and other underrepresented groups in technology. I’m proud of the diversity and inclusivity of the team at Microsoft, and my earlier teams at AT&amp;T. Diversity makes us more resilient, better able to adapt to change, and makes our decisions better. Second, one can bring a diversity of technical skills and interests to networking. Those interests might be in architecture, programming languages, optics, formal methods, data science, AI, or in fault tolerant and reliable system design. Open source systems are having enormous impact. SONiC, a Linux-based an open source initiative for networking operating systems, is a great example. Read this book, and bring your whole set of skills, experience and knowledge set to creating the networks of the future. SDN and Disaggregation brings diversity and openness. So exciting.</span></p>
<p><span class="font4" style="font-weight:bold;">Can you describe one or two of the most exciting projects you have worked on during your career? What were the biggest challenges?</span></p>
<p><span class="font52">The cloud is by far the biggest thing to come along in a long time. The challenges there are head and shoulders above other system challenges I’ve worked on, in part because the cloud incorporate so many aspects of systems. Cloud scenarios stretch tremendously the challenge of networking. Traditional networking technology is only part of it; in practice today there’s operating systems and distributed systems, architecture, performance, security, reliability, machine learning, data science, and management-the whole stack. If we used to think of these individual areas as “gardens”, we can think of the cloud as a “farm” made up of all of these wonderful gardens. And the operational concerns of designing, monitoring and managing an ultra-reliable global-scale system are crucial, as the cloud provides critically important infrastructure for government, industry, education and more. All of that has to be rock solid; it needs to be secure; it needs to be trustworthy. Software is, of course, key to effectively monitoring and managing such a massive cloud. Here, SDN plays the central role in managing and provisioning at scale, creating, in essence, a software-defined data center. Software allows us to also innovate rapidly.</span></p>
<p><span class="font4" style="font-weight:bold;">How do you envision the future of networking and the Internet? What major challenges/ obstacles do you think lie ahead in their development, particularly in the areas of data center networking, and edge networks?</span></p>
<p><span class="font52">I’ve already talked about Cloud, and we are just say 10% into its evolution. Yet, it’s clear that the division of work in the end-to-end system will be an increasingly important issue. How much computation and storage will happen in the application and at the end-host? How much will happen in cloud components at the network’s “edge”, at or near the end host or container? And how much will happen in the data centers themselves. How will all of this be orchestrated? We’ll see cloud computing being pushed closer to the edge and we’ll see “horizontal” growth-a richer end-to-end computing/data/networking ecosystem-not just growth, say within a data center. This will be an area of great innovation.</span></p>
<p><span class="font52">5G wireless will be an important part of this mix.</span></p>
<p><span class="font4" style="font-weight:bold;">Who has inspired you professionally?</span></p>
<p><span class="font52">I’ve learned a tremendous amount, at both Microsoft and AT&amp;T, from customers and from the live site. Interacting with engineers inspires me, for their passion for dev and dev-ops of the entire lifecycle (invention to development to deployment to ultimate decommission) of operational services and systems. These are the people who know architecture and systems from end to end, inside out. They’re great to work with and have so much insight, experience and knowledge to share, whether that be Microsoft’s Azure Cloud or earlier in my career AT&amp;T’s networks. I’ve also loved working with the researchers who have established some of the principles underlying the design and management of these at-scale systems.</span></p><img src="networking_files/networking-475.jpg" alt="" style="width:531pt;height:153pt;">
<h1><a name="bookmark418"></a><span class="font27" style="font-weight:bold;">Wireless and Mobile</span></h1>
<p><span class="font27" style="font-weight:bold;">Networks</span></p>
<p><span class="font53">In the telephony world, the past 25 years have been the golden years of cellular telephony. The number of worldwide mobile cellular subscribers increased from 34 million in 1993 to 8.3 billion subscribers in 2019. There are now a larger number of mobile phone subscriptions than there are people on our planet. The many advantages of cell phones are evident to all—anywhere, anytime, untethered access to the global telephone network via a highly portable lightweight device. More recently, smartphones, tablets, and laptops have become wirelessly connected to the Internet via a cellular or WiFi network. And increasingly, devices such as gaming consoles, thermostats, home security systems, home appliances, watches, eye glasses, cars, traffic control systems and more are being wirelessly connected to the Internet.</span></p>
<p><span class="font53">From a networking standpoint, the challenges posed by networking these wireless and mobile devices, particularly at the link layer and the network layer, are so different from traditional wired computer networks that an individual chapter devoted to the study of wireless and mobile networks (i.e., </span><span class="font53" style="font-style:italic;">this</span><span class="font53"> chapter) is appropriate.</span></p>
<p><span class="font53">We’ll begin this chapter with a discussion of mobile users, wireless links, and networks, and their relationship to the larger (typically wired) networks to which they connect. We’ll draw a distinction between the challenges posed by the </span><span class="font53" style="font-style:italic;">wireless </span><span class="font53">nature of the communication links in such networks, and by the </span><span class="font53" style="font-style:italic;">mobility</span><span class="font53"> that these wireless links enable. Making this important distinction—between wireless and mobility—will allow us to better isolate, identify, and master the key concepts in each area.</span></p>
<p><a name="bookmark419"></a><span class="font53">We will begin with an overview of wireless access infrastructure and associated terminology. We’ll then consider the characteristics of this wireless link in Section 7.2. We include a brief introduction to code division multiple access (CDMA), a shared-medium access protocol that is often used in wireless networks, in Section 7.2. In Section 7.3, we’ll examine the link-level aspects of the IEEE 802.11 (WiFi) wireless LAN standard in some depth; we’ll also say a few words about Bluetooth wireless personal area networks. In Section 7.4, we’ll provide an overview of cellular Internet access, including 4G and emerging 5G cellular technologies that provide both voice and high-speed Internet access. In Section 7.5, we’ll turn our attention to mobility, focusing on the problems of locating a mobile user, routing to the mobile user, and “handing over” the mobile user who dynamically moves from one point of attachment to the network to another. We’ll examine how these mobility services are implemented in the 4G/5G cellular networks, and the in the Mobile IP standard in Section 7.6. Finally, we’ll consider the impact of wireless links and mobility on transport-layer protocols and networked applications in Section 7.7.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">7.1 </span><span class="font24" style="font-weight:bold;">Introduction</span></p></li></ul>
<p><span class="font53">Figure 7.1 shows the setting in which we’ll consider the topics of wireless data communication and mobility. We’ll begin by keeping our discussion general enough to cover a wide range of networks, including both wireless LANs such as WiFi and 4G and 5G cellular networks; we’ll drill down into a more detailed discussion of specific wireless architectures in later sections. We can identify the following elements in a wireless network:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Wireless hosts.</span><span class="font53"> As in the case of wired networks, hosts are the end-system devices that run applications. A </span><span class="font53" style="font-weight:bold;">wireless host </span><span class="font53">might be a smartphone, tablet, or laptop, or it could be an Internet of Things (IoT) device such as a sensor, appliance, automobile, or any other of the myriad devices being connected to the Internet. The hosts themselves may or may not be mobile.</span></p></li>
<li>
<p><a name="bookmark420"></a><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Wireless links.</span><span class="font53"> A host connects to a base station (defined below) or to another wireless host through a </span><span class="font53" style="font-weight:bold;">wireless communication link</span><span class="font53">. Different wireless link technologies have different transmission rates and can transmit over different distances. Figure 7.2 shows two key characteristics, link transmission rates and coverage ranges, of the more popular wireless network standards. (The figure is only meant to provide a rough idea of these characteristics. For example, some of these types of networks are only now being deployed, and some link rates can increase or decrease beyond the values shown depending on distance, channel conditions, and the number of users in the wireless network.) We’ll cover these standards later in the first half of this chapter; we’ll also consider other wireless link characteristics (such as their bit error rates and the causes of bit errors) in Section 7.2.</span></p>
<div><img src="networking_files/networking-476.jpg" alt="" style="width:138pt;height:133pt;">
<p><span class="font4">Key:</span></p>
</div><br clear="all">
<div>
<p><span class="font41">Wireless access point</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-477.jpg" alt="" style="width:25pt;height:65pt;">
<p><span class="font41">Wireless host</span></p>
<p><span class="font41">Wireless host in motion</span></p>
</div><br clear="all">
<div>
<p><span class="font41">Coverage area</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-478.jpg" alt="" style="width:199pt;height:273pt;">
</div><br clear="all"></li></ul>
<p><span class="font7" style="font-weight:bold;">Figure 7.1 </span><span class="font50">♦ </span><span class="font5">Elements of a wireless network</span></p>
<p><span class="font53">In Figure 7.1, wireless links connect wireless hosts located at the edge of the network into the larger network infrastructure. We hasten to add that wireless links are also sometimes used </span><span class="font53" style="font-style:italic;">within</span><span class="font53"> a network to connect routers, switches, and other network equipment. However, our focus in this chapter will be on the use of wireless communication at the network edge, as it is here that many of the most exciting technical challenges, and most of the growth, are occurring.</span></p>
<p><span class="font53">• </span><span class="font53" style="font-style:italic;">Base station.</span><span class="font53"> The </span><span class="font53" style="font-weight:bold;">base station </span><span class="font53">is a key part of the wireless network infrastructure. Unlike the wireless host and wireless link, a base station has no obvious counterpart in a wired network. A base station is responsible for sending and receiving data (e.g., packets) to and from a wireless host that is associated with that base station. A base station will often be responsible for coordinating the transmission of multiple wireless hosts with which it is associated. When we say a wireless host is “associated” with a base station, we mean that (1) the host is within the wireless communication distance of the base station, and (2) the host uses that base station to relay data between it (the host) and the larger network. </span><span class="font53" style="font-weight:bold;">Cell towers </span><span class="font53">in cellular networks and </span><span class="font53" style="font-weight:bold;">access points </span><span class="font53">in 802.11 wireless LANs are examples of base stations.</span></p><img src="networking_files/networking-479.jpg" alt="" style="width:305pt;height:201pt;">
<p><span class="font42">10-30m</span></p>
<p><span class="font42">50-200m &nbsp;&nbsp;&nbsp;&nbsp;200m-4Km 4Km-15Km</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 7.2 </span><span class="font50">♦ </span><span class="font5">Wireless transmission rates and range for WiFi, cellular 4G/5G and Bluetooth standards (note: axes are not linear)</span></p>
<p><span class="font53">In Figure 7.1, the base station is connected to the larger network (e.g., the Internet, corporate or home network), thus functioning as a link-layer relay between the wireless host and the rest of the world with which the host communicates.</span></p>
<p><span class="font53">Hosts associated with a base station are often referred to as operating in </span><span class="font53" style="font-weight:bold;">infrastructure mode</span><span class="font53">, since all traditional network services (e.g., address assignment and routing) are provided by the network to which a host is connected via the base station. In </span><span class="font53" style="font-weight:bold;">ad hoc networks</span><span class="font53">, wireless hosts have no such infrastructure with which to connect. In the absence of such infrastructure, the hosts themselves must provide for services such as routing, address assignment, DNS-like name translation, and more.</span></p>
<p><span class="font53">When a mobile host moves beyond the range of one base station and into the range of another, it will change its point of attachment into the larger network (i.e., change the base station with which it is associated)—a process referred to as </span><span class="font53" style="font-weight:bold;">handoff </span><span class="font53">or </span><span class="font53" style="font-weight:bold;">handover</span><span class="font53">. Such mobility raises many challenging questions. If a host can move, how does one find the mobile host’s current location in the network so that data can be forwarded to that mobile host? How is addressing performed, given that a host can be in one of many possible locations? If the host moves </span><span class="font53" style="font-style:italic;">during</span><span class="font53"> a TCP connection or phone call, how is data routed so that the connection continues uninterrupted? These and many (many!) other questions make wireless and mobile networking an area of exciting networking research.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Network infrastructure.</span><span class="font53"> This is the larger network with which a wireless host may wish to communicate.</span></p></li></ul>
<p><span class="font53">Having discussed the “pieces” of a wireless network, we note that these pieces can be combined in many different ways to form different types of wireless networks. You may find a taxonomy of these types of wireless networks useful as you read on in this chapter, or read/learn more about wireless networks beyond this book. At the highest level we can classify wireless networks according to two criteria: </span><span class="font53" style="font-style:italic;">(i) </span><span class="font53">whether a packet in the wireless network crosses exactly </span><span class="font53" style="font-style:italic;">one wireless hop or multiple wireless hops,</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">(ii)</span><span class="font53"> whether there is </span><span class="font53" style="font-style:italic;">infrastructure</span><span class="font53"> such as a base station in the network:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Single-hop, infrastructure-based.</span><span class="font53"> These networks have a base station that is connected to a larger wired network (e.g., the Internet). Furthermore, all communication is between this base station and a wireless host over a single wireless hop. The 802.11 networks you use in the classroom, cafe, or library; and the 4G LTE data networks that we will learn about shortly all fall in this category. The vast majority of our daily interactions are with single-hop, infrastructure-based wireless networks.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Single-hop, infrastructure-less.</span><span class="font53"> In these networks, there is no base station that is connected to a wireless network. However, as we will see, one of the nodes in this single-hop network may coordinate the transmissions of the other nodes. Bluetooth networks (that connect small wireless devices such as keyboards, speakers, and headsets, and which we will study in Section 7.3.6) are single-hop, infrastructure-less networks.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Multi-hop, infrastructure-based.</span><span class="font53"> In these networks, a base station is present that is wired to the larger network. However, some wireless nodes may have to relay their communication through other wireless nodes in order to communicate via the base station. Some wireless sensor networks and so-called </span><span class="font53" style="font-weight:bold;">wireless mesh networks </span><span class="font53">deployed in homes fall in this category.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Multi-hop, infrastructure-less.</span><span class="font53"> There is no base station in these networks, and nodes may have to relay messages among several other nodes in order to reach a destination. Nodes may also be mobile, with connectivity changing among nodes—a class of networks known as </span><span class="font53" style="font-weight:bold;">mobile ad hoc networks (MANETs)</span><span class="font53">. If the mobile nodes are vehicles, the network is a </span><span class="font53" style="font-weight:bold;">vehicular ad hoc network (VANET)</span><span class="font53">. As you might imagine, the development of protocols for such networks is challenging and is the subject of much ongoing research.</span></p></li></ul>
<p><span class="font53">In this chapter, we’ll mostly confine ourselves to single-hop networks, and then mostly to infrastructure-based networks.</span></p>
<p><span class="font53">Let’s now dig deeper into the technical challenges that arise in wireless and mobile networks. We’ll begin by first considering the individual wireless link, deferring our discussion of mobility until later in this chapter.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">7.2 </span><span class="font24" style="font-weight:bold;">Wireless Links and Network Characteristics</span></p></li></ul>
<p><span class="font53">Wireless links differ from their wired counterparts in a number important ways:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Decreasing signal strength.</span><span class="font53"> Electromagnetic radiation attenuates as it passes through matter (e.g., a radio signal passing through a wall). Even in free space, the signal will disperse, resulting in decreased signal strength (sometimes referred to as </span><span class="font53" style="font-weight:bold;">path loss</span><span class="font53">) as the distance between sender and receiver increases.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Interference from other sources.</span><span class="font53"> Radio sources transmitting in the same frequency band will interfere with each other. For example, 2.4 GHz wireless phones and 802.11b wireless LANs transmit in the same frequency band. Thus, the 802.11b wireless LAN user talking on a 2.4 GHz wireless phone can expect that neither the network nor the phone will perform particularly well. In addition to interference from transmitting sources, electromagnetic noise within the environment (e.g., a nearby motor, a microwave) can result in interference. For this reason, a number of more recent 802.11 standards operate in the 5GHz frequency band.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Multipath propagation.</span><span class="font53" style="font-weight:bold;"> Multipath propagation </span><span class="font53">occurs when portions of the electromagnetic wave reflect off objects and the ground, taking paths of different lengths between a sender and receiver. This results in the blurring of the received signal at the receiver. Moving objects between the sender and receiver can cause multipath propagation to change over time.</span></p></li></ul>
<p><span class="font53">For a detailed discussion of wireless channel characteristics, models, and measurements, see [Anderson 1995; Almers 2007].</span></p>
<p><span class="font53">The discussion above suggests that bit errors will be more common in wireless links than in wired links. For this reason, it is perhaps not surprising that wireless link protocols (such as the 802.11 protocol we’ll examine in the following section) employ not only powerful CRC error detection codes, but also link-level relia-ble-data-transfer protocols that retransmit corrupted frames.</span></p>
<p><a name="bookmark421"></a><span class="font53">Having considered the impairments that can occur on a wireless channel, let’s next turn our attention to the host receiving the wireless signal. This host receives an electromagnetic signal that is a combination of a degraded form of the original signal transmitted by the sender (degraded due to the attenuation and multipath propagation effects that we discussed above, among others) and background noise in the environment. The </span><span class="font53" style="font-weight:bold;">signal-to-noise ratio (SNR) </span><span class="font53">is a relative measure of the strength of the received signal (i.e., the information being transmitted) and this noise. The SNR is typically measured in units of decibels (dB), a unit of measure that some think is used by</span></p><img src="networking_files/networking-480.jpg" alt="" style="width:200pt;height:180pt;">
<p><span class="font4">SNR (dB)</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 7.3 </span><span class="font50">♦ </span><span class="font5">Bit error rate, transmission rate, and SNR</span></p>
<p><span class="font53">electrical engineers primarily to confuse computer scientists. The SNR, measured in dB, is 20 times the ratio of the base-10 logarithm of the amplitude of the received signal to the amplitude of the noise. For our purposes here, we need only know that a larger SNR makes it easier for the receiver to extract the transmitted signal from the background noise.</span></p>
<p><span class="font53">Figure 7.3 (adapted from [Holland 2001]) shows the bit error rate (BER)— roughly speaking, the probability that a transmitted bit is received in error at the receiver—versus the SNR for three different modulation techniques for encoding information for transmission on an idealized wireless channel. The theory of modulation and coding, as well as signal extraction and BER, is well beyond the scope of this text (see [Schwartz 1980; Goldsmith 2005] for a discussion of these topics). Nonetheless, Figure 7.3 illustrates several physical-layer characteristics that are important in understanding higher-layer wireless communication protocols:</span></p>
<p><span class="font53">• </span><span class="font53" style="font-style:italic;">For a given modulation scheme, the higher the SNR, the lower the BER.</span><span class="font53"> Since a sender can increase the SNR by increasing its transmission power, a sender can decrease the probability that a frame is received in error by increasing its transmission power. Note, however, that there is arguably little practical gain in increasing the power beyond a certain threshold, say to decrease the BER from 10</span><span class="font4"><sup>-</sup></span><span class="font53"><sup>12</sup> to 10</span><span class="font4"><sup>-</sup></span><span class="font53"><sup>13</sup>. There are also </span><span class="font53" style="font-style:italic;">disadvantages</span><span class="font53"> associated with increasing the transmission power: More energy must be expended by the sender</span></p>
<div><img src="networking_files/networking-481.jpg" alt="" style="width:142pt;height:117pt;">
<p><span class="font4">C &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;B</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-482.jpg" alt="" style="width:142pt;height:38pt;">
</div><br clear="all">
<div><img src="networking_files/networking-483.jpg" alt="" style="width:146pt;height:113pt;">
<p><span class="font7" style="font-weight:bold;">Figure 7.4 </span><span class="font50">♦ </span><span class="font5">Hidden terminal problem caused by obstacle (a) and fading (b)</span></p>
</div><br clear="all">
<p><span class="font53">(an important concern for battery-powered mobile users), and the sender’s transmissions are more likely to interfere with the transmissions of another sender (see Figure 7.4(b)).</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">For a given SNR, a modulation technique with a higher bit transmission rate (whether in error or not) will have a higher BER.</span><span class="font53"> For example, in Figure 7.3, with an SNR of 10 dB, BPSK modulation with a transmission rate of 1 Mbps has a BER of less than 10</span><span class="font4"><sup>-</sup></span><span class="font53"><sup>7</sup>, while with QAM16 modulation with a transmission rate of 4 Mbps, the BER is 10</span><span class="font4"><sup>-</sup></span><span class="font53"><sup>1</sup>, far too high to be practically useful. However, with an SNR of 20 dB, QAM16 modulation has a transmission rate of 4 Mbps and a BER of 10</span><span class="font4"><sup>-</sup></span><span class="font53"><sup>7</sup>, while BPSK modulation has a transmission rate of only 1 Mbps and a BER that is so low as to be (literally) “off the charts.” If one can tolerate a BER of 10</span><span class="font4"><sup>-</sup></span><span class="font53"><sup>7</sup>, the higher transmission rate offered by QAM16 would make it the preferred modulation technique in this situation. These considerations give rise to the final characteristic, described next.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Dynamic selection of the physical-layer modulation technique can be used to adapt the modulation technique to channel conditions.</span><span class="font53"> The SNR (and hence the BER) may change as a result of mobility or due to changes in the environment. Adaptive modulation and coding are used in the 802.11 WiFi and in 4G and 5G cellular data networks that we’ll study in Sections 7.3 and 7.4. This allows, for example, the selection of a modulation technique that provides the highest transmission rate possible subject to a constraint on the BER, for given channel characteristics.</span></p></li></ul>
<p><span class="font53">A higher and time-varying bit error rate is not the only difference between a wired and wireless link. Recall that in the case of wired broadcast links, all nodes receive the transmissions from all other nodes. In the case of wireless links, the situation is not as simple, as shown in Figure 7.4. Suppose that Station A is transmitting to Station B. Suppose also that Station C is transmitting to Station B. With the so-called </span><span class="font53" style="font-weight:bold;">hidden terminal problem</span><span class="font53">, physical obstructions in the environment (for example, a mountain or a building) may prevent A and C from hearing each other’s transmissions, even though A’s and C’s transmissions are indeed interfering at the destination, B. This is shown in Figure 7.4(a). A second scenario that results in undetectable collisions at the receiver results from the </span><span class="font53" style="font-weight:bold;">fading </span><span class="font53">of a signal’s strength as it propagates through the wireless medium. Figure 7.4(b) illustrates the case where A and C are placed such that their signals are not strong enough to detect each other’s transmissions, yet their signals </span><span class="font53" style="font-style:italic;">are</span><span class="font53"> strong enough to interfere with each other at station B. As we’ll see in Section 7.3, the hidden terminal problem and fading make multiple access in a wireless network considerably more complex than in a wired network.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">7.2.1 </span><span class="font23" style="font-weight:bold;">CDMA</span></p></li></ul>
<p><span class="font53">Recall from Chapter 6 that when hosts communicate over a shared medium, a protocol is needed so that the signals sent by multiple senders do not interfere at the receivers. In Chapter 6, we described three classes of medium access protocols: channel partitioning, random access, and taking turns. Code division multiple access (CDMA) belongs to the family of channel partitioning protocols. It is prevalent in wireless LAN and cellular technologies. Because CDMA is so important in the wireless world, we’ll take a quick look at CDMA now, before getting into specific wireless access technologies in the subsequent sections.</span></p>
<p><span class="font53">In a CDMA protocol, each bit being sent is encoded by multiplying the bit by a signal (the code) that changes at a much faster rate (known as the </span><span class="font53" style="font-weight:bold;">chipping rate</span><span class="font53">) than the original sequence of data bits. Figure 7.5 shows a simple, idealized CDMA encoding/decoding scenario. Suppose that the rate at which original data bits reach the CDMA encoder defines the unit of time; that is, each original data bit to be transmitted requires a one-bit slot time. Let </span><span class="font53" style="font-style:italic;">d</span><span class="font53"> be the value of the data bit for the </span><span class="font53" style="font-style:italic;">i</span><span class="font53">th bit slot. For mathematical convenience, we represent a data bit with a 0 value as </span><span class="font55">— </span><span class="font53">1. Each bit slot is further subdivided into </span><span class="font53" style="font-style:italic;">M</span><span class="font53"> mini-slots; in Figure 7.5, </span><span class="font53" style="font-style:italic;">M =</span><span class="font53"> 8, although in practice </span><span class="font53" style="font-style:italic;">M</span><span class="font53"> is much larger. The CDMA code used by the sender consists of a sequence of </span><span class="font53" style="font-style:italic;">M</span><span class="font53"> values, </span><span class="font53" style="font-style:italic;">c<sub>m</sub>, m =</span><span class="font53"> 1, . . . , </span><span class="font53" style="font-style:italic;">M</span><span class="font53">, each taking a </span><span class="font55">+</span><span class="font53">1 or </span><span class="font55">— </span><span class="font53">1 value. In the example in Figure 7.5, the </span><span class="font53" style="font-style:italic;">M</span><span class="font53">-bit CDMA code being used by the sender is (1, 1, 1, </span><span class="font55">— </span><span class="font53">1, 1, </span><span class="font55">— </span><span class="font53">1, </span><span class="font55">— </span><span class="font53">1, </span><span class="font55">— </span><span class="font53">1).</span></p>
<p><a name="bookmark422"></a><span class="font53">To illustrate how CDMA works, let us focus on the </span><span class="font53" style="font-style:italic;">i</span><span class="font53">th data bit, </span><span class="font53" style="font-style:italic;">d.</span><span class="font53"> For the </span><span class="font53" style="font-style:italic;">m</span><span class="font53">th mini-slot of the bit-transmission time of </span><span class="font53" style="font-style:italic;">d<sub>i</sub></span><span class="font53">, the output of the CDMA encoder, </span><span class="font53" style="font-style:italic;">Z<sub>imi</sub>,</span><span class="font53"> is the value of </span><span class="font53" style="font-style:italic;">d<sub>i</sub></span><span class="font53"> multiplied by the </span><span class="font53" style="font-style:italic;">m</span><span class="font53">th bit in the assigned CDMA code, </span><span class="font53" style="font-style:italic;">c<sub>m</sub></span><span class="font53">:</span></p>
<p><span class="font53" style="font-style:italic;">Z</span><span class="font50" style="font-style:italic;">i</span><span class="font50">,</span><span class="font50" style="font-style:italic;">m</span><span class="font54"> = </span><span class="font50" style="font-style:italic;">di</span><span class="font60"> • </span><span class="font53" style="font-style:italic;">C</span><span class="font50" style="font-style:italic;">m</span><span class="font53"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(7.1)</span></p>
<div>
<p><span class="font5" style="font-weight:bold;">Sender</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Data bits</span></p>
<p><span class="font4">Code</span></p><img src="networking_files/networking-484.jpg" alt="" style="width:195pt;height:101pt;">
<p><span class="font4">Time slot 1</span></p>
<p><span class="font4">Time slot 0</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Channel output </span><span class="font4" style="font-style:italic;">Z<sub>im</sub></span></p>
<table border="1">
<tr><td colspan="3"></td><td style="vertical-align:middle;">
<p><span class="font4">1</span></p></td><td></td><td style="vertical-align:middle;">
<p><span class="font4">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">1</span></p></td><td></td><td style="vertical-align:middle;">
<p><span class="font4">1</span></p></td><td colspan="3"></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font4">-1</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">-1</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">-1</span></p></td><td></td><td style="vertical-align:middle;">
<p><span class="font4">-1</span></p></td><td colspan="6"></td><td style="vertical-align:middle;">
<p><span class="font4">-1</span></p></td><td></td><td style="vertical-align:middle;">
<p><span class="font4">-1</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">-1</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">-1</span></p></td></tr>
</table>
<p><span class="font4">Time slot 1 Time slot 0</span></p>
<p><span class="font4">channel output channel output</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-485.jpg" alt="" style="width:230pt;height:140pt;">
<p><span class="font7" style="font-weight:bold;">Figure 7.5 </span><span class="font50">♦ </span><span class="font5">A simple CDMA example: Sender encoding, receiver decoding</span></p>
</div><br clear="all">
<p><span class="font53">In a simple world, with no interfering senders, the receiver would receive the encoded bits, </span><span class="font53" style="font-style:italic;">Z<sub>im</sub>,</span><span class="font53"> and recover the original data bit, </span><span class="font53" style="font-style:italic;">d<sub>t</sub>,</span><span class="font53"> by computing:</span></p>
<p><span class="font53" style="font-style:italic;"><sup>d</sup></span><span class="font50" style="font-style:italic;">i </span><span class="font53" style="font-style:italic;">= 1 E<sup>Z</sup></span><span class="font50" style="font-style:italic;">i</span><span class="font49" style="font-style:italic;">,</span><span class="font53" style="font-style:italic;">m • c<sub>m</sub></span><span class="font53"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(7.2)</span></p>
<p><span class="font53" style="font-style:italic;"><sup>M</sup> </span><span class="font50" style="font-style:italic;">m </span><span class="font51" style="font-style:italic;">=</span><span class="font50"> 1</span></p>
<p><span class="font53">The reader might want to work through the details of the example in Figure 7.5 to see that the original data bits are indeed correctly recovered at the receiver using Equation 7.2.</span></p>
<p><span class="font53">The world is far from ideal, however, and as noted above, CDMA must work in the presence of interfering senders that are encoding and transmitting their data using a different assigned code. But how can a CDMA receiver recover a sender’s original data bits when those data bits are being tangled with bits being transmitted by other senders? CDMA works under the assumption that the interfering transmitted bit signals are additive. This means, for example, that if three senders send a 1 value, and a fourth sender sends a </span><span class="font55">— </span><span class="font53">1 value during the same mini-slot, then the received signal at all receivers during that mini-slot is a 2 (since 1 </span><span class="font55">+ </span><span class="font53">1 </span><span class="font55">+ </span><span class="font53">1 </span><span class="font55">— </span><span class="font53">1 </span><span class="font54">= </span><span class="font53">2). In the presence of multiple senders, sender </span><span class="font53" style="font-style:italic;">s</span><span class="font53"> computes its encoded transmissions, </span><span class="font53" style="font-style:italic;">Z<sup>s</sup><sub>im</sub>,</span><span class="font53"> in exactly the same manner as in Equation 7.1. The value received at a receiver during the </span><span class="font53" style="font-style:italic;">mth</span><span class="font53"> mini-slot of the </span><span class="font53" style="font-style:italic;">i</span><span class="font53">th bit slot, however, is now the </span><span class="font53" style="font-style:italic;">sum</span><span class="font53"> of the transmitted bits from all </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> senders during that mini-slot:</span></p>
<p><span class="font50" style="font-style:italic;">N</span></p>
<p><span class="font53" style="font-style:italic;">Z</span><span class="font49" style="font-style:italic;">* </span><span class="font50" style="font-style:italic;">m </span><span class="font53" style="font-style:italic;">= </span><span class="font61" style="font-variant:small-caps;">a </span><span class="font53" style="font-style:italic;">Z</span><span class="font50" style="font-style:italic;">Sm s </span><span class="font51" style="font-style:italic;">=</span><span class="font50"> 1</span></p>
<p><span class="font53">Amazingly, if the senders’ codes are chosen carefully, each receiver can recover the data sent by a given sender out of the aggregate signal simply by using the sender’s code in exactly the same manner as in Equation 7.2:</span></p>
<p><span class="font53" style="font-style:italic;">d</span><span class="font50" style="font-style:italic;">i </span><span class="font53" style="font-style:italic;">=</span><span class="font53"> — A</span><span class="font53" style="font-style:italic;">Z</span><span class="font53">*<sub>m</sub> • &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(7.3)</span></p>
<p><span class="font50" style="font-style:italic;">i </span><span class="font11" style="font-style:italic;font-variant:small-caps;">ti</span><span class="font50" style="font-style:italic;"> r i</span><span class="font50">, </span><span class="font50" style="font-style:italic;">m m</span></p>
<p><span class="font53" style="font-style:italic;"><sup>M</sup></span><span class="font50" style="font-style:italic;">m </span><span class="font51" style="font-style:italic;">=</span><span class="font50"> 1</span></p>
<p><span class="font53">as shown in Figure 7.6, for a two-sender CDMA example. The </span><span class="font53" style="font-style:italic;">M</span><span class="font53">-bit CDMA code being used by the upper sender is (1, 1, 1, </span><span class="font55">— </span><span class="font53">1, 1, </span><span class="font55">— </span><span class="font53">1, </span><span class="font55">— </span><span class="font53">1, </span><span class="font55">— </span><span class="font53">1), while the CDMA code being used by the lower sender is (1, </span><span class="font55">— </span><span class="font53">1, 1, 1, 1, </span><span class="font55">— </span><span class="font53">1, 1, 1). Figure 7.6 illustrates a receiver recovering the original data bits from the upper sender. Note that the receiver is able to extract the data from sender 1 in spite of the interfering transmission from sender 2.</span></p>
<p><span class="font53">Recall our cocktail analogy from Chapter 6. A CDMA protocol is similar to having partygoers speaking in multiple languages; in such circumstances humans are actually quite good at locking into the conversation in the language they understand, while filtering out the remaining conversations. We see here that CDMA is a partitioning protocol in that it partitions the codespace (as opposed to time or frequency) and assigns each node a dedicated piece of the codespace.</span></p>
<p><span class="font53">Our discussion here of CDMA is necessarily brief; in practice a number of difficult issues must be addressed. First, in order for the CDMA receivers to be able to extract a particular sender’s signal, the CDMA codes must be carefully chosen. Second, our discussion has assumed that the received signal strengths from various senders are the same; in reality, this can be difficult to achieve. There is a considerable body of literature addressing these and other issues related to CDMA; see [Pickholtz 1982; Viterbi 1995] for details.</span></p>
<p><span class="font5" style="font-weight:bold;">Senders</span></p>
<div>
<p><span class="font4">Data bits</span></p>
<p><span class="font4">Code</span></p>
<p><span class="font4">Data bits</span></p>
<p><span class="font4">Code</span></p><img src="networking_files/networking-486.jpg" alt="" style="width:177pt;height:186pt;">
<p><span class="font4" style="font-style:italic;">d</span><span class="font50" style="font-style:italic;">i ■ </span><span class="font4" style="font-style:italic;">c'</span><span class="font50" style="font-style:italic;">m</span></p>
<p><span class="font4" style="font-style:italic;">di</span><span class="font0"> • </span><span class="font4" style="font-style:italic;">c</span><span class="font50" style="font-style:italic;">m</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-487.jpg" alt="" style="width:26pt;height:41pt;">
</div><br clear="all">
<div><img src="networking_files/networking-488.jpg" alt="" style="width:80pt;height:60pt;">
</div><br clear="all">
<div><img src="networking_files/networking-489.jpg" alt="" style="width:366pt;height:140pt;">
<p><span class="font7" style="font-weight:bold;">Figure 7.6 </span><span class="font50">♦ </span><span class="font5">A two-sender CDMA example</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">7.3 </span><span class="font24" style="font-weight:bold;">WiFi: 802.11 Wireless LANs</span></p></li></ul>
<p><a name="bookmark423"></a><span class="font53">Pervasive in the workplace, the home, educational institutions, cafes, airports, and street corners, wireless LANs are now one of the most important access network technologies in the Internet today. Although many technologies and standards for wireless LANs were developed in the 1990s, one particular class of standards has clearly emerged as the winner: the </span><span class="font53" style="font-weight:bold;">IEEE 802.11 wireless LAN</span><span class="font53">, also known as </span><span class="font53" style="font-weight:bold;">WiFi</span><span class="font53">. In this section, we’ll take a close look at 802.11 wireless LANs, examining its frame structure, its medium access protocol, and its internetworking of 802.11 LANs with wired Ethernet LANs.</span></p>
<p><span class="font53">As summarized in Table 7.1, there are several 802.11 standards [IEEE 802.11 2020]. The 802.11 b, g, n, ac, ax are successive generations of 802.11 technology aimed for wireless local area networks (WLANs), typically less than 70 m range in a home office, workplace, or business setting. The 802.11 n, ac, and ax standards have recently been branded as WiFi 4, 5 and 6, respectively—no doubt competing with 4G and 5G cellular network branding. The 802.11 af, ah standards operate over longer distances and are aimed at Internet of Things, sensor networks, and metering applications.</span></p>
<p><span class="font53">The different 802.11 b, g, n, ac, ax standards all share some common characteristics, including the 802.11 frame format that we will study shortly, and are backward compatible, meaning, for example, that a mobile capable only of 802.11 g may still interact with a newer 802.11 ac or 802.11 ax base station. They also all use the same medium access protocol, CSMA/CA, which we’ll also discuss shortly, while also 802.11 ax also supports centralized scheduling by the base station of transmissions from associated wireless devices.</span></p>
<p><span class="font53">However, as shown in Table 7.1, the standards have some major differences at the physical layer. 802.11 devices operate in two different frequency ranges: 2.4-2.485 GHz (referred to as the 2.4 GHz range) and 5.1-5.8 GHz (referred to as the 5 GHz range). The 2.4 GHz range is an unlicensed frequency band, where 802.11 devices may compete for frequency spectrum with 2.4 GHz phones and appliances such as microwave ovens. At 5 GHz, 802.11 LANs have a shorter transmission distance for a given power level and suffer more from multipath propagation. The 802.11n, 802.11ac, and 802.11ax standards use multiple input multiple-output (MIMO) antennas; that is, two or more antennas on the sending side and two or more antennas on the receiving side that are transmitting/receiving different signals</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font6">IEEE 802.11 standard</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Year</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Max data rate</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Range</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Frequency</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">802.11 b</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">1999</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">11 Mbps</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">30 m</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">2.4 Ghz</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">802.11 g</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">2003</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">54 Mbps</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">30 m</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">2.4 Ghz</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">802.11 n (WiFi 4)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">2009</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">600</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">70 m</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">2.4, 5 Ghz</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">802.11 ac (WiFi 5)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">2013</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">3.47 Gpbs</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">70 m</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">5 Ghz</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">802.11 ax (WiFi 6)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">2020 (expected)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">14 Gbps</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">70 m</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">2.4, 5 Ghz</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">802.11 af</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">2014</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">35-560 Mbps</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">1 Km</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">unused TV bands (54-790 MHz)</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">802.11 ah</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">2017</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">347 Mbps</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">1 Km</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">900 Mhz</span></p></td></tr>
</table>
<p><span class="font53">[Diggavi 2004]. 802.11ac and 802.11 ax base stations may transmit to multiple stations simultaneously, and use “smart” antennas to adaptively beamform to target transmissions in the direction of a receiver. This decreases interference and increases the distance reached at a given data rate. The data rates shown in Table 7.1 are for an idealized environment, for example, a receiver close to the base station, with no interference—a scenario that we’re unlikely to experience in practice! So as the saying goes, YMMV: Your Mileage (or in this case your wireless data rate) May Vary.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">7.3.1 </span><span class="font23" style="font-weight:bold;">The 802.11 Wireless LAN Architecture</span></p></li></ul>
<p><span class="font53">Figure 7.7 illustrates the principal components of the 802.11 wireless LAN architecture. The fundamental building block of the 802.11 architecture is the </span><span class="font53" style="font-weight:bold;">basic service set (BSS)</span><span class="font53">. A BSS contains one or more wireless stations and a central </span><span class="font53" style="font-weight:bold;">base station</span><span class="font53">, known as an </span><span class="font53" style="font-weight:bold;">access point (AP) </span><span class="font53">in 802.11 parlance. Figure 7.7 shows the AP in each of two BSSs connecting to an interconnection device (such as a switch or router), which in turn leads to the Internet. In a typical home network, there is one AP and one router (typically integrated together as one unit) that connects the BSS to the Internet.</span></p>
<p><span class="font53">As with Ethernet devices, each 802.11 wireless station has a 6-byte MAC address that is stored in the firmware of the station’s adapter (that is, 802.11 network interface card). Each AP also has a MAC address for its wireless interface. As with Ethernet, these MAC addresses are administered by IEEE and are (in theory) globally unique.</span></p>
<p><span class="font53">As noted in Section 7.1, wireless LANs that deploy APs are often referred to as </span><span class="font53" style="font-weight:bold;">infrastructure wireless LANs</span><span class="font53">, with the “infrastructure” being the APs along with the</span></p>
<div><img src="networking_files/networking-490.jpg" alt="" style="width:104pt;height:94pt;">
<p><span class="font4" style="font-weight:bold;">BSS 1</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Internet</span></p>
<p><span class="font4">Switch or router</span></p><img src="networking_files/networking-491.jpg" alt="" style="width:145pt;height:161pt;">
<p><span class="font4" style="font-weight:bold;">BSS 2</span></p>
</div><br clear="all">
<p><a name="bookmark424"></a><span class="font7" style="font-weight:bold;">Figure 7.7 </span><span class="font50">♦ </span><span class="font5">IEEE 802.11 LAN architecture</span></p>
<p><span class="font4" style="font-weight:bold;">BSS</span></p><img src="networking_files/networking-492.jpg" alt="" style="width:132pt;height:132pt;">
<p><span class="font7" style="font-weight:bold;">Figure 7.8 </span><span class="font50">♦ </span><span class="font5">An IEEE 802.11 ad hoc network</span></p>
<p><span class="font53">wired Ethernet infrastructure that interconnects the APs and a router. Figure 7.8 shows that IEEE 802.11 stations can also group themselves together to form an ad hoc network—a network with no central control and with no connections to the “outside world.” Here, the network is formed “on the fly,” by mobile devices that have found themselves in proximity to each other, that have a need to communicate, and that find no preexisting network infrastructure in their location. An ad hoc network might be formed when people with laptops get together (e.g., in a conference room, a train, or a car) and want to exchange data in the absence of a centralized AP. There has been tremendous interest in ad hoc networking, as communicating portable devices continue to proliferate. In this section, though, we’ll focus our attention on infrastructure wireless LANs.</span></p>
<p><span class="font22" style="font-weight:bold;">Channels and Association</span></p>
<p><span class="font53">In 802.11, each wireless station needs to associate with an AP before it can send or receive network-layer data. Although all of the 802.11 standards use association, we’ll discuss this topic specifically in the context of IEEE 802.11b, g, n, ac, ax.</span></p>
<p><span class="font53">When a network administrator installs an AP, the administrator assigns a one-or two-word </span><span class="font53" style="font-weight:bold;">Service Set Identifier (SSID) </span><span class="font53">to the access point. (When you choose Wi-Fi under Setting on your iPhone, for example, a list is displayed showing the SSID of each AP in range.) The administrator must also assign a channel number to the AP. To understand channel numbers, recall that 802.11 operates in the frequency range of 2.4 GHz to 2.4835 GHz. Within this 85 MHz band, 802.11 defines 11 partially overlapping channels. Any two channels are non-overlapping if and only if they are separated by four or more channels. In particular, the set of channels 1, 6, and 11 is the only set of three non-overlapping channels. This means that an administrator could create a wireless LAN with an aggregate maximum transmission rate of three times the maximum transmission rate shown in Table 7.1 by installing three 802.11 APs at the same physical location, assigning channels 1, 6, and 11 to the APs, and interconnecting each of the APs with a switch.</span></p>
<p><span class="font53">Now that we have a basic understanding of 802.11 channels, let’s describe an interesting (and not completely uncommon) situation—that of a WiFi jungle. A </span><span class="font53" style="font-weight:bold;">WiFi jungle </span><span class="font53">is any physical location where a wireless station receives a sufficiently strong signal from two or more APs. For example, in many cafes in New York City, a wireless station can pick up a signal from numerous nearby APs. One of the APs might be managed by the cafe, while the other APs might be in residential apartments near the cafe. Each of these APs would likely be located in a different IP subnet and would have been independently assigned a channel.</span></p>
<p><span class="font53">Now suppose you enter such a WiFi jungle with your smartphone, tablet, or laptop, seeking wireless Internet access and a blueberry muffin. Suppose there are five APs in the WiFi jungle. To gain Internet access, your wireless device needs to join exactly one of the subnets and hence needs to </span><span class="font53" style="font-weight:bold;">associate </span><span class="font53">with exactly one of the APs. Associating means the wireless device creates a virtual wire between itself and the AP. Specifically, only the associated AP will send data frames (that is, frames containing data, such as a datagram) to your wireless device, and your wireless device will send data frames into the Internet only through the associated AP. But how does your wireless device associate with a particular AP? And more fundamentally, how does your wireless device know which APs, if any, are out there in the jungle?</span></p>
<p><span class="font53">The 802.11 standard requires that an AP periodically send </span><span class="font53" style="font-weight:bold;">beacon frames</span><span class="font53">, each of which includes the AP’s SSID and MAC address. Your wireless device, knowing that APs are sending out beacon frames, scans the 11 channels, seeking beacon frames from any APs that may be out there (some of which may be transmitting on the same channel—it’s a jungle out there!). Having learned about available APs from the beacon frames, you (or your wireless device) select one of the APs for association.</span></p>
<p><span class="font53">The 802.11 standard does not specify an algorithm for selecting which of the available APs to associate with; that algorithm is left up to the designers of the 802.11 firmware and software in your wireless device. Typically, the device chooses the AP whose beacon frame is received with the highest signal strength. While a high signal strength is good (see, e.g., Figure 7.3), signal strength is not the only AP characteristic that will determine the performance a device receives. In particular, it’s possible that the selected AP may have a strong signal, but may be overloaded with other affiliated devices (that will need to share the wireless bandwidth at that AP), while an unloaded AP is not selected due to a slightly weaker signal. A number of alternative ways of choosing APs have thus recently been proposed [Vasudevan 2005; Nicholson 2006; Sundaresan 2006]. For an interesting and down-to-earth discussion of how signal strength is measured, see [Bardwell 2004].</span></p>
<p><span class="font53">The process of scanning channels and listening for beacon frames is known as </span><span class="font53" style="font-weight:bold;">passive scanning </span><span class="font53">(see Figure 7.9a). A wireless device can also perform </span><span class="font53" style="font-weight:bold;">active scanning</span><span class="font53">, by broadcasting a probe frame that will be received by all APs within the wireless device’s range, as shown in Figure 7.9b. APs respond to the probe request frame with a probe response frame. The wireless device can then choose the AP with which to associate from among the responding APs.</span></p>
<div><img src="networking_files/networking-493.jpg" alt="" style="width:192pt;height:98pt;">
<p><span class="font4" style="font-weight:bold;">a. Passive scanning</span></p>
<ul style="list-style:none;"><li>
<p><span class="font4">1. Beacon frames sent from APs</span></p></li>
<li>
<p><span class="font4">2. Association Request frame sent: H1 to selected </span><span class="font9" style="font-variant:small-caps;">Ap</span></p></li>
<li>
<p><span class="font4">3. Association Response frame sent: Selected AP to H1</span></p></li></ul>
</div><br clear="all">
<div><img src="networking_files/networking-494.jpg" alt="" style="width:192pt;height:98pt;">
<p><span class="font4" style="font-weight:bold;">a. Active scanning</span></p>
<ul style="list-style:none;"><li>
<p><span class="font4">1. Probe Request frame broadcast from H1</span></p></li>
<li>
<p><span class="font4">2. Probes Response frame sent from APs</span></p></li>
<li>
<p><span class="font4">3. Association Request frame sent:</span></p></li></ul>
<p><span class="font4">H1 to selected AP</span></p>
<ul style="list-style:none;"><li>
<p><span class="font4">4. Association Response frame sent:</span></p></li></ul>
<p><span class="font4">Selected AP to H1</span></p>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 7.9 </span><span class="font50">♦ </span><span class="font5">Active and passive scanning for access points</span></p>
<p><span class="font53">After selecting the AP with which to associate, the wireless device sends an association request frame to the AP, and the AP responds with an association response frame. Note that this second request/response handshake is needed with active scanning, since an AP responding to the initial probe request frame doesn’t know which of the (possibly many) responding APs the device will choose to associate with, in much the same way that a DHCP client can choose from among multiple DHCP servers (see Figure 4.21). Once associated with an AP, the device will want to join the subnet (in the IP addressing sense of Section 4.3.3) to which the AP belongs. Thus, the device will typically send a DHCP discovery message (see Figure 4.21) into the subnet via the AP in order to obtain an IP address on the subnet. Once the address is obtained, the rest of the world then views that device simply as another host with an IP address in that subnet.</span></p>
<p><span class="font53">In order to create an association with a particular AP, the wireless device may be required to authenticate itself to the AP. 802.11 wireless LANs provide a number of alternatives for authentication and access. One approach, used by many companies, is to permit access to a wireless network based on a device’s MAC address. A second approach, used by many Internet cafes, employs usernames and passwords. In both cases, the AP typically communicates with an authentication server, relaying information between the wireless device and the authentication server using a protocol such as RADIUS [RFC 2865] or DIAMETER [RFC 6733]. Separating the authentication server from the AP allows one authentication server to serve many APs, centralizing the (often sensitive) decisions of authentication and access within the single server, and keeping AP costs and complexity low. We’ll see in chapter 8 that the new IEEE 802.11i protocol defining security aspects of the 802.11 protocol family takes precisely this approach.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">7.3.2 </span><span class="font23" style="font-weight:bold;">The 802.11 MAC Protocol</span></p></li></ul>
<p><span class="font53">Once a wireless device is associated with an AP, it can start sending and receiving data frames to and from the access point. But because multiple wireless devices, or the AP itself may want to transmit data frames at the same time over the same channel, a multiple access protocol is needed to coordinate the transmissions. In the following, we'll refer to the devices or the AP as wireless “stations” that share the multiple access channel. As discussed in Chapter 6 and Section 7.2.1, broadly speaking there are three classes of multiple access protocols: channel partitioning (including CDMA), random access, and taking turns. Inspired by the huge success of Ethernet and its random access protocol, the designers of 802.11 chose a random access protocol for 802.11 wireless LANs. This random access protocol is referred to as </span><span class="font53" style="font-weight:bold;">CSMA with collision avoidance</span><span class="font53">, or more succinctly as </span><span class="font53" style="font-weight:bold;">CSMA/CA</span><span class="font53">. As with Ethernet’s CSMA/CD, the “CSMA” in CSMA/CA stands for “carrier sense multiple access,” meaning that each station senses the channel before transmitting, and refrains from transmitting when the channel is sensed busy. Although both Ethernet and 802.11 use carrier-sensing random access, the two MAC protocols have important differences. First, instead of using collision detection, 802.11 uses collision-avoidance techniques. Second, because of the relatively high bit error rates of wireless channels, 802.11 (unlike Ethernet) uses a link-layer acknowledgment/retransmission (ARQ) scheme. We’ll describe 802.11’s collision-avoidance and link-layer acknowledgment schemes below.</span></p>
<p><span class="font53">Recall from Sections 6.3.2 and 6.4.2 that with Ethernet’s collision-detection algorithm, an Ethernet station listens to the channel as it transmits. If, while transmitting, it detects that another station is also transmitting, it aborts its transmission and tries to transmit again after waiting a small, random amount of time. Unlike the 802.3 Ethernet protocol, the 802.11 MAC protocol does </span><span class="font53" style="font-style:italic;">not</span><span class="font53"> implement collision detection. There are two important reasons for this:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;The ability to detect collisions requires the ability to send (the station’s own signal) and receive (to determine whether another station is also transmitting) at the same time. Because the strength of the received signal is typically very small compared to the strength of the transmitted signal at the 802.11 adapter, it is costly to build hardware that can detect a collision.</span></p></li>
<li>
<p><span class="font53">• &nbsp;More importantly, even if the adapter could transmit and listen at the same time (and presumably abort transmission when it senses a busy channel), the adapter would still not be able to detect all collisions, due to the hidden terminal problem and fading, as discussed in Section 7.2.</span></p></li></ul>
<p><a name="bookmark425"></a><span class="font53">Because 802.11wireless LANs do not use collision detection, once a station begins to transmit a frame, </span><span class="font53" style="font-style:italic;">it transmits the frame in its entirety;</span><span class="font53"> that is, once a station</span></p>
<div>
<p><span class="font4" style="font-weight:bold;">Source</span></p><img src="networking_files/networking-495.jpg" alt="" style="width:40pt;height:42pt;">
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Destination</span></p><img src="networking_files/networking-496.jpg" alt="" style="width:39pt;height:42pt;">
</div><br clear="all">
<div><img src="networking_files/networking-497.jpg" alt="" style="width:172pt;height:211pt;">
<p><span class="font7" style="font-weight:bold;">Figure 7.10 </span><span class="font50">♦ </span><span class="font5">802.11 uses link-layer acknowledgments</span></p>
</div><br clear="all">
<p><span class="font53">gets started, there is no turning back. As one might expect, transmitting entire frames (particularly long frames) when collisions are prevalent can significantly degrade a multiple access protocol’s performance. In order to reduce the likelihood of collisions, 802.11 employs several collision-avoidance techniques, which we’ll shortly discuss.</span></p>
<p><span class="font53">Before considering collision avoidance, however, we’ll first need to examine 802.11’s </span><span class="font53" style="font-weight:bold;">link-layer acknowledgment </span><span class="font53">scheme. Recall from Section 7.2 that when a station in a wireless LAN sends a frame, the frame may not reach the destination station intact for a variety of reasons. To deal with this non-negligible chance of failure, the 802.11 MAC protocol uses link-layer acknowledgments. As shown in Figure 7.10, when the destination station receives a frame that passes the CRC, it waits a short period of time known as the </span><span class="font53" style="font-weight:bold;">Short Inter-frame Spacing (SIFS) </span><span class="font53">and then sends back an acknowledgment frame. If the transmitting station does not receive an acknowledgment within a given amount of time, it assumes that an error has occurred and retransmits the frame, using the CSMA/CA protocol to access the channel. If an acknowledgment is not received after some fixed number of retransmissions, the transmitting station gives up and discards the frame.</span></p>
<p><span class="font53">Having discussed how 802.11 uses link-layer acknowledgments, we’re now in a position to describe the 802.11 CSMA/CA protocol. Suppose that a station (wireless device or an AP) has a frame to transmit.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">1. &nbsp;If initially the station senses the channel idle, it transmits its frame after a short period of time known as the </span><span class="font53" style="font-weight:bold;">Distributed Inter-frame Space (DIFS)</span><span class="font53">; see Figure 7.10.</span></p></li>
<li>
<p><span class="font53">2. Otherwise, the station chooses a random backoff value using binary exponential backoff (as we encountered in Section 6.3.2) and counts down this value after DIFS when the channel is sensed idle. While the channel is sensed busy, the counter value remains frozen.</span></p></li>
<li>
<p><span class="font53">3. When the counter reaches zero (note that this can only occur while the channel is sensed idle), the station transmits the entire frame and then waits for an acknowledgment.</span></p></li>
<li>
<p><span class="font53">4. If an acknowledgment is received, the transmitting station knows that its frame has been correctly received at the destination station. If the station has another frame to send, it begins the CSMA/CA protocol at step 2. If the acknowledgment isn’t received, the transmitting station reenters the backoff phase in step 2, with the random value chosen from a larger interval.</span></p></li></ul>
<p><span class="font53">Recall that under Ethernet’s CSMA/CD, multiple access protocol (Section 6.3.2), a station begins transmitting as soon as the channel is sensed idle. With CSMA/CA, however, the station refrains from transmitting while counting down, even when it senses the channel to be idle. Why do CSMA/CD and CDMA/CA take such different approaches here?</span></p>
<p><span class="font53">To answer this question, let’s consider a scenario in which two stations each have a data frame to transmit, but neither station transmits immediately because each senses that a third station is already transmitting. With Ethernet’s CSMA/CD, the two stations would each transmit as soon as they detect that the third station has finished transmitting. This would cause a collision, which isn’t a serious issue in CSMA/CD, since both stations would abort their transmissions and thus avoid the useless transmissions of the remainders of their frames. In 802.11, however, the situation is quite different. Because 802.11 does not detect a collision and abort transmission, a frame suffering a collision will be transmitted in its entirety. The goal in 802.11 is thus to avoid collisions whenever possible. In 802.11, if the two stations sense the channel busy, they both immediately enter random backoff, hopefully choosing different backoff values. If these values are indeed different, once the channel becomes idle, one of the two stations will begin transmitting before the other, and (if the two stations are not hidden from each other) the “losing station” will hear the “winning station’s” signal, freeze its counter, and refrain from transmitting until the winning station has completed its transmission. In this manner, a costly collision is avoided. Of course, collisions can still occur with 802.11 in this scenario: The two stations could be hidden from each other, or the two stations could choose random backoff values that are close enough that the transmission from the station starting first have yet to reach the second station. Recall that we encountered this problem earlier in our discussion of random access algorithms in the context of Figure 6.12.</span></p>
<p><span class="font22" style="font-weight:bold;">Dealing with Hidden Terminals: RTS and CTS</span></p>
<p><span class="font53">The 802.11 MAC protocol also includes a nifty (but optional) reservation scheme that helps avoid collisions even in the presence of hidden terminals. Let’s investigate this scheme in the context of Figure 7.11, which shows two wireless stations and one access point. Both of the wireless stations are within range of the AP (whose coverage is shown as a shaded circle) and both have associated with the AP. However, due to fading, the signal ranges of wireless stations are limited to the interiors of the shaded circles shown in Figure 7.11. Thus, each of the wireless stations is hidden from the other, although neither is hidden from the AP.</span></p>
<p><span class="font53">Let’s now consider why hidden terminals can be problematic. Suppose Station H1 is transmitting a frame and halfway through H1’s transmission, Station H2 wants to send a frame to the AP. H2, not hearing the transmission from H1, will first wait a DIFS interval and then transmit the frame, resulting in a collision. The channel will therefore be wasted during the entire period of H1’s transmission as well as during H2’s transmission.</span></p>
<p><span class="font53">In order to avoid this problem, the IEEE 802.11 protocol allows a station to use a short </span><span class="font53" style="font-weight:bold;">Request to Send (RTS) </span><span class="font53">control frame and a short </span><span class="font53" style="font-weight:bold;">Clear to Send (CTS) </span><span class="font53">control frame to </span><span class="font53" style="font-style:italic;">reserve</span><span class="font53"> access to the channel. When a sender wants to send a DATA frame, it can first send an RTS frame to the AP, indicating the total time required to transmit the DATA frame and the acknowledgment (ACK) frame. When the AP receives the RTS frame, it responds by broadcasting a CTS frame. This CTS frame</span></p><img src="networking_files/networking-498.jpg" alt="" style="width:153pt;height:153pt;">
<p><span class="font7" style="font-weight:bold;">Figure 7.11 </span><span class="font50">♦ </span><span class="font5">Hidden terminal example: H1 is hidden from H2, and vice versa</span></p>
<p><span class="font53">serves two purposes: It gives the sender explicit permission to send and also instructs the other stations not to send for the reserved duration.</span></p>
<p><span class="font53">Thus, in Figure 7.12, before transmitting a DATA frame, H1 first broadcasts an RTS frame, which is heard by all stations in its circle, including the AP. The AP then responds with a CTS frame, which is heard by all stations within its range, including H1 and H2. Station H2, having heard the CTS, refrains from transmitting for the time specified in the CTS frame. The RTS, CTS, DATA, and ACK frames are shown in Figure 7.12.</span></p>
<p><span class="font4" style="font-weight:bold;">Source</span></p>
<p><span class="font4" style="font-weight:bold;">Destination &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;All other nodes</span></p><img src="networking_files/networking-499.jpg" alt="" style="width:275pt;height:42pt;"><img src="networking_files/networking-500.jpg" alt="" style="width:264pt;height:326pt;">
<p><span class="font7" style="font-weight:bold;">Figure 7.12 </span><span class="font50">♦ </span><span class="font5">Collision avoidance using the RTS and CTS frames</span></p>
<p><span class="font53">The use of the RTS and CTS frames can improve performance in two important ways:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;The hidden station problem is mitigated, since a long DATA frame is transmitted only after the channel has been reserved.</span></p></li>
<li>
<p><span class="font53">• &nbsp;Because the RTS and CTS frames are short, a collision involving an RTS or CTS frame will last only for the duration of the short RTS or CTS frame. Once the RTS and CTS frames are correctly transmitted, the following DATA and ACK frames should be transmitted without collisions.</span></p></li></ul>
<p><span class="font53">You are encouraged to check out the 802.11 animation in the textbook’s Web site. This interactive animation illustrates the CSMA/CA protocol, including the RTS/ CTS exchange sequence.</span></p>
<p><span class="font53">Although the RTS/CTS exchange can help reduce collisions, it also introduces delay and consumes channel resources. For this reason, the RTS/CTS exchange is only used (if at all) to reserve the channel for the transmission of a long DATA frame. In practice, each wireless station can set an RTS threshold such that the RTS/ CTS sequence is used only when the frame is longer than the threshold. For many wireless stations, the default RTS threshold value is larger than the maximum frame length, so the RTS/CTS sequence is skipped for all DATA frames sent.</span></p>
<p><span class="font22" style="font-weight:bold;">Using 802.11 as a Point-to-Point Link</span></p>
<p><span class="font53">Our discussion so far has focused on the use of 802.11 in a multiple access setting. We should mention that if two nodes each have a directional antenna, they can point their directional antennas at each other and run the 802.11 protocol over what is essentially a point-to-point link. Given the low cost of commodity 802.11 hardware, the use of directional antennas and an increased transmission power allow 802.11 to be used as an inexpensive means of providing wireless point-to-point connections over tens of kilometers distance. [Raman 2007] describes one of the first such multi-hop wireless networks, operating in the rural Ganges plains in India using point-to-point 802.11 links.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">7.3.3 </span><span class="font23" style="font-weight:bold;">The IEEE 802.11 Frame</span></p></li></ul>
<p><span class="font53">Although the 802.11 frame shares many similarities with an Ethernet frame, it also contains a number of fields that are specific to its use for wireless links. The 802.11 frame is shown in Figure 7.13. The numbers above each of the fields in the frame represent the lengths of the fields in </span><span class="font53" style="font-style:italic;">bytes;</span><span class="font53"> the numbers above each of the subfields in the frame control field represent the lengths of the subfields in </span><span class="font53" style="font-style:italic;">bits.</span><span class="font53"> Let’s now examine the fields in the frame as well as some of the more important subfields in the frame’s control field.</span></p>
<p><span class="font22" style="font-weight:bold;">Payload and CRC Fields</span></p>
<p><a name="bookmark426"></a><span class="font53">At the heart of the frame is the payload, which typically consists of an IP datagram or an ARP packet. Although the field is permitted to be as long as 2,312 bytes, it is</span></p>
<p><span class="font4" style="font-weight:bold;">Frame (numbers indicate field length in bytes):</span></p>
<table border="1">
<tr><td>
<p><span class="font4">2</span></p></td><td>
<p><span class="font4">2</span></p></td><td>
<p><span class="font4">6</span></p></td><td>
<p><span class="font4">6</span></p></td><td>
<p><span class="font4">6</span></p></td><td>
<p><span class="font4">2</span></p></td><td>
<p><span class="font4">6</span></p></td><td>
<p><span class="font4">0-2312</span></p></td><td>
<p><span class="font4">4</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font4">Frame control</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Duration</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Address</span></p>
<p><span class="font4">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Address</span></p>
<p><span class="font4">2</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Address</span></p>
<p><span class="font4">3</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Seq control</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Address</span></p>
<p><span class="font4">4</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Payload</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">CRC</span></p></td></tr>
</table>
<p><span class="font4" style="font-weight:bold;">Frame control field expanded (numbers indicate field length in bits):</span></p>
<table border="1">
<tr><td>
<p><span class="font4">2</span></p></td><td>
<p><span class="font4">2</span></p></td><td>
<p><span class="font4">4</span></p></td><td>
<p><span class="font4">1</span></p></td><td>
<p><span class="font4">1</span></p></td><td>
<p><span class="font4">1</span></p></td><td>
<p><span class="font4">1</span></p></td><td>
<p><span class="font4">1</span></p></td><td>
<p><span class="font4">1</span></p></td><td>
<p><span class="font4">1</span></p></td><td>
<p><span class="font4">1</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">Protocol</span></p></td><td rowspan="2" style="vertical-align:middle;">
<p><span class="font4">Type</span></p></td><td rowspan="2" style="vertical-align:middle;">
<p><span class="font4">Subtype</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">To</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">From</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">More</span></p></td><td rowspan="2" style="vertical-align:middle;">
<p><span class="font4">Retry</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">Power</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">More</span></p></td><td rowspan="2" style="vertical-align:middle;">
<p><span class="font4">WEP</span></p></td><td rowspan="2" style="vertical-align:middle;">
<p><span class="font4">Rsvd</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font4">version</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">AP</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">AP</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">frag</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">mgt</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">data</span></p></td></tr>
</table>
<p><span class="font7" style="font-weight:bold;">Figure 7.13 </span><span class="font50">♦ </span><span class="font5">The 802.11 frame</span></p>
<p><span class="font53">typically fewer than 1,500 bytes, holding an IP datagram or an ARP packet. As with an Ethernet frame, an 802.11 frame includes a 32-bit cyclic redundancy check (CRC) so that the receiver can detect bit errors in the received frame. As we’ve seen, bit errors are much more common in wireless LANs than in wired LANs, so the CRC is even more useful here.</span></p>
<p><span class="font22" style="font-weight:bold;">Address Fields</span></p>
<p><span class="font53">Perhaps the most striking difference in the 802.11 frame is that it has </span><span class="font53" style="font-style:italic;">four</span><span class="font53"> address fields, each of which can hold a 6-byte MAC address. But why four address fields? Doesn’t a source MAC field and destination MAC field suffice, as they do for Ethernet? It turns out that three address fields are needed for internetworking purposes—specifically, for moving the network-layer datagram from a wireless station through an AP to a router interface. The fourth address field is used when APs forward frames to each other in ad hoc mode. Since we are only considering infrastructure networks here, let’s focus our attention on the first three address fields. The 802.11 standard defines these fields as follows:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;Address 2 is the MAC address of the station that transmits the frame. Thus, if a wireless station transmits the frame, that station’s MAC address is inserted in the address 2 field. Similarly, if an AP transmits the frame, the AP’s MAC address is inserted in the address 2 field.</span></p></li>
<li>
<p><span class="font53">• &nbsp;Address 1 is the MAC address of the wireless station that is to receive the frame. Thus if a mobile wireless station transmits the frame, address 1 contains the MAC address of the destination AP. Similarly, if an AP transmits the frame, address 1 contains the MAC address of the destination wireless station.</span></p></li>
<li>
<p><span class="font53">• &nbsp;To understand address 3, recall that the BSS (consisting of the AP and wireless stations) is part of a subnet, and that this subnet connects to other subnets via some router interface. Address 3 contains the MAC address of this router interface.</span></p></li></ul>
<p><span class="font4">Internet</span></p>
<p><span class="font4">Router</span></p><img src="networking_files/networking-501.jpg" alt="" style="width:258pt;height:174pt;">
<p><span class="font4" style="font-weight:bold;">BSS 1</span></p>
<p><span class="font4" style="font-weight:bold;">BSS 2</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 7.14 </span><span class="font50">♦ </span><span class="font5">The use of address fields in 802.11 frames: Sending frames between H1 and R1</span></p>
<p><span class="font53">To gain further insight into the purpose of address 3, let’s walk through an internetworking example in the context of Figure 7.14. In this figure, there are two APs, each of which is responsible for a number of wireless stations. Each of the APs has a direct connection to a router, which in turn connects to the global Internet. We should keep in mind that an AP is a link-layer device, and thus neither “speaks” IP nor understands IP addresses. Consider now moving a datagram from the router interface R1 to the wireless Station H1. The router is not aware that there is an AP between it and H1; from the router’s perspective, H1 is just a host in one of the subnets to which it (the router) is connected.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;The router, which knows the IP address of H1 (from the destination address of the datagram), uses ARP to determine the MAC address of H1, just as in an ordinary Ethernet LAN. After obtaining H1’s MAC address, router interface R1 encapsulates the datagram within an Ethernet frame. The source address field of this frame contains R1’s MAC address, and the destination address field contains H1’s MAC address.</span></p></li>
<li>
<p><span class="font53">• &nbsp;When the Ethernet frame arrives at the AP, the AP converts the 802.3 Ethernet frame to an 802.11 frame before transmitting the frame into the wireless channel. The AP fills in address 1 and address 2 with H1’s MAC address and its own MAC address, respectively, as described above. For address 3, the AP inserts the MAC address of R1. In this manner, H1 can determine (from address 3) the MAC address of the router interface that sent the datagram into the subnet.</span></p></li></ul>
<p><span class="font53">Now consider what happens when the wireless station H1 responds by moving a datagram from H1 to R1.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;H1 creates an 802.11 frame, filling the fields for address 1 and address 2 with the AP’s MAC address and H1’s MAC address, respectively, as described above. For address 3, H1 inserts R1’s MAC address.</span></p></li>
<li>
<p><span class="font53">• &nbsp;When the AP receives the 802.11 frame, it converts the frame to an Ethernet frame. The source address field for this frame is H1’s MAC address, and the destination address field is R1’s MAC address. Thus, address 3 allows the AP to determine the appropriate destination MAC address when constructing the Ethernet frame.</span></p></li></ul>
<p><span class="font53">In summary, address 3 plays a crucial role for internetworking the BSS with a wired LAN.</span></p>
<p><span class="font22" style="font-weight:bold;">Sequence Number, Duration, and Frame Control Fields</span></p>
<p><span class="font53">Recall that in 802.11, whenever a station correctly receives a frame from another station, it sends back an acknowledgment. Because acknowledgments can get lost, the sending station may send multiple copies of a given frame. As we saw in our discussion of the rdt2.1 protocol (Section 3.4.1), the use of sequence numbers allows the receiver to distinguish between a newly transmitted frame and the retransmission of a previous frame. The sequence number field in the 802.11 frame thus serves exactly the same purpose here at the link layer as it did in the transport layer in Chapter 3.</span></p>
<p><span class="font53">Recall that the 802.11 protocol allows a transmitting station to reserve the channel for a period of time that includes the time to transmit its data frame and the time to transmit an acknowledgment. This duration value is included in the frame’s duration field (both for data frames and for the RTS and CTS frames).</span></p>
<p><span class="font53">As shown in Figure 7.13, the frame control field includes many subfields. We’ll say just a few words about some of the more important subfields; for a more complete discussion, you are encouraged to consult the 802.11 specification [Held 2001; Crow 1997; IEEE 802.11 1999]. The </span><span class="font53" style="font-style:italic;">type</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">subtype</span><span class="font53"> fields are used to distinguish the association, RTS, CTS, ACK, and data frames. The </span><span class="font53" style="font-style:italic;">to</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">from</span><span class="font53"> fields are used to define the meanings of the different address fields. (These meanings change depending on whether ad hoc or infrastructure modes are used and, in the case of infrastructure mode, whether a wireless station or an AP is sending the frame.) Finally the WEP field indicates whether encryption is being used or not (WEP is discussed in Chapter 8).</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">7.3.4 </span><span class="font23" style="font-weight:bold;">Mobility in the Same IP Subnet</span></p></li></ul>
<p><a name="bookmark427"></a><span class="font53">In order to increase the physical range of a wireless LAN, companies and universities will often deploy multiple BSSs within the same IP subnet. This naturally raises the issue of mobility among the BSSs—how do wireless stations seamlessly move from one BSS to another while maintaining ongoing TCP sessions? As we’ll see in this subsection, mobility can be handled in a relatively straightforward manner when the BSSs are part of the subnet. When stations move between subnets, more sophisticated mobility management protocols will be needed, such as those we’ll study in Sections 7.5 and 7.6.</span></p>
<p><span class="font53">Let’s now look at a specific example of mobility between BSSs in the same subnet. Figure 7.15 shows two interconnected BSSs with a host, H1, moving from BSS1 to BSS2. Because in this example the interconnection device that connects the two BSSs is </span><span class="font53" style="font-style:italic;">not</span><span class="font53"> a router, all of the stations in the two BSSs, including the APs, belong to the same IP subnet. Thus, when H1 moves from BSS1 to BSS2, it may keep its IP address and all of its ongoing TCP connections. If the interconnection device were a router, then H1 would have to obtain a new IP address in the subnet in which it was moving. This address change would disrupt (and eventually terminate) any on-going TCP connections at H1. In Section 7.6, we’ll see how a network-layer mobility protocol, such as mobile IP, can be used to avoid this problem.</span></p>
<p><span class="font53">But what specifically happens when H1 moves from BSS1 to BSS2? As H1 wanders away from AP1, H1 detects a weakening signal from AP1 and starts to scan for a stronger signal. H1 receives beacon frames from AP2 (which in many corporate and university settings will have the same SSID as AP1). H1 then disassociates with AP1 and associates with AP2, while keeping its IP address and maintaining its ongoing TCP sessions.</span></p>
<p><span class="font53">This addresses the handover problem from the host and AP viewpoint. But what about the switch in Figure 7.15? How does it know that the host has moved from one AP to another? As you may recall from Chapter 6, switches are “self-learning” and automatically build their forwarding tables. This self-learning feature nicely handles occasional moves (for example, when an employee gets transferred from one department to another); however, switches were not designed to support highly mobile users who want to maintain TCP connections while moving between BSSs. To appreciate the problem here, recall that before the move, the switch has an entry in its forwarding table that pairs H1’s MAC address with the outgoing switch interface through which H1 can be reached. If H1 is initially in BSS1, then a datagram destined to H1 will be directed to H1 via AP1. Once H1 associates with BSS2, however, its frames should be directed to AP2. One solution (a bit of a hack, really) is for AP2 to send a broadcast Ethernet frame with H1’s source address to the switch just after</span></p>
<p><span class="font4">Switch</span></p><img src="networking_files/networking-502.jpg" alt="" style="width:198pt;height:107pt;">
<p><span class="font7" style="font-weight:bold;">Figure 7.15 </span><span class="font50">♦ </span><span class="font5">Mobility in the same subnet</span></p>
<p><span class="font53">the new association. When the switch receives the frame, it updates its forwarding table, allowing H1 to be reached via AP2. The 802.11f standards group is developing an inter-AP protocol to handle these and related issues.</span></p>
<p><span class="font53">Our discussion above has focused on mobility with the same LAN subnet. Recall that VLANs, which we studied in Section 6.4.4, can be used to connect together islands of LANs into a large virtual LAN that can span a large geographical region. Mobility among base stations within such a VLAN can be handled in exactly the same manner as above [Yu 2011].</span></p>
<div><img src="networking_files/networking-503.jpg" alt="" style="width:168pt;height:22pt;">
</div><br clear="all">
<div>
<p><span class="font23" style="font-weight:bold;">CASE HISTORY</span></p>
</div><br clear="all">
<p><span class="font4" style="font-weight:bold;">LOCATION DISCOVERY: GPS AND WIFI POSITIONING</span></p>
<p><span class="font4">Many of the most useful and important smartphone apps today are location-based mobile apps, including Foursquare, Yelp, Uber, Pokemon Go, and Waze. These software apps all make use of an API that allows them to extract their current geographical position directly from the smartphone. Have you ever wondered how your smartphone obtains its geographical position? Today, it is done by combining two systems, the </span><span class="font5" style="font-weight:bold;">Global Positioning System (GPS) </span><span class="font4">and the </span><span class="font5" style="font-weight:bold;">WiFi Positioning System (WPS)</span><span class="font4">.</span></p>
<p><span class="font4">The GPS, with a constellation of 30+ satellites, broadcasts satellite location and timing information, which in turn is used by each GPS receiver to estimate its geolocation. The United States government created the system, maintains it, and makes it freely accessible to anyone with a GPS receiver. The satellites have very stable atomic clocks that are synchronized with one another and with ground clocks. The satellites also know their locations with great precision. Each GPS satellite continuously broadcasts a radio signal containing its current time and position. If a GPS receiver obtains this information from at least four satellites, it can solve triangulation equations to estimate its position.</span></p>
<p><span class="font4">GPS, however, cannot always provide accurate geolocations if it does not have line-of-sight with at least four GPS satellites or when there is interference from other high-frequency communication systems. This is particularly true in urban environments, where tall buildings frequently block GPS signals. This is where WiFi positioning systems come to the rescue. WiFi positioning systems make use of databases of WiFi access points, which are independently maintained by various Internet companies, including Google, Apple, and Microsoft. Each database contains information about millions of WiFi access points, including each access point’s SSID and an estimate of its geographic location. To understand how a WiFi positioning system makes use of such a database, consider an Android smartphone along with the Google location service. From each nearby access point, the smartphone receives and measures the signal strength of beacon signals (see Section 7.3.1), which contain the access point’s SSID. The smartphone can therefore continually send messages to the Google location service (in the cloud) that include the SSIDs of nearby access points and the corresponding signal strengths. It will also send its GPS position (obtained via the satellite broadcast</span></p>
<p><span class="font4">signals, as described above) when available. Using the signal-strength information, Google will estimate the distance between the smartphone and each of the WiFi access points. Leveraging these estimated distances, it can then solve triangulation equations to estimate the smartphone's geolocation. Finally, this WiFi-based estimate is combined with the GPS satellite-based estimate to form an aggregate estimate, which is then sent back to the smartphone and used by the location-based mobile apps.</span></p>
<p><span class="font4">But you may still be wondering how Google (and Apple, Microsoft, and so on) obtain and maintain the database of access points, and in particular, the access point's geographic location? Recall that for a given access point, every nearby Android smartphone will send to the Google location service the strength of the signal received from the access point as well as the smartphone's estimated location. Given that thousands of smartphones may be passing by the access point during any single day, Google's location service will have </span><span class="font4" style="font-style:italic;">lots</span><span class="font4"> of data at its disposition to use in estimating the access point's position, again by solving triangulation equations. Thus, the access points help the smartphones determine their locations, and in turn the smartphones help the access points determine their locations!</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">7.3.5 </span><span class="font23" style="font-weight:bold;">Advanced Features in 802.11</span></p></li></ul>
<p><span class="font53">We’ll wrap up our coverage of 802.11 with a short discussion of two advanced capabilities found in 802.11 networks. As we’ll see, these capabilities are </span><span class="font53" style="font-style:italic;">not</span><span class="font53"> completely specified in the 802.11 standard, but rather are made possible by mechanisms specified in the standard. This allows different vendors to implement these capabilities using their own (proprietary) approaches, presumably giving them an edge over the competition.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font22" style="font-weight:bold;">802.11 Rate Adaptation</span></p></li></ul>
<p><span class="font53">We saw earlier in Figure 7.3 that different modulation techniques (with the different transmission rates that they provide) are appropriate for different SNR scenarios. Consider, for example, a mobile 802.11 user who is initially 20 meters away from the base station, with a high signal-to-noise ratio. Given the high SNR, the user can communicate with the base station using a physical-layer modulation technique that provides high transmission rates while maintaining a low BER. This is one happy user! Suppose now that the user becomes mobile, walking away from the base station, with the SNR falling as the distance from the base station increases. In this case, if the modulation technique used in the 802.11 protocol operating between the base station and the user does not change, the BER will become unacceptably high as the SNR decreases, and eventually no transmitted frames will be received correctly.</span></p>
<p><a name="bookmark428"></a><span class="font53">For this reason, some 802.11 implementations have a rate adaptation capability that adaptively selects the underlying physical-layer modulation technique to use based on current or recent channel characteristics. If a node sends two frames in a row without receiving an acknowledgment (an implicit indication of bit errors on the channel), the transmission rate falls back to the next lower rate. If 10 frames in a row are acknowledged, or if a timer that tracks the time since the last fallback expires, the transmission rate increases to the next higher rate. This rate adaptation mechanism shares the same “probing” philosophy as TCP’s congestion-control mechanism—when conditions are good (reflected by ACK receipts), the transmission rate is increased until something “bad” happens (the lack of ACK receipts); when something “bad” happens, the transmission rate is reduced. 802.11 rate adaptation and TCP congestion control are thus similar to the young child who is constantly pushing his/her parents for more and more (say candy for a young child, later curfew hours for the teenager) until the parents finally say “Enough!” and the child backs off (only to try again later after conditions have hopefully improved!). A number of other schemes have also been proposed to improve on this basic automatic rateadjustment scheme [Kamerman 1997; Holland 2001; Lacage 2004].</span></p>
<p><span class="font22" style="font-weight:bold;">Power Management</span></p>
<p><span class="font53">Power is a precious resource in mobile devices, and thus the 802.11 standard provides power-management capabilities that allow 802.11 nodes to minimize the amount of time that their sense, transmit, and receive functions and other circuitry need to be “on.” 802.11 power management operates as follows. A node is able to explicitly alternate between sleep and wake states (not unlike a sleepy student in a classroom!). A node indicates to the access point that it will be going to sleep by setting the power-management bit in the header of an 802.11 frame to 1. A timer in the node is then set to wake up the node just before the AP is scheduled to send its beacon frame (recall that an AP typically sends a beacon frame every 100 msec). Since the AP knows from the set power-transmission bit that the node is going to sleep, it (the AP) knows that it should not send any frames to that node, and will buffer any frames destined for the sleeping host for later transmission.</span></p>
<p><span class="font53">A node will wake up just before the AP sends a beacon frame, and quickly enter the fully active state (unlike the sleepy student, this wakeup requires only 250 microseconds [Kamerman 1997]!). The beacon frames sent out by the AP contain a list of nodes whose frames have been buffered at the AP. If there are no buffered frames for the node, it can go back to sleep. Otherwise, the node can explicitly request that the buffered frames be sent by sending a polling message to the AP. With an inter-beacon time of 100 msec, a wakeup time of 250 microseconds, and a similarly small time to receive a beacon frame and check to ensure that there are no buffered frames, a node that has no frames to send or receive can be asleep 99% of the time, resulting in a significant energy savings.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">7.3.6 </span><span class="font23" style="font-weight:bold;">Personal Area Networks: Bluetooth<a name="footnote2"></a><sup><a href="#bookmark429">2</a></sup></span></p></li></ul>
<p><span class="font53" style="font-weight:bold;">Bluetooth </span><span class="font53">networks seem to have quickly become part of everyday life. Perhaps you’ve used a Bluetooth network as a “cable replacement” technology to interconnect your computer with a wireless keyboard, mouse, or other peripheral device. Or perhaps you’ve used a Bluetooth network to connect your wireless earbuds, speaker, watch, or health monitoring band to your smartphone or to connect your smartphone to a car’s audio system. In all of these cases, Bluetooth operates over short ranges (tens of meters or less), at low power, and at low cost. For this reason, Bluetooth networks are sometimes referred to as </span><span class="font53" style="font-weight:bold;">wireless personal area networks </span><span class="font53">(WPANs) or </span><span class="font53" style="font-weight:bold;">piconets.</span></p>
<p><span class="font53">Although Bluetooth networks are small and relatively simple by design, they’re packed with many of the link-level networking techniques that we’ve studied earlier including time division multiplexing (TDM) and frequency division (Section 6.3.1), randomized backoff (Section 6.3.2), polling (Section 6.3.3), error detection </span><span class="font53" style="font-style:italic;">and</span><span class="font53"> correction (Section 6.2), reliable data transfer via ACKs and NAKS (Section 3.4.1). And that’s just considering Bluetooth’s link layer!</span></p>
<p><span class="font53">Bluetooth networks operate in the unlicensed 2.4 GHz Industrial, Scientific and Medical (ISM) radio band along with other home appliances such as microwaves, garage door openers, and cordless phones. As a result, Bluetooth networks are designed explicitly with noise and interference in mind. The Bluetooth wireless channel is operated in a TDM manner, with time slots of 625 microseconds. During each time slot, a sender transmits on one of 79 channels, with the channel (frequency) changing in a known but pseudo-random manner from slot to slot. This form of channel hopping, known as </span><span class="font53" style="font-weight:bold;">frequency-hopping spread spectrum </span><span class="font53">(FHSS), is used so that interference from another device or appliance operating in the ISM band will only interfere with Bluetooth communications in at most a subset of the slots. Bluetooth data rates can reach up to 3 Mbps.</span></p>
<p><span class="font53">Bluetooth networks are ad hoc networks—no network infrastructure (e.g., an access point) is needed. Instead, Bluetooth devices must organize </span><span class="font53" style="font-style:italic;">themselves</span><span class="font53"> into a piconet of up to eight active devices, as shown in Figure 7.16. One of these devices</span></p>
<div><img src="networking_files/networking-504.jpg" alt="" style="width:72pt;height:18pt;">
</div><br clear="all">
<div>
<p><span class="font52">Radius of coverage</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-505.jpg" alt="" style="width:32pt;height:28pt;">
</div><br clear="all">
<div>
<p><span class="font52">Key:</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-506.jpg" alt="" style="width:98pt;height:29pt;">
</div><br clear="all">
<div>
<p><span class="font40">CC Centralized Controller</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-507.jpg" alt="" style="width:14pt;height:14pt;">
<p><span class="font40">Client device</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-508.jpg" alt="" style="width:14pt;height:14pt;">
<p><span class="font40">Parked device</span></p>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 7.16 </span><span class="font50">♦ </span><span class="font5">A Bluetooth piconet</span></p>
<p><span class="font53">is designated as the centralized controller, with the remaining devices acting as clients. The centralized controller node truly rules the piconet—its clock determines time in the piconet (e.g., determines TDM slot boundaries), it determine the slot-to-slot frequency hopping sequence, it controls entry of client devices into the piconet, it controls the power (100 mW, 2.5mW, or 1 mW) at which client devices transmit; and uses polling to grant clients permission to transmit once admitted to the network. In addition to the active devices, there can also be up to 255 “parked” devices in the piconet. These parked devices are often in some form of “sleep mode” to conserve energy (as we saw with 802.11 power management) and will awaken periodically, according to the centralized controller’s schedule, to receive beacon messages from the centralized controller. A parked device cannot communicate until its status has been changed from parked to active by the centralized controller node.</span></p>
<p><span class="font53">Because Bluetooth ad hoc networks must be </span><span class="font53" style="font-weight:bold;">self-organizing</span><span class="font53">, it’s worth looking into how they bootstrap their network structure. When a centralized controller node wants to form a Bluetooth network, it must first determine which other Bluetooth devices are within range; this is the </span><span class="font53" style="font-weight:bold;">neighbor discovery </span><span class="font53">problem. The centralized controller does this by broadcasting a series of 32 inquiry messages, each on a different frequency channel, and repeats the transmission sequence for up to 128 times. A client device listens on its chosen frequency, hoping to hear one of the centralized controller’s inquiry messages on this frequency. When it hears an inquiry message, it backs off a random amount of time between 0 and 0.3 seconds (to avoid collisions with other responding nodes, reminiscent of Ethernet’s binary backoff) and then responds to the centralized controller with a message containing its device ID.</span></p>
<p><span class="font53">Once the Bluetooth centralized controller has discovered all of the potential clients within range, it then invites those clients that it wishes to join the piconet. This second phase is known as </span><span class="font53" style="font-weight:bold;">Bluetooth paging</span><span class="font53">, and is reminiscent of 802.11 clients associating with a base station. Through the paging process, the centralized controller will inform the client of the frequency-hopping pattern to be used, and the sender’s clock. The centralized controller begins the paging process by again sending 32 identical paging invitation messages, each now addressed to a specific client, but again using different frequencies, since that client has yet to learn the frequencyhopping pattern. Once the client replies with an ACK message to the paging invitation message, the centralized controller sends frequency-hopping information, clock synchronization information and an active member address to the client, and then finally polls the client, now using the frequency-hopping pattern, to ensure that the client is connected into the network.</span></p>
<p><span class="font53">In our discussion above, we have only touched on Bluetooth’s wireless networking. Higher level protocols provide for reliable data packet transfer, circuitlike streaming of audio and video, changing transmission power levels, changing active/parked state (and other states), and more. More recent versions of Bluetooth have addressed low energy and security considerations. For more information about Bluetooth, the interested reader should consult [Bisdikian 2001, Colbach 2017, and Bluetooth 2020].</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">7.4 </span><span class="font24" style="font-weight:bold;">Cellular Networks: 4G and 5G</span></p></li></ul>
<p><span class="font53">In the previous section, we examined how a host can access the Internet when within the vicinity of an 802.11 WiFi access point (AP). But as we’ve seen, APs have small coverage areas, and a host certainly will not be able to associate with every AP it encounters. As a result, WiFi access is hardly ubiquitous for a user on the move.</span></p>
<p><span class="font53">By contrast, 4G cellular network access has rapidly become pervasive. A recent measurement study of more than one million US mobile cellular network subscribers found that they can find 4G signals more than 90% of the time, with download speeds of 20 Mbps and higher. Users of Korea’s three major cellular carriers are able to find a 4G signal between 95 and 99.5% of the time [Open Signal 2019]. As a result, it is now commonplace to stream HD videos or participate in videoconferences while on the move in a car, bus, or high-speed train. The ubiquity of 4G Internet access has also enabled myriad new IoT applications such as Internet-connected shared bike and scooter systems, and smartphone applications such as mobile payments (commonplace in China since 2018) and Internet-based messaging (WeChat, WhatsApp, and more).</span></p>
<p><span class="font53">The term </span><span class="font53" style="font-style:italic;">cellular</span><span class="font53"> refers to the fact that the region covered by a cellular network is partitioned into a number of geographic coverage areas, known as </span><span class="font53" style="font-weight:bold;">cells. </span><span class="font53">Each cell contains a </span><span class="font53" style="font-weight:bold;">base station </span><span class="font53">that transmits signals to, and receives signals from, the </span><span class="font53" style="font-weight:bold;">mobile devices </span><span class="font53">currently in its cell. The coverage area of a cell depends on many factors, including the transmitting power of the base station, the transmitting power of the devices, obstructing buildings in the cell, and the height and type of the base station antennas.</span></p>
<p><span class="font53">In this section, we provide an overview of the current 4G and emerging 5G cellular networks. We’ll consider the wireless first hop between the mobile device and the base station, as well as the cellular carrier’s all-IP core network that connects the wireless first hop into the carrier’s network, other carrier networks, and the larger Internet. Perhaps surprisingly (given the origins of mobile cellular networks in the telephony world, which had a </span><span class="font53" style="font-style:italic;">very</span><span class="font53"> different network architecture from the Internet), we’ll encounter many of the architectural principles in 4G networks that we encountered in our Internet-focused studies in Chapters 1-6, including protocol layering, an edge/core distinction, the interconnection of multiple provider networks to form a global “network of networks,” and the clear separation of data and control planes with logically centralized control. We’ll now see these principles through the lens of mobile cellular networks (rather than through an Internet lens) and thus see these principles instantiated in different ways. And of course, with a carrier’s network having an allIP core, we’ll also encounter many of the Internet protocols that we now know well. We’ll cover additional 4G topics—mobility management in Section 7.6, and 4G security in Section 8.8—later, after developing the basic principles needed for these topics.</span></p>
<p><a name="bookmark430"></a><span class="font53">Our discussion here of 4G and 5G networks will be relatively brief. Mobile cellular networking is an area with great breadth and depth, with many universities offering several courses on the topic. Readers seeking a deeper understanding are encouraged to see [Goodman 1997; Kaaranen 2001; Lin 2001; Korhonen 2003; Schiller 2003; Palat 2009; Scourias 2012; Turner 2012; Akyildiz 2010], as well as the particularly excellent and exhaustive books [Mouly 1992; Sauter 2014].</span></p>
<p><span class="font53">Just as Internet RFCs define Internet-standard architecture and protocols, 4G and 5G networks are also defined by standards documents known as Technical Specifications. These documents are freely available online at [3GPP 2020]. Just like RFCs, technical specifications can make for rather dense and detailed reading. But when you have a question, they are the definitive source for answers!</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">7.4.1 </span><span class="font23" style="font-weight:bold;">4G LTE Cellular Networks: Architecture and Elements</span></p></li></ul>
<p><span class="font53">The 4G networks that are pervasive as of this writing in 2020 implement the 4G Long-Term Evolution standard, or more succinctly </span><span class="font53" style="font-weight:bold;">4G LTE</span><span class="font53">. In this section, we’ll describe 4G LTE networks. Figure 7.17 shows the major elements of the 4G LTE network architecture. The network broadly divides into the radio network at the cellular network’s edge and the core network. All network elements communicate with each other using the IP protocol we studied in Chapter 4. As with earlier 2G and 3G networks, 4G LTE is full of rather obtuse acronyms and element names. We’ll try to cut through that jumble by first focusing on element functions and how the various elements of a 4G LTE network interact with each other in both the data and the control planes:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-weight:bold;">Mobile Device. </span><span class="font53">This is a smartphone, tablet, laptop, or IoT device that connects into a cellular carrier’s network. This is where applications such as web browsers, map apps, voice and videoconference apps, mobile payment apps, and so much more are run. The mobile device typically implements the full 5-layer Internet protocol stack, including the transport and application layers, as we saw with hosts at the Internet’s network edge. The mobile device is a network endpoint, with an IP address (obtained through NAT, as we’ll see). The mobile device also has a globally unique 64-bit identifier called the </span><span class="font53" style="font-weight:bold;">International Mobile Subscriber Identity (IMSI)</span><span class="font53">, which is stored on its SIM (Subscriber Identity Module) card. The IMSI identifies the subscriber in the worldwide cellular carrier network system, including the country and home cellular carrier network to which the subscriber belongs. In some ways, the IMSI is analogous to a MAC address. The SIM card also stores information about the services that the subscriber is able to access and encryption key information for that subscriber. In the official 4G LTE jargon, the mobile device is referred to as </span><span class="font53" style="font-weight:bold;">User Equipment (UE)</span><span class="font53">. However, in this textbook, we’ll use the more reader-friendly term “mobile device” throughout. We also note here that a mobile device is not always mobile; for example, the device might be a fixed temperature sensor or a surveillance camera.</span></p></li>
<li>
<p><a name="bookmark431"></a><span class="font53">• &nbsp;</span><span class="font53" style="font-weight:bold;">Base Station. </span><span class="font53">The base station sits at the “edge” of the carrier’s network and is responsible for managing the wireless radio resources and the mobile devices with its coverage area (shown as a hexagonal cell in Figure 7.17). As we’ll see, a mobile device will interact with a base station to attach to the carrier’s network. The base station coordinates device authentication and allocation of resources</span></p></li></ul><img src="networking_files/networking-509.jpg" alt="" style="width:325pt;height:147pt;">
<p><span class="font4">__radio access J</span><span class="font4" style="text-decoration:underline;"> </span><span class="font4">network</span></p>
<p><span class="font4">all-IP Enhanced Packet Core (EPC)</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 7.17 </span><span class="font50">♦ </span><span class="font5">Elements of the 4G LTE architecture</span></p>
<p><span class="font53">(channel access) in the radio access network. In this sense, cellular base station functions are comparable (but by no means identical) to those of APs in wireless LANs. But cellular base stations have several other important roles not found in wireless LANs. In particular, base stations create device-specific IP tunnels from the mobile device to gateways and interact among themselves to handle device mobility among cells. Nearby base stations also coordinate among themselves to manage the radio spectrum to minimize interference between cells. In the official 4G LTE terminology, the base station is referred to as an “</span><span class="font53" style="font-weight:bold;">eNode-B</span><span class="font53">,” which is rather opaque and non-descriptive. In this textbook, we will instead use the reader-friendlier term “base station” throughout.</span></p>
<p><span class="font53">As an aside, if you find LTE terminology a bit opaque, you aren’t alone! The etymology of “eNode-B” is rooted in earlier 3G terminology, where network function points were referred to as “nodes,” with “B” harkening back to earlier “Base Station (BS)” 1G terminology or “Base Transceiver Station (BTS)” in 2G terminology. 4G LTE is an “e”volution over 3G, and hence, an “e” now precedes “Node-B” in 4G LTE terminology. This name opaqueness shows no signs in stopping! In 5G systems, eNode-B functions are now referred to as “ng-eNB”; perhaps you can guess what that acronym stands for!</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-weight:bold;">Home Subscriber Server (HSS). </span><span class="font53">As shown in Figure 7.18, the HSS is a control-plane element. The HSS is a database, storing information about the mobile devices for which the HSS’s network is their home network. It is used in conjunction with the MME (discussed below) for device authentication.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-weight:bold;">Serving Gateway (S-GW), Packet Data Network Gateway (P-GW), and other network routers. </span><span class="font53">As shown in Figure 7.18, the Serving Gateway and the Packet Data Network Gateway are two routers (often collocated in practice) that lie on the data path between the mobile device and the Internet. The PDN Gateway also provides NAT IP addresses to mobile devices and performs NAT functions (see Section 4.3.4). The PDN Gateway is the last LTE element that a datagram originating at a mobile device encounters before entering the larger Internet. To the outside world, the P-GW looks like any other gateway router; the mobility of the mobile nodes within the cellular carrier’s LTE network is hidden from the outside world behind the P-GW. In addition to these gateway routers, a cellular carrier’s all-IP core will have additional routers whose role is similar to that of traditional IP routers—to forward IP datagrams among themselves along paths that will typically terminate at elements of the LTE core network.</span></p></li></ul>
<p><span class="font53">• </span><span class="font53" style="font-weight:bold;">Mobility Management Entity (MME). </span><span class="font53">The MME is also a control-plane element, as shown in Figure 7.18. Along with the HSS, it plays an important role in authenticating a device wanting to connect into its network. It also sets up the tunnels on the data path from/to the device and the PDN Internet gateway router, and maintains information about an active mobile device’s cell location within the carrier’s cellular network. But, as shown in Figure 7.18, it is not in the forwarding path for the mobile device’s datagrams being sent to and from the Internet.</span></p>
<p><span class="font53">o </span><span class="font53" style="font-style:italic;">Authentication.</span><span class="font53"> It is important for the network and the mobile device attaching to the network to </span><span class="font53" style="font-style:italic;">mutually</span><span class="font53"> authenticate each other—for the network to know that the attaching device is indeed the device associated with a given IMSI, and for the mobile device to know that the network to which it is attaching is also a legitimate cellular carrier network. We will cover authentication in Chapter 8 and cover 4G authentication in Section 8.8. Here, we simply note that the MME plays a middleman role between the mobile and Home Subscriber Service (HSS) in the mobile’s home network. Specifically, after receiving an attach request from mobile device, the local MME contacts the HSS in the mobile’s home network. The mobile’s home HSS then returns enough encrypted information to the local MME to prove to the mobile device that the home HSS is performing authentication through this MME, and for the mobile device to prove to the MME that it is indeed the mobile associated with that IMSI. When a mobile device is attached to its home network, the HSS to be contacted during authentication is located within that same home network. However, when a mobile device is roaming on a visited network operated by a different cellular network carrier, the MME in that roaming network will need to contact the HSS in the mobile device’s home network.</span></p>
<p><span class="font53">o </span><span class="font53" style="font-style:italic;">Path setup.</span><span class="font53"> As shown in the bottom half of Figure 7.18, the data path from the mobile device to the carrier’s gateway router consists of a wireless first hop between the mobile device and the base station, and concatenated IP tunnels between the base station and the Serving Gateway, and the Serving Gateway and the PDN Gateway. Tunnels are setup under the control of the MME and used for data forwarding (rather than direct forwarding among network routers) to facilitate device mobility—when a device moves, only the tunnel endpoint</span></p>
<div><img src="networking_files/networking-510.jpg" alt="" style="width:34pt;height:34pt;">
<p><span class="font4">Base station</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-511.jpg" alt="" style="width:135pt;height:75pt;">
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Control plane</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-512.jpg" alt="" style="width:70pt;height:34pt;">
<p><span class="font4">Base station</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-513.jpg" alt="" style="width:107pt;height:16pt;">
<p><span class="font4">S-GW &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;P-GW</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 7.18 </span><span class="font50">♦ </span><span class="font5">LTE data-plane and control-plane elements</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">User data plane</span></p>
</div><br clear="all">
<p><span class="font53">terminating at the base station needs to be changed, while other tunnel endpoints, and the Quality of Service associated with a tunnel, remain unchanged.</span></p>
<p><span class="font53">o </span><span class="font53" style="font-style:italic;">Cell location tracking.</span><span class="font53"> As the device moves between cells, the base stations will update the MME on the device’s location. If the mobile device is in a sleep mode but nonetheless moving between cells, the base stations can no longer track the device’s location. In this case, it will be the responsibility of the MME to locate the device for wakeup, through a process known as </span><span class="font53" style="font-weight:bold;">paging.</span></p>
<p><span class="font53">Table 7.2 summarizes the key LTE architectural elements that we have discussed above and compares these functions with those we encountered in our study of WiFi wireless LANs (WLANs).</span></p>
<table border="1">
<tr><td>
<p><span class="font6">LTE Element</span></p></td><td>
<p><span class="font6">Description &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Similar WLAN function(s)</span></p></td></tr>
<tr><td>
<p><span class="font6">Mobile device (UE: User equipment)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">End user's IP-capable wireless/mobile device &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Host, end-system</span></p>
<p><span class="font6">(e.g., smartphone, tablet, laptop)</span></p></td></tr>
<tr><td>
<p><span class="font6">Base Station (eNode-B)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Network side of wireless access link &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Access point (AP), although the LTE base station</span></p>
<p><span class="font6">into LTE network &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;performs many functions not found in WLANs</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">The Mobility Management Entity (MME)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Coordinator for mobile device services: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Access point (AP), although the MME performs</span></p>
<p><span class="font6">authentication, mobility management &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;many functions not found in WLANs</span></p></td></tr>
<tr><td>
<p><span class="font6">Home Subscriber Server (HSS)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Located in a mobile device's </span><span class="font6" style="font-style:italic;">home</span><span class="font6"> network, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;No WLAN equivalent</span></p>
<p><span class="font6">providing authentication, access privileges in home and visited networks</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Serving Gateway (S-GW), PDN-Gateway (P-GW)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Routers in a cellular carrier's network, coordinating iBGP and eBGP routers in access ISP network forwarding to outside of the carrier's network</span></p></td></tr>
<tr><td>
<p><span class="font6">Radio Access Network</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Wireless link between mobile device and a &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;802.11 wireless link between mobile and AP</span></p>
<p><span class="font6">base station</span></p></td></tr>
</table>
<p><span class="font7" style="font-weight:bold;">Table 7.2 </span><span class="font50">♦ </span><span class="font5">LTE Elements, and similar WLAN (WiFi) functions</span></p>
<div><img src="networking_files/networking-514.jpg" alt="" style="width:168pt;height:22pt;">
</div><br clear="all">
<div>
<p><span class="font23" style="font-weight:bold;">CASE HISTORY</span></p>
</div><br clear="all">
<p><span class="font4" style="font-weight:bold;">THE ARCHITECTURAL EVOLUTION FROM 2G TO 3G TO 4G</span></p>
<p><span class="font4">In a relatively short span of 20 years, cellular carrier networks have undergone an astonishing transition from being almost exclusively circuit-switched telephone networks to being all-IP packet-switched data networks which include voice as just one of many applications. How did this transition happen from an architectural standpoint? Was there a “flag day,” when the previous telephony-oriented networks were turned “off” and the all-IP cellular network was turned “on”? Or did elements in the previous telephony-oriented networks begin taking on dual circuit (legacy) and packet (new) functionality, as we saw with the IPv4-to-IPv6 transition in Section 4.3.5?</span></p>
<p><span class="font4">Figure 7.19 is taken from the earlier 7th edition of this textbook, which covered both 2G and 3G cellular networks. (We have retired this historical material, which is still available on this book’s website, in favor of a deeper coverage of 4G LTE in this 8th edition). Although the 2G network is a circuit-switched mobile telephone network, a comparison of Figures 7.17 and 7.19 illustrates a similar conceptual structure, albeit for voice rather than for data services—a wireless edge controlled by a base station, a gateway from the carrier’s network to the outside world, and aggregation points between the base stations and the gateway.</span></p>
<div><img src="networking_files/networking-515.jpg" alt="" style="width:252pt;height:171pt;">
<p><span class="font4">Base station</span></p>
<p><span class="font4">controller</span></p>
<p><span class="font4">Public Telephone Network</span></p>
<p><span class="font4">Base station controller</span></p>
<p><span class="font4">Switching Center</span></p>
<p><span class="font4">Mobile Gateway Mobile Switching</span></p>
<p><span class="font4">Center</span></p>
<p><span class="font4">Base Station System (BSS)</span></p>
<p><span class="font5" style="font-weight:bold;">Figure 7.19 ♦ </span><span class="font4">Elements of the 2G cellular architecture, supporting circuit-switched voice service with the carrier’s core network</span></p>
</div><br clear="all">
<div>
<p><span class="font4">System (BSS)</span></p>
</div><br clear="all">
<p><span class="font4">Figure 7.20 (also taken from the 7th edition of this textbook) shows the main architectural components of the 3G cellular architecture, which supports both circuit-switched voice service </span><span class="font4" style="font-style:italic;">and</span><span class="font4"> packet-switched data services. Here, the transition from a voice-only network to a combined voice and data network is clear: the existing core 2G cellular voice network elements remained untouched. </span><span class="font4" style="font-style:italic;">However, additional cellular data functionality was added in parallel to, and functioned independently from, the existing core voice network at that time.</span><span class="font4"> As shown in Figure 7.20, the splitting point into these two separate core voice and data networks happened at the network edge, at the base station in the radio access network. The alternative-integrating new data services directly into the core elements of the existing cellular voice network—would have raised the same challenges encountered in integrating new (IPv6) and legacy (IPv4) technologies in the Internet. The carriers also wanted to leverage and exploit their considerable investment of existing infrastructure (and profitable services!) in their existing cellular voice network.</span></p>
<div>
<p><span class="font4">Public Telephone</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Network</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-516.jpg" alt="" style="width:26pt;height:32pt;">
</div><br clear="all">
<div>
<p><span class="font4">Gateway Mobile</span></p><img src="networking_files/networking-517.jpg" alt="" style="width:252pt;height:132pt;">
<p><span class="font4">Switching Center</span></p>
<p><span class="font4">Mobile Switching Center</span></p>
<p><span class="font4">Public Internet</span></p>
<p><span class="font4">Serving GPRS Support Node</span></p>
<p><span class="font4">Gateway GPRS Support Node</span></p>
<p><span class="font5" style="font-weight:bold;">Figure 7.20 ♦ </span><span class="font4">3G system architecture: supporting separate circuit-switched voice service and packet-switched data service with the carrier's core network</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Radio Network</span></p>
<p><span class="font4">Controller (RNC)</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">7.4.2 </span><span class="font23" style="font-weight:bold;">LTE Protocols Stacks</span></p></li></ul>
<p><span class="font53">Since the 4G LTE architecture is an all-IP architecture, we’re already very familiar with the higher-layer protocols in the LTE protocol stack, in particular IP, TCP, UDP, and various application layer protocols, from our studies in Chapters 2 through 5. Consequently, the new LTE protocols that we’ll focus on here are primarily at the link and physical layers, and in mobility management.</span></p>
<p><span class="font53">Figure 7.21 shows the user-plane protocol stacks at the LTE mobile node, the base station, and the serving gateway. We’ll touch on several of LTE’s control-plane protocols later when we study LTE mobility management (Section 7.6) and security (Section 8.8). As we can see from Figure 7.21, most of the new and interesting userplane protocol activity is happening at the wireless radio link between the mobile device and the base station.</span></p>
<p><span class="font53">LTE divides the mobile device’s link layer into three sublayers:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Packet Data Convergence.</span><span class="font53"> This uppermost sublayer of the link layer sits just below IP. The Packet Data Convergence Protocol (PDCP) [3GPP PDCP 2019] performs IP header/compression in order to decrease the number of bits sent over the wireless link, and encryption/decryption of the IP datagram using keys that were established via signaling messages between the LTE mobile device and the Mobility Management Entity (MME) when the mobile device first attached to the network; we’ll cover aspects of LTE security in Section 8.8.2.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Radio Link Control.</span><span class="font53"> The Radio Link Control (RLC) Protocol [3GPP RLCP 2018] performs two important functions: </span><span class="font53" style="font-style:italic;">(i)</span><span class="font53"> fragmenting (on the sending side) and reassembly (on the receiving) of IP datagrams that are too large to fit into</span></p>
<table border="1">
<tr><td rowspan="3"></td><td>
<p><span class="font4">Application</span></p></td><td colspan="2"></td><td>
<p><span class="font4">GTP-U</span></p></td><td rowspan="5"></td><td>
<p><span class="font4">GTP-U</span></p></td><td>
<p><span class="font4">GTP-U</span></p></td></tr>
<tr><td>
<p><span class="font4">Transport</span></p></td><td></td><td></td><td>
<p><span class="font4">UDP</span></p></td><td>
<p><span class="font4">UDP</span></p></td><td>
<p><span class="font4">UDP</span></p></td></tr>
<tr><td>
<p><span class="font4">IP</span></p></td><td rowspan="3"></td><td>
<p><span class="font4">IP</span></p></td><td>
<p><span class="font4">IP</span></p></td><td>
<p><span class="font4">IP</span></p></td><td>
<p><span class="font4">IP</span></p></td></tr>
<tr><td>
<p><span class="font51" style="font-weight:bold;">T</span></p>
<p><span class="font51" style="font-weight:bold;">c</span></p></td><td>
<p><span class="font50">Packet Data Convergence</span></p>
<p><span class="font50">Radio Link</span></p>
<p><span class="font50">Medium Access</span></p></td><td>
<p><span class="font50">Packet Data Convergence</span></p>
<p><span class="font50">Radio Link</span></p>
<p><span class="font50">Medium Access</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">Link</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">Link</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">Link</span></p></td></tr>
<tr><td></td><td style="vertical-align:bottom;">
<p><span class="font4">Physical</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">Physical</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">Physical</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">Physical</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">Physical</span></p></td></tr>
</table>
<div><img src="networking_files/networking-518.jpg" alt="" style="width:70pt;height:31pt;">
<p><span class="font4">Base station</span></p>
<p><a name="bookmark432"></a><span class="font7" style="font-weight:bold;">Figure 7.21 </span><span class="font50">♦ </span><span class="font5">LTE data-plane protocol stacks</span></p>
</div><br clear="all"></li></ul>
<p><span class="font4">to/ from </span><span class="font53">the underlying link-layer frames, and </span><span class="font53" style="font-style:italic;">(ii)</span><span class="font53"> link-layer reliable data transfer at the through the use of an ACK/NAK-based ARQ protocol. Recall the we’ve studied the basic elements of ARQ protocols in Section 3.4.1.</span></p>
<div><img src="networking_files/networking-519.jpg" alt="" style="width:112pt;height:16pt;">
<p><span class="font4">Serving Gateway PDN Gateway</span></p>
<p><span class="font4">(S-GW) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(P-GW)</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Internet</span></p>
</div><br clear="all">
<p><span class="font53">• </span><span class="font53" style="font-style:italic;">Medium Access Control (MAC).</span><span class="font53"> The MAC layer performs transmission scheduling, that is, the requesting and use of the radio transmission slots described in Section 7.4.4. The MAC sublayer also performs additional error detection/ correction functions, including the use of redundant bit transmission as a forward error-correction technique. The amount of redundancy can be adapted to channel conditions.</span></p>
<p><span class="font53">Figure 7.21 also shows the use of tunnels in the user data path. As discussed above, these tunnels are established, under MME control, when the mobile device first attaches to the network. Each tunnel between two endpoints has a unique tunnel endpoint identifier (TEID). When the base station receives datagrams from the mobile device, it encapsulates them using the GPRS Tunneling Protocol [3GPP GTPv1-U 2019], including the TEID, and sends them in UDP segments to the Serving Gateway at the other end of the tunnel. On the receiving side, the base station decapsulates tunneled UDP datagrams, extracts the encapsulated IP datagram destined for the mobile device, and forwards that IP datagram over the wireless hop to the mobile device.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">7.4.3 </span><span class="font23" style="font-weight:bold;">LTE Radio Access Network</span></p></li></ul>
<p><span class="font53">LTE uses a combination of frequency division multiplexing and time division multiplexing on the downstream channel, known as orthogonal frequency division multiplexing (OFDM) [Hwang 2009]. (The term “orthogonal” comes from the fact the signals being sent on different frequency channels are created so that they interfere very little with each other, even when channel frequencies are tightly spaced). In LTE, each active mobile device is allocated one or more 0.5 ms time slots in one or more of the channel frequencies. Figure 7.22 shows an allocation of eight time slots over four frequencies. By being allocated increasingly more time slots (whether on the same frequency or on different frequencies), a mobile device is able to achieve increasingly higher transmission rates. Slot (re)allocation among mobile devices can be performed as often as once every millisecond. Different modulation schemes can also be used to change the transmission rate; see our earlier discussion of Figure 7.3 and dynamic selection of modulation schemes in WiFi networks.</span></p>
<p><a name="bookmark433"></a><span class="font53">The particular allocation of time slots to mobile devices is not mandated by the LTE standard. Instead, the decision of which mobile devices will be allowed to transmit in a given time slot on a given frequency is determined by the scheduling algorithms provided by the LTE equipment vendor and/or the network operator. With opportunistic scheduling [Bender 2000; Kolding 2003; Kulkarni 2005], matching the physical-layer protocol to the channel conditions between the sender and receiver and choosing the receivers to which packets will be sent based on channel conditions allow the base station to make best use of the wireless medium. In addition, user</span></p><img src="networking_files/networking-520.jpg" alt="" style="width:266pt;height:144pt;">
<p><span class="font7" style="font-weight:bold;">Figure 7.22 </span><span class="font50">♦ </span><span class="font5">Twenty 0.5-ms slots organized into 10 ms frames at each frequency. An eight-slot allocation is shown shaded.</span></p>
<p><span class="font53">priorities and contracted levels of service (e.g., silver, gold, or platinum) can be used in scheduling downstream packet transmissions. In addition to the LTE capabilities described above, LTE-Advanced allows for downstream bandwidths of hundreds of Mbps by allocating aggregated channels to a mobile device [Akyildiz 2010].</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">7.4.4 </span><span class="font23" style="font-weight:bold;">Additional LTE Functions: Network Attachment and Power Management</span></p></li></ul>
<p><span class="font53">Let’s conclude or study of 4G LTE here by considering two additional important LTE functions: </span><span class="font53" style="font-style:italic;">(i)</span><span class="font53"> the process with which a mobile device first attaches to the network and </span><span class="font53" style="font-style:italic;">(ii)</span><span class="font53"> the techniques used by the mobile device, in conjunction with core network elements, to manage its power use.</span></p>
<p><span class="font22" style="font-weight:bold;">Network Attachment</span></p>
<p><span class="font53">The process by which a mobile device attaches to the cellular carrier’s network divides broadly into three phases:</span></p>
<p><a name="bookmark434"></a><span class="font53">• </span><span class="font53" style="font-style:italic;">Attachment to a Base Station.</span><span class="font53"> This first phase of device attachment is similar in purpose to, but quite different in practice from, the 802.11 association protocol that we studied in Section 7.31. A mobile device wishing to attach to a cellular carrier network will begin a bootstrap process to learn about, and then associate with, a nearby base station. The mobile device initially searches all channels in all frequency bands for a primary synchronization signal that is periodically broadcast every 5 ms by a base station. Once this signal is found, the mobile device remains on this frequency and locates the secondary synchronization signal. With information found in this second signal, the device can locate (following several further steps) additional information such as channel bandwidth, channel configurations, and the cellular carrier information of that base station. Armed with this information, the mobile device can select a base station to associate with (preferentially attaching to its home network, if available) and establish a control-plane signaling connection across the wireless hop with that base station. This mobile-to-base-station channel will be used through the remainder of the network attachment process.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Mutual Authentication.</span><span class="font53"> In our earlier description of the Mobility Management Entity (MME) in Section 7.4.1, we noted that the base station contacts the local MME to perform mutual authentication—a process that we’ll study in further detail in Section 8.8.2. This is the second phase of network attachment, allowing the network to know that the attaching device is indeed the device associated with a given IMSI, and the mobile device to know that the network to which it is attaching is also a legitimate cellular carrier network. Once this second phase of network attachment is complete, the MME and mobile device have mutually authenticated each other, and the MME also knows the identity of the base station to which the mobile is attached. Armed with this information, the MME is now ready to configure the Mobile-device-to-PDN-gateway data path.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Mobile-device-to-PDN-gateway Data Path Configuration.</span><span class="font53"> The MME contacts the PDN gateway (which also provides a NAT address for the mobile device), the Serving gateway, and the base station to establish the two tunnels shown in Figure 7.21. Once this phase is complete, the mobile device is able to send/receive IP datagrams via the base station through these tunnels to and from the Internet!</span></p></li></ul>
<p><span class="font22" style="font-weight:bold;">Power Management: Sleep Modes</span></p>
<p><span class="font53">Recall in our earlier discussion of advanced features in 802.11 (Section 7.3.5) and Bluetooth (Section 7.3.6) that a radio in a wireless device may enter a sleep state to save power when it is not transmitting or receiving in order to minimize the amount of time that the mobile device’s circuitry needs to be “on” for sending/receiving data, and for channel sensing. In 4G LTE, a sleeping mobile device can be in one of two different sleep states. In the discontinuous reception state, which is typically entered after several hundred milliseconds of inactivity [Sauter 2014], the mobile device and the base station will schedule periodic times in advance (typically several hundred milliseconds apart) at which the mobile device will wake up and actively monitor the channel for downstream (base station to mobile device) transmissions; apart from these scheduled times, however, the mobile device’s radio will be sleeping.</span></p>
<p><span class="font53">If the discontinuous reception state might be considered a “light sleep,” the second sleep state—the Idle state—which follows even longer periods of 5 to 10 seconds of inactivity, might be thought of as a “deep sleep.” While in this deep sleep, the mobile device’s radio wakes up and monitors the channel even less frequently. Indeed, this sleep is so deep that if the mobile device moves into a new cell in the carrier’s network while sleeping, it need not inform the base station with which it was previous associated. Thus, when waking up periodically from this deep sleep, the mobile device will need to re-establish an association with a (potentially new) base station in order to check for paging messages broadcast by the MME to base stations nearby the base station with which the mobile was last associated. These control-plane paging messages, which are broadcast by these base stations to all mobile devices in their cells, indicate which mobile devices should fully wake up and re-establish a new data-plane connection to a base station (see Figure 7.18) in order to receive incoming packets.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">7.4.5 </span><span class="font23" style="font-weight:bold;">The Global Cellular Network: A Network of Networks</span></p></li></ul>
<p><span class="font53">Having now studied the 4G cellular network architecture, let’s take a step back at take a look at how the global cellular network—itself a “network of networks” like the Internet—is organized.</span></p>
<p><span class="font53">Figure 7.23 shows a user’s mobile smartphone connected via a 4G base station into its </span><span class="font53" style="font-weight:bold;">home network</span><span class="font53">. The user’s home mobile network is operated by a cellular</span></p><img src="networking_files/networking-521.jpg" alt="" style="width:331pt;height:279pt;">
<p><a name="bookmark435"></a><span class="font7" style="font-weight:bold;">Figure 7.23 </span><span class="font50">♦ </span><span class="font5">The global cellular data network: a network of networks.</span></p>
<p><span class="font53">carrier such as Verizon, AT&amp;T, T-Mobile, or Sprint in the United States; Orange in France; or SK Telecom in Korea. The user’s home network, in turn, is connected to the networks of other cellular carriers and to the global Internet, though one or more gateway routers in the home network, as shown in Figure 7.23. The mobile networks themselves interconnect with each other either via the public Internet or via an Internet Protocol Packet eXchange (IPX) Network [GSMA 2018a]. An IPX is a managed network specifically for interconnecting cellular carriers, similar to Internet eXchange Points (see Figure 1.15) for peering among ISPs. From Figure 7.23, we can see that the global cellular network is indeed a “network of networks”—just like the Internet (recall Figure 1.15 and Section 5.4). 4G networks can also peer with 3G cellular voice/data networks and earlier voice-only networks.</span></p>
<p><span class="font53">We’ll return shortly to additional 4G LTE topics—mobility management in Section 7.6, and 4G security in Section 8.8.2—later, after developing the basic principles needed for these topics. Let’s now take a quick look at the emerging 5G networks.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">7.4.6 </span><span class="font23" style="font-weight:bold;">5G Cellular Networks</span></p></li></ul>
<p><span class="font53">The ultimate wide-area data service would be one with ubiquitous gigabit connection speeds, extremely low latency, and unrestricted limitations on the number of users and devices that could be supported in any region. Such a service would open the door to all kinds of new applications, including pervasive augmented reality and virtual reality, control of autonomous vehicles via wireless connections, control of robots in factories via wireless connections, and replacement of residential access technologies, such as DSL and cable, with fixed wireless Internet services (that is, residential wireless connections from base stations to modems in homes).</span></p>
<p><span class="font53">It is expected that 5G, for which progressively improved versions are likely to be rolled out in the 2020 decade, will make a big step towards achieving the goals of the ultimate wide-area data service. It is predicted that 5G will provide roughly a 10x increase in peak bitrate, a 10x decrease in latency, and a 100x increase in traffic capacity over 4G [Qualcomm 2019].</span></p>
<p><span class="font53">Principally, 5G refers to “5G NR (New Radio),” which is the standard adopted by 3GPP. Other 5G technologies besides NR do exist, however. For example, Verizon’s proprietary 5G TF network operates on 28 and 39 GHz frequencies and is used only for fixed wireless Internet service, not in smartphones.</span></p>
<p><a name="bookmark436"></a><span class="font53">5G standards divide frequencies into two groups: FR1 (450 MHz-6 GHz) and FR2 (24 GHz-52 GHz). Most early deployments will be in the FR1 space, although there are early deployments as of 2020 in the FR2 space for fixed Internet residential access as mentioned just above. Importantly, the physical layer (that is, wireless) aspects of 5G are </span><span class="font53" style="font-style:italic;">not</span><span class="font53"> backward-compatible with 4G mobile communications systems such as LTE: in particular, it can’t be delivered to existing smartphones by deploying base station upgrades or software updates. Therefore, in the transition to 5G, wireless carriers will need to make substantial investments in physical infrastructure.</span></p>
<p><span class="font53">FR2 frequencies are also known as </span><span class="font53" style="font-weight:bold;">millimeter wave frequencies</span><span class="font53">. While millimeter wave frequencies allow for much faster data speeds, they come with two major drawbacks:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;Millimeter wave frequencies have much shorter range from base station to receivers. This makes millimeter wave technology unsuitable in rural areas and requires denser deployments of base stations in urban areas.</span></p></li>
<li>
<p><span class="font53">• &nbsp;Millimeter wave communication is highly susceptible to atmospheric interference. Nearby foliage and rain can cause problems for outdoor use.</span></p></li></ul>
<p><span class="font53">5G is not one cohesive standard, but instead consists of three co-existing standards [Dahlman 2018]:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">eMBB (Enhanced Mobile Broadband).</span><span class="font53"> Initial deployments of 5G NR have focused on eMBB, which provides for increased bandwidth for higher download and upload speeds, as well as a moderate reduction in latency when compared to 4G LTE. eMBB enables rich media applications, such as mobile augmented reality and virtual reality, as well as mobile 4K resolution and 360° video streaming.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">URLLC (Ultra Reliable Low-Latency Communications).</span><span class="font53"> URLLC is targeted towards applications that are highly latency-sensitive, such as factory automation and autonomous driving. URLLC is targeting latencies of 1msec. As of this writing, technologies that enable URLLC are still being standardized.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">mMTC (Massive Machine Type Communications).</span><span class="font53"> mMTC is a narrowband access type for sensing, metering, and monitoring applications. One priority for the design of 5G networks is to lower barriers for network connectivity for IoT devices. In addition to lowering latency, emerging technologies for 5G networks are focusing on reducing power requirements, making the use of IoT devices more pervasive than has been with 4G LTE.</span></p></li></ul>
<p><span class="font22" style="font-weight:bold;">5G and Millimeter Wave Frequencies</span></p>
<p><span class="font53">Many 5G innovations will be a direct result of working in the millimeter wave frequencies in the 24 GHz-52 GHz band. For example, these frequencies offer the potential of achieving 100x increase in capacity over 4G. To get some insight into this, capacity can be defined as the product of three terms [Bjornson 2017]:</span></p>
<p><span class="font53">capacity </span><span class="font54">= </span><span class="font53">cell density </span><span class="font55">X </span><span class="font53">available spectrum </span><span class="font55">X </span><span class="font53">spectral efficiency</span></p>
<p><span class="font53">where cell density is in units of cells/km<sup>2</sup>, available spectrum is in units of Hertz, and spectral efficiency is a measure of how efficiently each base station can communicate with users and is in units of bps/Hz/cell. By multiplying these units out, it is easy to see that capacity is in units of bps/km<sup>2</sup>. For each of these three terms, the values will be larger for 5G than for 4G:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;Because millimeter frequencies have much shorter range than 4G LTE frequencies, more base stations are required, which in turn increases the cell density.</span></p></li>
<li>
<p><span class="font53">• &nbsp;Because 5G FR2 operates in a much larger frequency band (52 </span><span class="font54">— </span><span class="font53">24 </span><span class="font54">= </span><span class="font53">28 GHz) than 4G LTE (up to about 2 GHz), it has more available spectrum.</span></p></li>
<li>
<p><span class="font53">• &nbsp;With regard to spectral efficiency, information theory says that if you want to double spectral efficiency, a 17-fold increase in power is needed [Bjornson 2017]. Instead of increasing power, 5G uses MIMO-technology (the same technology we encountered in our study of 802.11 networks in Section 7.3), which uses multiple antennas at each base station. Rather than broadcasting signals in all directions, each MIMO antenna employs </span><span class="font53" style="font-weight:bold;">beam forming </span><span class="font53">and directs the signal at the user. MIMO technology allows a base station to send to 10-20 users at the same time in the same frequency band.</span></p></li></ul>
<p><span class="font53">By increasing all three terms in the capacity equation, 5G is expected to provide a 100x increase in capacity in urban areas. Similarly, owing to the much wider frequency band, 5G is expected to provide peak download rates of 1 Gbps or higher.</span></p>
<p><span class="font53">Millimeter wave signals are, however, easily blocked by buildings and trees. </span><span class="font53" style="font-weight:bold;">Small cell stations </span><span class="font53">are needed to fill in coverage gaps between base stations and users. In a highly populous region, the distance between two small cells could vary from 10 to 100 meters [Dahlman 2018].</span></p>
<p><span class="font22" style="font-weight:bold;">5G Core Network</span></p>
<p><span class="font53">The </span><span class="font53" style="font-weight:bold;">5G Core network </span><span class="font53">is the data network that manages all of the 5G mobile voice, data and Internet connections. The 5G Core network is being redesigned to better integrate with the Internet and cloud-based services, and also includes distributed servers and caches across the network, thereby reducing latency. Network function virtualization (as discussed in Chapters 4 and 5), and network slicing for different applications and services, will be managed in the core.</span></p>
<p><span class="font53">The new 5G Core specification introduces major changes in the way mobile networks support a wide variety of services with varied performance. As in the case of the 4G core network (recall Figures 7.17 and 7.18), the 5G core relays data traffic from end devices, authenticates devices, and manages device mobility. The 5G core also contains all of the network elements that we encountered in Section 7.4.2—the mobile devices, the cells, the base stations, and the Mobility Management Entity (now divided into two sub-elements, as discussed below), the HSS, and the Serving and PDN gateways.</span></p>
<p><span class="font53">Although the 4G and 5G core networks perform similar functions, there are some major differences in that the new 5G core architecture. The 5G Core is designed for complete control and user-plane separation (see Chapter 5). The 5G Core consists purely of virtualized software-based network functions. This new architecture will give operators the flexibility to meet the diverse requirements of the different 5G applications. Some of the new 5G core network functions include [Rommer 2019]:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">User-Plane Function (UPF).</span><span class="font53"> Control and user-plane separation (see Chapter 5) allows packet processing to be distributed and pushed to the network edge.</span></p></li>
<li>
<p><span class="font53">• </span><span class="font53" style="font-style:italic;">Access and Mobility Management Function (AMF).</span><span class="font53"> The 5G Core essentially decomposes the 4G Mobility Management Entity (MME) into two functional elements: AMF and SMF. The AMF receives all the connection and session information from end-user equipment but only handles connection and mobility management tasks.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Session Management Function (SMF).</span><span class="font53"> Session management is handled by the Session Management Function (SMF). The SMF is responsible for interacting with the decoupled data plane. The SMF also performs IP address management and plays the role of DHCP.</span></p></li></ul>
<p><span class="font53">As of this writing (2020), 5G is in its early stages of deployment, and many 5G standards have yet to be finalized. Only time will tell whether 5G will become a pervasive broadband wireless service, whether it will successfully compete with WiFi for indoor wireless service, whether it will become a critical component of factory automation and the autonomous vehicle infrastructure, and whether it will take us a big step forward toward the ultimate wide-area wireless service.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">7.5 </span><span class="font24" style="font-weight:bold;">Mobility Management: Principles</span></p></li></ul>
<p><span class="font53">Having covered the wireless nature of the communication links in a wireless network, it’s now time to turn our attention to the mobility that these wireless links enable. In the broadest sense, a mobile device is one that changes its point of attachment into the network over time. Because the term mobility has taken on many meanings in both the computer and telephony worlds, it will serve us well first to carefully consider forms of mobility.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">7.5.1 </span><span class="font23" style="font-weight:bold;">Device Mobility: a Network-layer Perspective</span></p></li></ul>
<p><a name="bookmark437"></a><span class="font53">From the network layer’s standpoint, a physically mobile device will present a very different set of challenges to the network layer, depending on how active the device is as it moves between points of attachment to the network. At the one end of the spectrum, scenario </span><span class="font53" style="font-style:italic;">(a)</span><span class="font53"> in Figure 7.24 is the mobile user who himself/herself physically moves between networks, but powers down the mobile device when moving. For example, a student might disconnect from a wireless classroom network and power down his/her device, head to the dining commons and connect to the wireless access</span></p>
<div>
<p><span class="font4" style="font-style:italic;">(a)</span><span class="font4"> Device mobility between access networks, but powered down while moving between access networks</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-style:italic;">(b)</span><span class="font4"> Device mobility </span><span class="font4" style="font-style:italic;">(c)</span><span class="font4"> Device mobility only within same wireless access network, in single provider network</span></p>
</div><br clear="all">
<div>
<p class="font4">among access networks in single provider network, <span class="font4" style="font-style:italic;">while maintaining</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-style:italic;">(d)</span><span class="font4"> Device mobility among multiple provider networks, </span><span class="font4" style="font-style:italic;">while maintaining ongoing connections</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-style:italic;">ongoing connections</span></p>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 7.24 </span><span class="font50">♦ </span><span class="font5">Various degrees of mobility, from a network-layer perspective</span></p>
<p><span class="font53">network there while eating, and then disconnect and power down from the dining commons network, walk to the library, and connect to the library’s wireless network while studying. From a networking perspective, this device is </span><span class="font53" style="font-style:italic;">not</span><span class="font53"> mobile—it attaches to an access network and remains in that access network while on. In this case, the device serially associates with, and later disassociates from, each wireless access network encountered. This case of device (non-)mobility can be completely handled using the networking mechanisms we’ve already studied in Sections 7.3 and 7.4.</span></p>
<p><span class="font53">In scenario </span><span class="font53" style="font-style:italic;">(b)</span><span class="font53"> in Figure 7.24, the device is physically mobile but remains attached to the same access network. This device is also </span><span class="font53" style="font-style:italic;">not</span><span class="font53"> mobile from a networklayer perspective. Additionally, if the device remains associated with the same 802.11 AP or LTE base station, the device is not even mobile from a link-layer perspective.</span></p>
<p><span class="font53">From a network standpoint, our interest in device mobility really starts with case </span><span class="font53" style="font-style:italic;">(c), </span><span class="font53">where a device changes its access network (e.g., 802.11 WLAN or LTE cell) while continuing to send and receiving IP datagrams, and while maintaining higher-level (e.g., TCP) connections. Here, the network will need to provide </span><span class="font53" style="font-weight:bold;">handover—</span><span class="font53">a transfer of responsibility for forwarding datagrams to/from one AP or base station to the mobile device—as the device moves among WLANs or among LTE cells. We’ll cover handover in detail in Section 7.6. If the handover occurs within access networks belonging to a single network provider, that provider can orchestrate handover on its own. When a mobile device roams between multiple provider networks, as in scenario </span><span class="font53" style="font-style:italic;">(d),</span><span class="font53"> the providers must orchestrate handover together, which considerably complicates the handover process.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">7.5.2 </span><span class="font23" style="font-weight:bold;">Home Networks and Roaming on Visited Networks</span></p></li></ul>
<p><a name="bookmark438"></a><span class="font53">As we learned in our discussions of cellular 4G LTE networks in Section 7.4.1, every subscriber has a “home” with some cellular provider. We learned that the Home Subscriber Service (HSS) stores information about each of its subscribers, including a globally unique device ID (embedded in a subscriber’s SIM card), information about services that the subscriber may access, cryptographic keys to be used for communication, and billing/charging information. When a device is connected to a cellular network, other than its </span><span class="font53" style="font-weight:bold;">home network</span><span class="font53">, that device is said to be </span><span class="font53" style="font-weight:bold;">roaming </span><span class="font53">on a </span><span class="font53" style="font-weight:bold;">visited network</span><span class="font53">. When a mobile device attaches to, and roams on, a visited network, coordination will be required between the home network and the visited network.</span></p>
<p><span class="font53">The Internet does not have a similarly strong notion of a home network or a visited network. In practice, a student’s home network might be the network operated by his/her school; for mobile professionals, their home network might be their company network. The visited network might be the network of a school or a company they are visiting. But there is no notion of a home/visited network deeply embedded in the Internet’s architecture. The Mobile IP protocol [Perkins 1998, RFC 5944], which we will cover briefly in Section 7.6, was a proposal that strongly incorporated the notion of home/visited networks. But Mobile IP has seen limited deployment/use in practice. There are also activities underway that are built on top of the existing IP infrastructure to provide authenticated network access across visited IP networks. Eduroam [Eduroam 2020] is one such activity.</span></p>
<p><span class="font53">The notion of a mobile device having a home network provides two important advantages: the home network provides a single location where information about that device can be found, and (as we will see) it can serve as a coordination point for communication to/from a roaming mobile device.</span></p>
<p><span class="font53">To appreciate the potential value of the central point of information and coordination, consider the human analogy of a 20-something adult Bob moving out of the family home. Bob becomes mobile, living in a series of dormitories and apartments, and often changing addresses. If an old friend Alice wants to get in touch, how can Alice find the current address of Bob? One common way is to contact the family, since a mobile 20-something adult will often register his or her current address with the family (if for no other reason than so that the parents can send money to help pay the rent!). The family home becomes that unique location that others can go to as a first step in communicating with Bob. Additionally, later postal communication from Alice may be either </span><span class="font53" style="font-style:italic;">indirect</span><span class="font53"> (e.g., with mail being sent first to Bob’s family home and then forwarded to Bob) or </span><span class="font53" style="font-style:italic;">direct</span><span class="font53"> (e.g., with Alice using the address obtained from Bob’s parents to send mail directly to Bob).</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">7.5.3 </span><span class="font23" style="font-weight:bold;">Direct and Indirect Routing to/from a Mobile Device</span></p></li></ul>
<p><span class="font53">Let us now consider the conundrum faced by the Internet-connected host (that we will refer to as a </span><span class="font53" style="font-style:italic;">correspondent)</span><span class="font53"> in Figure 7.25 wishing to communicate with a mobile device that might be located within that mobile device’s cellular home network, or might be roaming in a visited network. In our development below, we’ll adopt a 4G/5G cellular network perspective, since these networks have such a long history of supporting device mobility. But as we’ll see, the fundamental challenges and basic solution approaches for supporting device mobility are equally applicable in both cellular networks and in the Internet.</span></p>
<p><a name="bookmark439"></a><span class="font53">As shown in Figure 7.25, we’ll assume that the mobile device has a globally unique identifier associated with it. In 4G, LTE cellular networks (see Section 7.4),</span></p>
<div><img src="networking_files/networking-522.jpg" alt="" style="width:79pt;height:54pt;">
<p><span class="font4">Permanent IP: 128.119.40.186 IMSI 78:4f:43:98:d9:27</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-523.jpg" alt="" style="width:42pt;height:54pt;">
<p><span class="font4">Subscriber</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-524.jpg" alt="" style="width:37pt;height:38pt;">
<p><span class="font4">Mobility manager</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-525.jpg" alt="" style="width:86pt;height:37pt;">
<p><span class="font4">gateway</span></p>
<p><span class="font4" style="font-weight:bold;">Home Network</span></p>
<p><span class="font4">128.119/16</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Public or private Internet</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-526.jpg" alt="" style="width:156pt;height:102pt;">
</div><br clear="all">
<div><img src="networking_files/networking-527.jpg" alt="" style="width:82pt;height:26pt;">
<p><span class="font4">gateway</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Visited Network</span></p>
<p><span class="font4">79.129/16</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-528.jpg" alt="" style="width:160pt;height:51pt;">
<p><span class="font7" style="font-weight:bold;">Figure 7.25 </span><span class="font50">♦ </span><span class="font5">Elements of a mobile network architecture</span></p>
</div><br clear="all">
<p><span class="font53">this would be the International Mobile Subscriber Identity (IMSI) and an associated phone number, stored on a mobile device’s SIM card. For mobile Internet users, this would be a permanent IP address in the IP address range of its home network, as in the case of the Mobile IP architecture.</span></p>
<p><span class="font53">What approaches might be used in a mobile network architecture that would allow a datagram sent by the correspondent to reach that mobile device? Three basic approaches can be identified and are discussed below. As we will see, the latter two of these are adopted in practice.</span></p>
<p><span class="font22" style="font-weight:bold;">Leveraging the Existing IP Address Infrastructure</span></p>
<p><span class="font53">Perhaps the simplest approach to routing to a mobile device in a visited network is to simply use the existing IP addressing infrastructure—to add nothing new to the architecture. What could be easier!</span></p>
<p><span class="font53">Recall from our discussion of Figure 4.21 that an ISP uses BGP to advertise routes to destination networks by enumerating the CIDRized address ranges of reachable networks. A visited network could thus advertise to all other networks that a particular mobile device is resident in its network simply by advertising a highly specific address—the mobile device’s full 32-bit IP permanent address—essentially informing other networks that it has the path to be used to forward datagrams to that mobile device. These neighboring networks would then propagate this routing information throughout the network as part of the normal BGP procedure of updating routing information and forwarding tables. Since datagrams will always be forwarded to the router advertising the most specific destination for that address (see Section 4.3), all datagrams addressed to that mobile device will be forwarded to the visited network. If the mobile device leaves one visited network and joins another, the new visited network can advertise a new, highly specific route to the mobile device, and the old visited network can withdraw its routing information regarding the mobile device.</span></p>
<p><span class="font53">This solves two problems at once, and does so without making changes to the network-layer infrastructure! Other networks know the location of the mobile device, and it is easy to route datagrams to the mobile device, since the forwarding tables will direct datagrams to the visited network. The killer drawback, however, is that of scalability—network routers would have to maintain forwarding table entries for potentially billions of mobile devices, and update a device’s entry each time it roams to a different network. Clearly, this approach would not work in practice. Some additional drawbacks are explored in the problems at the end of this chapter.</span></p>
<p><span class="font53">An alternative, more practical, approach (and one that has been adopted in practice) is to push mobility functionality from the network core to the network edge— a recurring theme in our study of Internet architecture. A natural way to do this is via the mobile device’s home network. In much the same way that parents of the mobile 20-something adult track their child’s location, a mobility management entity (MME) in the mobile device’s home network could track the visited network in which the mobile device resides. This information might reside in a database, shown as the HSS database in Figure 7.25. A protocol operating between the visited network and the home network will be needed to update the network in which the mobile device resides. You might recall that we encountered the MME and HSS elements in our study of 4G LTE. We’ll reuse their element names here, since they are so descriptive, and also because they are pervasively deployed in 4G networks.</span></p>
<p><span class="font53">Let’s next consider the visited network elements shown in Figure 7.25 in more detail. The mobile device will clearly need an IP address in the visited network. The possibilities here include using a permanent address associated with the mobile device’s home network, allocating a new address in the address range of the visited network, or providing an IP address via NAT (see Section 4.3.4). In the latter two cases, a mobile device has a transient identifier (a newly allocated IP address) in addition to its permanent identifiers stored in the HSS in its home network. These cases are analogous to a writer addressing a letter to the address of the house in which our mobile 20-something adult is currently living. In the case of a NAT address, datagrams destined to the mobile device would eventually reach the NAT gateway router in the visited network, which would then perform NAT address translation and forward the datagram to the mobile device.</span></p>
<p><span class="font53">We have now seen a number of elements of a solution to the correspondent’s dilemma in Figure 7.24: home and visited networks, the MME and HSS, and mobile device addressing. But how should datagrams be addressed and forwarded to the mobile device? Since only the HSS (and not network-wide routers) knows the location of the mobile device, the correspondent cannot simply address a datagram to the mobile device’s permanent address and send it into the network. Something more must be done. Two approaches can be identified: indirect and direct routing.</span></p>
<p><span class="font22" style="font-weight:bold;">Indirect Routing to a Mobile Device</span></p>
<p><span class="font53">Let’s again consider the correspondent that wants to send a datagram to a mobile device. In the </span><span class="font53" style="font-weight:bold;">indirect routing </span><span class="font53">approach, the correspondent simply addresses the datagram to the mobile device’s permanent address and sends the datagram into the network, blissfully unaware of whether the mobile device is resident in its home network or in a visited network; mobility is thus completely transparent to the correspondent. Such datagrams are first routed, as usual, to the mobile device’s home network. This is illustrated in step 1 in Figure 7.26.</span></p>
<div><img src="networking_files/networking-529.jpg" alt="" style="width:49pt;height:128pt;">
</div><br clear="all">
<div><img src="networking_files/networking-530.jpg" alt="" style="width:20pt;height:37pt;">
</div><br clear="all">
<div>
<p><span class="font4">Permanent IP: 128.119.40.186 IMSI 78:4f:43:98:d9:27</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-531.jpg" alt="" style="width:29pt;height:46pt;">
<p><span class="font4">Home Subscriber Service</span></p>
</div><br clear="all">
<div>
<p><span class="font4">NAT IP:</span></p>
<p><span class="font4">10.0.0.99</span></p>
<p><span class="font4">IMSI</span></p>
<p><span class="font4">78:4f:43:98:d9:27</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Mobility manager</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Mobility manager</span></p>
<p><span class="font4">Home network gateway</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Visited network gateway</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Home Network</span></p>
<p><span class="font4">128.119/16</span></p>
</div><br clear="all">
<p><span class="font4" style="font-weight:bold;">Visited Network</span></p>
<p><span class="font4">79.129/16</span></p>
<p><span class="font4">Correspondent</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 7.26 </span><span class="font50">♦ </span><span class="font5">Indirect routing to a mobile device</span></p>
<p><span class="font53">Let’s now turn our attention to the HSS, which is responsible for interacting with visited networks to track the mobile device’s location, and the home network’s gateway router. One job of this gateway router is to be on the lookout for an arriving datagram addressed to a device whose home is in that network, but that currently resides in a visited network. The home network gateway intercepts this datagram, consults with the HSS to determine the visited network where the mobile device is resident, and forwards the datagram toward the visited network gateway router—step 2 in Figure 7.26. The visited network gateway router then forwards the datagram toward the mobile device—step 3 in Figure 7.26. If NAT translation is used, as in Figure 7.26, the visited network gateway router performs NAT translation.</span></p>
<p><span class="font53">It is instructive to consider the rerouting at the home network in bit more detail. Clearly, the home network gateway will need to forward the arriving datagram to the gateway router in the visited network. On the other hand, it is desirable to leave the correspondent’s datagram intact, since the application receiving the datagram should be unaware that the datagram was forwarded via the home network. Both goals can be satisfied by having the home gateway encapsulate the correspondent’s original complete datagram within a new (larger) datagram. This larger datagram is then addressed and delivered to the visited network’s gateway router, which will decapsulate the datagram—that is, remove the correspondent’s original datagram from within the larger encapsulating datagram—and forward (step 3 in Figure 7.26) the original datagram to the mobile device. The sharp reader will note that the encap-sulation/decapsulation described here is precisely the notion of tunneling, discussed in Section 4.3 in the context of IPv6; indeed, we also discussed the use of tunneling in the context of Figure 7.18, when we introduced the 4G LTE data plane.</span></p>
<p><span class="font53">Finally, let’s consider how the mobile device sends datagrams to the correspondent. In the context of Figure 7.26, the mobile device will clearly need to forward the datagram through the visited gateway router, in order to perform NAT translation. But how then should the visited gateway router forward the datagram to the correspondent? As shown in Figure 7.26, there are two options here: </span><span class="font53" style="font-style:italic;">(4a)</span><span class="font53"> the datagram could be tunneled back to the home gateway router, and sent to the correspondent from there, or </span><span class="font53" style="font-style:italic;">(4b)</span><span class="font53"> the datagram could be transmitted from the visited network directly to the correspondent—an approach known as </span><span class="font53" style="font-weight:bold;">local breakout </span><span class="font53">[GSMA 2019a] in LTE.</span></p>
<p><span class="font53">Let’s summarize our discussion of indirect routing by reviewing the new network-layer functionality required to support mobility.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">A mobile-device-to-visited-network association protocol.</span><span class="font53"> The mobile device will need to associate with the visited network, and will similarly need to disassociate when leaving the visited network.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">A visited-network-to-home-network-HSS registration protocol.</span><span class="font53"> The visited network will need to register the mobile device’s location with the HSS in the home network, and perhaps use information obtained from the HSS in performing device authentication.</span></p></li></ul>
<p><span class="font53">• </span><span class="font53" style="font-style:italic;">A datagram tunneling protocol between in the home network gateway and the visited network gateway router.</span><span class="font53"> The sending side performs encapsulation and forwarding of the correspondent’s original datagram; on the receiving side, the gateway router performs decapsulation, NAT translation, and forwarding of the original datagram to the mobile device.</span></p>
<p><span class="font53">The previous discussion provides all the needed elements for a mobile device to maintain an ongoing connection with a correspondent as the device moves among networks. When a device roams from one visited network to another, the new visited network information needs to be updated in the home network HSS, and the home-gateway-router-to-visited-gateway-router tunnel endpoint needs to be moved. But will the mobile device see an interrupted flow of datagrams as it moves between networks? As long as the time between the mobile device disconnection from one visited network and its attachment to the next visited network is small, few datagrams will be lost. Recall from Chapter 3 that end-to-end connections can experience datagram loss due to network congestion. Hence, occasional datagram loss within a connection when a device moves between networks is by no means a catastrophic problem. If loss-free communication is required, upper-layer mechanisms will recover from datagram loss, whether such loss results from network congestion or from device mobility.</span></p>
<p><span class="font53">Our discussion above has been purposefully somewhat generic. An indirect routing approach is used in the mobile IP standard [RFC 5944], as well as in 4G LTE networks [Sauter 2014]. Their details, in particular the tunneling procedures employed, differ just a bit from our generic discussion above.</span></p>
<p><span class="font22" style="font-weight:bold;">Direct Routing to a Mobile Device</span></p>
<p><span class="font53">The indirect routing approach illustrated in Figure 7.26 suffers from an inefficiency known as the </span><span class="font53" style="font-weight:bold;">triangle routing problem—</span><span class="font53">datagrams addressed to the mobile device must be forwarded first to the home network and then to the visited network, even when a much more efficient route exists between the correspondent and the roaming mobile device. In the worst case, imagine a mobile user who is roaming on the same network that is the home network for an overseas colleague who our mobile user is visiting. The two are sitting side-by-side and exchanging data. Datagrams between the mobile user and his overseas colleague will be forwarded to the mobile user’s home network and then back again to the visited network!</span></p>
<p><span class="font53" style="font-weight:bold;">Direct routing </span><span class="font53">overcomes the inefficiency of triangle routing, but does so at the cost of additional complexity. In the direct routing approach, shown in Figure 7.27, the correspondent first discovers the visited network in which the mobile is resident. This is done by querying the HSS in the mobile device’s home network, assuming (as in the case of indirect routing) that the mobile device’s visited network is registered in the HSS. This is shown as steps 1 and 2 in Figure 7.27. The correspondent then tunnels datagrams from its network </span><span class="font53" style="font-style:italic;">directly</span><span class="font53"> to the gateway router in the mobile device’s visited network.</span></p>
<div><img src="networking_files/networking-532.jpg" alt="" style="width:49pt;height:128pt;">
</div><br clear="all">
<div><img src="networking_files/networking-533.jpg" alt="" style="width:20pt;height:37pt;">
</div><br clear="all">
<div>
<p><span class="font4">Permanent IP: 128.119.40.186 IMSI 78:4f:43:98:d9:27</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Mobility manager</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-534.jpg" alt="" style="width:29pt;height:46pt;">
<p><span class="font4">Home Subscriber Service</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Home Network </span><span class="font4">128.119/16</span></p><img src="networking_files/networking-535.jpg" alt="" style="width:136pt;height:133pt;">
<p><span class="font4">Correspondent</span></p>
<p><span class="font4">Home network gateway</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 7.27 </span><span class="font50">♦ </span><span class="font5">Direct routing to a mobile device</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-536.jpg" alt="" style="width:187pt;height:185pt;">
</div><br clear="all">
<p><span class="font53">While direct routing overcomes the triangle routing problem, it introduces two important additional challenges:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;A mobile-user location protocol is needed for the correspondent to query the HSS to obtain the mobile device’s visited network (steps 1 and 2 in Figure 7.27). This is in addition to the protocol needed for the mobile device to register its location with its HSS.</span></p></li>
<li>
<p><span class="font53">• &nbsp;When the mobile device moves from one visited network to another, how will the correspondent know to now forward datagrams to the new visited network? In the case of indirect routing, this problem was easily solved by updating the HSS in the home network, and changing the tunnel endpoint to terminate at the gateway router of the new visited network. However, with direct routing, this change in visited networks is not so easily handled, as the HSS is queried by the correspondent only at the beginning of the session. Thus, additional protocol mechanisms would be required to proactively update the correspondent each time the mobile device moves. Two problems at the end of this chapter explore solutions to this problem.</span></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">7.6 </span><span class="font24" style="font-weight:bold;">Mobility Management in Practice</span></p></li></ul>
<p><span class="font53">In the previous section, we identified key fundamental challenges and potential solutions in developing a network architecture to support device mobility: the notions of home and visited networks; the home network’s role as a central point of information and control for mobile devices subscribed to that home network; control-plane functions needed by a home network’s mobility management entity to track a mobile device roaming among visited networks; and data-plane approaches of direct and indirect routing to enable a correspondent and a mobile device to exchange datagrams. Let’s now look at how these principles are put into practice! In Section 7.2.1, we’ll study mobility management in 4G/5G networks; in Section 7.2.1, we’ll look at Mobile IP, which has been proposed for the Internet.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">7.6.1 </span><span class="font23" style="font-weight:bold;">Mobility Management in 4G/5G Networks</span></p></li></ul>
<p><span class="font53">Our earlier study of 4G and emerging 5G architectures in Section 7.4 acquainted us with all of the network elements that play a central role in 4G/5G mobility management. Let’s now illustrate how those elements interoperate with each other to provide mobility services in today’s 4G/5G networks [Sauter 2014; GSMA 2019b], which have their roots in earlier 3G cellular voice and data networks [Sauter 2014], and even earlier 2G voice-only networks [Mouly 1992]. This will help us synthesize what we’ve learned so far, allow us to introduce a few more advanced topics as well, and provide a lens into what might be in store for 5G mobility management.</span></p>
<p><span class="font53">Let’s consider a simple scenario in which a mobile user (e.g., a passenger in a car), with a smartphone attaches to a visited 4G/5G network, begins streaming a HD video from a remote server, and then moves from the cell coverage of one 4G/5G base station to another. The four major steps in this scenario are shown in Figure 7.28:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">1. </span><span class="font53" style="font-style:italic;">Mobile device and base station association.</span><span class="font53"> The mobile device associates with a base station in the visited network.</span></p></li>
<li>
<p><span class="font53">2. </span><span class="font53" style="font-style:italic;">Control-plane configuration of network elements for the mobile device.</span><span class="font53"> The visited and home networks establish control-plane state indicating that the mobile device is resident in the visited network.</span></p></li>
<li>
<p><span class="font53">3. </span><span class="font53" style="font-style:italic;">Data-plane configuration of forwarding tunnels for the mobile device.</span><span class="font53"> The visited network and the home network establish tunnels through which the mobile device and streaming server can send/receive IP datagrams, using indirect routing through the home network’s Packet Data Network gateway (P-GW).</span></p></li>
<li>
<p><span class="font53">4. </span><span class="font53" style="font-style:italic;">Mobile device handover from one base station to another.</span><span class="font53"> The mobile device changes its point of attachment to the visited network, via handover from one base station to another.</span></p></li></ul>
<p><a name="bookmark440"></a><span class="font53">Let’s now consider each of these four steps in more detail.</span></p>
<div><img src="networking_files/networking-537.jpg" alt="" style="width:48pt;height:61pt;">
<p><span class="font4">PDN gateway (P-GW)</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Home Network</span></p><img src="networking_files/networking-538.jpg" alt="" style="width:24pt;height:101pt;">
<p><span class="font4" style="font-weight:bold;">Internet</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-539.jpg" alt="" style="width:14pt;height:14pt;">
</div><br clear="all">
<div><img src="networking_files/networking-540.jpg" alt="" style="width:216pt;height:132pt;">
<p><span class="font4" style="font-weight:bold;">Visited Network</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-541.jpg" alt="" style="width:20pt;height:20pt;">
</div><br clear="all">
<div><img src="networking_files/networking-542.jpg" alt="" style="width:20pt;height:37pt;">
<p><span class="font4">Streaming server</span></p>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 7.28 </span><span class="font50">♦ </span><span class="font5">An example 4G/5G mobility scenario</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53" style="font-weight:bold;">1. Base station association. </span><span class="font53">Recall that in Section 7.4.2, we studied the procedures by which a mobile device associates with a base station. We learned that the mobile device listens on all frequencies for primary signals being transmitted by base stations in its area. The mobile device acquires progressively more information about these base stations, ultimately selecting the base station with which to associate, and bootstrapping a control-signaling channel with that base station. As part of this association, the mobile device provides the base station with its International Mobile Subscriber Identity (IMSI), which uniquely identifies the mobile device as well as its home network and other additional subscriber information.</span></p></li>
<li>
<p><span class="font53" style="font-weight:bold;">2. Control-plane configuration of LTE network elements for the mobile device. </span><span class="font53">Once the mobile-device-to-base-station signaling channel has been established, the base station can contact the MME in the visited network. The MME will consult and configure a number of 4G/5G elements in both the home and visited networks to establish state on behalf of the mobile node:</span></p></li></ul>
<p><span class="font53">• The MME will use to the IMSI and other information provided by the mobile device to retrieve authentication, encryption, and available network service information for that subscriber. That information might be in the MME’s local cache, retrieved from another MME that the mobile device had recently contacted, or retrieved from the HSS in the mobile device’s home network. The mutual authentication process (which we will cover in more detail in Section 8.8) ensures that the visited network is sure about the identity of the mobile device and that the device can authenticate the network to which it is attaching.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;The MME informs the HSS in the mobile device’s home network that the mobile device is now resident in the visited network, and the HSS updates its database.</span></p></li>
<li>
<p><span class="font53">• &nbsp;The base station and the mobile device select parameters for the data-plane channel to be established between the mobile device and the base station (recall that a control plane signaling channel is already in operation).</span></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font53" style="font-weight:bold;">3. Data-plane configuration of forwarding tunnels for the mobile device. </span><span class="font53">The MME next configures the data plane for the mobile device, as shown in Figure 7.29. Two tunnels are established. One tunnel is between the base station and a Serving Gateway in the visited network. The second tunnel is between that Serving Gateway and the PDN Gateway router </span><span class="font53" style="font-style:italic;">in the mobile device’s home network. </span><span class="font53">4G LTE implements this form of symmetric indirect routing—all traffic to/from the mobile device will be tunneled through the device’s home network. 4G/5G tunnels use the GPRS Tunneling Protocol (GTP), specified in [3GPP GTPv1-U 2019]. The Tunnel Endpoint ID (TEID) in the GTP header indicates which tunnel a datagram belongs, allowing multiple flows to be multiplexed and de-multiplexed by GTP between tunnel endpoints.</span></p></li></ul>
<p><span class="font53">It is instructive to compare the configuration of tunnels in Figure 7.29 (the case of mobile roaming in a visited network) with that of Figure 7.18 (the case of mobility</span></p>
<div>
<p><span class="font4">PDN gateway (P-GW)</span></p><img src="networking_files/networking-543.jpg" alt="" style="width:95pt;height:134pt;">
<p><span class="font4" style="font-weight:bold;">Internet</span></p>
<p><span class="font4" style="font-weight:bold;">Home Network</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-544.jpg" alt="" style="width:172pt;height:59pt;">
<p><span class="font4">Serving</span></p>
</div><br clear="all">
<div>
<p><span class="font4">gateway (S-GW)</span></p><img src="networking_files/networking-545.jpg" alt="" style="width:39pt;height:23pt;">
<p><span class="font4">PDN gateway (P-GW)</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-546.jpg" alt="" style="width:33pt;height:59pt;">
</div><br clear="all">
<div><img src="networking_files/networking-547.jpg" alt="" style="width:19pt;height:35pt;">
<p><span class="font4">Streaming server</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Visited Network</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-548.jpg" alt="" style="width:29pt;height:75pt;">
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 7.29 </span><span class="font50">♦ </span><span class="font5">Tunneling in 4G/5G networks between the Serving Gateway in the visited network and the PDN gateway in the home network </span><span class="font53">only within the mobile device’s home network). We see that in both cases, the Serving Gateway is co-resident in the same network as the mobile device, but PDN Gateway (which is always the PDN Gateway in the mobile device’s home network) may be in a different network than the mobile device. This is precisely indirect routing. An alternative to indirect routing, known as </span><span class="font53" style="font-weight:bold;">local breakout </span><span class="font53">[GSMA 2019a] has been specified in which the Serving Gateway establishes a tunnel to the PDN Gateway in the local, visited network. In practice, however, local breakout is not widely used [Sauter 2014].</span></p>
<p><span class="font53">Once the tunnels have been configured and activated, the mobile device can now forward packets to/from the Internet via the PDN gateway in its home network!</span></p>
<p><span class="font53" style="font-weight:bold;">4. Handover management. </span><span class="font53">A </span><span class="font53" style="font-weight:bold;">handover </span><span class="font53">occurs when a mobile device changes its association from one base station to another. The handover process described below is the same, regardless of whether the mobile device is resident in its home network, or is roaming in a visited network.</span></p>
<p><span class="font53">As shown in Figure 7.30, datagrams to/from the device are initially (before handover) forwarded to the mobile through one base station (which we’ll refer to as the </span><span class="font53" style="font-style:italic;">source</span><span class="font53"> base station), and after handover are routed to the mobile device through another base station (which we’ll refer to as the </span><span class="font53" style="font-style:italic;">target</span><span class="font53"> base station). As we will see, a handover between base stations results not only in the mobile device transmitting/ receiving to/from a new base station but also in a change of the base-station side of the Serving-Gateway-to-base-station tunnel in Figure 7.29. In the simplest case of handover, when the two base stations are near each other and in the same network, all changes occurring as a result of handover are thus relatively local. In particular, the PDN gateway being used by the Serving Gateway remains blissfully unaware of device mobility. Of course, more complicated handoff scenarios will require the use of more complex mechanisms [Sauter 2014; GSMA 2019a].</span></p>
<div><img src="networking_files/networking-549.jpg" alt="" style="width:43pt;height:23pt;">
<p><span class="font4">PDN gateway (P-GW)</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-550.jpg" alt="" style="width:267pt;height:162pt;">
<p><span class="font7" style="font-weight:bold;">Figure 7.30 </span><span class="font50">♦ </span><span class="font5">Steps in handing over a mobile device from the source base station to the target base station</span></p>
</div><br clear="all">
<p><span class="font53">There may be several reasons for handover to occur. For example, the signal between the current base station and the mobile may have deteriorated to such an extent that communication is severely impaired. Or a cell may have become overloaded, handling a large amount of traffic; handing over mobile devices to less congested nearby cells may alleviate this congestion. A mobile device periodically measures characteristics of a beacon signal from its current base station as well as signals from nearby base stations that it can “hear.” These measurements are reported once or twice a second to the mobile device’s current (source) base station. Based on these measurements, the current loads of mobiles in nearby cells, and other factors, the source base station may choose to initiate a handover. The 4G/5G standards do not specify a specific algorithm to be used by a base station to determine whether or not to perform handover, or which target base station to choose; this is an active area of research [Zheng 2008; Alexandris 2016].</span></p>
<p><span class="font53">Figure 7.30 illustrates the steps involved when a source base station decides to hand over a mobile device to the target base station.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">1. The current (source) base station selects the target base station, and sends a Handover Request message to the target base station.</span></p></li>
<li>
<p><span class="font53">2. The target base station checks whether it has the resources to support the mobile device and its quality of service requirements. If so, it pre-allocates channel resources (e.g., time slots) on its radio access network and other resources</span></p></li></ul>
<p><span class="font53">for that device. This pre-allocation of resources frees the mobile device from having to go through the time-consuming base-station association protocol discussed earlier, allowing handover to be executed as fast as possible. The target base station replies to the source base station with a Handover Request Acknowledge message, containing all the information at the target base station that the mobile device will need to associate with the new base station.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">3. The source base station receives the Handover Request Acknowledgement message and informs the mobile device of the target base station’s identity and channel access information. At this point, the mobile device can begin send-ing/receiving datagrams to/from the new target base station. From the mobile device’s point of view, handover is now complete! However, there is still a bit of work to be done within the network.</span></p></li>
<li>
<p><span class="font53">4. The source base station will also stop forwarding datagrams to the mobile device and instead forward any tunneled datagrams it receives to the target base station, which will later forward these datagrams to the mobile device.</span></p></li>
<li>
<p><span class="font53">5. The target base station informs the MME that it (the target base station) will be the new base station servicing the mobile device. The MME, in turn, signals</span></p></li></ul>
<p><span class="font53">to the Serving Gateway and the target base station to reconfigure the Serving-Gateway-to-base-station tunnel to terminate at the target base station, rather than at the source base station.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">6. The target base station confirms back to the source base station that the tunnel has been reconfigured, allowing the source base station to release resources associated with that mobile device.</span></p></li>
<li>
<p><span class="font53">7. At this point, the target base station can also begin delivering datagrams to the mobile device, including datagrams forwarded to the target base station by the source base station during handover, as well as datagrams newly arriving on the reconfigured tunnel from the Serving Gateway. It can also forward outgoing datagrams received from the mobile device into the tunnel to the Serving Gateway.</span></p></li></ul>
<p><span class="font53">The roaming configurations in today’s 4G LTE networks, such as that discussed above, will also be used in future emerging 5G networks [GSMA 2019c]. Recall, however, from our discussion in Section 7.4.6 that the 5G networks will be denser, with significantly smaller cell sizes. This will make handover an even more critically important network function. In addition, low handover latency will be critical for many real-time 5G applications. The migration of the cellular network control plane to the SDN framework that we studied earlier in Chapter 5 [GSMA 2018b; Condoluci 2018] promises to enable implementations of a higher-capacity, lower-latency 5G cellular network control plane. The application of SDN in a 5G context is the subject of considerable research [Giust 2015; Ordonez-Lucena 2017; Nguyen 2016].</span></p>
<p><span class="font56" style="font-weight:bold;">7.6.2 </span><span class="font23" style="font-weight:bold;">Mobile IP</span></p>
<p><span class="font53">Today’s Internet does not have any widely deployed infrastructure that provides the type of services for “on the go” mobile users that we encountered for 4G/5G cellular networks. But this is certainly not due to the lack of technical solutions for providing such services in an Internet setting! Indeed, the Mobile IP architecture and protocols [RFC 5944] that we will briefly discuss below have been standardized by Internet RFCs for more than 20 years, and research has continued on new, more secure and more generalized mobility solutions [Venkataramani 2014].</span></p>
<p><a name="bookmark441"></a><span class="font53">Instead, it has perhaps been the lack of motivating business and use cases [Arkko 2012] and the timely development and deployment of alternative mobility solutions in cellular networks that has blunted the deployment of Mobile IP. Recall that 20 years ago, 2G cellular networks had already provided a solution for mobile voice services (the “killer app” for mobile users); additionally, next generation 3G networks supporting voice </span><span class="font53" style="font-style:italic;">and</span><span class="font53"> data were on the horizon. Perhaps the dual technology solution—mobile services via cellular networks when we are truly mobile and “on the go” (i.e., the rightmost side of the mobility spectrum in Figure 7.24) and Internet services via 802.11 networks or wireline networks when we are stationary or moving locally (i.e., the leftmost side of the mobility spectrum in Figure 7.24)—that we had 20 years ago and still have today will persist into the future.</span></p>
<p><span class="font53">It will nonetheless be instructive to briefly overview the Mobile IP standard here, as it provides many of the same services as cellular networks and implements many of the same basic mobility principles. Earlier editions of this textbook have provided a more in-depth study of Mobile IP than we will provide here; the interested reader can find this retired material on this textbook’s website. The Internet architecture and protocols for supporting mobility, collectively known as Mobile IP, are defined primarily in RFC 5944 for IPv4. Mobile IP, like 4G/5G, is a complex standard, and would require an entire book to describe in detail; indeed one such book is [Perkins 1998b]. Our modest goal here is to provide an overview of the most important aspects of Mobile IP.</span></p>
<p><span class="font53">The overall architecture and elements of Mobile IP are strikingly similar to that of cellular provider networks. There is a strong notion of a home network, in which a mobile device has a permanent IP address, and visited networks (known as “foreign” networks in Mobile IP), where the mobile device will be allocated a care-of-address. The home agent in Mobile IP has a similar function to the LTE HSS: it tracks the location of a mobile device by receiving updates from foreign agents in foreign networks visited by that mobile device, just as the HSS receives updates from Mobility Management Entities (MMEs) in visited networks in which a 4G mobile device resides. And both 4G/5G and Mobile IP use indirect routing to a mobile node, using tunnels to connect the gateway routers in the home and visited/foreign networks. Table 7.3 summarizes the elements of the Mobile IP architecture, along with a comparison with similar elements in 4G/5G networks</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font6">4G/5G element</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Mobile IP element</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Discussion</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Home network</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Home network</span></p></td><td></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Visited network</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Foreign network</span></p></td><td></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">IMSI identifier</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Permanent IP address</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Globally unique routable address information</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Home Subscriber Service (HSS)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Home agent</span></p></td><td></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Mobility Management Entity (MME)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Foreign agent</span></p></td><td></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Data plane: indirect forwarding via the home network, with tunneling between the home and visited network, and tunneling within the network in which the mobile device resides</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Data plane: indirect forwarding via the home network, with tunneling between the home and visited network</span></p></td><td></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Base station (eNode-B)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Access Point (AP)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">No specific AP technology is specified in Mobile IP</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Radio Access Network</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">WLAN</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">No specific WLAN technology is specified in Mobile IP</span></p></td></tr>
</table>
<p><span class="font7" style="font-weight:bold;">Table 7.3 </span><span class="font50">♦ </span><span class="font5">Commonalities between 4G/5G and Mobile IP architectures</span></p>
<p><span class="font53">The mobile IP standard consists of three main pieces:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Agent discovery.</span><span class="font53"> Mobile IP defines the protocols used by a foreign agent to advertise its mobility services to a mobile device that wishes to attach to its network. Those services will include providing a care-of-address to the mobile device for use in the foreign network, registration of the mobile device with the home agent in the mobile device’s home network, and forwarding of datagrams to/from the mobile device, among other services.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Registration with the home agent.</span><span class="font53"> Mobile IP defines the protocols used by the mobile device and/or foreign agent to register and deregister a care-of-address with a mobile device’s home agent.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Indirect routing of datagrams.</span><span class="font53"> Mobile IP also defines the manner in which datagrams are forwarded to mobile devices by a home agent, including rules for forwarding datagrams and handling error conditions, and several forms of tunneling [RFC 2003, RFC 2004].</span></p></li></ul>
<p><span class="font53">Again, our coverage here of Mobile IP has been intentionally brief. The interested reader should consult the references in this section, or more-detailed discussions of Mobile IP in earlier editions of this textbook.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">7.7 </span><span class="font24" style="font-weight:bold;">Wireless and Mobility: Impact on Higher-Layer Protocols</span></p></li></ul>
<p><span class="font53">In this chapter, we’ve seen that wireless networks differ significantly from their wired counterparts at both the link layer (as a result of wireless channel characteristics such as fading, multipath, and hidden terminals) and at the network layer (as a result of mobile users who change their points of attachment to the network). But are there important differences at the transport and application layers? It’s tempting to think that these differences will be minor, since the network layer provides the same best-effort delivery service model to upper layers in both wired and wireless networks. Similarly, if protocols such as TCP or UDP are used to provide transportlayer services to applications in both wired and wireless networks, then the application layer should remain unchanged as well. In one sense, our intuition is right—TCP and UDP can (and do) operate in networks with wireless links. On the other hand, transport protocols in general, and TCP in particular, can sometimes have very different performance in wired and wireless networks, and it is here, in terms of performance, that differences are manifested. Let’s see why.</span></p>
<p><a name="bookmark442"></a><span class="font53">Recall that TCP retransmits a segment that is either lost or corrupted on the path between sender and receiver. In the case of mobile users, loss can result from either network congestion (router buffer overflow) or from handover (e.g., from delays in rerouting segments to a mobile’s new point of attachment to the network). In all cases, TCP’s receiver-to-sender ACK indicates only that a segment was not received intact; the sender is unaware of whether the segment was lost due to congestion, during handover, or due to detected bit errors. In all cases, the sender’s response is the same—to retransmit the segment. TCP’s congestion-control response is </span><span class="font53" style="font-style:italic;">also</span><span class="font53"> the same in all cases—TCP decreases its congestion window, as discussed in Section 3.7. By unconditionally decreasing its congestion window, TCP implicitly assumes that segment loss results from congestion rather than corruption or handover. We saw in Section 7.2 that bit errors are much more common in wireless networks than in wired networks. When such bit errors occur or when handover loss occurs, there’s really no reason for the TCP sender to decrease its congestion window (and thus decrease its sending rate). Indeed, it may well be the case that router buffers are empty and packets are flowing along the end-to-end path unimpeded by congestion.</span></p>
<p><span class="font53">Researchers realized in the early to mid 1990s that given high bit error rates on wireless links and the possibility of handover loss, TCP’s congestion-control response could be problematic in a wireless setting. Three broad classes of approaches are possible for dealing with this problem:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Local recovery.</span><span class="font53"> Local recovery protocols recover from bit errors when and where (e.g., at the wireless link) they occur, for example, the 802.11 ARQ protocol we studied in Section 7.3, or more sophisticated approaches that use both ARQ and FEC [Ayanoglu 1995] that we saw in use in 4G/5G networks in Section 7.4.2.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">TCP sender awareness of wireless links.</span><span class="font53"> In the local recovery approaches, the TCP sender is blissfully unaware that its segments are traversing a wireless link. An alternative approach is for the TCP sender and receiver to be aware of the existence of a wireless link, to distinguish between congestive losses occurring in the wired network and corruption/loss occurring at the wireless link, and to invoke congestion control only in response to congestive wired-network losses. [Liu 2003] investigates techniques for distinguishing between losses on the wired and wireless segments of an end-to-end path. [Huang 2013] provides insights on developing transport protocol mechanisms and applications that are more LTE-friendly.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Split-connection approaches.</span><span class="font53"> In a split-connection approach [Bakre 1995], the end-to-end connection between the mobile user and the other end point is broken into two transport-layer connections: one from the mobile host to the wireless access point, and one from the wireless access point to the other communication end point (which we’ll assume here is a wired host). The end-to-end connection is thus formed by the concatenation of a wireless part and a wired part. The transport layer over the wireless segment can be a standard TCP connection [Bakre 1995], or a specially tailored error recovery protocol on top of UDP. [Yavatkar 1994] investigates the use of a transport-layer selective repeat protocol over the wireless connection. Measurements reported in [Wei 2006] indicate that split TCP connections have been widely used in cellular data networks, and that significant improvements can indeed be made through the use of split TCP connections.</span></p></li></ul>
<p><span class="font53">Our treatment of TCP over wireless links has been necessarily brief here. In-depth surveys of TCP challenges and solutions in wireless networks can be found in [Hanabali 2005; Leung 2006]. We encourage you to consult the references for details of this ongoing area of research.</span></p>
<p><span class="font53">Having considered transport-layer protocols, let us next consider the effect of wireless and mobility on application-layer protocols. Because of the shared nature of the wireless spectrum, applications that operate over wireless links, particularly over cellular wireless links, must treat bandwidth as a scarce commodity. For example, a Web server serving content to a Web browser executing on a 4G smartphone will likely not be able to provide the same image-rich content that it gives to a browser operating over a wired connection. Although wireless links do provide challenges at the application layer, the mobility they enable also makes possible a rich set of location-aware and context-aware applications [Baldauf 2007]. More generally, wireless and mobile networks will continue to play a key role in realizing the ubiquitous computing environments of the future [Weiser 1991]. It’s fair to say that we’ve only seen the tip of the iceberg when it comes to the impact of wireless and mobile networks on networked applications and their protocols!</span></p>
<p><span class="font59" style="font-weight:bold;">7.8 </span><span class="font24" style="font-weight:bold;">Summary</span></p>
<p><span class="font53">Wireless and mobile networks first revolutionized telephony and are now having an increasingly profound impact in the world of computer networks as well. With their anytime, anywhere, untethered access into the global network infrastructure, they are not only making network access more ubiquitous, they are also enabling an exciting new set of location-dependent services. Given the growing importance of wireless and mobile networks, this chapter has focused on the principles, common link technologies, and network architectures for supporting wireless and mobile communication.</span></p>
<p><a name="bookmark443"></a><span class="font53">We began this chapter with an introduction to wireless and mobile networks, drawing an important distinction between the challenges posed by the </span><span class="font53" style="font-style:italic;">wireless</span><span class="font53"> nature of the communication links in such networks, and by the </span><span class="font53" style="font-style:italic;">mobility</span><span class="font53"> that these wireless links enable. This allowed us to better isolate, identify, and master the key concepts in each area. We focused first on wireless communication, considering the characteristics of a wireless link in Section 7.2. In Sections 7.3 and 7.4, we examined the link-level aspects of the IEEE 802.11 (WiFi) wireless LAN standard, Bluetooth, and 4G/5G cellular neworks. We then turned our attention to the issue of mobility. In Section 7.5, we identified several forms of mobility, with points along this spectrum posing different challenges and admitting different solutions. We considered the problems of locating and routing to a mobile user, as well as approaches for handing over the mobile user who dynamically moves from one point of attachment to the network to another. We examined how these issues were addressed in 4G/5G networks and in the Mobile IP standard. Finally, we considered the impact of wireless links and mobility on transport-layer protocols and networked applications in Section 7.7.</span></p>
<p><span class="font53">Although we have devoted an entire chapter to the study of wireless and mobile networks, an entire book (or more) would be required to fully explore this exciting and rapidly expanding field. We encourage you to delve more deeply into this field by consulting the many references provided in this chapter.</span></p>
<p><span class="font24" style="font-weight:bold;">Homework Problems and Questions</span></p>
<p><span class="font23" style="font-weight:bold;">Chapter 7 Review Questions</span></p>
<p><span class="font43" style="font-weight:bold;">SECTION 7.1</span></p>
<p><span class="font53">R1. What does it mean for a wireless network to be operating in “infrastructure mode”? If the network is not in infrastructure mode, what mode of operation is it in, and what is the difference between that mode of operation and infrastructure mode?</span></p>
<p><span class="font53">R2. Both MANET and VANET are multi-hop infrastructure-less wireless networks. What is the difference between them?</span></p>
<p><span class="font43" style="font-weight:bold;">SECTION 7.2</span></p>
<p><span class="font53">R3. What are the differences between the following types of wireless channel impairments: path loss, multipath propagation, interference from other sources?</span></p>
<p><span class="font53">R4. As a mobile node gets farther and farther away from a base station, what are two actions that a base station could take to ensure that the loss probability of a transmitted frame does not increase?</span></p>
<p><span class="font43" style="font-weight:bold;">SECTION 7.3</span></p>
<p><span class="font53">R5. Describe the role of the beacon frames in 802.11.</span></p>
<p><span class="font53">R6. An access point periodically sends beacon frames. What are the contents of the beacon frames?</span></p>
<p><span class="font53">R7. Why are acknowledgments used in 802.11 but not in wired Ethernet?</span></p>
<p><span class="font53">R8. What is the difference between passive scanning and active scanning?</span></p>
<p><span class="font53">R9. What are the two main purposes of a CTS frame?</span></p>
<p><span class="font53">R10. Suppose the IEEE 802.11 RTS and CTS frames were as long as the standard DATA and ACK frames. Would there be any advantage to using the CTS and RTS frames? Why or why not?</span></p>
<p><a name="bookmark444"></a><span class="font53">R11. Section 7.3.4 discusses 802.11 mobility, in which a wireless station moves from one BSS to another within the same subnet. When the APs are interconnected with a switch, an AP may need to send a frame with a spoofed MAC address to get the switch to forward the frame properly. Why?</span></p>
<p><span class="font53">R12. What is the difference between Bluetooth and Zigbee in terms of data rate?</span></p>
<p><span class="font53">R13. What is the role of the base station in 4G/5G cellular architecture? With which other 4G/5G network elements (mobile device, MME, HSS, Serving Gateway Router, PDN Gateway Router) does it </span><span class="font53" style="font-style:italic;">directly</span><span class="font53"> communicate with in the control plane? In the data plane?</span></p>
<p><span class="font53">R14. What is an International Mobile Subscriber Identity (IMSI)?</span></p>
<p><span class="font53">R15. What is the role of the Home Subscriber Service (HSS) in 4G/5G cellular architecture? With which other 4G/5G network elements (mobile device, base station, MME, Serving Gateway Router, PDN Gateway Router) does it </span><span class="font53" style="font-style:italic;">directly</span><span class="font53"> communicate with in the control plane? In the data plane?</span></p>
<p><span class="font53">R16. What is the role of the Mobility Management Entity (MME) in 4G/5G cellular architecture? With which other 4G/5G network elements (mobile device, base station, HSS, Serving Gateway Router, PDN Gateway Router) does it </span><span class="font53" style="font-style:italic;">directly </span><span class="font53">communicate with in the control plane? In the data plane?</span></p>
<p><span class="font53">R17. Describe the purpose of two tunnels in the data plane of the 4G/5G cellular architecture. When a mobile device is attached to its own home network, at which 4G/5G network element (mobile device, base station, HSS, MME, Serving Gateway Router, PDN Gateway Router) does each end of each of the two tunnels terminate?</span></p>
<p><span class="font53">R18. What are the three sublayers in the link layer in the LTE protocol stack? Briefly describe their functions.</span></p>
<p><span class="font53">R19. Does the LTE wireless access network use FDMA, TDMA, or both? Explain your answer.</span></p>
<p><span class="font53">R20. Describe the two possible sleep modes of a 4G/5G mobile device. In each of these sleep modes, will the mobile device remain associated with the same base station between the time it goes to sleep and the time it wakes up and first sends/receives a new datagram?</span></p>
<p><span class="font53">R21. What is meant by a “visited network” and a “home network” in 4G/5G cellular architecture?</span></p>
<p><span class="font53">R22. List three important differences between 4G and 5G cellular networks.</span></p>
<p><span class="font43" style="font-weight:bold;">SECTION 7.5</span></p>
<p><span class="font53">R23. What does it mean that a mobile device is said to be “roaming?”</span></p>
<p><span class="font53">R24. What is meant by “hand over” of a network device?</span></p>
<p><span class="font53">R25. What is the difference between direct and indirect routing of datagrams to/ from a roaming mobile host?</span></p>
<p><span class="font53">R26. What does “triangle routing” mean?</span></p>
<p><span class="font51">*The terms used above may differ from the terms found in the official Bluetooth Specification. The terms used in the official specification DO NOT align with Pearson’s commitment to promoting diversity, equality, and inclusion, and protecting against bias and stereotyping in the global population of the learners we serve.</span></p>
<p><span class="font43" style="font-weight:bold;">SECTION 7.6</span></p>
<p><span class="font53">R27. Describe the similarity and differences in tunnel configuration when a mobile device is resident in its home network, versus when it is roaming in a visited network.</span></p>
<p><span class="font53">R28. When a mobile device is handed over from one base station to another in a 4G/5G network, which network element makes the decision to initiate that handover? Which network element chooses the target base station to which the mobile device will be handed over?</span></p>
<p><span class="font53">R29. Describe how and when the forwarding path of datagrams entering the visited network and destined to the mobile device changes before, during, and after hand over.</span></p>
<p><span class="font53">R30. Consider the following elements of the Mobile IP architecture: the home network, foreign network permanent IP address, home agent, foreign agent, data plane forwarding, Access Point (AP), and WLANs at the network edge. What are the closest equivalent elements in the 4G/5G cellular network architecture?</span></p>
<p><span class="font43" style="font-weight:bold;">SECTION 7.7</span></p>
<p><span class="font53">R31. What are three approaches that can be used to avoid having a single wireless link degrade the performance of an end-to-end transport-layer TCP connection?</span></p>
<p><span class="font24" style="font-weight:bold;">Problems</span></p>
<p><span class="font53">P1. Consider the single-sender CDMA example in Figure 7.5. What would be the sender’s output (for the 2 data bits shown) if the sender’s CDMA code were (1, 1, </span><span class="font55">-</span><span class="font53">1, 1, 1, </span><span class="font55">-</span><span class="font53">1, </span><span class="font55">-</span><span class="font53">1, 1)?</span></p>
<p><span class="font53">P2. Consider sender 2 in Figure 7.6. What is the sender’s output to the channel (before it is added to the signal from sender 1), Z<sup>2</sup> </span><span class="font53" style="font-style:italic;"><sub>!m</sub></span><span class="font53">?</span></p>
<p><span class="font53">P3. After selecting the AP with which to associate, a wireless host sends an association request frame to the AP, and the AP responds with an association response frame. Once associated with an AP, the host will want to join the subnet (in the IP addressing sense of Section 4.4.2) to which the AP belongs. What does the host do next?</span></p>
<p><span class="font53">P4. If two CDMA senders have codes (1, 1, 1, </span><span class="font55">- </span><span class="font53">1, 1, </span><span class="font55">- </span><span class="font53">1, </span><span class="font55">- </span><span class="font53">1, </span><span class="font55">- </span><span class="font53">1) and (1, </span><span class="font55">- </span><span class="font53">1, 1, 1, 1, 1, 1, 1), would the corresponding receivers be able to decode the data correctly? Justify.</span></p>
<p><span class="font53">P5. Suppose there are two ISPs providing WiFi access in a particular cafe, with each ISP operating its own AP and having its own IP address block.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Further suppose that by accident, each ISP has configured its AP to operate over channel 11. Will the 802.11 protocol completely break down in this situation? Discuss what happens when two stations, each associated with a different ISP, attempt to transmit at the same time.</span></p></li>
<li>
<p><span class="font53">b. Now suppose that one AP operates over channel 1 and the other over channel 11. How do your answers change?</span></p></li></ul>
<p><span class="font53">P6. In step 4 of the CSMA/CA protocol, a station that successfully transmits a frame begins the CSMA/CA protocol for a second frame at step 2, rather than at step 1. What rationale might the designers of CSMA/CA have had in mind by having such a station not transmit the second frame immediately (if the channel is sensed idle)?</span></p>
<p><span class="font53">P7. Suppose an 802.11b station is configured to always reserve the channel with the RTS/CTS sequence. Suppose this station suddenly wants to transmit 1,000 bytes of data, and all other stations are idle at this time. Assume a transmission rate of 10 Mbps. Calculate the time required to transmit the frame and receive the acknowledgment as a function of SIFS and DIFS, ignoring propagation delay and assuming no bit errors.</span></p>
<p><span class="font53">P8. Consider the scenario shown in Figure 7.31, in which there are four wireless nodes, A, B, C, and D. The radio coverage of the four nodes is shown via the shaded ovals; all nodes share the same frequency. When A transmits, it can only be heard/received by B; when B transmits, both A and C can hear/ receive from B; when C transmits, both B and D can hear/receive from C; when D transmits, only C can hear/receive from D.</span></p>
<p><span class="font53">Suppose now that each node has an infinite supply of messages that it wants to send to each of the other nodes. If a message’s destination is not an immediate neighbor, then the message must be relayed. For example, if A wants to send to D, a message from A must first be sent to B, which then sends the message to C, which then sends the message to D. Time is slotted, with a message transmission time taking exactly one time slot, e.g., as in slotted Aloha. During a slot, a node can do one of the following: </span><span class="font53" style="font-style:italic;">(i)</span><span class="font53"> send a message, </span><span class="font53" style="font-style:italic;">(ii)</span><span class="font53"> receive a message (if exactly one message is being sent to it), (</span><span class="font53" style="font-style:italic;">iii</span><span class="font53">) remain silent. As always, if a node hears two or more simultaneous transmissions, a collision occurs and none of the transmitted messages are received successfully. You can assume here that there are no bit-level errors, and thus if exactly one message is sent, it will be received correctly by those within the transmission radius of the sender.</span></p>
<ul style="list-style:none;"><li>
<p class="font53">a. Suppose now that an omniscient controller (i.e., a controller that knows the state of every node in the network) can command each node to do whatever it (the omniscient controller) wishes, that is, to send a message, to receive a</p></li></ul><img src="networking_files/networking-551.jpg" alt="" style="width:211pt;height:45pt;">
<p><span class="font7" style="font-weight:bold;">Figure 7.31 </span><span class="font50">♦ </span><span class="font5">Scenario for problem P8</span></p>
<p><span class="font53">message, or to remain silent. Given this omniscient controller, what is the maximum rate at which a data message can be transferred from C to A, given that there are no other messages between any other source/destination pairs?</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">b. Suppose now that A sends messages to B, and D sends messages to C. What is the combined maximum rate at which data messages can flow from A to B and from D to C?</span></p></li>
<li>
<p><span class="font53">c. Suppose now that A sends messages to B, and C sends messages to D. What is the combined maximum rate at which data messages can flow from A to B and from C to D?</span></p></li>
<li>
<p><span class="font53">d. Suppose now that the wireless links are replaced by wired links. Repeat questions (a) through (c) again in this wired scenario.</span></p></li>
<li>
<p><span class="font53">e. Now suppose we are again in the wireless scenario, and that for every data message sent from source to destination, the destination will send an ACK message back to the source (e.g., as in TCP). Also suppose that each ACK message takes up one slot. Repeat questions (a)-(c) above for this scenario.</span></p></li></ul>
<p><span class="font53">P9. Power is a precious resource in mobile devices, and thus the 802.11 standard provides power-management capabilities that allow 802.11 nodes to minimize the amount of time that their sense, transmit, and receive functions and other circuitry need to be “on.” In 802.11, a node is able to explicitly alternate between sleep and wake states. Explain in brief how a node communicates with the AP to perform power management.</span></p>
<p><span class="font53">P10. Consider the following idealized LTE scenario. The downstream channel (see Figure 7.22) is slotted in time, across F frequencies. There are four nodes, A, B, C, and D, reachable from the base station at rates of 10 Mbps, 5 Mbps, 2.5 Mbps, and 1 Mbps, respectively, on the downstream channel. These rates assume that the base station utilizes all time slots available on all F frequencies to send to just one station. The base station has an infinite amount of data to send to each of the nodes, and can send to any one of these four nodes using any of the F frequencies during any time slot in the downstream sub-frame.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. What is the maximum rate at which the base station can send to the nodes, assuming it can send to any node it chooses during each time slot? Is your solution fair? Explain and define what you mean by “fair.”</span></p></li>
<li>
<p><span class="font53">b. If there is a fairness requirement that each node must receive an equal amount of data during each one second interval, what is the average transmission rate by the base station (to all nodes) during the downstream sub-frame? Explain how you arrived at your answer.</span></p></li>
<li>
<p><span class="font53">c. Suppose that the fairness criterion is that any node can receive at most twice as much data as any other node during the sub-frame. What is the average transmission rate by the base station (to all nodes) during the subframe? Explain how you arrived at your answer.</span></p></li></ul>
<p><span class="font53">P11. In Section 7.5, one proposed solution that allowed mobile users to maintain their IP addresses as they moved among foreign networks was to have a foreign network advertise a highly specific route to the mobile user and use the existing routing infrastructure to propagate this information throughout the network. We identified scalability as one concern. Suppose that when a mobile user moves from one network to another, the new foreign network advertises a specific route to the mobile user, and the old foreign network withdraws its route. Consider how routing information propagates in a distance-vector algorithm (particularly for the case of interdomain routing among networks that span the globe).</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Will other routers be able to route datagrams immediately to the new foreign network as soon as the foreign network begins advertising its route?</span></p></li>
<li>
<p><span class="font53">b. Is it possible for different routers to believe that different foreign networks contain the mobile user?</span></p></li>
<li>
<p><span class="font53">c. Discuss the timescale over which other routers in the network will eventually learn the path to the mobile users.</span></p></li></ul>
<p><span class="font53">P12. In 4G/5G networks, what effect will handoff have on end-to-end delays of datagrams between the source and destination?</span></p>
<p><span class="font53">P13. Consider a mobile device that powers on and attaches to an LTE visited network </span><span class="font53" style="font-style:italic;">A,</span><span class="font53"> and assume that indirect routing to the mobile device from its home network </span><span class="font53" style="font-style:italic;">H</span><span class="font53"> is being used. Subsequently, while roaming, the device moves out of range of visited network </span><span class="font53" style="font-style:italic;">A</span><span class="font53"> and moves into range of an LTE visited network </span><span class="font53" style="font-style:italic;">B.</span><span class="font53"> You will design a handover process from a base station </span><span class="font53" style="font-style:italic;">BS.A</span><span class="font53"> in visited network </span><span class="font53" style="font-style:italic;">A</span><span class="font53"> to a base station </span><span class="font53" style="font-style:italic;">BS.B</span><span class="font53"> in visited network </span><span class="font53" style="font-style:italic;">B</span><span class="font53">. Sketch the series of steps that would need to be taken, taking care to identify the network elements involved (and the networks to which they belong), to accomplish this handover. Assume that following handover, the tunnel from the home network to the visited network will terminate in visiting network </span><span class="font53" style="font-style:italic;">B</span><span class="font53">.</span></p>
<p><span class="font53">P14. Consider again the scenario in Problem P13. But now assume that the tunnel from home network </span><span class="font53" style="font-style:italic;">H</span><span class="font53"> to visited network </span><span class="font53" style="font-style:italic;">A</span><span class="font53"> will continue to be used. That is, visited network </span><span class="font53" style="font-style:italic;">A</span><span class="font53"> will serve as an anchor point following handover. (Aside: this is actually the process used for routing circuit-switched voice calls to a roaming mobile phone in 2G GSM networks.) In this case, additional tunnel(s) will need to be built to reach the mobile device in its resident visited network </span><span class="font53" style="font-style:italic;">B</span><span class="font53">. Once again, sketch the series of steps that would need to be taken, taking care to identify the network elements involved (and the networks to which they belong), to accomplish this handover.</span></p>
<p><span class="font53">What are one advantage and one disadvantage of this approach over the approach taken in your solution to Problem P13?</span></p>
<p><span class="font24" style="font-weight:bold;">Wireshark Lab: WiFi</span></p>
<p><a name="bookmark445"></a><span class="font53">At the Web site for this textbook, </span><a href="http://www.pearsonglobaleditions.com"><span class="font53">www.pearsonglobaleditions.com</span></a><span class="font53">, also mirrored on the instructors’ website, </span><a href="http://gaia.cs.umass.edu/kurose_ross"><span class="font53">http://gaia.cs.umass.edu/kurose_ross</span></a><span class="font53">, you’ll find a Wireshark lab for this chapter that captures and studies the 802.11 frames exchanged between a wireless laptop and an access point.</span></p>
<p><span class="font23" style="font-weight:bold;">AN INTERVIEW WITH...</span></p>
<p><span class="font11" style="font-weight:bold;">Deborah Estrin</span></p>
<div><img src="networking_files/networking-552.jpg" alt="" style="width:86pt;height:109pt;">
<p><span class="font3">Courtesy of Deborah Estrin</span></p>
</div><br clear="all">
<p><span class="font46">Deborah Estrin is a Professor of Computer Science and Associate Dean for Impact at Cornell Tech in New York City and a Professor of Public Health at Weill Cornell Medical College. She received her Ph.D. (1985) in Computer Science from M.I.T. and her B.S. (1980) from UC Berkeley. Estrin’s early research focused on the design of network protocols, including multicast and inter-domain routing. In 2002 Estrin founded the NSF-funded Science and Technology Center at UCLA, Center for Embedded Networked Sensing (CENS</span><a href="http://cens.ucla.edu"><span class="font46"> http://cens.ucla.edu.</span></a><span class="font46">). CENS launched new areas of multi-disciplinary computer systems research from sensor networks for environmental monitoring, to participatory sensing and mobile health. As described in her 2013 TEDMED talk, she explores how individuals can benefit from the pervasive data byproducts of digital and IoT interactions for health and life management. Professor Estrin is an elected member of the American Academy of Arts and Sciences (2007), the National Academy of Engineering (2009), and the National Academy of Medicine (2019). She is a Fellow of the IEEE, ACM, and AAAS. She was selected as the first ACM-W Athena Lecturer (2006), awarded the Anita Borg Institute's Women of Vision Award for Innovation (2007), inducted into the WITI hall of fame (2008), received honorary doctorates from EPFL (2008) and Uppsala University (2011), and was selected as a MacArthur Fellow (2018).</span></p>
<p><span class="font4" style="font-weight:bold;">Please describe a few of the most exciting projects you have worked on during your career. What were the biggest challenges?</span></p>
<p><a name="bookmark446"></a><span class="font52">In the mid-90s at USC and ISI, I had the great fortune to work with the likes of Steve Deering, Mark Handley, and Van Jacobson on the design of multicast routing protocols (in particular, PIM). I tried to carry many of the architectural design lessons from multicast into the design of ecological monitoring arrays, where for the first time I really began to take applications and multidisciplinary research seriously. The need for jointly innovating in the social and technological space is what interests me so much about my latest area of research, mobile health. The challenges in multicast routing, environmental sensing and mobile health are as diverse as the problem domains, but what they have in common is the need to keep our eyes open to whether we have the problem definition right as we iterate between design and deployment, prototype and pilot. None of these are problems that could be solved solely analytically, or with simulation or even in constructed laboratory experiments. They challenged our ability to retain clean architectures in the presence of messy problems and contexts, and they required extensive collaboration.</span></p>
<p><span class="font4" style="font-weight:bold;">What changes and innovations do you see happening in wireless networks and mobility in the future?</span></p>
<p><span class="font52">In a prior edition of this interview I said that I have never put much faith into predicting the future, but I did go on to speculate that we might see the end of feature phones (i.e., those that are not programmable and are used only for voice and text messaging) as smart phones become more and more powerful and the primary point of Internet access for many—and now not so many years later that is clearly the case. I also predicted that we would see the continued proliferation of embedded SIMs by which all sorts of devices have the ability to communicate via the cellular network at low data rates. While that has occurred, we see many devices and “Internet of Things” that use embedded WiFi and other lower power, shorter range, forms of connectivity to local hubs. I did not anticipate at that time the emergence of a large consumer wearables market or interactive voice agents like Siri and Alexa. By the time the next edition is published I expect broad proliferation of personal applications that leverage data from IoT and other digital traces.</span></p>
<p><span class="font4" style="font-weight:bold;">Where do you see the future of networking and the Internet?</span></p>
<p><span class="font52">Again I think it’s useful to look both back and forward. Previously I commented that the efforts in named data and software-defined networking would emerge to create a more manageable, evolvable, and richer infrastructure and more generally represent moving the role of architecture higher up in the stack. In the beginnings of the Internet, architecture was layer 4 and below, with applications being more siloed/monolithic, sitting on top. Now data and analytics dominate transport. The adoption of SDN (which I was really happy to see introduced into the 7 th edition of this book) has been well beyond what I ever anticipated. That said, new challenges have emerged from higher up in the stack. Machine Learning based systems and services favor scale, particularly when they rely on continuous consumer engagement (clicks) for financial viability. The resulting information ecosystem has become far more monolithic than in earlier decades. This is a challenge for networking, the Internet, and frankly our society.</span></p>
<p><span class="font4" style="font-weight:bold;">What people inspired you professionally?</span></p>
<p><span class="font52">There are three people who come to mind. First, Dave Clark, the secret sauce and undersung hero of the Internet community. I was lucky to be around in the early days to see him act as the “organizing principle” of the IAB and Internet governance; the priest of rough consensus and running code. Second, Scott Shenker, for his intellectual brilliance, integrity, and persistence. I strive for, but rarely attain, his clarity in defining problems and solutions. He is always the first person I e-mail for advice on matters large and small. Third, my sister Judy Estrin, who had the creativity and commitment to spend the first half of her career bringing ideas and concepts to market; and now has the courage to study, write, and advise on how to rebuild it to support a healthier democracy.</span></p>
<p><span class="font4" style="font-weight:bold;">What are your recommendations for students who want careers in computer science and networking?</span></p>
<p><span class="font52">First, build a strong foundation in your academic work, balanced with any and every real-world work experience you can get. As you look for a working environment, seek opportunities in problem areas you really care about and with smart teams that you can learn from and work with to build things that matter.</span></p>
<p><span class="font70" style="font-style:italic;">This page is intentionally left blank</span></p><img src="networking_files/networking-553.jpg" alt="" style="width:531pt;height:153pt;">
<h1><a name="bookmark8"></a><span class="font27" style="font-weight:bold;">Security in Computer Networks</span></h1>
<p><span class="font53">Way back in Section 1.6, we described some of the more prevalent and damaging classes of Internet attacks, including malware attacks, denial of service, sniffing, source masquerading, and message modification and deletion. Although we have since learned a tremendous amount about computer networks, we still haven’t examined how to secure networks from those attacks. Equipped with our newly acquired expertise in computer networking and Internet protocols, we’ll now study in-depth secure communication and, in particular, how computer networks can be defended from those nasty bad guys.</span></p>
<p><span class="font53">Let us introduce Alice and Bob, two people who want to communicate and wish to do so “securely.” This being a networking text, we should remark that Alice and Bob could be two routers that want to exchange routing tables securely, a client and server that want to establish a secure transport connection, or two e-mail applications that want to exchange secure e-mail—all case studies that we will consider later in this chapter. Alice and Bob are well-known fixtures in the security community, perhaps because their names are more fun than a generic entity named “A” that wants to communicate securely with a generic entity named “B.” Love affairs, wartime communication, and business transactions are the commonly cited human needs for secure communications; preferring the first to the latter two, we’re happy to use Alice and Bob as our sender and receiver, and imagine them in this first scenario.</span></p>
<p><a name="bookmark447"></a><span class="font53">We said that Alice and Bob want to communicate and wish to do so “securely,” but what precisely does this mean? As we will see, security (like love) is a many-splendored thing; that is, there are many facets to security. Certainly, Alice and Bob would like for the contents of their communication to remain secret from an eavesdropper. They probably would also like to make sure that when they are communicating, they are indeed communicating with each other, and that if their communication is tampered with by an eavesdropper, that this tampering is detected. In the first part of this chapter, we’ll cover the fundamental cryptography techniques that allow for encrypting communication, authenticating the party with whom one is communicating, and ensuring message integrity.</span></p>
<p><span class="font53">In the second part of this chapter, we’ll examine how the fundamental cryptography principles can be used to create secure networking protocols. Once again taking a top-down approach, we’ll examine secure protocols in each of the (top four) layers, beginning with the application layer. We’ll examine how to secure e-mail, how to secure a TCP connection, how to provide blanket security at the network layer, and how to secure a wireless LAN. In the third part of this chapter we’ll consider operational security, which is about protecting organizational networks from attacks. In particular, we’ll take a careful look at how firewalls and intrusion detection systems can enhance the security of an organizational network.</span></p>
<p><span class="font59" style="font-weight:bold;">8.1 </span><span class="font24" style="font-weight:bold;">What Is Network Security?</span></p>
<p><span class="font53">Let’s begin our study of network security by returning to our lovers, Alice and Bob, who want to communicate “securely.” What precisely does this mean? Certainly, Alice wants only Bob to be able to understand a message that she has sent, even though they </span><span class="font53" style="font-style:italic;">are</span><span class="font53"> communicating over an insecure medium where an intruder (Trudy, the intruder) may intercept whatever is transmitted from Alice to Bob. Bob also wants to be sure that the message he receives from Alice was indeed sent by Alice, and Alice wants to make sure that the person with whom she is communicating is indeed Bob. Alice and Bob also want to make sure that the contents of their messages have not been altered in transit. They also want to be assured that they can communicate in the first place (i.e., that no one denies them access to the resources needed to communicate). Given these considerations, we can identify the following desirable properties of </span><span class="font53" style="font-weight:bold;">secure communication</span><span class="font53">.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Confidentiality.</span><span class="font53"> Only the sender and intended receiver should be able to understand the contents of the transmitted message. Because eavesdroppers may intercept the message, this necessarily requires that the message be somehow </span><span class="font53" style="font-weight:bold;">encrypted </span><span class="font53">so that an intercepted message cannot be understood by an interceptor. This aspect of confidentiality is probably the most commonly perceived meaning of the term </span><span class="font53" style="font-style:italic;">secure communication.</span><span class="font53"> We’ll study cryptographic techniques for encrypting and decrypting data in Section 8.2.</span></p></li>
<li>
<p><a name="bookmark448"></a><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Message integrity.</span><span class="font53"> Alice and Bob want to ensure that the content of their communication is not altered, either maliciously or by accident, in transit. Extensions to the checksumming techniques that we encountered in reliable transport</span></p></li></ul>
<p><span class="font53">and data link protocols can be used to provide such message integrity. We will study message integrity in Section 8.3.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">End-point authentication.</span><span class="font53"> Both the sender and receiver should be able to confirm the identity of the other party involved in the communication—to confirm that the other party is indeed who or what they claim to be. Face-to-face human communication solves this problem easily by visual recognition. When communicating entities exchange messages over a medium where they cannot see the other party, authentication is not so simple. When a user wants to access an inbox, how does the mail server verify that the user is the person he or she claims to be? We study end-point authentication in Section 8.4.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Operational security.</span><span class="font53"> Almost all organizations (companies, universities, and so on) today have networks that are attached to the public Internet. These networks therefore can potentially be compromised. Attackers can attempt to deposit worms into the hosts in the network, obtain corporate secrets, map the internal network configurations, and launch DoS attacks. We’ll see in Section 8.9 that operational devices such as firewalls and intrusion detection systems are used to counter attacks against an organization’s network. A firewall sits between the organization’s network and the public network, controlling packet access to and from the network. An intrusion detection system performs “deep packet inspection,” alerting the network administrators about suspicious activity.</span></p></li></ul>
<p><span class="font53">Having established what we mean by network security, let’s next consider exactly what information an intruder may have access to, and what actions can be taken by the intruder. Figure 8.1 illustrates the scenario. Alice, the sender, wants to send data to Bob, the receiver. In order to exchange data securely, while meeting the requirements of confidentiality, end-point authentication, and message integrity, Alice and Bob will exchange control messages and data messages (in much the same way that TCP senders and receivers exchange control segments and data segments).</span></p>
<div>
<p><span class="font4">Data</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-554.jpg" alt="" style="width:46pt;height:77pt;">
<p><span class="font4">Secure sender</span></p>
<p><span class="font4">Alice</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Control, data messages</span></p><img src="networking_files/networking-555.jpg" alt="" style="width:124pt;height:45pt;">
</div><br clear="all">
<div><img src="networking_files/networking-556.jpg" alt="" style="width:27pt;height:42pt;">
<p><span class="font4">Trudy</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Secure receiver</span></p><img src="networking_files/networking-557.jpg" alt="" style="width:38pt;height:76pt;">
<p><span class="font4">Bob</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Data</span></p>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 8.1 </span><span class="font50">♦ </span><span class="font5">Sender, receiver, and intruder (Alice, Bob, and Trudy)</span></p>
<p><span class="font53">All or some of these messages will typically be encrypted. As discussed in Section 1.6, an intruder can potentially perform</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">eavesdropping—</span><span class="font53">sniffing and recording control and data messages on the channel.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">modification, insertion,</span><span class="font53"> or </span><span class="font53" style="font-style:italic;">deletion</span><span class="font53"> of messages or message content.</span></p></li></ul>
<p><span class="font53">As we’ll see, unless appropriate countermeasures are taken, these capabilities allow an intruder to mount a wide variety of security attacks: snooping on communication (possibly stealing passwords and data), impersonating another entity, hijacking an ongoing session, denying service to legitimate network users by overloading system resources, and so on. A summary of reported attacks is maintained at the CERT Coordination Center [CERT 2020].</span></p>
<p><span class="font53">Having established that there are indeed real threats loose in the Internet, what are the Internet equivalents of Alice and Bob, our friends who need to communicate securely? Certainly, Bob and Alice might be human users at two end systems, for example, a real Alice and a real Bob who really do want to exchange secure e-mail. They might also be participants in an electronic commerce transaction. For example, a real Bob might want to transfer his credit card number securely to a Web server to purchase an item online. Similarly, a real Alice might want to interact with her bank online. The parties needing secure communication might themselves also be part of the network infrastructure. Recall that the domain name system (DNS, see Section 2.4) or routing daemons that exchange routing information (see Chapter 5) require secure communication between two parties. The same is true for network management applications, a topic we examined in Chapter 5). An intruder that could actively interfere with DNS lookups (as discussed in Section 2.4), routing computations (Sections 5.3 and 5.4), or network management functions (Sections 5.5 and 5.7) could wreak havoc in the Internet.</span></p>
<p><span class="font53">Having now established the framework, a few of the most important definitions, and the need for network security, let us next delve into cryptography. While the use of cryptography in providing confidentiality is self-evident, we’ll see shortly that it is also central to providing end-point authentication and message integrity—making cryptography a cornerstone of network security.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">8.2 </span><span class="font24" style="font-weight:bold;">Principles of Cryptography</span></p></li></ul>
<p><a name="bookmark449"></a><span class="font53">Although cryptography has a long history dating back at least as far as Julius Caesar, modern cryptographic techniques, including many of those used in the Internet, are based on advances made in the past 30 years. Kahn’s book, </span><span class="font53" style="font-style:italic;">The Codebreakers</span><span class="font53"> [Kahn 1967], and Singh’s book, </span><span class="font53" style="font-style:italic;">The Code Book: The Science of Secrecy from Ancient Egypt to Quantum Cryptography</span><span class="font53"> [Singh 1999], provide a fascinating look at the</span></p>
<p><span class="font4">Plaintext</span></p>
<div>
<p><span class="font4">Plaintext</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Ciphertext</span></p>
<p><span class="font4">Encryption algorithm</span></p>
<p><span class="font4">&gt; Decryption lgorithm</span></p>
<p><span class="font4" style="font-style:italic;font-variant:small-caps;"><sup>K</sup>a</span></p><img src="networking_files/networking-558.jpg" alt="" style="width:201pt;height:100pt;">
<p><span class="font4">Alice</span></p>
<p><span class="font4">Bob</span></p>
<p><span class="font4">Trudy</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 8.2 </span><span class="font50">♦ </span><span class="font5">Cryptographic components</span></p>
</div><br clear="all">
<p><span class="font4">Key:</span></p>
<p><span class="font53">long history of cryptography. A complete discussion of cryptography itself requires a complete book [Bishop 2003; Kaufman 2002; Schneier 2015] and so we only touch on the essential aspects of cryptography, particularly as they are practiced on the Internet. We also note that while our focus in this section will be on the use of cryptography for confidentiality, we’ll see shortly that cryptographic techniques are inextricably woven into authentication, message integrity, nonrepudiation, and more.</span></p>
<p><span class="font53">Cryptographic techniques allow a sender to disguise data so that an intruder can gain no information from the intercepted data. The receiver, of course, must be able to recover the original data from the disguised data. Figure 8.2 illustrates some of the important terminology.</span></p>
<p><span class="font53">Suppose now that Alice wants to send a message to Bob. Alice’s message in its original form (e.g., “</span><span class="font36">Bob, I love you. Alice</span><span class="font53">”) is known as </span><span class="font53" style="font-weight:bold;">plaintext</span><span class="font53">, or </span><span class="font53" style="font-weight:bold;">cleartext</span><span class="font53">. Alice encrypts her plaintext message using an </span><span class="font53" style="font-weight:bold;">encryption algorithm </span><span class="font53">so that the encrypted message, known as </span><span class="font53" style="font-weight:bold;">ciphertext</span><span class="font53">, looks unintelligible to any intruder. Interestingly, in many modern cryptographic systems, including those used in the Internet, the encryption technique itself is </span><span class="font53" style="font-style:italic;">known—</span><span class="font53">published, standardized, and available to everyone (e.g., [RFC 1321; RFC 3447; RFC 2420; NIST 2001]), even a potential intruder! Clearly, if everyone knows the method for encoding data, then there must be some secret information that prevents an intruder from decrypting the transmitted data. This is where keys come in.</span></p>
<p><span class="font53">In Figure 8.2, Alice provides a </span><span class="font53" style="font-weight:bold;">key</span><span class="font53">, </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">A</span><span class="font53" style="font-style:italic;">,</span><span class="font53"> a string of numbers or characters, as input to the encryption algorithm. The encryption algorithm takes the key and the plaintext message, </span><span class="font53" style="font-style:italic;">m,</span><span class="font53"> as input and produces ciphertext as output. The notation </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">A</span><span class="font53" style="font-style:italic;">(m)</span><span class="font53"> refers to the ciphertext form (encrypted using the key </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">A</span><span class="font53" style="font-style:italic;">)</span><span class="font53"> of the plaintext message, </span><span class="font53" style="font-style:italic;">m</span><span class="font53">. The actual encryption algorithm that uses key </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">A</span><span class="font53"> will be evident from the context. Similarly, Bob will provide a key, </span><span class="font53" style="font-style:italic;">K<sub>B</sub>,</span><span class="font53"> to the </span><span class="font53" style="font-weight:bold;">decryption algorithm </span><span class="font53">that takes the ciphertext and Bob’s key as input and produces the original plaintext as output. That is, if Bob receives an encrypted message </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">A</span><span class="font53" style="font-style:italic;">(m),</span><span class="font53"> he decrypts it by computing </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">B</span><span class="font53" style="font-style:italic;">(K</span><span class="font50" style="font-style:italic;">A</span><span class="font53" style="font-style:italic;">(m)) = m.</span><span class="font53"> In </span><span class="font53" style="font-weight:bold;">symmetric key systems</span><span class="font53">, Alice’s and Bob’s keys are identical and are secret. In </span><span class="font53" style="font-weight:bold;">public key systems</span><span class="font53">, a pair of keys is used. One of the keys is known to both Bob and Alice (indeed, it is known to the whole world). The other key is known only by either Bob or Alice (but not both). In the following two subsections, we consider symmetric key and public key systems in more detail.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">8.2.1 </span><span class="font23" style="font-weight:bold;">Symmetric Key Cryptography</span></p></li></ul>
<p><span class="font53">All cryptographic algorithms involve substituting one thing for another, for example, taking a piece of plaintext and then computing and substituting the appropriate ciphertext to create the encrypted message. Before studying a modern key-based cryptographic system, let us first get our feet wet by studying a very old, very simple symmetric key algorithm attributed to Julius Caesar, known as the </span><span class="font53" style="font-weight:bold;">Caesar cipher </span><span class="font53">(a cipher is a method for encrypting data).</span></p>
<p><span class="font53">For English text, the Caesar cipher would work by taking each letter in the plaintext message and substituting the letter that is </span><span class="font53" style="font-style:italic;">k</span><span class="font53"> letters later (allowing wraparound; that is, having the letter </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> followed by the letter </span><span class="font53" style="font-style:italic;">a)</span><span class="font53"> in the alphabet. For example, if </span><span class="font53" style="font-style:italic;">k =</span><span class="font53"> 3, then the letter </span><span class="font53" style="font-style:italic;">a</span><span class="font53"> in plaintext becomes </span><span class="font53" style="font-style:italic;">d</span><span class="font53"> in ciphertext; </span><span class="font53" style="font-style:italic;">b</span><span class="font53"> in plaintext becomes </span><span class="font53" style="font-style:italic;">e</span><span class="font53"> in ciphertext, and so on. Here, the value of </span><span class="font53" style="font-style:italic;">k</span><span class="font53"> serves as the key. As an example, the plaintext message “</span><span class="font36">bob, i love you. Alice</span><span class="font53">” becomes “</span><span class="font36">ere, l oryh brx. dolfh</span><span class="font53">” in ciphertext. While the ciphertext does indeed look like gibberish, it wouldn’t take long to break the code if you knew that the Caesar cipher was being used, as there are only 25 possible key values.</span></p>
<p><span class="font53">An improvement on the Caesar cipher is the </span><span class="font53" style="font-weight:bold;">monoalphabetic cipher</span><span class="font53">, which also substitutes one letter of the alphabet with another letter of the alphabet. However, rather than substituting according to a regular pattern (e.g., substitution with an offset of </span><span class="font53" style="font-style:italic;">k</span><span class="font53"> for all letters), any letter can be substituted for any other letter, as long as each letter has a unique substitute letter, and vice versa. The substitution rule in Figure 8.3 shows one possible rule for encoding plaintext.</span></p>
<p><span class="font53">The plaintext message “</span><span class="font36">bob, i love you. Alice</span><span class="font53">” becomes “</span><span class="font36">nkn, s gktc wky. Mgsbc</span><span class="font53">.” Thus, as in the case of the Caesar cipher, this looks like gibberish. A monoalphabetic cipher would also appear to be better than the Caesar cipher in that there are 26! (on the order of 10<sup>26</sup>) possible pairings of letters rather than 25 possible pairings. A brute-force approach of trying all 10<sup>26</sup> possible pairings</span></p>
<p><span class="font4">Plaintext letter: &nbsp;&nbsp;&nbsp;</span><span class="font34">a b c d e f g h i j k l m n o p q r s t u v w x y z</span></p>
<p><span class="font4">Ciphertext letter: </span><span class="font34">m n b v c x z a s d f g h j k l p o i u y t r e w q</span></p>
<p><a name="bookmark450"></a><span class="font7" style="font-weight:bold;">Figure 8.3 </span><span class="font50">♦ </span><span class="font5">A monoalphabetic cipher </span><span class="font53">would require far too much work to be a feasible way of breaking the encryption algorithm and decoding the message. However, by statistical analysis of the plaintext language, for example, knowing that the letters </span><span class="font53" style="font-style:italic;">e</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">t</span><span class="font53"> are the most frequently occurring letters in typical English text (accounting for 13 percent and 9 percent of letter occurrences), and knowing that particular two-and three-letter occurrences of letters appear quite often together (for example, “in,” “it,” “the,” “ion,” “ing,” and so forth) make it relatively easy to break this code. If the intruder has some knowledge about the possible contents of the message, then it is even easier to break the code. For example, if Trudy the intruder is Bob’s wife and suspects Bob of having an affair with Alice, then she might suspect that the names “bob” and “alice” appear in the text. If Trudy knew for certain that those two names appeared in the ciphertext and had a copy of the example ciphertext message above, then she could immediately determine seven of the 26 letter pairings, requiring 10</span><span class="font50">9 </span><span class="font53">fewer possibilities to be checked by a brute-force method. Indeed, if Trudy suspected Bob of having an affair, she might well expect to find some other choice words in the message as well.</span></p>
<p><span class="font53">When considering how easy it might be for Trudy to break Bob and Alice’s encryption scheme, one can distinguish three different scenarios, depending on what information the intruder has.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Ciphertext-only attack.</span><span class="font53"> In some cases, the intruder may have access only to the intercepted ciphertext, with no certain information about the contents of the plaintext message. We have seen how statistical analysis can help in a </span><span class="font53" style="font-weight:bold;">ciphertext-only attack </span><span class="font53">on an encryption scheme.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Known-plaintext attack.</span><span class="font53"> We saw above that if Trudy somehow knew for sure that “bob” and “alice” appeared in the ciphertext message, then she could have determined the (plaintext, ciphertext) pairings for the letters </span><span class="font53" style="font-style:italic;">a, l, i, c, e, b,</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">o</span><span class="font53">. Trudy might also have been fortunate enough to have recorded all of the ciphertext transmissions and then found Bob’s own decrypted version of one of the transmissions scribbled on a piece of paper. When an intruder knows some of the (plaintext, ciphertext) pairings, we refer to this as a </span><span class="font53" style="font-weight:bold;">known-plaintext attack </span><span class="font53">on the encryption scheme.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Chosen-plaintext attack.</span><span class="font53"> In a </span><span class="font53" style="font-weight:bold;">chosen-plaintext attack</span><span class="font53">, the intruder is able to choose the plaintext message and obtain its corresponding ciphertext form. For the simple encryption algorithms we’ve seen so far, if Trudy could get Alice to send the message, “</span><span class="font36">The quick brown fox jumps over the lazy dog</span><span class="font53">,” she could completely break the encryption scheme. We’ll see shortly that for more sophisticated encryption techniques, a chosen-plaintext attack does not necessarily mean that the encryption technique can be broken.</span></p></li></ul>
<p><span class="font53">Five hundred years ago, techniques improving on monoalphabetic encryption, known as </span><span class="font53" style="font-weight:bold;">polyalphabetic encryption</span><span class="font53">, were invented. The idea behind polyalphabetic encryption is to use multiple monoalphabetic ciphers, with a specific</span></p>
<p><span class="font4">Plaintext letter: </span><span class="font34">a b c d e f g h i j k l m n o p q r s t u v w x y z </span><span class="font4" style="font-style:italic;">C</span><span class="font50" style="font-style:italic;">i</span><span class="font4" style="font-style:italic;">(k =</span><span class="font4"> 5): </span><span class="font34">f g h i j k l m n o p q r s t u v w x y z a b c d e </span><span class="font4">C</span><span class="font50">2</span><span class="font4">(</span><span class="font4" style="font-style:italic;">k</span><span class="font4"> = 19): </span><span class="font34">t u v w x y z a b c d e f g h i j k l m n o p q r s</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 8.4 </span><span class="font50">♦ </span><span class="font5">A polyalphabetic cipher using two Caesar ciphers</span></p>
<p><span class="font53">monoalphabetic cipher to encode a letter in a specific position in the plaintext message. Thus, the same letter, appearing in different positions in the plaintext message, might be encoded differently. An example of a polyalphabetic encryption scheme is shown in Figure 8.4. It has two Caesar ciphers (with </span><span class="font53" style="font-style:italic;">k =</span><span class="font53"> 5 and </span><span class="font53" style="font-style:italic;">k =</span><span class="font53"> 19), shown as rows. We might choose to use these two Caesar ciphers, C</span><span class="font50">1 </span><span class="font53">and C<sub>2</sub>, in the repeating pattern C<sub>1</sub>, C<sub>2</sub>, C<sub>2</sub>, C<sub>1</sub>, C<sub>2</sub>. That is, the first letter of plaintext is to be encoded using C<sub>1</sub>, the second and third using C<sub>2</sub>, the fourth using C<sub>1</sub>, and the fifth using C<sub>2</sub>. The pattern then repeats, with the sixth letter being encoded using C</span><span class="font50">1</span><span class="font53">, the seventh with C<sub>2</sub>, and so on. The plaintext message “</span><span class="font36">bob, i love you</span><span class="font53">.” is thus encrypted “</span><span class="font36">ghu, n etox dhz</span><span class="font53">.” Note that the first </span><span class="font53" style="font-style:italic;">b</span><span class="font53"> in the plaintext message is encrypted using Ci, while the second </span><span class="font53" style="font-style:italic;">b</span><span class="font53"> is encrypted using C<sub>2</sub>. In this example, the encryption and decryption “key” is the knowledge of the two Caesar keys (</span><span class="font53" style="font-style:italic;">k =</span><span class="font53"> 5, </span><span class="font53" style="font-style:italic;">k =</span><span class="font53"> 19) and the pattern C</span><span class="font50">1</span><span class="font53">, C<sub>2</sub>, C<sub>2</sub>, C</span><span class="font50">1</span><span class="font53">, C<sub>2</sub>.</span></p>
<p><span class="font22" style="font-weight:bold;">Block Ciphers</span></p>
<p><span class="font53">Let us now move forward to modern times and examine how symmetric key encryption is done today. We focus on block ciphers, which are used in many secure Internet protocols, including PGP (for secure e-mail), TLS (for securing TCP connections), and IPsec (for securing the network-layer transport).</span></p>
<p><span class="font53">In a block cipher, the message to be encrypted is processed in blocks of </span><span class="font53" style="font-style:italic;">k</span><span class="font53"> bits. For example, if </span><span class="font53" style="font-style:italic;">k =</span><span class="font53"> 64, then the message is broken into 64-bit blocks, and each block is encrypted independently. To encode a block, the cipher uses a one-to-one mapping to map the </span><span class="font53" style="font-style:italic;">k</span><span class="font53">-bit block of cleartext to a </span><span class="font53" style="font-style:italic;">k</span><span class="font53">-bit block of ciphertext. Let’s look at an example. Suppose that </span><span class="font53" style="font-style:italic;">k =</span><span class="font53"> 3, so that the block cipher maps 3-bit inputs (cleartext) to 3-bit outputs (ciphertext). One possible mapping is given in Table 8.1. Notice that this is a one-to-one mapping; that is, there is a different output for each input. This block cipher breaks the message up into 3-bit blocks and encrypts each block according to the above mapping. You should verify that the message 010110001111 gets encrypted into 101000111001.</span></p>
<p><span class="font53">Continuing with this 3-bit block example, note that the mapping in Table 8.1 is just one mapping of many possible mappings. How many possible mappings are there? To answer this question, observe that a mapping is nothing more than a permutation of all the possible inputs. There are 2<sup>3</sup> ( </span><span class="font53" style="font-style:italic;">=</span><span class="font53"> 8) possible inputs (listed under the</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font6">input</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">output</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">input</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">output</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">000</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">110</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">100</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">011</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">001</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">111</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">101</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">010</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">010</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">101</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">110</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">000</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">011</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">100</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">111</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">001</span></p></td></tr>
</table>
<p><span class="font7" style="font-weight:bold;">Table 8.1 </span><span class="font50">♦ </span><span class="font5">A specific 3-bit block cipher</span></p>
<p><span class="font53">input columns). These eight inputs can be permuted in 8! </span><span class="font54">= </span><span class="font53">40,320 different ways. Since each of these permutations specifies a mapping, there are 40,320 possible mappings. We can view each of these mappings as a key—if Alice and Bob both know the mapping (the key), they can encrypt and decrypt the messages sent between them.</span></p>
<p><span class="font53">The brute-force attack for this cipher is to try to decrypt ciphtertext by using all mappings. With only 40,320 mappings (when </span><span class="font53" style="font-style:italic;">k =</span><span class="font53"> 3), this can quickly be accomplished on a desktop PC. To thwart brute-force attacks, block ciphers typically use much larger blocks, consisting of </span><span class="font53" style="font-style:italic;">k =</span><span class="font53"> 64 bits or even larger. Note that the number of possible mappings for a general </span><span class="font53" style="font-style:italic;">k</span><span class="font53">-block cipher is 2</span><span class="font53" style="font-style:italic;"><sup>k</sup></span><span class="font53">!, which is astronomical for even moderate values of </span><span class="font53" style="font-style:italic;">k</span><span class="font53"> (such as </span><span class="font53" style="font-style:italic;">k</span><span class="font54"> = </span><span class="font53">64).</span></p>
<p><span class="font53">Although full-table block ciphers, as just described, with moderate values of </span><span class="font53" style="font-style:italic;">k </span><span class="font53">can produce robust symmetric key encryption schemes, they are unfortunately difficult to implement. For </span><span class="font53" style="font-style:italic;">k =</span><span class="font53"> 64 and for a given mapping, Alice and Bob would need to maintain a table with 2<sup>64</sup> input values, which is an infeasible task. Moreover, if Alice and Bob were to change keys, they would have to each regenerate the table. Thus, a full-table block cipher, providing predetermined mappings between all inputs and outputs (as in the example above), is simply out of the question.</span></p>
<p><span class="font53">Instead, block ciphers typically use functions that simulate randomly permuted tables. An example (adapted from [Kaufman 2002]) of such a function for </span><span class="font53" style="font-style:italic;">k =</span><span class="font53"> 64 bits is shown in Figure 8.5. The function first breaks a 64-bit block into 8 chunks, with each chunk consisting of 8 bits. Each 8-bit chunk is processed by an 8-bit to 8-bit table, which is of manageable size. For example, the first chunk is processed by the table denoted by T</span><span class="font50">1</span><span class="font53">. Next, the 8 output chunks are reassembled into a 64-bit block. The positions of the 64 bits in the block are then scrambled (permuted) to produce a 64-bit output. This output is fed back to the 64-bit input, where another cycle begins. After </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> such cycles, the function provides a 64-bit block of ciphertext. The purpose of the rounds is to make each input bit affect most (if not all) of the final output bits. (If only one round were used, a given input bit would affect only 8 of the 64 output bits.) The key for this block cipher algorithm would be the eight permutation tables (assuming the scramble function is publicly known).</span></p>
<p><span class="font53">Today there are a number of popular block ciphers, including DES (standing for Data Encryption Standard), 3DES, and AES (standing for Advanced Encryption</span></p>
<p><span class="font4">Loop for </span><span class="font4" style="font-style:italic;">n </span><span class="font4">rounds</span></p><img src="networking_files/networking-559.jpg" alt="" style="width:306pt;height:188pt;">
<p><span class="font7" style="font-weight:bold;">Figure 8.5 </span><span class="font50">♦ </span><span class="font5">An example of a block cipher</span></p>
<p><span class="font53">Standard). Each of these standards uses functions, rather than predetermined tables, along the lines of Figure 8.5 (albeit more complicated and specific to each cipher). Each of these algorithms also uses a string of bits for a key. For example, DES uses 64-bit blocks with a 56-bit key. AES uses 128-bit blocks and can operate with keys that are 128, 192, and 256 bits long. An algorithm’s key determines the specific “mini-table” mappings and permutations within the algorithm’s internals. The bruteforce attack for each of these ciphers is to cycle through all the keys, applying the decryption algorithm with each key. Observe that with a key length of </span><span class="font53" style="font-style:italic;">n,</span><span class="font53"> there are </span><span class="font53" style="font-style:italic;">2<sup>n </sup></span><span class="font53">possible keys. NIST [NIST 2001] estimates that a machine that could crack 56-bit DES in one second (that is, try all 2<sup>56</sup> keys in one second) would take approximately 149 trillion years to crack a 128-bit AES key.</span></p>
<p><span class="font22" style="font-weight:bold;">Cipher-Block Chaining</span></p>
<p><span class="font53">In computer networking applications, we typically need to encrypt long messages or long streams of data. If we apply a block cipher as described by simply chopping up the message into .</span><span class="font53" style="font-style:italic;">fc</span><span class="font53">-bit blocks and independently encrypting each block, a subtle but important problem occurs. To see this, observe that two or more of the cleartext blocks can be identical. For example, the cleartext in two or more blocks could be “HTTP/1.1”. For these identical blocks, a block cipher would, of course, produce the same ciphertext. An attacker could potentially guess the cleartext when it sees identical ciphertext blocks and may even be able to decrypt the entire message by identifying identical ciphtertext blocks and using knowledge about the underlying protocol structure [Kaufman 2002].</span></p>
<p><span class="font53">To address this problem, we can mix some randomness into the ciphertext so that identical plaintext blocks produce different ciphertext blocks. To explain this idea, let </span><span class="font53" style="font-style:italic;">m(i)</span><span class="font53"> denote the </span><span class="font53" style="font-style:italic;">i</span><span class="font53">th plaintext block, </span><span class="font53" style="font-style:italic;">c(i)</span><span class="font53"> denote the </span><span class="font53" style="font-style:italic;">i</span><span class="font53">th ciphertext block, and </span><span class="font53" style="font-style:italic;">a </span><span class="font52" style="font-style:italic;">© </span><span class="font53" style="font-style:italic;">b</span><span class="font53"> denote the exclusive-or (XOR) of two bit strings, </span><span class="font53" style="font-style:italic;">a</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">b.</span><span class="font53"> (Recall that the 0 </span><span class="font4">© </span><span class="font53">0 </span><span class="font54">= </span><span class="font53">1 </span><span class="font4">© </span><span class="font53">1 </span><span class="font54">= </span><span class="font53">0 and 0 </span><span class="font4">© </span><span class="font53">1 </span><span class="font54">= </span><span class="font53">1 </span><span class="font4">© </span><span class="font53">0 </span><span class="font54">= </span><span class="font53">1, and the XOR of two bit strings is done on a bit-by-bit basis. So, for example, 10101010 </span><span class="font4">© </span><span class="font53">11110000 </span><span class="font54">= </span><span class="font53">01011010.) Also, denote the block-cipher encryption algorithm with key </span><span class="font53" style="font-style:italic;">S</span><span class="font53"> as </span><span class="font53" style="font-style:italic;">K<sub>S</sub>.</span><span class="font53"> The basic idea is as follows. The sender creates a random </span><span class="font53" style="font-style:italic;">k</span><span class="font53">-bit number </span><span class="font53" style="font-style:italic;">r(i)</span><span class="font53"> for the </span><span class="font53" style="font-style:italic;">i</span><span class="font53">th block and calculates </span><span class="font53" style="font-style:italic;">c(i</span><span class="font53">) </span><span class="font54">= </span><span class="font53" style="font-style:italic;">K<sub>S</sub>(m(i</span><span class="font53">) </span><span class="font4">© </span><span class="font53" style="font-style:italic;">r(i</span><span class="font53">)). Note that a new </span><span class="font53" style="font-style:italic;">k</span><span class="font53">-bit random number is chosen for each block. The sender then sends </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(1), </span><span class="font53" style="font-style:italic;">r</span><span class="font53">(1), </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(2), </span><span class="font53" style="font-style:italic;">r</span><span class="font53">(2), </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(3), </span><span class="font53" style="font-style:italic;">r</span><span class="font53">(3), and so on. Since the receiver receives </span><span class="font53" style="font-style:italic;">c(i)</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">r(i),</span><span class="font53"> it can recover each block of the plaintext by computing </span><span class="font53" style="font-style:italic;">m</span><span class="font53">(</span><span class="font53" style="font-style:italic;">i</span><span class="font53">) </span><span class="font54">= </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">S</span><span class="font53">(</span><span class="font53" style="font-style:italic;">c</span><span class="font53"> (</span><span class="font53" style="font-style:italic;">i</span><span class="font53">)) </span><span class="font4">© </span><span class="font53" style="font-style:italic;">r</span><span class="font53">(</span><span class="font53" style="font-style:italic;">i</span><span class="font53">). It is important to note that, although </span><span class="font53" style="font-style:italic;">r</span><span class="font53">(</span><span class="font53" style="font-style:italic;">i</span><span class="font53">) is sent in the clear and thus can be sniffed by Trudy, she cannot obtain the plaintext </span><span class="font53" style="font-style:italic;">m</span><span class="font53">(</span><span class="font53" style="font-style:italic;">i</span><span class="font53">), since she does not know the key </span><span class="font53" style="font-style:italic;">K<sub>S</sub>.</span><span class="font53"> Also note that if two plaintext blocks </span><span class="font53" style="font-style:italic;">m</span><span class="font53">(</span><span class="font53" style="font-style:italic;">i</span><span class="font53">) and </span><span class="font53" style="font-style:italic;">m(j)</span><span class="font53"> are the same, the corresponding ciphertext blocks </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(</span><span class="font53" style="font-style:italic;">i</span><span class="font53">) and </span><span class="font53" style="font-style:italic;">c(j)</span><span class="font53"> will be different (as long as the random numbers </span><span class="font53" style="font-style:italic;">r</span><span class="font53">(</span><span class="font53" style="font-style:italic;">i</span><span class="font53">) and </span><span class="font53" style="font-style:italic;">r(j)</span><span class="font53"> are different, which occurs with very high probability).</span></p>
<p><span class="font53">As an example, consider the 3-bit block cipher in Table 8.1. Suppose the plaintext is 010010010. If Alice encrypts this directly, without including the randomness, the resulting ciphertext becomes 101101101. If Trudy sniffs this ciphertext, because each of the three cipher blocks is the same, she can correctly surmise that each of the three plaintext blocks are the same. Now suppose instead Alice generates the random blocks </span><span class="font53" style="font-style:italic;">r</span><span class="font53">(1) </span><span class="font54">= </span><span class="font53">001, </span><span class="font53" style="font-style:italic;">r</span><span class="font53">(2) </span><span class="font54">= </span><span class="font53">111, and </span><span class="font53" style="font-style:italic;">r</span><span class="font53">(3) </span><span class="font54">= </span><span class="font53">100 and uses the above technique to generate the ciphertext </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(1) </span><span class="font54">= </span><span class="font53">100, </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(2) </span><span class="font54">= </span><span class="font53">010, and </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(3) </span><span class="font54">= </span><span class="font53">000. Note that the three ciphertext blocks are different even though the plaintext blocks are the same. Alice then sends </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(1), </span><span class="font53" style="font-style:italic;">r</span><span class="font53">(1), </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(2), and </span><span class="font53" style="font-style:italic;">r</span><span class="font53">(2). You should verify that Bob can obtain the original plaintext using the shared key </span><span class="font53" style="font-style:italic;">K<sub>S</sub></span><span class="font53">.</span></p>
<p><span class="font53">The astute reader will note that introducing randomness solves one problem but creates another: namely, Alice must transmit twice as many bits as before. Indeed, for each cipher bit, she must now also send a random bit, doubling the required bandwidth. In order to have our cake and eat it too, block ciphers typically use a technique called </span><span class="font53" style="font-weight:bold;">Cipher Block Chaining (CBC)</span><span class="font53">. The basic idea is to send only </span><span class="font53" style="font-style:italic;">one random value along with the very first message, and then have the sender and receiver use the computed coded blocks in place of the subsequent random number.</span><span class="font53"> Specifically, CBC operates as follows:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">1. Before encrypting the message (or the stream of data), the sender generates a random </span><span class="font53" style="font-style:italic;">k</span><span class="font53">-bit string, called the </span><span class="font53" style="font-weight:bold;">Initialization Vector (IV)</span><span class="font53">. Denote this initialization vector by </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(0). The sender sends the IV to the receiver </span><span class="font53" style="font-style:italic;">in cleartext</span><span class="font53">.</span></p></li>
<li>
<p><span class="font53">2. For the first block, the sender calculates </span><span class="font53" style="font-style:italic;">m</span><span class="font53">(1) </span><span class="font54">© </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(0), that is, calculates the exclu-sive-or of the first block of cleartext with the IV. It then runs the result through the block-cipher algorithm to get the corresponding ciphertext block; that is,</span></p></li></ul>
<p><span class="font53" style="font-style:italic;">c</span><span class="font53">(1) </span><span class="font54">= </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">S</span><span class="font53">(</span><span class="font53" style="font-style:italic;">m</span><span class="font53">(1) </span><span class="font4">© </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(0)). The sender sends the encrypted block </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(1) to the receiver.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">3. For the </span><span class="font53" style="font-style:italic;">i</span><span class="font53">th block, the sender generates the </span><span class="font53" style="font-style:italic;">i</span><span class="font53">th ciphertext block from </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(</span><span class="font53" style="font-style:italic;">i</span><span class="font53">) </span><span class="font54">= </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">S</span><span class="font53" style="font-style:italic;">(m(i) </span><span class="font52" style="font-style:italic;">© </span><span class="font53" style="font-style:italic;">c(i -</span><span class="font53"> 1)).</span></p></li></ul>
<p><span class="font53">Let’s now examine some of the consequences of this approach. First, the receiver will still be able to recover the original message. Indeed, when the receiver receives </span><span class="font53" style="font-style:italic;">c(i),</span><span class="font53"> it decrypts it with </span><span class="font53" style="font-style:italic;">K<sub>S</sub></span><span class="font53"> to obtain </span><span class="font53" style="font-style:italic;">s(i</span><span class="font53">) </span><span class="font54">= </span><span class="font53" style="font-style:italic;">m(i) </span><span class="font52" style="font-style:italic;">© </span><span class="font53" style="font-style:italic;">c(i —</span><span class="font53"> 1); since the receiver also knows </span><span class="font53" style="font-style:italic;">c(i —</span><span class="font53"> 1), it then obtains the cleartext block from </span><span class="font53" style="font-style:italic;">m</span><span class="font53">(</span><span class="font53" style="font-style:italic;">i</span><span class="font53">) </span><span class="font54">= </span><span class="font53" style="font-style:italic;">s(i) </span><span class="font52" style="font-style:italic;">© </span><span class="font53" style="font-style:italic;">c(i —</span><span class="font53"> 1). Second, even if two cleartext blocks are identical, the corresponding ciphtertexts (almost always) will be different. Third, although the sender sends the IV in the clear, an intruder will still not be able to decrypt the ciphertext blocks, since the intruder does not know the secret key, </span><span class="font53" style="font-style:italic;">S</span><span class="font53">. Finally, the sender only sends one overhead block (the IV), thereby negligibly increasing the bandwidth usage for long messages (consisting of hundreds of blocks).</span></p>
<p><span class="font53">As an example, let’s now determine the ciphertext for the 3-bit block cipher in Table 8.1 with plaintext 010010010 and IV </span><span class="font54">= </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(0) </span><span class="font54">= </span><span class="font53">001. The sender first uses the IV to calculate </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(1) </span><span class="font54">= </span><span class="font53" style="font-style:italic;">K<sub>S</sub>(m(1) </span><span class="font52" style="font-style:italic;">© </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(0)) </span><span class="font54">= </span><span class="font53">100. The sender then calculates </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(2) </span><span class="font54">= </span><span class="font53" style="font-style:italic;">K<sub>S</sub>(m(2)</span><span class="font4"> © </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(1)) </span><span class="font54">= </span><span class="font53" style="font-style:italic;">K<sub>S</sub></span><span class="font53">(010 </span><span class="font4">© </span><span class="font53">100) </span><span class="font54">= </span><span class="font53">000, and </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(3) </span><span class="font54">= </span><span class="font53" style="font-style:italic;">K<sub>S</sub>(m(3)</span><span class="font4"> © </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(2)) </span><span class="font54">= </span><span class="font53" style="font-style:italic;">K<sub>S</sub></span><span class="font53">(010 </span><span class="font4">© </span><span class="font53">000) </span><span class="font54">= </span><span class="font53">101. The reader should verify that the receiver, knowing the IV and </span><span class="font53" style="font-style:italic;">K<sub>S</sub></span><span class="font53"> can recover the original plaintext.</span></p>
<p><span class="font53">CBC has an important consequence when designing secure network protocols: we’ll need to provide a mechanism within the protocol to distribute the IV from sender to receiver. We’ll see how this is done for several protocols later in this chapter.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">8.2.2 </span><span class="font23" style="font-weight:bold;">Public Key Encryption</span></p></li></ul>
<p><span class="font53">For more than 2,000 years (since the time of the Caesar cipher and up to the 1970s), encrypted communication required that the two communicating parties share a common secret—the symmetric key used for encryption and decryption. One difficulty with this approach is that the two parties must somehow agree on the shared key; but to do so in itself requires secure communication. Perhaps the parties could first meet and agree on the key in person (for example, two of Caesar’s centurions might meet at the Roman baths) and thereafter communicate with encryption. In a networked world, however, communicating parties may never meet and may never converse except over the network.</span></p>
<p><a name="bookmark451"></a><span class="font53">Is it possible for two parties to communicate with encryption without having a shared secret key that is known in advance? In 1976, Diffie and Hellman [Diffie 1976] demonstrated an algorithm (known now as Diffie-Hellman Key Exchange) to do just that—a radically different and marvelously elegant approach toward secure communication that has led to the development of today’s public key cryptography systems. We’ll see shortly that public key cryptography systems also have several wonderful properties that make them useful not only for encryption, but for authentication and digital signatures as well. Interestingly, it has come to light that ideas similar to those in [Diffie 1976] and [RSA 1978] had been independently developed in the early 1970s in a series of secret reports by researchers at the Communications-Electronics Security Group in the United Kingdom [Ellis 1987].</span></p>
<p><span class="font50" style="font-style:italic;">- &nbsp;&nbsp;KB+</span><span class="font4"> Public encryption key</span></p>
<p><span class="font50" style="font-style:italic;">— &nbsp;&nbsp;KB</span><span class="font4"> Private decryption key</span></p>
<div>
<p><span class="font4">Plaintext</span></p>
<p><span class="font4">Plaintext</span></p><img src="networking_files/networking-560.jpg" alt="" style="width:334pt;height:49pt;">
</div><br clear="all">
<div><img src="networking_files/networking-561.jpg" alt="" style="width:37pt;height:41pt;">
</div><br clear="all">
<div><img src="networking_files/networking-562.jpg" alt="" style="width:26pt;height:37pt;">
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 8.6 </span><span class="font50">♦ </span><span class="font5">Public key cryptography</span></p>
<p><span class="font53">As is often the case, great ideas can spring up independently in many places; fortunately, public key advances took place not only in private, but also in the public view, as well.</span></p>
<p><span class="font53">The use of public key cryptography is conceptually quite simple. Suppose Alice wants to communicate with Bob. As shown in Figure 8.6, rather than Bob and Alice sharing a single secret key (as in the case of symmetric key systems), Bob (the recipient of Alice’s messages) instead has two keys—a </span><span class="font53" style="font-weight:bold;">public key </span><span class="font53">that is available to </span><span class="font53" style="font-style:italic;">everyone</span><span class="font53"> in the world (including Trudy the intruder) and a </span><span class="font53" style="font-weight:bold;">private key </span><span class="font53">that is known only to Bob. We will use the notation </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">B</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">B</span><span class="font53"> to refer to Bob’s public and private keys, respectively. In order to communicate with Bob, Alice first fetches Bob’s public key. Alice then encrypts her message, </span><span class="font53" style="font-style:italic;">m,</span><span class="font53"> to Bob using Bob’s public key and a known (for example, standardized) encryption algorithm; that is, Alice computes </span><span class="font53" style="font-style:italic;">K</span><span class="font3" style="font-style:italic;">+</span><span class="font53" style="font-style:italic;">(m).</span><span class="font53"> Bob receives Alice’s encrypted message and uses his private key and a known (for example, standardized) decryption algorithm to decrypt Alice’s encrypted message. That is, Bob computes </span><span class="font53" style="font-style:italic;">K</span><span class="font3" style="font-style:italic;">B</span><span class="font53" style="font-style:italic;">(K</span><span class="font3" style="font-style:italic;">+</span><span class="font53" style="font-style:italic;">(m)).</span><span class="font53"> We will see below that there are encryption/ decryption algorithms and techniques for choosing public and private keys such that </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">B</span><span class="font53">(</span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">B</span><span class="font53">(</span><span class="font53" style="font-style:italic;">m</span><span class="font53">)) </span><span class="font54">= </span><span class="font53" style="font-style:italic;">m;</span><span class="font53"> that is, applying Bob’s public key, </span><span class="font53" style="font-style:italic;">K</span><span class="font3" style="font-style:italic;">+</span><span class="font53" style="font-style:italic;">,</span><span class="font53"> to a message, </span><span class="font53" style="font-style:italic;">m</span><span class="font53"> (to get </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">B</span><span class="font53">(</span><span class="font53" style="font-style:italic;">m</span><span class="font53">)), and then applying Bob’s private key, </span><span class="font53" style="font-style:italic;">K</span><span class="font3" style="font-style:italic;">-</span><span class="font53" style="font-style:italic;">,</span><span class="font53"> to the encrypted version of </span><span class="font53" style="font-style:italic;">m</span><span class="font53"> (that is, computing </span><span class="font53" style="font-style:italic;">K</span><span class="font3" style="font-style:italic;">B</span><span class="font53" style="font-style:italic;">(K</span><span class="font3" style="font-style:italic;">+</span><span class="font53" style="font-style:italic;">(m)))</span><span class="font53"> gives back </span><span class="font53" style="font-style:italic;">m.</span><span class="font53"> This is a remarkable result! In this manner, Alice can use Bob’s publicly available key to send a secret message to Bob without either of them having to distribute any secret keys! We will see shortly that we can interchange the public key and private key encryption and get the same remarkable result—that is, </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">B </span><span class="font53" style="font-style:italic;">(<sub>B</sub><sup>+</sup>(m)) = K</span><span class="font50" style="font-style:italic;">B </span><span class="font53" style="font-style:italic;">(K</span><span class="font3" style="font-style:italic;">-</span><span class="font53" style="font-style:italic;">(m)) = m.</span></p>
<p><span class="font53">Although public-key cryptography is appealing, one concern immediately springs to mind. Since Bob’s encryption key is public, anyone can send an encrypted message to Bob, including Alice or someone </span><span class="font53" style="font-style:italic;">pretending</span><span class="font53"> to be Alice. In the case of a single shared secret key, the fact that the sender knows the secret key implicitly identifies the sender to the receiver. In the case of public key cryptography, however, this is no longer the case since anyone can send an encrypted message to Bob using Bob’s publicly available key. A digital signature, a topic we will study in Section 8.3, is needed to bind a sender to a message.</span></p>
<p><span class="font22" style="font-weight:bold;">RSA</span></p>
<p><span class="font53">While there may be many algorithms that address these concerns, the </span><span class="font53" style="font-weight:bold;">RSA algorithm </span><span class="font53">(named after its founders, Ron Rivest, Adi Shamir, and Leonard Adleman) has become almost synonymous with public key cryptography. Let’s first see how RSA works and then examine why it works.</span></p>
<p><span class="font53">RSA makes extensive use of arithmetic operations using modulo-</span><span class="font53" style="font-style:italic;">n</span><span class="font53"> arithmetic. So let’s briefly review modular arithmetic. Recall that </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> simply means the remainder of </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> when divided by </span><span class="font53" style="font-style:italic;">n</span><span class="font53">; so, for example, 19 mod 5 </span><span class="font54">= </span><span class="font53">4. In modular arithmetic, one performs the usual operations of addition, multiplication, and exponentiation. However, the result of each operation is replaced by the integer remainder that is left when the result is divided by </span><span class="font53" style="font-style:italic;">n</span><span class="font53">. Adding and multiplying with modular arithmetic is facilitated with the following handy facts:</span></p>
<p><span class="font53">[(</span><span class="font53" style="font-style:italic;">a</span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n</span><span class="font53">) </span><span class="font55">+ </span><span class="font53" style="font-style:italic;">(b</span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n</span><span class="font53">)] mod </span><span class="font53" style="font-style:italic;">n = (a</span><span class="font55"> + </span><span class="font53" style="font-style:italic;">b)</span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n</span></p>
<p><span class="font53">[(</span><span class="font53" style="font-style:italic;">a</span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n</span><span class="font53">) </span><span class="font55">— </span><span class="font53">(</span><span class="font53" style="font-style:italic;">b</span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n</span><span class="font53">)] mod </span><span class="font53" style="font-style:italic;">n = (a — b)</span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n</span></p>
<p><span class="font53">[(</span><span class="font53" style="font-style:italic;">a</span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n</span><span class="font53">) </span><span class="font60">• </span><span class="font53">(</span><span class="font53" style="font-style:italic;">b</span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n</span><span class="font53">)] mod </span><span class="font53" style="font-style:italic;">n = (a </span><span class="font60" style="font-style:italic;">• </span><span class="font53" style="font-style:italic;">b)</span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n</span></p>
<p><span class="font53">It follows from the third fact that (</span><span class="font53" style="font-style:italic;">a</span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n</span><span class="font53">)</span><span class="font53" style="font-style:italic;"><sup>d</sup></span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n = a<sup>d</sup></span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n</span><span class="font53">, which is an identity that we will soon find very useful.</span></p>
<p><span class="font53">Now suppose that Alice wants to send to Bob an RSA-encrypted message, as shown in Figure 8.6. In our discussion of RSA, let’s always keep in mind that a message is nothing but a bit pattern, and every bit pattern can be uniquely represented by an integer number (along with the length of the bit pattern). For example, suppose a message is the bit pattern 1001; this message can be represented by the decimal integer 9. Thus, when encrypting a message with RSA, it is equivalent to encrypting the unique integer number that represents the message.</span></p>
<p><span class="font53">There are two interrelated components of RSA:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;The choice of the public key and the private key</span></p></li>
<li>
<p><span class="font53">• &nbsp;The encryption and decryption algorithm</span></p></li></ul>
<p><span class="font53">To generate the public and private RSA keys, Bob performs the following steps:</span></p>
<ul style="list-style:none;"><li>
<p class="font53">1. Choose two large prime numbers, <span class="font53" style="font-style:italic;">p</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">q.</span><span class="font53"> How large should </span><span class="font53" style="font-style:italic;">p</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">q</span><span class="font53"> be? The larger the values, the more difficult it is to break RSA, but the longer it takes to perform the encoding and decoding. RSA Laboratories recommends that the product of </span><span class="font53" style="font-style:italic;">p</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">q</span><span class="font53"> be on the order of 1,024 bits. For a discussion of how to find large prime numbers, see [Caldwell 2020].</span></p></li>
<li>
<p><span class="font53">2. Compute </span><span class="font53" style="font-style:italic;">n = pq</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">z = (p —</span><span class="font53"> 1)(</span><span class="font53" style="font-style:italic;">q</span><span class="font55"> - </span><span class="font53">1).</span></p></li>
<li>
<p><span class="font53">3. Choose a number, </span><span class="font53" style="font-style:italic;">e,</span><span class="font53"> less than </span><span class="font53" style="font-style:italic;">n</span><span class="font53">, that has no common factors (other than 1) with </span><span class="font53" style="font-style:italic;">z-</span><span class="font53"> (In this case, </span><span class="font53" style="font-style:italic;">e</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> are said to be relatively prime.) The letter </span><span class="font53" style="font-style:italic;">e</span><span class="font53"> is used since this value will be used in encryption.</span></p></li>
<li>
<p><span class="font53">4. Find a number, </span><span class="font53" style="font-style:italic;">d,</span><span class="font53"> such that </span><span class="font53" style="font-style:italic;">ed —</span><span class="font53"> 1 is exactly divisible (that is, with no remainder) by </span><span class="font53" style="font-style:italic;">z</span><span class="font53">. The letter </span><span class="font53" style="font-style:italic;">d</span><span class="font53"> is used because this value will be used in decryption. Put another way, given </span><span class="font53" style="font-style:italic;">e</span><span class="font53">, we choose </span><span class="font53" style="font-style:italic;">d</span><span class="font53"> such that</span></p></li></ul>
<p><span class="font53" style="font-style:italic;">ed</span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">z</span><span class="font54"> = </span><span class="font53">1</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">5. The public key that Bob makes available to the world, </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">—</span><span class="font3" style="font-style:italic;">+</span><span class="font53" style="font-style:italic;">,</span><span class="font53"> is the pair of numbers (</span><span class="font53" style="font-style:italic;">n</span><span class="font53">, </span><span class="font53" style="font-style:italic;">e</span><span class="font53">); his private key, </span><span class="font53" style="font-style:italic;">K</span><span class="font3" style="font-style:italic;">—</span><span class="font53" style="font-style:italic;">,</span><span class="font53"> is the pair of numbers (</span><span class="font53" style="font-style:italic;">n</span><span class="font53">, </span><span class="font53" style="font-style:italic;">d</span><span class="font53">).</span></p></li></ul>
<p><span class="font53">The encryption by Alice and the decryption by Bob are done as follows:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;Suppose Alice wants to send Bob a bit pattern represented by the integer number </span><span class="font53" style="font-style:italic;">m</span><span class="font53"> (with </span><span class="font53" style="font-style:italic;">m &lt;&nbsp;n</span><span class="font53">). To encode, Alice performs the exponentiation </span><span class="font53" style="font-style:italic;">m<sup>e</sup>,</span><span class="font53"> and then computes the integer remainder when </span><span class="font53" style="font-style:italic;">m<sup>e</sup></span><span class="font53"> is divided by </span><span class="font53" style="font-style:italic;">n</span><span class="font53">. In other words, the encrypted value, </span><span class="font53" style="font-style:italic;">c,</span><span class="font53"> of Alice’s plaintext message, </span><span class="font53" style="font-style:italic;">m</span><span class="font53">, is</span></p></li></ul>
<p><span class="font53" style="font-style:italic;">c = m<sup>e</sup></span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n</span></p>
<p><span class="font53">The bit pattern corresponding to this ciphertext </span><span class="font53" style="font-style:italic;">c</span><span class="font53"> is sent to Bob.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;To decrypt the received ciphertext message, </span><span class="font53" style="font-style:italic;">c</span><span class="font53">, Bob computes</span></p></li></ul>
<p><span class="font53" style="font-style:italic;">m = c<sup>d</sup></span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n</span></p>
<p><span class="font53">which requires the use of his private key (</span><span class="font53" style="font-style:italic;">n</span><span class="font53">, </span><span class="font53" style="font-style:italic;">d</span><span class="font53">).</span></p>
<p><span class="font53">As a simple example of RSA, suppose Bob chooses </span><span class="font53" style="font-style:italic;">p =</span><span class="font53"> 5 and </span><span class="font53" style="font-style:italic;">q =</span><span class="font53"> 7. (Admittedly, these values are far too small to be secure.) Then </span><span class="font53" style="font-style:italic;">n =</span><span class="font53"> 35 and </span><span class="font53" style="font-style:italic;">z =</span><span class="font53"> 24. Bob chooses </span><span class="font53" style="font-style:italic;">e =</span><span class="font53"> 5, since 5 and 24 have no common factors. Finally, Bob chooses </span><span class="font53" style="font-style:italic;">d =</span><span class="font53"> 29, since 5 </span><span class="font60">• </span><span class="font53">29 </span><span class="font55">— </span><span class="font53">1 (that is, </span><span class="font53" style="font-style:italic;">ed —</span><span class="font53"> 1) is exactly divisible by 24. Bob makes the two values, </span><span class="font53" style="font-style:italic;">n =</span><span class="font53"> 35 and </span><span class="font53" style="font-style:italic;">e =</span><span class="font53"> 5, public and keeps the value </span><span class="font53" style="font-style:italic;">d</span><span class="font54"> = </span><span class="font53">29 secret. Observing these two public values, suppose Alice now wants to send the letters </span><span class="font53" style="font-style:italic;">l, o, v,</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">e</span><span class="font53"> to Bob. Interpreting each letter as a number between 1 and 26 (with </span><span class="font53" style="font-style:italic;">a</span><span class="font53"> being 1, and </span><span class="font53" style="font-style:italic;">z</span><span class="font53"> being 26), Alice and Bob perform the encryption and decryption shown in Tables 8.2 and 8.3, respectively. Note that in this example, we consider each of the four letters as a distinct message. A more realistic example would be to convert the four letters into their 8-bit ASCII representations and then encrypt the integer corresponding to the resulting 32-bit bit pattern. (Such a realistic example generates numbers that are much too long to print in a textbook!)</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Plaintext Letter</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6" style="font-style:italic;">m</span><span class="font5" style="font-style:italic;">.</span><span class="font6"> numeric representation</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6" style="font-style:italic;">m</span><span class="font6"><sup>e</sup></span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Ciphertext c </span><span class="font54">= </span><span class="font6" style="font-style:italic;">m</span><span class="font6"><sup>e</sup> mod </span><span class="font6" style="font-style:italic;">n</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">l</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">12</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">248832</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">17</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">o</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">15</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">759375</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">15</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">v</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">22</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">5153632</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">22</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">e</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">5</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">3125</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">10</span></p></td></tr>
</table>
<p><span class="font7" style="font-weight:bold;">Table 8.2 </span><span class="font50">♦ </span><span class="font5">Alice's RSA encryption, </span><span class="font5" style="font-style:italic;">e </span><span class="font53" style="font-style:italic;">= </span><span class="font5" style="font-style:italic;">5, n </span><span class="font53" style="font-style:italic;">=</span><span class="font5"> 35</span></p>
<p><span class="font53">Given that the “toy” example in Tables 8.2 and 8.3 has already produced some extremely large numbers, and given that we saw earlier that </span><span class="font53" style="font-style:italic;">p</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">q</span><span class="font53"> should each be several hundred bits long, several practical issues regarding RSA come to mind. How does one choose large prime numbers? How does one then choose </span><span class="font53" style="font-style:italic;">e</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">d? </span><span class="font53">How does one perform exponentiation with large numbers? A discussion of these important issues is beyond the scope of this book; see [Kaufman 2002] and the references therein for details.</span></p>
<p><span class="font22" style="font-weight:bold;">Session Keys</span></p>
<p><span class="font53">We note here that the exponentiation required by RSA is a rather time-consuming process. As a result, RSA is often used in practice in combination with symmetric key cryptography. For example, if Alice wants to send Bob a large amount of encrypted data, she could do the following. First Alice chooses a key that will be used to encode the data itself; this key is referred to as a </span><span class="font53" style="font-weight:bold;">session key</span><span class="font53">, and is denoted by </span><span class="font53" style="font-style:italic;">K<sub>S</sub>.</span><span class="font53"> Alice must inform Bob of the session key, since this is the shared symmetric key they will use with a symmetric key cipher (e.g., with DES or AES). Alice encrypts the session key using Bob’s public key, that is, computes </span><span class="font53" style="font-style:italic;">c = (K<sub>S</sub>)<sup>e </sup></span><span class="font53">mod </span><span class="font53" style="font-style:italic;">n.</span><span class="font53"> Bob receives the RSA-encrypted session key, </span><span class="font53" style="font-style:italic;">c</span><span class="font53">, and decrypts it to obtain</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Ciphertext </span><span class="font6" style="font-style:italic;">c</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6" style="font-style:italic;">c<sup>d</sup></span></p></td><td style="vertical-align:bottom;">
<p><span class="font6" style="font-style:italic;">m</span><span class="font6"> = </span><span class="font6" style="font-style:italic;">d</span><span class="font6"> mod </span><span class="font6" style="font-style:italic;">n</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Plaintext Letter</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">17</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">4819685721067509150915091411825223071697</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">12</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">l</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">15</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">127834039403948858939111232757568359375</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">15</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">o</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">22</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">851643319086537701956194499721106030592</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">22</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">v</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">10</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">1000000000000000000000000000000</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">5</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">e</span></p></td></tr>
</table>
<p><span class="font7" style="font-weight:bold;">Table 8.3 </span><span class="font50">♦ </span><span class="font5">Bob's RSA decryption, </span><span class="font5" style="font-style:italic;">d </span><span class="font53" style="font-style:italic;">=</span><span class="font5"> 29, </span><span class="font5" style="font-style:italic;">n </span><span class="font53" style="font-style:italic;">=</span><span class="font5"> 35</span></p>
<p><span class="font53">the session key, </span><span class="font53" style="font-style:italic;">K<sub>S</sub>.</span><span class="font53"> Bob now knows the session key that Alice will use for her encrypted data transfer.</span></p>
<p><span class="font22" style="font-weight:bold;">Why Does RSA Work?</span></p>
<p><span class="font53">RSA encryption/decryption appears rather magical. Why should it be that by applying the encryption algorithm and then the decryption algorithm, one recovers the original message? In order to understand why RSA works, again denote </span><span class="font53" style="font-style:italic;">n = pq, </span><span class="font53">where </span><span class="font53" style="font-style:italic;">p</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">q</span><span class="font53"> are the large prime numbers used in the RSA algorithm.</span></p>
<p><span class="font53">Recall that, under RSA encryption, a message (uniquely represented by an integer), </span><span class="font53" style="font-style:italic;">m,</span><span class="font53"> is exponentiated to the power </span><span class="font53" style="font-style:italic;">e</span><span class="font53"> using modulo-</span><span class="font53" style="font-style:italic;">n</span><span class="font53"> arithmetic, that is,</span></p>
<p><span class="font53" style="font-style:italic;">c = m<sup>e</sup></span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n</span></p>
<p><span class="font53">Decryption is performed by raising this value to the power </span><span class="font53" style="font-style:italic;">d,</span><span class="font53"> again using modulo-</span><span class="font53" style="font-style:italic;">n </span><span class="font53">arithmetic. The result of an encryption step followed by a decryption step is thus </span><span class="font53" style="font-style:italic;">(m<sup>e</sup></span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n)<sup>d</sup></span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n</span><span class="font53">. Let’s now see what we can say about this quantity. As mentioned earlier, one important property of modulo arithmetic is </span><span class="font53" style="font-style:italic;">(a</span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n)<sup>d</sup></span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n = a<sup>d</sup></span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n </span><span class="font53">for any values </span><span class="font53" style="font-style:italic;">a</span><span class="font53">, </span><span class="font53" style="font-style:italic;">n</span><span class="font53">, and </span><span class="font53" style="font-style:italic;">d</span><span class="font53">. Thus, using </span><span class="font53" style="font-style:italic;">a = m<sup>e</sup></span><span class="font53"> in this property, we have</span></p>
<p><span class="font53">(</span><span class="font53" style="font-style:italic;">m<sup>e</sup></span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n</span><span class="font53">)</span><span class="font53" style="font-style:italic;"><sup>d</sup></span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n = m<sup>ed</sup></span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n</span></p>
<p><span class="font53">It therefore remains to show that </span><span class="font53" style="font-style:italic;">m<sup>ed</sup></span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n = m</span><span class="font53">. Although we’re trying to remove some of the magic about why RSA works, to establish this, we’ll need to use a rather magical result from number theory here. Specifically, we’ll need the result that says if</span><span class="font53" style="font-style:italic;">p</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">q</span><span class="font53"> are prime, </span><span class="font53" style="font-style:italic;">n = pq,</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">z = (p —</span><span class="font53"> 1)(</span><span class="font53" style="font-style:italic;">q</span><span class="font55"> - </span><span class="font53">1), then </span><span class="font53" style="font-style:italic;">x<sup>y</sup></span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> is the same as </span><span class="font53" style="font-style:italic;">x</span><span class="font49" style="font-style:italic;">(</span><span class="font53" style="font-style:italic;"><sup>y</sup></span><span class="font50"> mod </span><span class="font53" style="font-style:italic;"><sup>z</sup></span><span class="font53"><sup>)</sup> mod </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> [Kaufman 2002]. Applying this result with </span><span class="font53" style="font-style:italic;">x = m</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">y = ed</span><span class="font53"> we have</span></p>
<p><span class="font53" style="font-style:italic;">m<sup>ed</sup></span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n = m<sup>(ed</sup></span><span class="font53"><sup> mod z)</sup> mod </span><span class="font53" style="font-style:italic;">n</span></p>
<p><span class="font53">But remember that we have chosen </span><span class="font53" style="font-style:italic;">e</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">d</span><span class="font53"> such that </span><span class="font53" style="font-style:italic;">ed</span><span class="font53"> mod z </span><span class="font54">= </span><span class="font53">1. This gives us</span></p>
<p><span class="font53" style="font-style:italic;">m<sup>ed</sup></span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n = m</span><span class="font53"><sup>1</sup> mod </span><span class="font53" style="font-style:italic;">n = m</span></p>
<p><span class="font53">which is exactly the result we are looking for! By first exponentiating to the power of </span><span class="font53" style="font-style:italic;">e</span><span class="font53"> (that is, encrypting) and then exponentiating to the power of </span><span class="font53" style="font-style:italic;">d</span><span class="font53"> (that is, decrypting), we obtain the original value, </span><span class="font53" style="font-style:italic;">m.</span><span class="font53"> Even </span><span class="font53" style="font-style:italic;">more</span><span class="font53"> wonderful is the fact that if we first exponentiate to the power of </span><span class="font53" style="font-style:italic;">d</span><span class="font53"> and then exponentiate to the power of </span><span class="font53" style="font-style:italic;">e—</span><span class="font53">that is, we reverse the order of encryption and decryption, performing the decryption operation first and then applying the encryption operation—we also obtain the original value, </span><span class="font53" style="font-style:italic;">m</span><span class="font53">. This wonderful result follows immediately from the modular arithmetic:</span></p>
<p><span class="font53">(</span><span class="font53" style="font-style:italic;">m<sup>d</sup></span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n</span><span class="font53">)</span><span class="font53" style="font-style:italic;"><sup>e</sup></span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n = m<sup>de</sup></span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n = m<sup>ed</sup></span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n =</span><span class="font53"> (</span><span class="font53" style="font-style:italic;">m<sup>e</sup></span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n</span><span class="font53">)</span><span class="font53" style="font-style:italic;"><sup>d</sup></span><span class="font53"> mod </span><span class="font53" style="font-style:italic;">n</span></p>
<p><span class="font53">The security of RSA relies on the fact that there are no known algorithms for quickly factoring a number, in this case the public value </span><span class="font53" style="font-style:italic;">n,</span><span class="font53"> into the primes </span><span class="font53" style="font-style:italic;">p</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">q.</span><span class="font53"> If one knew </span><span class="font53" style="font-style:italic;">p</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">q</span><span class="font53">, then given the public value </span><span class="font53" style="font-style:italic;">e,</span><span class="font53"> one could easily compute the secret key, </span><span class="font53" style="font-style:italic;">d.</span><span class="font53"> On the other hand, it is not known whether or not there </span><span class="font53" style="font-style:italic;">exist</span><span class="font53"> fast algorithms for factoring a number, and in this sense, the security of RSA is not guaranteed. With recent advances in quantum computing, and published fast factoring algorithms for quantum computers, there are concerns that RSA may not be secure forever [MIT TR 2019]. But the practical realization of these algorithms still appears to be far in the future.</span></p>
<p><span class="font53">Another popular public-key encryption algorithm is the Diffie-Hellman algorithm, which we will briefly explore in the homework problems. Diffie-Hellman is not as versatile as RSA in that it cannot be used to encrypt messages of arbitrary length; it can be used, however, to establish a symmetric session key, which is in turn used to encrypt messages.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">8.3 </span><span class="font24" style="font-weight:bold;">Message Integrity and Digital Signatures</span></p></li></ul>
<p><span class="font53">In the previous section, we saw how encryption can be used to provide confidentiality to two communicating entities. In this section, we turn to the equally important cryptography topic of providing </span><span class="font53" style="font-weight:bold;">message integrity </span><span class="font53">(also known as message authentication). Along with message integrity, we will discuss two related topics in this section: digital signatures and end-point authentication.</span></p>
<p><span class="font53">We define the message integrity problem using, once again, Alice and Bob. Suppose Bob receives a message (which may be encrypted or may be in plaintext) and he believes this message was sent by Alice. To authenticate this message, Bob needs to verify:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">1. The message indeed originated from Alice.</span></p></li>
<li>
<p><span class="font53">2. The message was not tampered with on its way to Bob.</span></p></li></ul>
<p><span class="font53">We’ll see in Sections 8.4 through 8.7 that this problem of message integrity is a critical concern in just about all secure networking protocols.</span></p>
<p><a name="bookmark452"></a><span class="font53">As a specific example, consider a computer network using a link-state routing algorithm (such as OSPF) for determining routes between each pair of routers in the network (see Chapter 5). In a link-state algorithm, each router needs to broadcast a link-state message to all other routers in the network. A router’s link-state message includes a list of its directly connected neighbors and the direct costs to these neighbors. Once a router receives link-state messages from all of the other routers, it can create a complete map of the network, run its least-cost routing algorithm, and configure its forwarding table. One relatively easy attack on the routing algorithm is for Trudy to distribute bogus link-state messages with incorrect link-state information. Thus, the need for message integrity—when router B receives a link-state message from router A, router B should verify that router A actually created the message and, further, that no one tampered with the message in transit.</span></p>
<p><span class="font53">In this section, we describe a popular message integrity technique that is used by many secure networking protocols. But before doing so, we need to cover another important topic in cryptography—cryptographic hash functions.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">8.3.1 </span><span class="font23" style="font-weight:bold;">Cryptographic Hash Functions</span></p></li></ul>
<p><span class="font53">As shown in Figure 8.7, a hash function takes an input, </span><span class="font53" style="font-style:italic;">m,</span><span class="font53"> and computes a fixed-size string </span><span class="font53" style="font-style:italic;">H(m)</span><span class="font53"> known as a hash. The Internet checksum (Chapter 3) and CRCs (Chapter 6) meet this definition. A </span><span class="font53" style="font-weight:bold;">cryptographic hash function </span><span class="font53">is required to have the following additional property:</span></p>
<p><span class="font53">• It is computationally infeasible to find any two different messages </span><span class="font53" style="font-style:italic;">x</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">y</span><span class="font53"> such that </span><span class="font53" style="font-style:italic;">H(x) = H(y).</span></p>
<p><span class="font53">Informally, this property means that it is computationally infeasible for an intruder to substitute one message for another message that is protected by the hash function. That is, if (</span><span class="font53" style="font-style:italic;">m</span><span class="font53">, </span><span class="font53" style="font-style:italic;">H</span><span class="font53">(</span><span class="font53" style="font-style:italic;">m</span><span class="font53">)) are the message and the hash of the message created by the sender, then an intruder cannot forge the contents of another message, </span><span class="font53" style="font-style:italic;">y</span><span class="font53">, that has the same hash value as the original message.</span></p>
<p><span class="font53">Let’s convince ourselves that a simple checksum, such as the Internet checksum, would make a poor cryptographic hash function. Rather than performing 1s complement arithmetic (as in the Internet checksum), let us compute a checksum by treating each character as a byte and adding the bytes together using 4-byte chunks at a time. Suppose Bob owes Alice $100.99 and sends an IOU to Alice consisting of the text string “</span><span class="font36">IOU100.99BOB</span><span class="font53">.” The ASCII representation (in hexadecimal notation) for these letters is </span><span class="font36">49,4F,55,31,30,30,2E,39,39,42,4F,42</span><span class="font53">.</span></p>
<p><span class="font53">Figure 8.8 (top) shows that the 4-byte checksum for this message is B2 C1 D2 AC. A slightly different message (and a much more costly one for Bob)</span></p><img src="networking_files/networking-563.jpg" alt="" style="width:332pt;height:156pt;">
<p><a name="bookmark453"></a><span class="font7" style="font-weight:bold;">Figure 8.7 </span><span class="font50">♦ </span><span class="font5">Hash functions</span></p>
<div>
<table border="1">
<tr><td></td><td>
<p><span class="font53">ASCII</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font36">Message</span></p></td><td style="vertical-align:bottom;">
<p><span class="font53">Representation</span></p></td></tr>
<tr><td>
<p><span class="font36">I O U 1</span></p></td><td>
<p><span class="font36">49 4F 55 31</span></p></td></tr>
<tr><td>
<p><span class="font36">0 0.9</span></p></td><td>
<p><span class="font36">30 30 2E 39</span></p></td></tr>
<tr><td>
<p><span class="font36">9 B O B</span></p></td><td>
<p><span class="font36">39 42 4F 42</span></p></td></tr>
<tr><td></td><td style="vertical-align:bottom;">
<p><span class="font36">B2 C1 D2 AC</span></p></td></tr>
</table>
</div><br clear="all">
<div>
<p><span class="font53">Checksum</span></p>
</div><br clear="all">
<div>
<table border="1">
<tr><td></td><td>
<p><span class="font53">ASCII</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font36">Message</span></p></td><td style="vertical-align:bottom;">
<p><span class="font53">Representation</span></p></td></tr>
<tr><td>
<p><span class="font36">I O U 9</span></p></td><td>
<p><span class="font36">49 4F 55 39</span></p></td></tr>
<tr><td>
<p><span class="font36">0 0.1</span></p></td><td>
<p><span class="font36">30 30 2E 31</span></p></td></tr>
<tr><td>
<p><span class="font36">9 B O B</span></p></td><td>
<p><span class="font36">39 42 4F 42</span></p></td></tr>
<tr><td></td><td style="vertical-align:bottom;">
<p><span class="font36">B2 C1 D2 AC</span></p></td></tr>
</table>
</div><br clear="all">
<div>
<p><span class="font53">Checksum</span></p>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 8.8 </span><span class="font50">♦ </span><span class="font5">Initial message and fraudulent message have the same checksum!</span></p>
<p><span class="font53">is shown in the bottom half of Figure 8.8. The messages “</span><span class="font36">IOU100.99BOB</span><span class="font53">” and “</span><span class="font36">IOU900.19BOB</span><span class="font53">” have the </span><span class="font53" style="font-style:italic;">same</span><span class="font53"> checksum. Thus, this simple checksum algorithm violates the requirement above. Given the original data, it is simple to find another set of data with the same checksum. Clearly, for security purposes, we are going to need a more powerful hash function than a checksum.</span></p>
<p><span class="font53">The MD5 hash algorithm of Ron Rivest [RFC 1321] is in wide use today. It computes a 128-bit hash in a four-step process consisting of a padding step (adding a one followed by enough zeros so that the length of the message satisfies certain conditions), an append step (appending a 64-bit representation of the message length before padding), an initialization of an accumulator, and a final looping step in which the message’s 16-word blocks are processed (mangled) in four rounds. For a description of MD5 (including a C source code implementation) see [RFC 1321].</span></p>
<p><span class="font53">The second major hash algorithm in use today is the Secure Hash Algorithm (SHA-1) [FIPS 1995]. This algorithm is based on principles similar to those used in the design of MD4 [RFC 1320], the predecessor to MD5. SHA-1, a US federal standard, is required for use whenever a cryptographic hash algorithm is needed for federal applications. It produces a 160-bit message digest. The longer output length makes SHA-1 more secure.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">8.3.2 </span><span class="font23" style="font-weight:bold;">Message Authentication Code</span></p></li></ul>
<p><a name="bookmark454"></a><span class="font53">Let’s now return to the problem of message integrity. Now that we understand hash functions, let’s take a first stab at how we might perform message integrity:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">1. Alice creates message </span><span class="font53" style="font-style:italic;">m</span><span class="font53"> and calculates the hash </span><span class="font53" style="font-style:italic;">H(m)</span><span class="font53"> (for example, with SHA-1).</span></p></li>
<li>
<p><span class="font53">2. Alice then appends </span><span class="font53" style="font-style:italic;">H</span><span class="font53">(</span><span class="font53" style="font-style:italic;">m</span><span class="font53">) to the message </span><span class="font53" style="font-style:italic;">m</span><span class="font53">, creating an extended message</span></p></li></ul>
<p><span class="font53">(</span><span class="font53" style="font-style:italic;">m</span><span class="font53">, </span><span class="font53" style="font-style:italic;">H</span><span class="font53">(</span><span class="font53" style="font-style:italic;">m</span><span class="font53">)), and sends the extended message to Bob.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">3. Bob receives an extended message (</span><span class="font53" style="font-style:italic;">m</span><span class="font53">, </span><span class="font53" style="font-style:italic;">h)</span><span class="font53"> and calculates </span><span class="font53" style="font-style:italic;">H</span><span class="font53">(</span><span class="font53" style="font-style:italic;">m</span><span class="font53">). If </span><span class="font53" style="font-style:italic;">H</span><span class="font53">(</span><span class="font53" style="font-style:italic;">m</span><span class="font53">) </span><span class="font54">= </span><span class="font53" style="font-style:italic;">h, </span><span class="font53">Bob concludes that everything is fine.</span></p></li></ul>
<p><span class="font53">This approach is obviously flawed. Trudy can create a bogus message </span><span class="font53" style="font-style:italic;">m'</span><span class="font53"> in which she says she is Alice, calculate </span><span class="font53" style="font-style:italic;">H</span><span class="font53">(</span><span class="font53" style="font-style:italic;">m</span><span class="font53">'), and send Bob (</span><span class="font53" style="font-style:italic;">m</span><span class="font53">', </span><span class="font53" style="font-style:italic;">H</span><span class="font53">(</span><span class="font53" style="font-style:italic;">m</span><span class="font53">')). When Bob receives the message, everything checks out in step 3, so Bob doesn’t suspect any funny business.</span></p>
<p><span class="font53">To perform message integrity, in addition to using cryptographic hash functions, Alice and Bob will need a shared secret </span><span class="font53" style="font-style:italic;">s</span><span class="font53">. This shared secret, which is nothing more than a string of bits, is called the </span><span class="font53" style="font-weight:bold;">authentication key</span><span class="font53">. Using this shared secret, message integrity can be performed as follows:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">1. Alice creates message </span><span class="font53" style="font-style:italic;">m</span><span class="font53">, concatenates </span><span class="font53" style="font-style:italic;">5</span><span class="font53"> with </span><span class="font53" style="font-style:italic;">m</span><span class="font53"> to create </span><span class="font53" style="font-style:italic;">m</span><span class="font55"> + </span><span class="font53" style="font-style:italic;">s,</span><span class="font53"> and calculates the hash </span><span class="font53" style="font-style:italic;">H(m</span><span class="font55"> + </span><span class="font53" style="font-style:italic;">s</span><span class="font53">) (for example, with SHA-1). </span><span class="font53" style="font-style:italic;">H(m</span><span class="font55"> + </span><span class="font53" style="font-style:italic;">s</span><span class="font53">) is called the </span><span class="font53" style="font-weight:bold;">message authentication code (MAC)</span><span class="font53">.</span></p></li>
<li>
<p><span class="font53">2. Alice then appends the MAC to the message </span><span class="font53" style="font-style:italic;">m</span><span class="font53">, creating an extended message </span><span class="font53" style="font-style:italic;">(m, H(m</span><span class="font55"> + </span><span class="font53" style="font-style:italic;">s</span><span class="font53">)), and sends the extended message to Bob.</span></p></li>
<li>
<p><span class="font53">3. Bob receives an extended message (</span><span class="font53" style="font-style:italic;">m, h</span><span class="font53">) and knowing </span><span class="font53" style="font-style:italic;">s</span><span class="font53">, calculates the MAC </span><span class="font53" style="font-style:italic;">H(m</span><span class="font55"> + </span><span class="font53" style="font-style:italic;">s</span><span class="font53">). If </span><span class="font53" style="font-style:italic;">H(m</span><span class="font55"> + </span><span class="font53" style="font-style:italic;">s</span><span class="font53">) </span><span class="font54">= </span><span class="font53" style="font-style:italic;">h</span><span class="font53">, Bob concludes that everything is fine.</span></p></li></ul>
<p><span class="font53">A summary of the procedure is shown in Figure 8.9. Readers should note that the MAC here (standing for “message authentication code”) is not the same MAC used in link-layer protocols (standing for “medium access control”)!</span></p>
<p><span class="font53">One nice feature of a MAC is that it does not require an encryption algorithm. Indeed, in many applications, including the link-state routing algorithm described earlier, communicating entities are only concerned with message integrity and are</span></p>
<div><img src="networking_files/networking-564.jpg" alt="" style="width:81pt;height:59pt;">
<p><span class="font4" style="font-style:italic;">H(m+s)</span></p>
<p><span class="font4">Key:</span></p>
<p><span class="font4" style="font-style:italic;text-decoration:underline;">| m | </span><span class="font4" style="font-style:italic;">s</span></p>
</div><br clear="all">
<div>
<p><span class="font39" style="text-decoration:underline;">S3</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-565.jpg" alt="" style="width:11pt;height:30pt;">
<p><span class="font4">Internet</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-566.jpg" alt="" style="width:138pt;height:96pt;">
</div><br clear="all">
<div>
<p><span class="font41">= Message</span></p>
<p><span class="font41">= Shared secret</span></p>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 8.9 </span><span class="font50">♦ </span><span class="font5">Message authentication code (MAC)</span></p>
<p><span class="font53">not concerned with message confidentiality. Using a MAC, the entities can authenticate the messages they send to each other without having to integrate complex encryption algorithms into the integrity process.</span></p>
<p><span class="font53">As you might expect, a number of different standards for MACs have been proposed over the years. The most popular standard today is </span><span class="font53" style="font-weight:bold;">HMAC</span><span class="font53">, which can be used either with MD5 or SHA-1. HMAC actually runs data and the authentication key through the hash function twice [Kaufman 2002; RFC 2104].</span></p>
<p><span class="font53">There still remains an important issue. How do we distribute the shared authentication key to the communicating entities? For example, in the link-state routing algorithm, we would somehow need to distribute the secret authentication key to each of the routers in the autonomous system. (Note that the routers can all use the same authentication key.) A network administrator could actually accomplish this by physically visiting each of the routers. Or, if the network administrator is a lazy guy, and if each router has its own public key, the network administrator could distribute the authentication key to any one of the routers by encrypting it with the router’s public key and then sending the encrypted key over the network to the router.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">8.3.3 </span><span class="font23" style="font-weight:bold;">Digital Signatures</span></p></li></ul>
<p><span class="font53">Think of the number of the times you’ve signed your name to a piece of paper during the last week. You sign checks, credit card receipts, legal documents, and letters. Your signature attests to the fact that you (as opposed to someone else) have acknowledged and/or agreed with the document’s contents. In a digital world, one often wants to indicate the owner or creator of a document, or to signify one’s agreement with a document’s content. A </span><span class="font53" style="font-weight:bold;">digital signature </span><span class="font53">is a cryptographic technique for achieving these goals in a digital world.</span></p>
<p><span class="font53">Just as with handwritten signatures, digital signing should be done in a way that is verifiable and nonforgeable. That is, it must be possible to prove that a document signed by an individual was indeed signed by that individual (the signature must be verifiable) and that </span><span class="font53" style="font-style:italic;">only</span><span class="font53"> that individual could have signed the document (the signature cannot be forged).</span></p>
<p><span class="font53">Let’s now consider how we might design a digital signature scheme. Observe that when Bob signs a message, Bob must put something on the message that is unique to him. Bob could consider attaching a MAC for the signature, where the MAC is created by appending his key (unique to him) to the message, and then taking the hash. But for Alice to verify the signature, she must also have a copy of the key, in which case the key would not be unique to Bob. Thus, MACs are not going to get the job done here.</span></p>
<p><span class="font53">Recall that with public-key cryptography, Bob has both a public and private key, with both of these keys being unique to Bob. Thus, public-key cryptography is an excellent candidate for providing digital signatures. Let us now examine how it is done.</span></p>
<p><a name="bookmark455"></a><span class="font53">Suppose that Bob wants to digitally sign a document, </span><span class="font53" style="font-style:italic;">m.</span><span class="font53"> We can think of the document as a file or a message that Bob is going to sign and send. As shown in Figure 8.10, to sign this document, Bob simply uses his private key, </span><span class="font53" style="font-style:italic;">K</span><span class="font3" style="font-style:italic;">-</span><span class="font53" style="font-style:italic;">,</span><span class="font53"> to compute</span></p>
<p><span class="font4">Message: </span><span class="font4" style="font-style:italic;">m</span></p>
<p><span class="font4">Signed message: </span><span class="font4" style="font-style:italic;font-variant:small-caps;">Kb~ (m</span><span class="font4">)</span></p><img src="networking_files/networking-567.jpg" alt="" style="width:335pt;height:118pt;">
<p><span class="font7" style="font-weight:bold;">Figure 8.10 </span><span class="font50">♦ </span><span class="font5">Creating a digital signature for a document</span></p>
<p><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">]</span><span class="font3" style="font-style:italic;">-</span><span class="font53" style="font-style:italic;">(m).</span><span class="font53"> At first, it might seem odd that Bob is using his private key (which, as we saw in Section 8.2, was used to decrypt a message that had been encrypted with his public key) to sign a document. But recall that encryption and decryption are nothing more than mathematical operations (exponentiation to the power of </span><span class="font53" style="font-style:italic;">e</span><span class="font53"> or </span><span class="font53" style="font-style:italic;">d</span><span class="font53"> in RSA; see Section 8.2) and recall that Bob’s goal is not to scramble or obscure the contents of the document, but rather to sign the document in a manner that is verifiable and nonforge-able. Bob’s digital signature of the document is </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">B</span><span class="font3">-</span><span class="font53">(</span><span class="font53" style="font-style:italic;">m</span><span class="font53">).</span></p>
<p><span class="font53">Does the digital signature </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">B</span><span class="font53">(</span><span class="font53" style="font-style:italic;">m</span><span class="font53">) meet our requirements of being verifiable and nonforgeable? Suppose Alice has </span><span class="font53" style="font-style:italic;">m</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">B</span><span class="font3">-</span><span class="font53">(</span><span class="font53" style="font-style:italic;">m</span><span class="font53">). She wants to prove in court (being litigious) that Bob had indeed signed the document and was the only person who could have possibly signed the document. Alice takes Bob’s public key, </span><span class="font53" style="font-style:italic;">K</span><span class="font3" style="font-style:italic;">+</span><span class="font53" style="font-style:italic;">,</span><span class="font53"> and applies it to the digital signature, </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">B</span><span class="font53">(</span><span class="font53" style="font-style:italic;">m</span><span class="font53">), associated with the document, </span><span class="font53" style="font-style:italic;">m</span><span class="font53">. That is, she computes </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">B</span><span class="font53">(</span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">B</span><span class="font53">(</span><span class="font53" style="font-style:italic;">m</span><span class="font53">)), and voila, with a dramatic flurry, she produces </span><span class="font53" style="font-style:italic;">m</span><span class="font53">, which exactly matches the original document! Alice then argues that only Bob could have signed the document, for the following reasons:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;Whoever signed the message must have used the private key, </span><span class="font53" style="font-style:italic;">K</span><span class="font3" style="font-style:italic;">-</span><span class="font53" style="font-style:italic;">,</span><span class="font53"> in computing the signature </span><span class="font53" style="font-style:italic;">K</span><span class="font3" style="font-style:italic;">-</span><span class="font53" style="font-style:italic;">(m),</span><span class="font53"> such that </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">B</span><span class="font53" style="font-style:italic;">(K</span><span class="font3" style="font-style:italic;">-</span><span class="font53" style="font-style:italic;">(m)) = m.</span></p></li>
<li>
<p><span class="font53">• &nbsp;The only person who could have known the private key, </span><span class="font53" style="font-style:italic;">K</span><span class="font3" style="font-style:italic;">-</span><span class="font53" style="font-style:italic;">,</span><span class="font53"> is Bob. Recall from our discussion of RSA in Section 8.2 that knowing the public key, </span><span class="font53" style="font-style:italic;">K</span><span class="font3" style="font-style:italic;">+</span><span class="font53" style="font-style:italic;">,</span><span class="font53"> is of no help in learning the private key, </span><span class="font53" style="font-style:italic;">K</span><span class="font3" style="font-style:italic;">-</span><span class="font53" style="font-style:italic;">.</span><span class="font53"> Therefore, the only person who could know </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">B</span><span class="font53"> is the person who generated the pair of keys, </span><span class="font53" style="font-style:italic;">(K</span><span class="font3" style="font-style:italic;">+</span><span class="font53" style="font-style:italic;">, K</span><span class="font50" style="font-style:italic;">B</span><span class="font53" style="font-style:italic;">),</span><span class="font53"> in the first place, Bob. (Note that this assumes, though, that Bob has not given </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">B</span><span class="font53"> to anyone, nor has anyone stolen </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">B</span><span class="font53"> from Bob.)</span></p></li></ul>
<p><span class="font53">It is also important to note that if the original document, </span><span class="font53" style="font-style:italic;">m</span><span class="font53">, is ever modified to some alternate form, </span><span class="font53" style="font-style:italic;">m',</span><span class="font53"> the signature that Bob created for </span><span class="font53" style="font-style:italic;">m</span><span class="font53"> will not be valid for </span><span class="font53" style="font-style:italic;">m', </span><span class="font53">since </span><span class="font53" style="font-style:italic;">K</span><span class="font3" style="font-style:italic;">+</span><span class="font53" style="font-style:italic;">(K</span><span class="font3" style="font-style:italic;">g</span><span class="font53" style="font-style:italic;">(m))</span><span class="font53"> does not equal </span><span class="font53" style="font-style:italic;">m'.</span><span class="font53"> Thus, we see that digital signatures also provide message integrity, allowing the receiver to verify that the message was unaltered as well as the source of the message.</span></p>
<p><span class="font53">One concern with signing data by encryption is that encryption and decryption are computationally expensive. Given the overheads of encryption and decryption, signing data via complete encryption/decryption can be overkill. A more efficient approach is to introduce hash functions into the digital signature. Recall from Section 8.3.2 that a hash algorithm takes a message, </span><span class="font53" style="font-style:italic;">m</span><span class="font53">, of arbitrary length and computes a fixed-length “fingerprint” of the message, denoted by </span><span class="font53" style="font-style:italic;">H(m).</span><span class="font53"> Using a hash function, Bob signs the hash of a message rather than the message itself, that is, Bob calculates </span><span class="font53" style="font-style:italic;">K</span><span class="font3" style="font-style:italic;">-</span><span class="font53" style="font-style:italic;">(H(m)).</span><span class="font53"> Since </span><span class="font53" style="font-style:italic;">H</span><span class="font53">(</span><span class="font53" style="font-style:italic;">m</span><span class="font53">) is generally much smaller than the original message </span><span class="font53" style="font-style:italic;">m</span><span class="font53">, the computational effort required to create the digital signature is substantially reduced.</span></p>
<p><span class="font53">In the context of Bob sending a message to Alice, Figure 8.11 provides a summary of the operational procedure of creating a digital signature. Bob puts his original long message through a hash function. He then digitally signs the resulting hash with his private key. The original message (in cleartext) along with the digitally signed message digest (henceforth referred to as the digital signature) is then sent to Alice. Figure 8.12 provides a summary of the operational procedure of the signature. Alice applies the sender’s public key to the message to obtain a hash result. Alice also</span></p><img src="networking_files/networking-568.jpg" alt="" style="width:391pt;height:248pt;">
<p><span class="font7" style="font-weight:bold;">Figure 8.11 </span><span class="font50">♦ </span><span class="font5">Sending a digitally signed message</span></p><img src="networking_files/networking-569.jpg" alt="" style="width:389pt;height:295pt;">
<p><span class="font7" style="font-weight:bold;">Figure 8.12 </span><span class="font50">♦ </span><span class="font5">Verifying a signed message</span></p>
<p><span class="font53">applies the hash function to the cleartext message to obtain a second hash result. If the two hashes match, then Alice can be sure about the integrity and author of the message.</span></p>
<p><span class="font53">Before moving on, let’s briefly compare digital signatures with MACs, since they have parallels, but also have important subtle differences. Both digital signatures and MACs start with a message (or a document). To create a MAC out of the message, we append an authentication key to the message, and then take the hash of the result. Note that neither public key nor symmetric key encryption is involved in creating the MAC. To create a digital signature, we first take the hash of the message and then encrypt the message with our private key (using public key cryptography). Thus, a digital signature is a “heavier” technique, since it requires an underlying Public Key Infrastructure (PKI) with certification authorities as described below. We’ll see in Section 8.4 that PGP—a popular secure e-mail system—uses digital signatures for message integrity. We’ve seen already that OSPF uses MACs for message integrity. We’ll see in Sections 8.5 and 8.6 that MACs are also used for popular transport-layer and network-layer security protocols.</span></p>
<p><span class="font22" style="font-weight:bold;">Public Key Certification</span></p>
<p><span class="font53">An important application of digital signatures is </span><span class="font53" style="font-weight:bold;">public key certification</span><span class="font53">, that is, certifying that a public key belongs to a specific entity. Public key certification is used in many popular secure networking protocols, including IPsec and TLS.</span></p>
<p><span class="font53">To gain insight into this problem, let’s consider an Internet-commerce version of the classic “pizza prank.” Alice is in the pizza delivery business and accepts orders over the Internet. Bob, a pizza lover, sends Alice a plaintext message that includes his home address and the type of pizza he wants. In this message, Bob also includes a digital signature (that is, a signed hash of the original plaintext message) to prove to Alice that he is the true source of the message. To verify the signature, Alice obtains Bob’s public key (perhaps from a public key server or from the e-mail message) and checks the digital signature. In this manner she makes sure that Bob, rather than some adolescent prankster, placed the order.</span></p>
<p><span class="font53">This all sounds fine until clever Trudy comes along. As shown in Figure 8.13, Trudy is indulging in a prank. She sends a message to Alice in which she says she is Bob, gives Bob’s home address, and orders a pizza. In this message she also includes her (Trudy’s) public key, although Alice naturally assumes it is Bob’s public key. Trudy also attaches a digital signature, which was created with her own (Trudy’s) private key. After receiving the message, Alice applies Trudy’s public key (thinking that it is Bob’s) to the digital signature and concludes that the plaintext message was indeed created by Bob. Bob will be very surprised when the delivery person brings a pizza with pepperoni and anchovies to his home!</span></p>
<p><span class="font53">We see from this example that for public key cryptography to be useful, you need to be able to verify that you have the actual public key of the entity (person, router, browser, and so on) with whom you want to communicate. For example, when Alice wants to communicate with Bob using public key cryptography, she needs to verify that the public key that is supposed to be Bob’s is indeed Bob’s.</span></p>
<p><span class="font53">Binding a public key to a particular entity is typically done by a </span><span class="font53" style="font-weight:bold;">Certification Authority (CA)</span><span class="font53">, whose job is to validate identities and issue certificates. A CA has the following roles:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">1. A CA verifies that an entity (a person, a router, and so on) is who it says it is. There are no mandated procedures for how certification is done. When dealing with a CA, one must trust the CA to have performed a suitably rigorous identity verification. For example, if Trudy were able to walk into the Fly-by-Night CA and simply announce “I am Alice” and receive certificates associated with the identity of Alice, then one shouldn’t put much faith in public keys certified by the Fly-by-Night CA. On the other hand, one might (or might not!) be more willing to trust a CA that is part of a federal or state program. You can trust the identity associated with a public key only to the extent to which you can trust a CA and its identity verification techniques. What a tangled web of trust we spin!</span></p></li>
<li>
<p><span class="font53">2. Once the CA verifies the identity of the entity, the CA creates a </span><span class="font53" style="font-weight:bold;">certificate </span><span class="font53">that binds the public key of the entity to the identity. The certificate contains</span></p></li></ul><img src="networking_files/networking-570.jpg" alt="" style="width:26pt;height:42pt;">
<p><span class="font4">Message</span></p><img src="networking_files/networking-571.jpg" alt="" style="width:424pt;height:236pt;">
<p><span class="font7" style="font-weight:bold;">Figure 8.13 </span><span class="font50">♦ </span><span class="font5">Trudy masquerades as Bob using public key cryptography</span></p>
<p><span class="font53">the public key and globally unique identifying information about the owner of the public key (for example, a human name or an IP address). The certificate is digitally signed by the CA. These steps are shown in Figure 8.14.</span></p>
<p><span class="font53">Let us now see how certificates can be used to combat pizza-ordering pranksters, like Trudy, and other undesirables. When Bob places his order he also sends his CA-signed certificate. Alice uses the CA’s public key to check the validity of Bob’s certificate and extract Bob’s public key.</span></p>
<p><span class="font53">Both the International Telecommunication Union (ITU) and the IETF have developed standards for CAs. ITU X.509 [ITU 2005a] specifies an authentication service as well as a specific syntax for certificates. [RFC 1422] describes CA-based key management for use with secure Internet e-mail. It is compatible with X.509 but goes beyond X.509 by establishing procedures and conventions for a key management architecture. Table 8.4 describes some of the important fields in a certificate.</span></p>
<p><span class="font4">CA's private</span></p><img src="networking_files/networking-572.jpg" alt="" style="width:310pt;height:204pt;">
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Field Name</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Description</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Version</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Version number of X.509 specification</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Serial number</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">CA-issued unique identifier for a certificate</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Signature</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Specifies the algorithm used by CA to sign this certificate</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Issuer name</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Identity of CA issuing this certificate, in distinguished name (DN) [RFC 4514] format</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Validity period</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Start and end of period of validity for certificate</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Subject name</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Identity of entity whose public key is associated with this certificate, in DN format</span></p></td></tr>
<tr><td>
<p><span class="font6">Subject public key</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">The subject's public key as well indication of the public key algorithm (and algorithm parameters) to be used with this key</span></p></td></tr>
</table>
<p><span class="font7" style="font-weight:bold;">Table 8.4 </span><span class="font50">♦ </span><span class="font5">Selected fields in an X.509 and RFC 1422 public key</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">8.4 </span><span class="font24" style="font-weight:bold;">End-Point Authentication</span></p></li></ul>
<p><a name="bookmark456"></a><span class="font53" style="font-weight:bold;">End-point authentication </span><span class="font53">is the process of one entity proving its identity to another entity over a computer network, for example, a user proving its identity to an e-mail server. As humans, we authenticate each other in many ways: We recognize each other’s faces when we meet, we recognize each other’s voices on the telephone, we are authenticated by the customs official who checks us against the picture on our passport.</span></p>
<p><span class="font53">In this section, we consider how one party can authenticate another party when the two are communicating over a network. We focus here on authenticating a “live” party, at the point in time when communication is actually occurring. A concrete example is a user authenticating him or herself to an e-mail server. This is a subtly different problem from proving that a message received at some point in the past did indeed come from that claimed sender, as studied in Section 8.3.</span></p>
<p><span class="font53">When performing authentication over the network, the communicating parties cannot rely on biometric information, such as a visual appearance or a voiceprint. Indeed, we will see in our later case studies that it is often network elements such as routers and client/server processes that must authenticate each other. Here, authentication must be done solely on the basis of messages and data exchanged as part of an </span><span class="font53" style="font-weight:bold;">authentication protocol</span><span class="font53">. Typically, an authentication protocol would run </span><span class="font53" style="font-style:italic;">before </span><span class="font53">the two communicating parties run some other protocol (for example, a reliable data transfer protocol, a routing information exchange protocol, or an e-mail protocol). The authentication protocol first establishes the identities of the parties to each other’s satisfaction; only after authentication do the parties get down to the work at hand.</span></p>
<p><span class="font53">As in the case of our development of a reliable data transfer (rdt) protocol in Chapter 3, we will find it instructive here to develop various versions of an authentication protocol, which we will call </span><span class="font53" style="font-weight:bold;">ap </span><span class="font53">(authentication protocol), and poke holes in each version as we proceed. (If you enjoy this stepwise evolution of a design, you might also enjoy [Bryant 1988], which recounts a fictitious narrative between designers of an opennetwork authentication system, and their discovery of the many subtle issues involved.)</span></p>
<p><span class="font53">Let’s assume that Alice needs to authenticate herself to Bob.</span></p>
<p><span class="font53">Perhaps the simplest authentication protocol we can imagine is one where Alice simply sends a message to Bob saying she is Alice. This protocol is shown in Figure 8.15. The flaw here is obvious—there is no way for Bob actually to know that the person sending the message “I am Alice” is indeed Alice. For example, Trudy (the intruder) could just as well send such a message.</span></p>
<div>
<p><span class="font4">Alice</span></p><img src="networking_files/networking-573.jpg" alt="" style="width:36pt;height:38pt;">
</div><br clear="all">
<div>
<p><span class="font34">I am Alice</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Bob</span></p><img src="networking_files/networking-574.jpg" alt="" style="width:27pt;height:38pt;">
<p><span class="font50">*</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-575.jpg" alt="" style="width:26pt;height:42pt;">
<p><span class="font4">Trudy</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Alice &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Bob</span></p><img src="networking_files/networking-576.jpg" alt="" style="width:125pt;height:120pt;">
<p><span class="font4">Trudy</span></p>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 8.15 </span><span class="font50">♦ </span><span class="font5">Protocol </span><span class="font5" style="font-style:italic;">ap1.0</span><span class="font5"> and a failure scenario</span></p>
<p><span class="font22" style="font-weight:bold;">Authentication Protocol </span><span class="font53" style="font-weight:bold;font-style:italic;">ap2.0</span></p>
<p><span class="font53">If Alice has a well-known network address (e.g., an IP address) from which she always communicates, Bob could attempt to authenticate Alice by verifying that the source address on the IP datagram carrying the authentication message matches Alice’s well-known address. In this case, Alice would be authenticated. This might stop a very network-naive intruder from impersonating Alice, but it wouldn’t stop the determined student studying this book, or many others!</span></p>
<p><span class="font53">From our study of the network and data link layers, we know that it is not that hard (for example, if one had access to the operating system code and could build one’s own operating system kernel, as is the case with Linux and several other freely available operating systems) to create an IP datagram, put whatever IP source address we want (for example, Alice’s well-known IP address) into the IP datagram, and send the datagram over the link-layer protocol to the first-hop router. From then on, the incorrectly source-addressed datagram would be dutifully forwarded to Bob. This approach, shown in Figure 8.16, is a form of IP spoofing. IP spoofing can be avoided if Trudy’s first-hop router is configured to forward only datagrams containing Trudy’s IP source address [RFC 2827]. However, this capability is not universally deployed or enforced. Bob would thus be foolish to assume that Trudy’s network manager (who might be Trudy herself) had configured Trudy’s first-hop router to forward only appropriately addressed datagrams.</span></p>
<p><span class="font22" style="font-weight:bold;">Authentication Protocol </span><span class="font53" style="font-weight:bold;font-style:italic;">ap3.0</span></p>
<p><span class="font53">One classic approach to authentication is to use a secret password. The password is a shared secret between the authenticator and the person being authenticated. Gmail, Facebook, telnet, FTP, and many other services use password authentication. In protocol ap3.0, Alice thus sends her secret password to Bob, as shown in Figure 8.17.</span></p>
<div>
<p><span class="font4">Alice</span></p><img src="networking_files/networking-577.jpg" alt="" style="width:36pt;height:38pt;">
</div><br clear="all">
<div>
<p><span class="font4">Bob</span></p><img src="networking_files/networking-578.jpg" alt="" style="width:25pt;height:45pt;">
</div><br clear="all">
<div>
<p><span class="font34">Alice’s IP addr.</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-579.jpg" alt="" style="width:26pt;height:44pt;">
<p><span class="font4">Trudy</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Alice &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Bob</span></p><img src="networking_files/networking-580.jpg" alt="" style="width:127pt;height:122pt;">
<p><span class="font4">Trudy</span></p>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 8.16 </span><span class="font50">♦ </span><span class="font5">Protocol </span><span class="font5" style="font-style:italic;">ap2.0</span><span class="font5"> and a failure scenario</span></p>
<div>
<p><span class="font4">Alice &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Bob</span></p>
<p><span class="font34">I am Alice password</span></p><img src="networking_files/networking-581.jpg" alt="" style="width:125pt;height:120pt;">
<p><span class="font4">Trudy</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Alice &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Bob</span></p><img src="networking_files/networking-582.jpg" alt="" style="width:126pt;height:121pt;">
<p><span class="font4">Trudy</span></p>
</div><br clear="all">
<p><span class="font4">Key:</span></p>
<p><span class="font41">j</span><span class="font41" style="text-decoration:underline;">pj</span><span class="font41"> Tape recorder</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 8.17 </span><span class="font50">♦ </span><span class="font5">Protocol </span><span class="font5" style="font-style:italic;">ap3.0</span><span class="font5"> and a failure scenario</span></p>
<p><span class="font53">Since passwords are so widely used, we might suspect that protocol </span><span class="font53" style="font-style:italic;">ap3.0</span><span class="font53"> is fairly secure. If so, we’d be wrong! The security flaw here is clear. If Trudy eavesdrops on Alice’s communication, then she can learn Alice’s password. Lest you think this is unlikely, consider the fact that when you Telnet to another machine and log in, the login password is sent unencrypted to the Telnet server. Someone connected to the Telnet client or server’s LAN can possibly sniff (read and store) all packets transmitted on the LAN and thus steal the login password. In fact, this is a well-known approach for stealing passwords (see, for example, [Jimenez 1997]). Such a threat is obviously very real, so </span><span class="font53" style="font-style:italic;">ap3.0</span><span class="font53"> clearly won’t do.</span></p>
<p><span class="font22" style="font-weight:bold;">Authentication Protocol </span><span class="font53" style="font-weight:bold;font-style:italic;">ap3.1</span></p>
<p><span class="font53">Our next idea for fixing ap3.0 is naturally to encrypt the password. By encrypting the password, we can prevent Trudy from learning Alice’s password. If we assume that Alice and Bob share a symmetric secret key, </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">A </span><span class="font3" style="font-style:italic;">-</span><span class="font53" style="font-style:italic;"><sub>B</sub>,</span><span class="font53"> then Alice can encrypt the password and send her identification message, “</span><span class="font36">I am Alice</span><span class="font53">,” and her encrypted password to Bob. Bob then decrypts the password and, assuming the password is correct, authenticates Alice. Bob feels comfortable in authenticating Alice since Alice not only knows the password, but also knows the shared secret key value needed to encrypt the password. Let’s call this protocol </span><span class="font53" style="font-style:italic;">ap3.1</span><span class="font53">.</span></p>
<p><span class="font53">While it is true that </span><span class="font53" style="font-style:italic;">ap3.1</span><span class="font53"> prevents Trudy from learning Alice’s password, the use of cryptography here does not solve the authentication problem. Bob is subject to a </span><span class="font53" style="font-weight:bold;">playback attack</span><span class="font53">: Trudy need only eavesdrop on Alice’s communication, record the encrypted version of the password, and play back the encrypted version of the password to Bob to pretend that she is Alice. The use of an encrypted password in </span><span class="font53" style="font-style:italic;">ap3.1</span><span class="font53"> doesn’t make the situation manifestly different from that of protocol </span><span class="font53" style="font-style:italic;">ap3.0</span><span class="font53"> in Figure 8.17.</span></p>
<p><span class="font22" style="font-weight:bold;">Authentication Protocol </span><span class="font53" style="font-weight:bold;font-style:italic;">ap4.0</span></p>
<p><span class="font53">The failure scenario in Figure 8.17 resulted from the fact that Bob could not distinguish between the original authentication of Alice and the later playback of Alice’s original authentication. That is, Bob could not tell if Alice was live (that is, was currently really on the other end of the connection) or whether the messages he was receiving were a recorded playback of a previous authentication of Alice. The very </span><span class="font53" style="font-style:italic;">(very)</span><span class="font53"> observant reader will recall that the three-way TCP handshake protocol needed to address the same problem—the server side of a TCP connection did not want to accept a connection if the received SYN segment was an old copy (retransmission) of a SYN segment from an earlier connection. How did the TCP server side solve the problem of determining whether the client was really live? It chose an initial sequence number that had not been used in a very long time, sent that number to the client, and then waited for the client to respond with an ACK segment containing that number. We can adopt the same idea here for authentication purposes.</span></p>
<p><span class="font53">A </span><span class="font53" style="font-weight:bold;">nonce </span><span class="font53">is a number that a protocol will use only once in a lifetime. That is, once a protocol uses a nonce, it will never use that number again. Our </span><span class="font53" style="font-style:italic;">ap4.0</span><span class="font53"> protocol uses a nonce as follows:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">1. Alice sends the message “</span><span class="font36">I am Alice</span><span class="font53">” to Bob.</span></p></li>
<li>
<p><span class="font53">2. Bob chooses a nonce, R, and sends it to Alice.</span></p></li>
<li>
<p><span class="font53">3. Alice encrypts the nonce using Alice and Bob’s symmetric secret key, </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">A</span><span class="font3">_</span><span class="font53" style="font-style:italic;"><sub>B</sub>,</span><span class="font53"> and sends the encrypted nonce, </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">A</span><span class="font3" style="font-style:italic;">_</span><span class="font53" style="font-style:italic;"><sub>B</sub></span><span class="font53"> (R), back to Bob. As in protocol </span><span class="font53" style="font-style:italic;">ap3.1,</span><span class="font53"> it is the fact that Alice knows </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">A </span><span class="font3" style="font-style:italic;">_ </span><span class="font53" style="font-style:italic;"><sub>B</sub></span><span class="font53"> and uses it to encrypt a value that lets Bob know that the message he receives was generated by Alice. The nonce is used to ensure that Alice is live.</span></p></li>
<li>
<p><span class="font53">4. Bob decrypts the received message. If the decrypted nonce equals the nonce he sent Alice, then Alice is authenticated.</span></p></li></ul>
<p><span class="font53">Protocol </span><span class="font53" style="font-style:italic;">ap4.0</span><span class="font53"> is illustrated in Figure 8.18. By using the once-in-a-lifetime value, </span><span class="font53" style="font-style:italic;">R,</span><span class="font53"> and then checking the returned value, </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">A </span><span class="font3" style="font-style:italic;">_</span><span class="font53" style="font-style:italic;"><sub>B</sub> (R),</span><span class="font53"> Bob can be sure that Alice is both who she says she is (since she knows the secret key value needed to encrypt </span><span class="font53" style="font-style:italic;">R)</span><span class="font53"> and live (since she has encrypted the nonce, </span><span class="font53" style="font-style:italic;">R</span><span class="font53">, that Bob just created).</span></p>
<p><span class="font53">The use of a nonce and symmetric key cryptography forms the basis of </span><span class="font53" style="font-style:italic;">ap4.0.</span><span class="font53"> A natural question is whether we can use a nonce and public key cryptography (rather than symmetric key cryptography) to solve the authentication problem. This issue is explored in the problems at the end of the chapter.</span></p><img src="networking_files/networking-583.jpg" alt="" style="width:123pt;height:111pt;">
<p><span class="font7" style="font-weight:bold;">Figure 8.18 </span><span class="font50">♦ </span><span class="font5">Protocol </span><span class="font5" style="font-style:italic;">ap4.0</span><span class="font5"> and a failure scenario</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">8.5 </span><span class="font24" style="font-weight:bold;">Securing E-Mail</span></p></li></ul>
<p><span class="font53">In previous sections, we examined fundamental issues in network security, including symmetric key and public key cryptography, end-point authentication, key distribution, message integrity, and digital signatures. We are now going to examine how these tools are being used to provide security in the Internet.</span></p>
<p><span class="font53">Interestingly, it is possible to provide security services in any of the top four layers of the Internet protocol stack. When security is provided for a specific application-layer protocol, the application using the protocol will enjoy one or more security services, such as confidentiality, authentication, or integrity. When security is provided for a transport-layer protocol, all applications that use that protocol enjoy the security services of the transport protocol. When security is provided at the network layer on a host-to-host basis, all transport-layer segments (and hence all applicationlayer data) enjoy the security services of the network layer. When security is provided on a link basis, then the data in all frames traveling over the link receive the security services of the link.</span></p>
<p><span class="font53">In Sections 8.5 through 8.8, we examine how security tools are being used in the application, transport, network, and link layers. Being consistent with the general structure of this book, we begin at the top of the protocol stack and discuss security at the application layer. Our approach is to use a specific application, e-mail, as a case study for application-layer security. We then move down the protocol stack. We’ll examine the TLS protocol (which provides security at the transport layer), IPsec (which provides security at the network layer), and the security of the IEEE 802.11 wireless LAN protocol.</span></p>
<p><a name="bookmark457"></a><span class="font53">You might be wondering why security functionality is being provided at more than one layer in the Internet. Wouldn’t it suffice simply to provide the security functionality at the network layer and be done with it? There are two answers to this question. First, although security at the network layer can offer “blanket coverage” by encrypting all the data in the datagrams (that is, all the transport-layer segments) and by authenticating all the source IP addresses, it can’t provide user-level security. For example, a commerce site cannot rely on IP-layer security to authenticate a customer who is purchasing goods at the commerce site. Thus, there is a need for security functionality at higher layers as well as blanket coverage at lower layers. Second, it is generally easier to deploy new Internet services, including security services, at the higher layers of the protocol stack. While waiting for security to be broadly deployed at the network layer, which is probably still many years in the future, many application developers “just do it” and introduce security functionality into their favorite applications. A classic example is Pretty Good Privacy (PGP), which provides secure e-mail (discussed later in this section). Requiring only client and server application code, PGP was one of the first security technologies to be broadly used in the Internet.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">8.5.1 </span><span class="font23" style="font-weight:bold;">Secure E-Mail</span></p></li></ul>
<p><span class="font53">We now use the cryptographic principles of Sections 8.2 through 8.3 to create a secure e-mail system. We create this high-level design in an incremental manner, at each step introducing new security services. When designing a secure e-mail system, let us keep in mind the racy example introduced in Section 8.1—the love affair between Alice and Bob. Imagine that Alice wants to send an e-mail message to Bob, and Trudy wants to intrude.</span></p>
<p><span class="font53">Before plowing ahead and designing a secure e-mail system for Alice and Bob, we should consider which security features would be most desirable for them. First and foremost is </span><span class="font53" style="font-style:italic;">confidentiality.</span><span class="font53"> As discussed in Section 8.1, neither Alice nor Bob wants Trudy to read Alice’s e-mail message. The second feature that Alice and Bob would most likely want to see in the secure e-mail system is </span><span class="font53" style="font-style:italic;">sender authentication. </span><span class="font53">In particular, when Bob receives the message “</span><span class="font36">I don’t love you anymore. I never want to see you again. Formerly yours, Alice</span><span class="font53">,” he would naturally want to be sure that the message came from Alice and not from Trudy. Another feature that the two lovers would appreciate is </span><span class="font53" style="font-style:italic;">message integrity, </span><span class="font53">that is, assurance that the message Alice sends is not modified while en route to Bob. Finally, the e-mail system should provide </span><span class="font53" style="font-style:italic;">receiver authentication;</span><span class="font53"> that is, Alice wants to make sure that she is indeed sending the letter to Bob and not to someone else (for example, Trudy) who is impersonating Bob.</span></p>
<p><a name="bookmark458"></a><span class="font53">So let’s begin by addressing the foremost concern, confidentiality. The most straightforward way to provide confidentiality is for Alice to encrypt the message with symmetric key technology (such as DES or AES) and for Bob to decrypt the message on receipt. As discussed in Section 8.2, if the symmetric key is long enough, and if only Alice and Bob have the key, then it is extremely difficult for anyone else (including Trudy) to read the message. Although this approach is straightforward, it has the fundamental difficulty that we discussed in Section 8.2—distributing a symmetric key so that only Alice and Bob have copies of it. So we naturally consider an alternative approach—public key cryptography (using, for example, RSA). In the</span></p>
<p><span class="font53">public key approach, Bob makes his public key publicly available (e.g., in a public key server or on his personal Web page), Alice encrypts her message with Bob’s public key, and she sends the encrypted message to Bob’s e-mail address. When Bob receives the message, he simply decrypts it with his private key. Assuming that Alice knows for sure that the public key is Bob’s public key, this approach is an excellent means to provide the desired confidentiality. One problem, however, is that public key encryption is relatively inefficient, particularly for long messages.</span></p>
<p><span class="font53">To overcome the efficiency problem, let’s make use of a session key (discussed in Section 8.2.2). In particular, Alice (1) selects a random symmetric session key, </span><span class="font53" style="font-style:italic;">K<sub>S</sub>, </span><span class="font53">(2) encrypts her message, </span><span class="font53" style="font-style:italic;">m,</span><span class="font53"> with the symmetric key, (3) encrypts the symmetric key with Bob’s public key, </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">B</span><span class="font53"> <sup>+</sup>, (4) concatenates the encrypted message and the encrypted symmetric key to form a “package,” and (5) sends the package to Bob’s e-mail address. The steps are illustrated in Figure 8.19. (In this and the subsequent figures, the circled “</span><span class="font55">+</span><span class="font53">” represents concatenation and the circled “</span><span class="font55">—</span><span class="font53">” represents deconcatenation.) When Bob receives the package, he (1) uses his private key, </span><span class="font53" style="font-style:italic;">K</span><span class="font3" style="font-style:italic;">—</span><span class="font53" style="font-style:italic;">, </span><span class="font53">to obtain the symmetric key, </span><span class="font53" style="font-style:italic;">K<sub>S</sub>,</span><span class="font53"> and (2) uses the symmetric key </span><span class="font53" style="font-style:italic;">K<sub>S</sub></span><span class="font53"> to decrypt the message </span><span class="font53" style="font-style:italic;">m</span><span class="font53">.</span></p>
<p><span class="font53">Having designed a secure e-mail system that provides confidentiality, let’s now design another system that provides both sender authentication and message integrity. We’ll suppose, for the moment, that Alice and Bob are no longer concerned with confidentiality (they want to share their feelings with everyone!), and are concerned only about sender authentication and message integrity. To accomplish this task, we use digital signatures and message digests, as described in Section 8.3. Specifically, Alice (1) applies a hash function, </span><span class="font53" style="font-style:italic;">H</span><span class="font53"> (e.g., MD5), to her message, </span><span class="font53" style="font-style:italic;">m</span><span class="font53">, to obtain a message digest, (2) signs the result of the hash function with her private key, </span><span class="font53" style="font-style:italic;">K</span><span class="font3" style="font-style:italic;">—</span><span class="font53" style="font-style:italic;">,</span><span class="font53"> to create a digital signature, (3) concatenates the original (unencrypted) message with the signature to create a package, and (4) sends the package to Bob’s e-mail address. When Bob receives the package, he (1) applies Alice’s public key, </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">—</span><span class="font53">, to the signed</span></p>
<div><img src="networking_files/networking-584.jpg" alt="" style="width:133pt;height:124pt;">
<p><span class="font4">Internet</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-585.jpg" alt="" style="width:135pt;height:124pt;">
<p><span class="font7" style="font-weight:bold;">Figure 8.19 </span><span class="font50">♦ </span><span class="font5">Alice used a symmetric session key, </span><span class="font5" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">B</span><span class="font5" style="font-style:italic;">,</span><span class="font5"> to send a secret e-mail to Bob</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-586.jpg" alt="" style="width:165pt;height:99pt;">
<p><span class="font4">Alice sends e-mail message </span><span class="font4" style="font-style:italic;">m</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Internet</span></p><img src="networking_files/networking-587.jpg" alt="" style="width:68pt;height:105pt;">
</div><br clear="all">
<div><img src="networking_files/networking-588.jpg" alt="" style="width:67pt;height:103pt;">
</div><br clear="all">
<div><img src="networking_files/networking-589.jpg" alt="" style="width:28pt;height:38pt;">
</div><br clear="all">
<div>
<p><span class="font4">Bob receives e-mail message </span><span class="font4" style="font-style:italic;">m</span></p>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 8.20 </span><span class="font50">♦ </span><span class="font5">Using hash functions and digital signatures to provide sender authentication and message integrity</span></p>
<p><span class="font53">message digest and (2) compares the result of this operation with his own hash, </span><span class="font53" style="font-style:italic;">H, </span><span class="font53">of the message. The steps are illustrated in Figure 8.20. As discussed in Section 8.3, if the two results are the same, Bob can be pretty confident that the message came from Alice and is unaltered.</span></p>
<p><span class="font53">Now let’s consider designing an e-mail system that provides confidentiality, sender authentication, </span><span class="font53" style="font-style:italic;">and</span><span class="font53"> message integrity. This can be done by combining the procedures in Figures 8.19 and 8.20. Alice first creates a preliminary package, exactly as in Figure 8.20, that consists of her original message along with a digitally signed hash of the message. She then treats this preliminary package as a message in itself and sends this new message through the sender steps in Figure 8.19, creating a new package that is sent to Bob. The steps applied by Alice are shown in Figure 8.21. When Bob receives the package, he first applies his side of Figure 8.19 and then his side of Figure 8.20. It should be clear that this design achieves the goal of providing confidentiality, sender authentication, and message integrity. Note that, in this scheme, Alice uses public key cryptography twice: once with her own private key and once with Bob’s public key. Similarly, Bob also uses public key cryptography twice—once with his private key and once with Alice’s public key.</span></p>
<div><img src="networking_files/networking-590.jpg" alt="" style="width:306pt;height:131pt;">
<p><span class="font7" style="font-weight:bold;">Figure 8.21 </span><span class="font50">♦ </span><span class="font5">Alice uses symmetric key cyptography, public key cryptography, a hash function, and a digital signature to provide secrecy, sender authentication, and message integrity</span></p>
</div><br clear="all">
<p><span class="font53">The secure e-mail design outlined in Figure 8.21 probably provides satisfactory security for most e-mail users for most occasions. However, there is still one important issue that remains to be addressed. The design in Figure 8.21 requires Alice to obtain Bob’s public key, and requires Bob to obtain Alice’s public key. The distribution of these public keys is a nontrivial problem. For example, Trudy might masquerade as Bob and give Alice her own public key while saying that it is Bob’s public key, enabling her to receive the message meant for Bob. As we learned in Section 8.3, a popular approach for securely distributing public keys is to </span><span class="font53" style="font-style:italic;">certify</span><span class="font53"> the public keys using a CA.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">8.5.2 </span><span class="font23" style="font-weight:bold;">PGP</span></p></li></ul>
<p><span class="font53">Written by Phil Zimmermann in 1991, </span><span class="font53" style="font-weight:bold;">Pretty Good Privacy (PGP) </span><span class="font53">is a nice example of an e-mail encryption scheme [PGP 2020]. The PGP design is, in essence, the same as the design shown in Figure 8.21. Depending on the version, the PGP software uses MD5 or SHA for calculating the message digest; CAST, triple-DES, or IDEA for symmetric key encryption; and RSA for the public key encryption.</span></p>
<p><span class="font53">When PGP is installed, the software creates a public key pair for the user. The public key can be posted on the user’s Web site or placed in a public key server. The private key is protected by the use of a password. The password has to be entered every time the user accesses the private key. PGP gives the user the option of digitally signing the message, encrypting the message, or both digitally signing and encrypting. Figure 8.22 shows a PGP signed message. This message appears after the MIME header. The encoded data in the message is </span><span class="font53" style="font-style:italic;">K</span><span class="font3" style="font-style:italic;">- </span><span class="font53" style="font-style:italic;">(H(m)),</span><span class="font53"> that is, the digitally signed message digest. As we discussed above, in order for Bob to verify the integrity of the message, he needs to have access to Alice’s public key.</span></p>
<p><span class="font36">-----BEGIN PGP SIGNED MESSAGE-----</span></p>
<p><span class="font36">Hash: &nbsp;SHA1</span></p>
<p><span class="font36">Bob:</span></p>
<p><span class="font36">Can I see you tonight?</span></p>
<p><span class="font36">Passionately yours, Alice</span></p>
<p><span class="font36">-----BEGIN PGP SIGNATURE-----</span></p>
<p><span class="font36">Version: PGP for Personal Privacy 5.0</span></p>
<p><span class="font36">Charset: noconv</span></p>
<p><span class="font36">yhHJRHhGJGhgg/12EpJ+lo8gE4vB3mqJhFEvZP9t6n7G6m5Gw2 -----END PGP SIGNATURE-----</span></p>
<p><a name="bookmark459"></a><span class="font7" style="font-weight:bold;">Figure 8.22 </span><span class="font50">♦ </span><span class="font5">A PGP signed message</span></p>
<p><span class="font36">-----BEGIN PGP MESSAGE-----</span></p>
<p><span class="font36">Version: PGP for Personal Privacy 5.0</span></p>
<p><span class="font36">u2R4d+/jKmn8Bc5+hgDsqAewsDfrGdszX68liKm5F6Gc4sDfcXyt RfdS10juHgbcfDssWe7/K=lKhnMikLo0+1/BvcX4t==Ujk9PbcD4 Thdf2awQfgHbnmKlok8iy6gThlp -----END PGP MESSAGE</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 8.23 </span><span class="font50">♦ </span><span class="font5">A secret PGP message</span></p>
<p><span class="font53">Figure 8.23 shows a secret PGP message. This message also appears after the MIME header. Of course, the plaintext message is not included within the secret e-mail message. When a sender (such as Alice) wants both confidentiality and integrity, PGP contains a message like that of Figure 8.23 within the message of Figure 8.22.</span></p>
<p><span class="font53">PGP also provides a mechanism for public key certification, but the mechanism is quite different from the more conventional CA. PGP public keys are certified by a </span><span class="font53" style="font-style:italic;">web of trust.</span><span class="font53"> Alice herself can certify any key/username pair when she believes the pair really belong together. In addition, PGP permits Alice to say that she trusts another user to vouch for the authenticity of more keys. Some PGP users sign each other’s keys by holding key-signing parties. Users physically gather, exchange public keys, and certify each other’s keys by signing them with their private keys.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">8.6 </span><span class="font24" style="font-weight:bold;">Securing TCP Connections: TLS</span></p></li></ul>
<p><span class="font53">In the previous section, we saw how cryptographic techniques can provide confidentiality, data integrity, and end-point authentication to a specific application, namely, e-mail. In this section, we’ll drop down a layer in the protocol stack and examine how cryptography can enhance TCP with security services, including confidentiality, data integrity, and end-point authentication. This enhanced version of TCP is commonly known as </span><span class="font53" style="font-weight:bold;">Transport Layer Security (TLS)</span><span class="font53">, which has been standardized by the IETF [RFC 4346]. An earlier and similar version of this protocol is SSL version 3.</span></p>
<p><a name="bookmark460"></a><span class="font53">The SSL protocol was originally designed by Netscape, but the basic ideas behind securing TCP had predated Netscape’s work (for example, see Woo [Woo 1994]). Since its inception, SSL and its successor TLS have enjoyed broad deployment. TLS is supported by all popular Web browsers and Web servers, and it is used by Gmail and essentially all Internet commerce sites (including Amazon, eBay, and TaoBao). Hundreds of billions of dollars are spent over TLS every year. In fact, if you have ever purchased anything over the Internet with your credit card, the communication between your browser and the server for this purchase almost certainly went over TLS. (You can identify that TLS is being used by your browser when the URL begins with https: rather than http.)</span></p>
<p><span class="font53">To understand the need for TLS, let’s walk through a typical Internet commerce scenario. Bob is surfing the Web and arrives at the Alice Incorporated site, which is selling perfume. The Alice Incorporated site displays a form in which Bob is supposed to enter the type of perfume and quantity desired, his address, and his payment card number. Bob enters this information, clicks on Submit, and expects to receive (via ordinary postal mail) the purchased perfumes; he also expects to receive a charge for his order in his next payment card statement. This all sounds good, but if no security measures are taken, Bob could be in for a few surprises.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;If no confidentiality (encryption) is used, an intruder could intercept Bob’s order and obtain his payment card information. The intruder could then make purchases at Bob’s expense.</span></p></li>
<li>
<p><span class="font53">• &nbsp;If no data integrity is used, an intruder could modify Bob’s order, having him purchase ten times more bottles of perfume than desired.</span></p></li>
<li>
<p><span class="font53">• &nbsp;Finally, if no server authentication is used, a server could display Alice Incorporated’s famous logo when in actuality the site maintained by Trudy, who is masquerading as Alice Incorporated. After receiving Bob’s order, Trudy could take Bob’s money and run. Or Trudy could carry out an identity theft by collecting Bob’s name, address, and credit card number.</span></p></li></ul>
<p><span class="font53">TLS addresses these issues by enhancing TCP with confidentiality, data integrity, server authentication, and client authentication.</span></p>
<p><span class="font53">TLS is often used to provide security to transactions that take place over HTTP. However, because TLS secures TCP, it can be employed by any application that runs over TCP. TLS provides a simple Application Programmer Interface (API) with sockets, which is similar and analogous to TCP’s API. When an application wants to employ TLS, the application includes SSL classes/libraries. As shown in Figure 8.24, although TLS technically resides in the application layer, from the developer’s perspective it is a transport protocol that provides TCP’s services enhanced with security services.</span></p>
<div>
<p><span class="font4">I Application</span></p>
<p><span class="font4">TCP socket</span></p>
</div><br clear="all">
<div>
<p><span class="font4">TCP</span></p>
<p><span class="font4">IP</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">TCP API</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-591.jpg" alt="" style="width:107pt;height:101pt;">
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 8.24 </span><span class="font50">♦ </span><span class="font5">Although TLS technically resides in the application layer, from the developer's perspective it is a transport-layer protocol</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">8.6.1 </span><span class="font23" style="font-weight:bold;">The Big Picture</span></p></li></ul>
<p><span class="font53">We begin by describing a simplified version of TLS, one that will allow us to get a big-picture understanding of the </span><span class="font53" style="font-style:italic;">why</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">how</span><span class="font53"> of TLS. We will refer to this simplified version of TLS as “almost-TLS.” After describing almost-TLS, in the next subsection we’ll then describe the real TLS, filling in the details. Almost-TLS (and TLS) has three phases: </span><span class="font53" style="font-style:italic;">handshake, key derivation,</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">data transfer.</span><span class="font53"> We now describe these three phases for a communication session between a client (Bob) and a server (Alice), with Alice having a private/public key pair and a certificate that binds her identity to her public key.</span></p>
<p><span class="font22" style="font-weight:bold;">Handshake</span></p>
<p><span class="font53">During the handshake phase, Bob needs to (a) establish a TCP connection with Alice, (b) verify that Alice is </span><span class="font53" style="font-style:italic;">really</span><span class="font53"> Alice, and (c) send Alice a master secret key, which will be used by both Alice and Bob to generate all the symmetric keys they need for the TLS session. These three steps are shown in Figure 8.25. Note that once the TCP connection is established, Bob sends Alice a hello message. Alice then responds with her certificate, which contains her public key. As discussed in Section 8.3, because the certificate has been certified by a CA, Bob knows for sure that the public key in the certificate belongs to Alice. Bob then generates a Master Secret (MS) (which will only be used for this TLS session), encrypts the MS with Alice’s public key to create</span></p><img src="networking_files/networking-592.jpg" alt="" style="width:310pt;height:198pt;">
<p><a name="bookmark461"></a><span class="font7" style="font-weight:bold;">Figure 8.25 </span><span class="font50">♦ </span><span class="font5">The almost-TLS handshake, beginning with a TCP connection</span></p>
<p><span class="font53">the Encrypted Master Secret (EMS), and sends the EMS to Alice. Alice decrypts the EMS with her private key to get the MS. After this phase, both Bob and Alice (and no one else) know the master secret for this TLS session.</span></p>
<p><span class="font22" style="font-weight:bold;">Key Derivation</span></p>
<p><span class="font53">In principle, the MS, now shared by Bob and Alice, could be used as the symmetric session key for all subsequent encryption and data integrity checking. It is, however, generally considered safer for Alice and Bob to each use different cryptographic keys, and also to use different keys for encryption and integrity checking. Thus, both Alice and Bob use the MS to generate four keys:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;E</span><span class="font50">B </span><span class="font54">= </span><span class="font53">session encryption key for data sent from Bob to Alice</span></p></li>
<li>
<p><span class="font53">• M</span><span class="font50">B </span><span class="font54">= </span><span class="font53">session HMAC key for data sent from Bob to Alice, where HMAC [RFC 2104] is a standardized hashed message authentication code (MAC) that we encountered in section 8.3.2</span></p></li>
<li>
<p><span class="font53">• &nbsp;E<sub>A</sub> </span><span class="font54">= </span><span class="font53">session encryption key for data sent from Alice to Bob</span></p></li>
<li>
<p><span class="font53">• &nbsp;M</span><span class="font38" style="font-variant:small-caps;"><sub>a</sub></span><span class="font54"> = </span><span class="font53">session HMAC key for data sent from Alice to Bob</span></p></li></ul>
<p><span class="font53">Alice and Bob each generate the four keys from the MS. This could be done by simply slicing the MS into four keys. (But in </span><span class="font53" style="font-style:italic;">reality</span><span class="font53"> TLS it is a little more complicated, as we’ll see.) At the end of the key derivation phase, both Alice and Bob have all four keys. The two encryption keys will be used to encrypt data; the two HMAC keys will be used to verify the integrity of the data.</span></p>
<p><span class="font22" style="font-weight:bold;">Data Transfer</span></p>
<p><span class="font53">Now that Alice and Bob share the same four session keys (E</span><span class="font50">B</span><span class="font53">, M</span><span class="font50">B</span><span class="font53">, E<sub>A</sub>, and M<sub>A</sub>), they can start to send secured data to each other over the TCP connection. Since TCP is a byte-stream protocol, a natural approach would be for TLS to encrypt application data on the fly and then pass the encrypted data on the fly to TCP. But if we were to do this, where would we put the HMAC for the integrity check? We certainly do not want to wait until the end of the TCP session to verify the integrity of all of Bob’s data that was sent over the entire session! To address this issue, TLS breaks the data stream into records, appends an HMAC to each record for integrity checking, and then encrypts the record</span><span class="font55">+</span><span class="font53">HMAC. To create the HMAC, Bob inputs the record data along with the key M</span><span class="font50">B </span><span class="font53">into a hash function, as discussed in Section 8.3. To encrypt the package record</span><span class="font55">+</span><span class="font53">HMAC, Bob uses his session encryption key E</span><span class="font50">B</span><span class="font53">. This encrypted package is then passed to TCP for transport over the Internet.</span></p>
<p><span class="font53">Although this approach goes a long way, it still isn’t bullet-proof when it comes to providing data integrity for the entire message stream. In particular, suppose Trudy is a woman-in-the-middle and has the ability to insert, delete, and replace segments in the stream of TCP segments sent between Alice and Bob. Trudy, for example, could capture two segments sent by Bob, reverse the order of the segments, adjust the TCP sequence numbers (which are not encrypted), and then send the two reverse-ordered segments to Alice. Assuming that each TCP segment encapsulates exactly one record, let’s now take a look at how Alice would process these segments.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">1. TCP running in Alice would think everything is fine and pass the two records to the TLS sublayer.</span></p></li>
<li>
<p><span class="font53">2. TLS in Alice would decrypt the two records.</span></p></li>
<li>
<p><span class="font53">3. TLS in Alice would use the HMAC in each record to verify the data integrity of the two records.</span></p></li>
<li>
<p><span class="font53">4. TLS would then pass the decrypted byte streams of the two records to the application layer; but the complete byte stream received by Alice would not be in the correct order due to reversal of the records!</span></p></li></ul>
<p><span class="font53">You are encouraged to walk through similar scenarios for when Trudy removes segments or when Trudy replays segments.</span></p>
<p><span class="font53">The solution to this problem, as you probably guessed, is to use sequence numbers. TLS does this as follows. Bob maintains a sequence number counter, which begins at zero and is incremented for each TLS record he sends. Bob doesn’t actually include a sequence number in the record itself, but when he calculates the HMAC, he includes the sequence number in the HMAC calculation. Thus, the HMAC is now a hash of the data plus the HMAC key M<sub>B</sub> </span><span class="font53" style="font-style:italic;">plus the current sequence number.</span><span class="font53"> Alice tracks Bob’s sequence numbers, allowing her to verify the data integrity of a record by including the appropriate sequence number in the HMAC calculation. This use of TLS sequence numbers prevents Trudy from carrying out a woman-in-the-middle attack, such as reordering or replaying segments. (Why?)</span></p>
<p><span class="font22" style="font-weight:bold;">TLS Record</span></p>
<p><span class="font53">The TLS record (as well as the almost-TLS record) is shown in Figure 8.26. The record consists of a type field, version field, length field, data field, and HMAC field. Note that the first three fields are not encrypted. The type field indicates whether the record is a handshake message or a message that contains application data. It is also used to close the TLS connection, as discussed below. TLS at the receiving end uses the length field to extract the TLS records out of the incoming TCP byte stream. The version field is self-explanatory.</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font4">Type</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Version</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Length</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">Data</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">HMAC</span></p></td></tr>
<tr><td colspan="5"></td></tr>
</table>
<p><span class="font4">Encrypted with </span><span class="font4" style="font-style:italic;">E<sub>B</sub></span></p>
<p><span class="font7" style="font-weight:bold;">Figure 8.26 </span><span class="font50">♦ </span><span class="font5">Record format for TLS</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">8.6.2 </span><span class="font23" style="font-weight:bold;">A More Complete Picture</span></p></li></ul>
<p><span class="font53">The previous subsection covered the almost-TLS protocol; it served to give us a basic understanding of the why and how of TLS. Now that we have a basic understanding, we can dig a little deeper and examine the essentials of the actual TLS protocol. In parallel to reading this description of the TLS protocol, you are encouraged to complete the Wireshark TLS lab, available at the textbook’s Web site.</span></p>
<p><span class="font22" style="font-weight:bold;">TLS Handshake</span></p>
<p><span class="font53">SSL does not mandate that Alice and Bob use a specific symmetric key algorithm or a specific public-key algorithm. Instead, TLS allows Alice and Bob to agree on the cryptographic algorithms at the beginning of the TLS session, during the handshake phase. Additionally, during the handshake phase, Alice and Bob send nonces to each other, which are used in the creation of the session keys (E<sub>B</sub>, M<sub>B</sub>, E<sub>A</sub>, and M<sub>A</sub>). The steps of the real TLS handshake are as follows:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">1. The client sends a list of cryptographic algorithms it supports, along with a client nonce.</span></p></li>
<li>
<p><span class="font53">2. From the list, the server chooses a symmetric algorithm (for example, AES) and a public key algorithm (for example, RSA with a specific key length), and HMAC algorithm (MD5 or SHA-1) along with the HMAC keys. It sends back to the client its choices, as well as a certificate and a server nonce.</span></p></li>
<li>
<p><span class="font53">3. &nbsp;The client verifies the certificate, extracts the server’s public key, generates a Pre-Master Secret (PMS), encrypts the PMS with the server’s public key, and sends the encrypted PMS to the server.</span></p></li>
<li>
<p><span class="font53">4. Using the same key derivation function (as specified by the TLS standard), the client and server independently compute the Master Secret (MS) from the PMS and nonces. The MS is then sliced up to generate the two encryption and two HMAC keys. Furthermore, when the chosen symmetric cipher employs CBC (such as 3DES or AES), then two Initialization Vectors (IVs)—one for each side of the connection—are also obtained from the MS. Henceforth, all messages sent between client and server are encrypted and authenticated (with the HMAC).</span></p></li>
<li>
<p><span class="font53">5. The client sends the HMAC of all the handshake messages.</span></p></li>
<li>
<p><span class="font53">6. The server sends the HMAC of all the handshake messages.</span></p></li></ul>
<p><a name="bookmark462"></a><span class="font53">The last two steps protect the handshake from tampering. To see this, observe that in step 1, the client typically offers a list of algorithms—some strong, some weak. This list of algorithms is sent in cleartext, since the encryption algorithms and keys have not yet been agreed upon. Trudy, as a woman-in-the-middle, could delete the stronger algorithms from the list, forcing the client to select a weak algorithm. To prevent such a tampering attack, in step 5, the client sends the HMAC of the concatenation of all the handshake messages it sent and received. The server can compare this HMAC with the HMAC of the handshake messages it received and sent. If there is an inconsistency, the server can terminate the connection. Similarly, the server sends the HMAC of the handshake messages it has seen, allowing the client to check for inconsistencies.</span></p>
<p><span class="font53">You may be wondering why there are nonces in steps 1 and 2. Don’t sequence numbers suffice for preventing the segment replay attack? The answer is yes, but they don’t alone prevent the “connection replay attack.” Consider the following connection replay attack. Suppose Trudy sniffs all messages between Alice and Bob. The next day, Trudy masquerades as Bob and sends to Alice exactly the same sequence of messages that Bob sent to Alice on the previous day. If Alice doesn’t use nonces, she will respond with exactly the same sequence of messages she sent the previous day. Alice will not suspect any funny business, as each message she receives will pass the integrity check. If Alice is an e-commerce server, she will think that Bob is placing a second order (for exactly the same thing). On the other hand, by including a nonce in the protocol, Alice will send different nonces for each TCP session, causing the encryption keys to be different on the two days. Therefore, when Alice receives played-back TLS records from Trudy, the records will fail the integrity checks, and the bogus e-commerce transaction will not succeed. In summary, in TLS, nonces are used to defend against the “connection replay attack” and sequence numbers are used to defend against replaying individual packets during an ongoing session.</span></p>
<p><span class="font22" style="font-weight:bold;">Connection Closure</span></p>
<p><span class="font53">At some point, either Bob or Alice will want to end the TLS session. One approach would be to let Bob end the TLS session by simply terminating the underlying TCP connection—that is, by having Bob send a TCP FIN segment to Alice. But such a naive design sets the stage for the </span><span class="font53" style="font-style:italic;">truncation attack</span><span class="font53"> whereby Trudy once again gets in the middle of an ongoing TLS session and ends the session early with a TCP FIN. If Trudy were to do this, Alice would think she received all of Bob’s data when actuality she only received a portion of it. The solution to this problem is to indicate in the type field whether the record serves to terminate the TLS session. (Although the TLS type is sent in the clear, it is authenticated at the receiver using the record’s HMAC.) By including such a field, if Alice were to receive a TCP FIN before receiving a closure TLS record, she would know that something funny was going on.</span></p>
<p><span class="font53">This completes our introduction to TLS. We’ve seen that it uses many of the cryptography principles discussed in Sections 8.2 and 8.3. Readers who want to explore TLS on yet a deeper level can read Rescorla’s highly readable book on SSL/ TLS [Rescorla 2001].</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">8.7 </span><span class="font24" style="font-weight:bold;">Network-Layer Security: IPsec and Virtual Private Networks</span></p></li></ul>
<p><span class="font53">The IP security protocol, more commonly known as </span><span class="font53" style="font-weight:bold;">IPsec</span><span class="font53">, provides security at the network layer. IPsec secures IP datagrams between any two network-layer entities, including hosts and routers. As we will soon describe, many institutions (corporations, government branches, non-profit organizations, and so on) use IPsec to create </span><span class="font53" style="font-weight:bold;">virtual private networks (VPNs) </span><span class="font53">that run over the public Internet.</span></p>
<p><span class="font53">Before getting into the specifics of IPsec, let’s step back and consider what it means to provide confidentiality at the network layer. With network-layer confidentiality between a pair of network entities (for example, between two routers, between two hosts, or between a router and a host), the sending entity encrypts the payloads of all the datagrams it sends to the receiving entity. The encrypted payload could be a TCP segment, a UDP segment, an ICMP message, and so on. If such a network-layer service were in place, all data sent from one entity to the other— including e-mail, Web pages, TCP handshake messages, and management messages (such as ICMP and SNMP)—would be hidden from any third party that might be sniffing the network. For this reason, network-layer security is said to provide “blanket coverage.”</span></p>
<p><span class="font53">In addition to confidentiality, a network-layer security protocol could potentially provide other security services. For example, it could provide source authentication, so that the receiving entity can verify the source of the secured datagram. A networklayer security protocol could provide data integrity, so that the receiving entity can check for any tampering of the datagram that may have occurred while the datagram was in transit. A network-layer security service could also provide replay-attack prevention, meaning that Bob could detect any duplicate datagrams that an attacker might insert. We will soon see that IPsec indeed provides mechanisms for all these security services, that is, for confidentiality, source authentication, data integrity, and replay-attack prevention.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">8.7.1 </span><span class="font23" style="font-weight:bold;">IPsec and Virtual Private Networks (VPNs)</span></p></li></ul>
<p><span class="font53">An institution that extends over multiple geographical regions often desires its own IP network, so that its hosts and servers can send data to each other in a secure and confidential manner. To achieve this goal, the institution could actually deploy a stand-alone physical network—including routers, links, and a DNS infrastructure— that is completely separate from the public Internet. Such a disjoint network, dedicated to a particular institution, is called a </span><span class="font53" style="font-weight:bold;">private network</span><span class="font53">. Not surprisingly, a private network can be very costly, as the institution needs to purchase, install, and maintain its own physical network infrastructure.</span></p>
<p><a name="bookmark463"></a><span class="font53">Instead of deploying and maintaining a private network, many institutions today create VPNs over the existing public Internet. With a VPN, the institution’s inter-office traffic is sent over the public Internet rather than over a physically</span></p>
<div>
<p><span class="font4">IP &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;IPsec &nbsp;&nbsp;&nbsp;&nbsp;Secure</span></p>
<p><span class="font4">header header &nbsp;&nbsp;payload</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Public Internet</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-593.jpg" alt="" style="width:22pt;height:22pt;">
</div><br clear="all">
<div>
<p><span class="font4">Laptop w/IPsec</span></p><img src="networking_files/networking-594.jpg" alt="" style="width:34pt;height:37pt;">
<p><span class="font4" style="font-weight:bold;">Salesperson in Hotel</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-595.jpg" alt="" style="width:352pt;height:79pt;">
</div><br clear="all">
<div><img src="networking_files/networking-596.jpg" alt="" style="width:351pt;height:92pt;">
<p><span class="font7" style="font-weight:bold;">Figure 8.27 </span><span class="font50">♦ </span><span class="font5">Virtual private network (VPN)</span></p>
</div><br clear="all">
<p><span class="font53">independent network. But to provide confidentiality, the inter-office traffic is encrypted before it enters the public Internet. A simple example of a VPN is shown in Figure 8.27. Here the institution consists of a headquarters, a branch office, and traveling salespersons that typically access the Internet from their hotel rooms. (There is only one salesperson shown in the figure.) In this VPN, whenever two hosts within headquarters send IP datagrams to each other or whenever two hosts within the branch office want to communicate, they use good-old vanilla IPv4 (that is, without IPsec services). However, when two of the institution’s hosts communicate over a path that traverses the public Internet, the traffic is encrypted before it enters the Internet.</span></p>
<p><span class="font53">To get a feel for how a VPN works, let’s walk through a simple example in the context of Figure 8.27. When a host in headquarters sends an IP datagram to a salesperson in a hotel, the gateway router in headquarters converts the vanilla IPv4 datagram into an IPsec datagram and then forwards this IPsec datagram into the Internet. This IPsec datagram actually has a traditional IPv4 header, so that the routers in the public Internet process the datagram as if it were an ordinary IPv4 datagram—to them, the datagram is a perfectly ordinary datagram. But, as shown Figure 8.27, the payload of the IPsec datagram includes an IPsec header, which is used for IPsec processing; furthermore, the payload of the IPsec datagram is encrypted. When the IPsec datagram arrives at the salesperson’s laptop, the OS in the laptop decrypts the payload (and provides other security services, such as verifying data integrity) and passes the unencrypted payload to the upper-layer protocol (for example, to TCP or UDP).</span></p>
<p><span class="font53">We have just given a high-level overview of how an institution can employ IPsec to create a VPN. To see the forest through the trees, we have brushed aside many important details. Let’s now take a closer look.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">8.7.2 </span><span class="font23" style="font-weight:bold;">The AH and ESP Protocols</span></p></li></ul>
<p><span class="font53">IPsec is a rather complex animal—it is defined in more than a dozen RFCs. Two important RFCs are RFC 4301, which describes the overall IP security architecture, and RFC 6071, which provides an overview of the IPsec protocol suite. Our goal in this textbook, as usual, is not simply to re-hash the dry and arcane RFCs, but instead take a more operational and pedagogic approach to describing the protocols.</span></p>
<p><span class="font53">In the IPsec protocol suite, there are two principal protocols: the </span><span class="font53" style="font-weight:bold;">Authentication Header (AH) </span><span class="font53">protocol and the </span><span class="font53" style="font-weight:bold;">Encapsulation Security Payload (ESP) </span><span class="font53">protocol. When a source IPsec entity (typically a host or a router) sends secure datagrams to a destination entity (also a host or a router), it does so with either the AH protocol or the ESP protocol. The AH protocol provides source authentication and data integrity but </span><span class="font53" style="font-style:italic;">does not</span><span class="font53"> provide confidentiality. The ESP protocol provides source authentication, data integrity, </span><span class="font53" style="font-style:italic;">and</span><span class="font53"> confidentiality. Because confidentiality is often critical for VPNs and other IPsec applications, the ESP protocol is much more widely used than the AH protocol. In order to de-mystify IPsec and avoid much of its complication, we will henceforth focus exclusively on the ESP protocol. Readers wanting to learn also about the AH protocol are encouraged to explore the RFCs and other online resources.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">8.7.3 </span><span class="font23" style="font-weight:bold;">Security Associations</span></p></li></ul>
<p><span class="font53">IPsec datagrams are sent between pairs of network entities, such as between two hosts, between two routers, or between a host and router. Before sending IPsec datagrams from source entity to destination entity, the source and destination entities create a network-layer logical connection. This logical connection is called a </span><span class="font53" style="font-weight:bold;">security association (SA)</span><span class="font53">. An SA is a simplex logical connection; that is, it is unidirectional from source to destination. If both entities want to send secure datagrams to each other, then two SAs (that is, two logical connections) need to be established, one in each direction.</span></p>
<p><a name="bookmark464"></a><span class="font53">For example, consider once again the institutional VPN in Figure 8.27. This institution consists of a headquarters office, a branch office and, say, </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> traveling salespersons. For the sake of example, let’s suppose that there is bi-directional IPsec traffic between headquarters and the branch office and bi-directional IPsec traffic between headquarters and the salespersons. In this VPN, how many SAs are there? To answer this question, note that there are two SAs between the headquarters gateway router and the branch-office gateway router (one in each direction); for each</span></p>
<div>
<p><span class="font4">Headquarters</span></p><img src="networking_files/networking-597.jpg" alt="" style="width:110pt;height:41pt;">
<p><span class="font4">172.16.1/24</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 8.28 </span><span class="font50">♦ </span><span class="font5">Security association (SA) from R1 to R2</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Internet</span></p>
<p><span class="font4" style="font-weight:bold;">SA</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Branch Office</span></p><img src="networking_files/networking-598.jpg" alt="" style="width:113pt;height:44pt;">
<p><span class="font4">172.16.2/24</span></p>
</div><br clear="all">
<p><span class="font53">salesperson’s laptop, there are two SAs between the headquarters gateway router and the laptop (again, one in each direction). So, in total, there are (2 </span><span class="font55">+ </span><span class="font53" style="font-style:italic;">2n)</span><span class="font53"> SAs. </span><span class="font53" style="font-style:italic;">Keep in mind, however, that not all traffic sent into the Internet by the gateway routers or by the laptops will be IPsec secured.</span><span class="font53"> For example, a host in headquarters may want to access a Web server (such as Amazon or Google) in the public Internet. Thus, the gateway router (and the laptops) will emit into the Internet both vanilla IPv4 datagrams and secured IPsec datagrams.</span></p>
<p><span class="font53">Let’s now take a look “inside” an SA. To make the discussion tangible and concrete, let’s do this in the context of an SA from router R1 to router R2 in Figure 8.28. (You can think of Router R1 as the headquarters gateway router and Router R2 as the branch office gateway router from Figure 8.27.) Router R1 will maintain state information about this SA, which will include:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;A 32-bit identifier for the SA, called the </span><span class="font53" style="font-weight:bold;">Security Parameter Index (SPI)</span></p></li>
<li>
<p><span class="font53">• &nbsp;The origin interface of the SA (in this case 200.168.1.100) and the destination interface of the SA (in this case 193.68.2.23)</span></p></li>
<li>
<p><span class="font53">• &nbsp;The type of encryption to be used (for example, 3DES with CBC)</span></p></li>
<li>
<p><span class="font53">• &nbsp;The encryption key</span></p></li>
<li>
<p><span class="font53">• &nbsp;The type of integrity check (for example, HMAC with MD5)</span></p></li>
<li>
<p><span class="font53">• &nbsp;The authentication key</span></p></li></ul>
<p><span class="font53">Whenever router R1 needs to construct an IPsec datagram for forwarding over this SA, it accesses this state information to determine how it should authenticate and encrypt the datagram. Similarly, router R2 will maintain the same state information for this SA and will use this information to authenticate and decrypt any IPsec datagram that arrives from the SA.</span></p>
<p><span class="font53">An IPsec entity (router or host) often maintains state information for many SAs. For example, in the VPN example in Figure 8.27 with </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> salespersons, the headquarters gateway router maintains state information for (2 </span><span class="font55">+ </span><span class="font53">2</span><span class="font53" style="font-style:italic;">n</span><span class="font53">) SAs. An IPsec entity stores the state information for all of its SAs in its </span><span class="font53" style="font-weight:bold;">Security Association Database </span><span class="font53">(</span><span class="font53" style="font-weight:bold;">SAD</span><span class="font53">), which is a data structure in the entity’s OS kernel.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">8.7.4 </span><span class="font23" style="font-weight:bold;">The IPsec Datagram</span></p></li></ul>
<p><span class="font53">Having now described SAs, we can now describe the actual IPsec datagram. IPsec has two different packet forms, one for the so-called </span><span class="font53" style="font-weight:bold;">tunnel mode </span><span class="font53">and the other for the so-called </span><span class="font53" style="font-weight:bold;">transport mode</span><span class="font53">. The tunnel mode, being more appropriate for VPNs, is more widely deployed than the transport mode. In order to further de-mystify IPsec and avoid much of its complication, we henceforth focus exclusively on the tunnel mode. Once you have a solid grip on the tunnel mode, you should be able to easily learn about the transport mode on your own.</span></p>
<p><span class="font53">The packet format of the IPsec datagram is shown in Figure 8.29. You might think that packet formats are boring and insipid, but we will soon see that the IPsec datagram actually looks and tastes like a popular Tex-Mex delicacy! Let’s examine the IPsec fields in the context of Figure 8.28. Suppose router R1 receives an ordinary IPv4 datagram from host 172.16.1.17 (in the headquarters network) which is destined to host 172.16.2.48 (in the branch-office network). Router R1 uses the following recipe to convert this “original IPv4 datagram” into an IPsec datagram:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;Appends to the back of the original IPv4 datagram (which includes the original header fields!) an “ESP trailer” field</span></p></li>
<li>
<p><span class="font53">• &nbsp;Encrypts the result using the algorithm and key specified by the SA</span></p></li>
<li>
<p><span class="font53">• &nbsp;Appends to the front of this encrypted quantity a field called “ESP header”; the resulting package is called the “enchilada”</span></p></li>
<li>
<p><span class="font53">• &nbsp;Creates an authentication MAC over the </span><span class="font53" style="font-style:italic;">whole enchilada</span><span class="font53"> using the algorithm and key specified in the SA</span></p></li>
<li>
<p><span class="font53">• &nbsp;Appends the MAC to the back of the enchilada forming the </span><span class="font53" style="font-style:italic;">payload</span></p></li>
<li>
<p><span class="font53">• &nbsp;Finally, creates a brand new IP header with all the classic IPv4 header fields (together normally 20 bytes long), which it appends before the payload</span></p></li></ul>
<p><span class="font53">Note that the resulting IPsec datagram is a bona fide IPv4 datagram, with the traditional IPv4 header fields followed by a payload. But in this case, the payload</span></p>
<p><span class="font4">“Enchilada” authenticated</span></p><img src="networking_files/networking-599.jpg" alt="" style="width:336pt;height:110pt;">
<p><a name="bookmark465"></a><span class="font7" style="font-weight:bold;">Figure 8.29 </span><span class="font50">♦ </span><span class="font5">IPsec datagram format</span></p>
<p><span class="font53">contains an ESP header, the original IP datagram, an ESP trailer, and an ESP authentication field (with the original datagram and ESP trailer encrypted). The original IP datagram has 172.16.1.17 for the source IP address and 172.16.2.48 for the destination IP address. Because the IPsec datagram includes the original IP datagram, these addresses are included (and encrypted) as part of the payload of the IPsec packet. But what about the source and destination IP addresses that are in the new IP header, that is, in the left-most header of the IPsec datagram? As you might expect, they are set to the source and destination router interfaces at the two ends of the tunnels, namely, 200.168.1.100 and 193.68.2.23. Also, the protocol number in this new IPv4 header field is not set to that of TCP, UDP, or SMTP, but instead to 50, designating that this is an IPsec datagram using the ESP protocol.</span></p>
<p><span class="font53">After R1 sends the IPsec datagram into the public Internet, it will pass through many routers before reaching R2. Each of these routers will process the datagram as if it were an ordinary datagram—they are completely oblivious to the fact that the datagram is carrying IPsec-encrypted data. For these public Internet routers, because the destination IP address in the outer header is R2, the ultimate destination of the datagram is R2.</span></p>
<p><span class="font53">Having walked through an example of how an IPsec datagram is constructed, let’s now take a closer look at the ingredients in the enchilada. We see in Figure 8.29 that the ESP trailer consists of three fields: padding; pad length; and next header. Recall that block ciphers require the message to be encrypted to be an integer multiple of the block length. Padding (consisting of meaningless bytes) is used so that when added to the original datagram (along with the pad length and next header fields), the resulting “message” is an integer number of blocks. The pad-length field indicates to the receiving entity how much padding was inserted (and thus needs to be removed). The next header identifies the type (e.g., UDP) of data contained in the payload-data field. The payload data (typically the original IP datagram) and the ESP trailer are concatenated and then encrypted.</span></p>
<p><span class="font53">Appended to the front of this encrypted unit is the ESP header, which is sent in the clear and consists of two fields: the SPI and the sequence number field. The SPI indicates to the receiving entity the SA to which the datagram belongs; the receiving entity can then index its SAD with the SPI to determine the appropriate authentica-tion/decryption algorithms and keys. The sequence number field is used to defend against replay attacks.</span></p>
<p><span class="font53">The sending entity also appends an authentication MAC. As stated earlier, the sending entity calculates a MAC over the whole enchilada (consisting of the ESP header, the original IP datagram, and the ESP trailer—with the datagram and trailer being encrypted). Recall that to calculate a MAC, the sender appends a secret MAC key to the enchilada and then calculates a fixed-length hash of the result.</span></p>
<p><span class="font53">When R2 receives the IPsec datagram, R2 observes that the destination IP address of the datagram is R2 itself. R2 therefore processes the datagram. Because the protocol field (in the left-most IP header) is 50, R2 sees that it should apply IPsec ESP processing to the datagram. First, peering into the enchilada, R2 uses the SPI to determine to which SA the datagram belongs. Second, it calculates the MAC of the enchilada and verifies that the MAC is consistent with the value in the ESP MAC field. If it is, it knows that the enchilada comes from R1 and has not been tampered with. Third, it checks the sequence-number field to verify that the datagram is fresh (and not a replayed datagram). Fourth, it decrypts the encrypted unit using the decryption algorithm and key associated with the SA. Fifth, it removes padding and extracts the original, vanilla IP datagram. And finally, sixth, it forwards the original datagram into the branch office network toward its ultimate destination. Whew, what a complicated recipe, huh? Well no one ever said that preparing and unraveling an enchilada was easy!</span></p>
<p><span class="font53">There is actually another important subtlety that needs to be addressed. It centers on the following question: When R1 receives an (unsecured) datagram from a host in the headquarters network, and that datagram is destined to some destination IP address outside of headquarters, how does R1 know whether it should be converted to an IPsec datagram? And if it is to be processed by IPsec, how does R1 know which SA (of many SAs in its SAD) should be used to construct the IPsec datagram? The problem is solved as follows. Along with a SAD, the IPsec entity also maintains another data structure called the </span><span class="font53" style="font-weight:bold;">Security Policy Database (SPD)</span><span class="font53">. The SPD indicates what types of datagrams (as a function of source IP address, destination IP address, and protocol type) are to be IPsec processed; and for those that are to be IPsec processed, which SA should be used. In a sense, the information in a SPD indicates “what” to do with an arriving datagram; the information in the SAD indicates “how” to do it.</span></p>
<p><span class="font22" style="font-weight:bold;">Summary of IPsec Services</span></p>
<p><span class="font53">So what services does IPsec provide, exactly? Let us examine these services from the perspective of an attacker, say Trudy, who is a woman-in-the-middle, sitting somewhere on the path between R1 and R2 in Figure 8.28. Assume throughout this discussion that Trudy does not know the authentication and encryption keys used by the SA. What can and cannot Trudy do? First, Trudy cannot see the original datagram. If fact, not only is the data in the original datagram hidden from Trudy, but so is the protocol number, the source IP address, and the destination IP address. For datagrams sent over the SA, Trudy only knows that the datagram originated from 200.168.1.100 and is destined to 193.68.2.23. She does not know if it is carrying TCP, UDP, or ICMP data; she does not know if it is carrying HTTP, SMTP, or some other type of application data. This confidentiality thus goes a lot farther than SSL. Second, suppose Trudy tries to tamper with a datagram in the SA by flipping some of its bits. When this tampered datagram arrives at R2, it will fail the integrity check (using the MAC), thwarting Trudy’s vicious attempts once again. Third, suppose Trudy tries to masquerade as R1, creating a IPsec datagram with source 200.168.1.100 and destination 193.68.2.23. Trudy’s attack will be futile, as this datagram will again fail the integrity check at R2. Finally, because IPsec includes sequence numbers, Trudy will not be able create a successful replay attack. In summary, as claimed at the beginning of this section, IPsec provides—between any pair of devices that process packets through the network layer—confidentiality, source authentication, data integrity, and replay-attack prevention.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">8.7.5 </span><span class="font23" style="font-weight:bold;">IKE: Key Management in IPsec</span></p></li></ul>
<p><span class="font53">When a VPN has a small number of end points (for example, just two routers as in Figure 8.28), the network administrator can manually enter the SA information (encryption/authentication algorithms and keys, and the SPIs) into the SADs of the endpoints. Such “manual keying” is clearly impractical for a large VPN, which may consist of hundreds or even thousands of IPsec routers and hosts. Large, geographically distributed deployments require an automated mechanism for creating the SAs. IPsec does this with the Internet Key Exchange (IKE) protocol, specified in RFC 5996.</span></p>
<p><span class="font53">IKE has some similarities with the handshake in SSL (see Section 8.6). Each IPsec entity has a certificate, which includes the entity’s public key. As with SSL, the IKE protocol has the two entities exchange certificates, negotiate authentication and encryption algorithms, and securely exchange key material for creating session keys in the IPsec SAs. Unlike SSL, IKE employs two phases to carry out these tasks.</span></p>
<p><span class="font53">Let’s investigate these two phases in the context of two routers, R1 and R2, in Figure 8.28. The first phase consists of two exchanges of message pairs between R1 and R2:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;During the first exchange of messages, the two sides use Diffie-Hellman (see Homework Problems) to create a bi-directional </span><span class="font53" style="font-weight:bold;">IKE SA </span><span class="font53">between the routers. To keep us all confused, this bi-directional IKE SA is entirely different from the IPsec SAs discussed in Sections 8.6.3 and 8.6.4. The IKE SA provides an authenticated and encrypted channel between the two routers. During this first messagepair exchange, keys are established for encryption and authentication for the IKE SA. Also established is a master secret that will be used to compute IPSec SA keys later in phase 2. Observe that during this first step, RSA public and private keys are not used. In particular, neither R1 nor R2 reveals its identity by signing a message with its private key.</span></p></li>
<li>
<p><span class="font53">• &nbsp;During the second exchange of messages, both sides reveal their identity to each other by signing their messages. However, the identities are not revealed to a passive sniffer, since the messages are sent over the secured IKE SA channel. Also during this phase, the two sides negotiate the IPsec encryption and authentication algorithms to be employed by the IPsec SAs.</span></p></li></ul>
<p><a name="bookmark466"></a><span class="font53">In phase 2 of IKE, the two sides create an SA in each direction. At the end of phase 2, the encryption and authentication session keys are established on both sides for the two SAs. The two sides can then use the SAs to send secured datagrams, as described in Sections 8.7.3 and 8.7.4. The primary motivation for having two phases in IKE is computational cost—since the second phase doesn’t involve any publickey cryptography, IKE can generate a large number of SAs between the two IPsec entities with relatively little computational cost.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">8.8 </span><span class="font24" style="font-weight:bold;">Securing Wireless LANs and 4G/5G Cellular Networks</span></p></li></ul>
<p><span class="font53">Security is a particularly important concern in wireless networks, where the attacker can sniff frames by simply positioning a receiving device anywhere within the transmission range of the sender. This is true in both 802.11 wireless LANs, as well as in 4G/5G cellular networks. In both settings, we’ll see extensive use of the fundamental security techniques that we studied earlier in this chapter, including the use of nonces for authentication, cryptographic hashing for message integrity, derivation of shared symmetric keys for encrypting user-session data, and the extensive use of the AES encryption standard. We will also see, as is also the case in wired Internet settings, that wireless security protocols have undergone constant evolution, as researchers and hackers discover weaknesses and flaws in existing security protocols.</span></p>
<p><span class="font53">In this section, we present a brief introduction to wireless security in both 802.11(WiFi) and 4G/5G settings. For a more in-depth treatment, see the highly readable 802.11 security books [Edney 2003; Wright 2015], the excellent coverage of 3G/4G/5G security in [Sauter 2014], and recent surveys [Zou 2016; Kohlios 2018].</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">8.8.1 </span><span class="font23" style="font-weight:bold;">Authentication and Key Agreement in 802.11 Wireless LANs</span></p></li></ul>
<p><span class="font53">Let’s start our discussion of 802.11 security by identifying two (of many [Zou 2016]) critical security concerns that we’ll want an 802.11 network to handle:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Mutual authentication.</span><span class="font53"> Before a mobile device is allowed to fully attach to an access point and send datagrams to remote hosts, the network will typically want to first authenticate the device—to verify the identity of the mobile device attaching to the network, and to check that device’s access privileges. Similarly, the mobile device will want to authenticate the network to which it is attaching—to make sure that the network it is joining is truly the network to which it wants to attach. This two-way authentication is known as </span><span class="font53" style="font-weight:bold;">mutual authentication</span><span class="font53">.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Encryption.</span><span class="font53"> Since 802.11 frames will be exchanged over a wireless channel that can be sniffed and manipulated by potential ne’er do-wells, it will be important to encrypt link-level frames carrying user-level data exchanged between the mobile device and the access point (AP). Symmetric key encryption is used in practice, since encryption and decryption must be performed at high speeds. The mobile device and AP will need to derive the symmetric encryption and decryption keys to be used.</span></p></li></ul>
<p><a name="bookmark467"></a><span class="font53">Figure 8.30 illustrates the scenario of a mobile device wishing to attach to an 802.11 network. We see the two usual network components that we encountered</span></p>
<div>
<p><span class="font5">Mobile device</span></p><img src="networking_files/networking-600.jpg" alt="" style="width:38pt;height:42pt;">
</div><br clear="all">
<div>
<p><span class="font5">AP: access point</span></p><img src="networking_files/networking-601.jpg" alt="" style="width:59pt;height:27pt;">
</div><br clear="all">
<div>
<p><span class="font5">AS: authentication server</span></p>
<p><span class="font5">Wired network</span></p><img src="networking_files/networking-602.jpg" alt="" style="width:48pt;height:39pt;">
</div><br clear="all">
<div><img src="networking_files/networking-603.jpg" alt="" style="width:27pt;height:17pt;">
</div><br clear="all">
<div>
<p><span class="font4">Discovery of</span></p>
</div><br clear="all">
<div>
<p><span class="font4">security capabilities</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-604.jpg" alt="" style="width:24pt;height:14pt;">
</div><br clear="all">
<p><span class="font4">Mutual authentication and shared symmetric key derivation</span></p>
<p><span class="font4">I---------------------- (3.</span></p>
<p><span class="font4">Shared symmetric session key</span></p>
<div>
<p><span class="font4">distribution</span></p>
</div><br clear="all">
<p><span class="font4">&gt;■(4) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;------►</span></p>
<p><span class="font4">Encrypted communication between mobile device and a remote host via AP</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 8.30 </span><span class="font50">♦ </span><span class="font5">Mutual authentication and encryption-key derivation in WPA</span></p>
<p><span class="font53">in our earlier study of 802.11 networks in Section 7.3—the mobile device and the AP. We also see a new architectural component, the </span><span class="font53" style="font-weight:bold;">authentication server </span><span class="font53">(AS) that will be responsible for authenticating the mobile device. The authentication server might be co-located in the AP, but more typically and as shown in Figure 8.30, it is implemented as a separate server that provides authentication services. For authentication, the AP serves as a pass-through device, relaying authentication and key derivation messages between the mobile device and the authentication server. Such an authentication server would typically provide authentication services for all APs within its network.</span></p>
<p><span class="font53">We can identify four distinct phases to the process of mutual authentication and encryption-key derivation and use in Figure 8.30:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">1. </span><span class="font53" style="font-style:italic;">Discovery.</span><span class="font53"> In the discovery phase, the AP advertises its presence and the forms of authentication and encryption that can be provided to the mobile device. The mobile device then requests the specific forms of authentication and encryption that it desires. Although the device and AP are already exchanging messages, the device has not yet been authenticated nor does it have an encryption key for frame transmission over the wireless link, and so several more steps will be required before the device can communicate securely through the AP.</span></p></li>
<li>
<p><span class="font53">2. </span><span class="font53" style="font-style:italic;">Mutual authentication and shared symmetric key derivation.</span><span class="font53"> This is the most critical step in “securing” the 802.11 channel. As we will see, this step is greatly facilitated by assuming (which is true in practice in both 802.11 and 4G/5G networks) that the authentication server and the mobile device already have a </span><span class="font53" style="font-weight:bold;">shared common secret </span><span class="font53">before starting mutual authentication. In this step, the device and the authentication server will use this shared secret along with nonces (to prevent relay attacks) and cryptographic hashing (to ensure message integrity) in authenticating each other. They will also derive the shared session key to be used by the mobile device and the AP to encrypt frames transmitted over the 802.11 wireless link.</span></p></li>
<li>
<p><span class="font53">3. </span><span class="font53" style="font-style:italic;">Shared symmetric session key distribution.</span><span class="font53"> Since the symmetric encryption key is derived at the mobile device and the authentication server, a protocol will be needed for the authentication server to inform the AP of the shared symmetric session key. While this is rather straightforward, it still is a necessary step.</span></p></li>
<li>
<p><span class="font53">4. </span><span class="font53" style="font-style:italic;">Encrypted communication between mobile device and a remote host via the AP.</span><span class="font53"> This communication happens as we saw earlier in Section 7.3.2, with the link-layer frames sent between the mobile device and the AP being encrypted using the shared session key created and distributed by Steps 2 and 3. AES symmetric key cryptography, which we covered earlier in Section 8.2.1, is typically used in practice for encrypting/decrypting 802.11 frame data.</span></p></li></ul>
<p><span class="font22" style="font-weight:bold;">Mutual Authentication and Shared Symmetric Session Key Derivation</span></p>
<p><span class="font53">The topics of mutual authentication and shared symmetric session key derivation are the central components of 802.11 security. Since it is here that security flaws in various earlier versions of 802.11 security have been discovered, let’s tackle these challenges first.</span></p>
<p><span class="font53">The issue of 802.11security has attracted considerable attention in both technical circles and in the media. While there has been considerable discussion, there has been little debate—there is universal agreement that the original 802.11security specification known collectively as Wired Equivalent Privacy (WEP) contained a number of serious security flaws [Fluhrer 2001; Stubblefield 2002]. Once these flaws were discovered, public domain software was soon available exploiting these holes, making users of WEP-secured 802.11 WLANs as open to security attacks as users who used no security features at all. Readers interested in learning about WEP can consult the references, as well as earlier editions of this textbook, which covered WEP. As always, retired material from this book is available on the Companion Website.</span></p>
<p><span class="font53">WiFi Protected Access (WPA1) was developed in 2003 by the WiFi Alliance [WiFi 2020] to overcome WEP’s security flaws. The initial version of WPA1 improved on WEP by introducing message integrity checks, and avoiding attacks that allowed a user to infer encryption keys after observing the stream of encrypted messages for a period of time. WPA1 soon gave way to WPA2, which mandated the use of AES symmetric key encryption.</span></p>
<p><span class="font53">At the heart of WPA is a four-way handshake protocol that performs both mutual authentication and shared symmetric session-key derivation. The handshake protocol is shown in Figure 8.31 in simplified form. Note that both the mobile device (M) and the authentication server (AS) begin knowing a shared secret key </span><span class="font53" style="font-style:italic;">K<sub>AS-M</sub></span></p>
<div>
<p><span class="font5">M:</span></p>
<p><span class="font5">Mobile device</span></p><img src="networking_files/networking-605.jpg" alt="" style="width:38pt;height:42pt;">
</div><br clear="all">
<div><img src="networking_files/networking-606.jpg" alt="" style="width:23pt;height:10pt;">
<p><span class="font4" style="font-style:italic;font-variant:small-caps;"><sup>k</sup>as-m</span></p>
</div><br clear="all">
<p><span class="font5">AS: authentication server</span></p>
<div><img src="networking_files/networking-607.jpg" alt="" style="width:23pt;height:42pt;">
<p><span class="font4" style="font-style:italic;font-variant:small-caps;"><sup>k</sup>as-m</span></p>
</div><br clear="all">
<p><span class="font13" style="font-style:italic;">®</span><span class="font4" style="font-style:italic;">Nonce<sub>AS</sub></span></p>
<p><span class="font50" style="font-style:italic;">,.,-„,</span></p>
<p><span class="font4">using </span><span class="font4" style="font-style:italic;font-variant:small-caps;">K</span><span class="font8" style="font-style:italic;font-variant:small-caps;"><sub>as-m</sub></span><span class="font4" style="font-style:italic;font-variant:small-caps;">, Nonce</span><span class="font4" style="font-style:italic;"><sub>AS</sub>,</span></p>
<p><span class="font4" style="font-style:italic;">Nonce<sub>M</sub></span></p>
<p><span class="font4">(b) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&gt;</span></p>
<p><span class="font4" style="font-style:italic;">Nonc</span><span class="font50" style="font-style:italic;"><sup>e</sup><sub>M</sub></span><span class="font4" style="font-style:italic;">, </span><span class="font50" style="font-style:italic;"><sup>H</sup></span><span class="font4" style="font-style:italic;">MAC{</span><span class="font50" style="font-style:italic;"><sup>f</sup></span><span class="font4" style="font-style:italic;">{K</span><span class="font50" style="font-style:italic;">As-M</span><span class="font4" style="font-style:italic;">.</span><span class="font50" style="font-style:italic;"><sup>N</sup></span><span class="font4" style="font-style:italic;">onc</span><span class="font50" style="font-style:italic;"><sup>e</sup>As))</span><span class="font4"> &nbsp;&nbsp;&nbsp;Derive session key </span><span class="font4" style="font-style:italic;font-variant:small-caps;">Km-ap</span></p>
<p><span class="font4">using </span><span class="font4" style="font-style:italic;font-variant:small-caps;">Kas-m, Noncty.</span><span class="font50" style="font-style:italic;">, </span><span class="font4" style="font-style:italic;">Nonce<sub>M</sub></span></p>
<p><span class="font39">&lt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0-----------</span></p>
<ul style="list-style:none;"><li>
<p><span class="font4" style="font-style:italic;">c, d: used for group key derivation</span></p></li></ul>
<p><span class="font4" style="font-style:italic;">(d) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&gt;</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 8.31 </span><span class="font50">♦ </span><span class="font5">The WPA2 four-way handshake</span></p>
<p><span class="font53">(e.g., a password). One of their tasks will be to derive a shared symmetric sessionkey, </span><span class="font53" style="font-style:italic;font-variant:small-caps;">K</span><span class="font11" style="font-style:italic;font-variant:small-caps;"><sub>m ap</sub></span><span class="font54" style="font-style:italic;font-variant:small-caps;">,</span><span class="font53"> which will be used to encrypt/decrypt frames that are later transmitted between the mobile device (M) and the AP.</span></p>
<p><span class="font53">Mutual authentication and shared symmetric session-key derivation are accomplished in the first two steps, a and b, of the four-way handshake shown in Figure 8.31. Steps c and d are used to derive a second key used for group communication; see [Kohlios 2018; Zou 2016] for details.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. In this first step, the authentication server (AS) generates a nonce, </span><span class="font53" style="font-style:italic;">Nonce<sub>AS</sub>, </span><span class="font53">and sends it to the mobile device. Recall from Section 8.4 that nonces are used to avoid playback attacks and prove the “liveness” of the other side being authenticated.</span></p></li>
<li>
<p><span class="font53">b. The mobile device, M, receives the nonce, </span><span class="font53" style="font-style:italic;">Nonce<sub>AS</sub>,</span><span class="font53"> from the AS and generates its own nonce, </span><span class="font53" style="font-style:italic;">Nonce<sub>M</sub>.</span><span class="font53"> The mobile device then generates the symmetric shared session key, </span><span class="font53" style="font-style:italic;font-variant:small-caps;">K</span><span class="font11" style="font-style:italic;font-variant:small-caps;"><sub>m</sub></span><span class="font53" style="font-style:italic;"><sub> AP</sub>,</span><span class="font53"> using </span><span class="font53" style="font-style:italic;">Nonce<sub>AS</sub>, Nonce<sub>M</sub>,</span><span class="font53"> the initial shared secret key </span><span class="font53" style="font-style:italic;font-variant:small-caps;">K</span><span class="font11" style="font-style:italic;font-variant:small-caps;"><sub>as m</sub></span><span class="font54" style="font-style:italic;font-variant:small-caps;">,</span><span class="font53"> its MAC address, and the MAC address of the AS. It then sends its nonce, </span><span class="font53" style="font-style:italic;">Nonce<sub>M</sub>,</span><span class="font53"> and an HMAC-signed (see Figure 8.9) value that encodes </span><span class="font53" style="font-style:italic;">Nonce<sub>AS</sub></span><span class="font53"> and the original shared secret.</span></p></li></ul>
<p><span class="font53">The AS receives this message from M. By looking at the HMAC-signed version of the nonce it had just recently sent, </span><span class="font53" style="font-style:italic;">Nonce<sub>AS</sub>,</span><span class="font53"> the authentication server knows the mobile device is live; because the mobile device was able to encrypt using the shared secret key, </span><span class="font53" style="font-style:italic;font-variant:small-caps;">K</span><span class="font11" style="font-style:italic;font-variant:small-caps;"><sub>as m</sub></span><span class="font54" style="font-style:italic;font-variant:small-caps;">,</span><span class="font53"> the AS also knows that the mobile device is indeed who it claims to be (i.e., a device that knows the shared initial secret). The AS has thus authenticated the mobile device! The AS can also now perform the exact same computation as the mobile device to derive the shared symmetric session-key, </span><span class="font53" style="font-style:italic;">K<sub>M AP</sub>,</span><span class="font53"> using the </span><span class="font53" style="font-style:italic;">Nonce<sub>M</sub></span><span class="font53"> it received, </span><span class="font53" style="font-style:italic;">Nonce<sub>AS</sub>, </span><span class="font53">the initial shared secret key </span><span class="font53" style="font-style:italic;">K</span><span class="font53"> , its MAC address and the MAC address of </span><span class="font50" style="font-style:italic;">AS-Mi</span></p>
<p><span class="font53">the mobile device. At this point both the mobile device and the authentication server have computed the same shared symmetric key, </span><span class="font53" style="font-style:italic;">K<sub>M-AP</sub></span><span class="font53">, which will be used to encrypt/decrypt frames transmitted between the mobile device and the AP. The AS informs the AP of this key value in Step 3 in Figure 8.30.</span></p>
<p><span class="font53">WPA3 was released in June 2018 as an update to WPA2. The update addresses an attack on the four-way handshake protocol that could induce the reuse of previously used nonces [Vanhoef 2017] but still permits the use of the four-way handshake as a legacy protocol and includes longer key lengths, among other changes [WiFi 2019].</span></p>
<ul style="list-style:none;"><li>
<p><span class="font22" style="font-weight:bold;">802.11 Security Messaging Protocols</span></p></li></ul>
<p><span class="font53">Figure 8.32 shows the protocols used to implement the 802.11 security framework discussed above. The Extensible Authentication Protocol (EAP) [RFC 3748] defines the end-to-end message formats used in a simple request/response mode of interaction between the mobile device and authentication server, and are certified under WPA2. As shown in Figure 8.32, EAP messages are encapsulated using EAPoL (EAP over LAN) and sent over the 802.11 wireless link. These EAP messages are then decap-sulated at the access point, and then re-encapsulated using the RADIUS protocol for</span></p>
<div>
<p><span class="font5">M:</span></p>
<p><span class="font5">Mobile device</span></p><img src="networking_files/networking-608.jpg" alt="" style="width:38pt;height:42pt;">
</div><br clear="all">
<div>
<p><span class="font5">AP: access point</span></p><img src="networking_files/networking-609.jpg" alt="" style="width:52pt;height:26pt;">
</div><br clear="all">
<p><span class="font5">AS: authentication server </span><span class="font53">transmission over UDP/IP to the authentication server. While the RADIUS server and protocol [RFC 2865] are not required, they are </span><span class="font53" style="font-style:italic;">de facto</span><span class="font53"> standard components. The recently standardized DIAMETER protocol [RFC 3588] is projected to eventually replace RADIUS in the future.</span></p>
<div>
<p><span class="font5">Wired network</span></p><img src="networking_files/networking-610.jpg" alt="" style="width:33pt;height:39pt;">
</div><br clear="all">
<div><img src="networking_files/networking-611.jpg" alt="" style="width:241pt;height:60pt;">
<p><span class="font7" style="font-weight:bold;">Figure 8.32 </span><span class="font50">♦ </span><span class="font5">EAP is an end-to-end protocol. EAP messages are encapsulated using EAPoL over the wireless link between the mobile device and the access point, and using RADIUS over UDP/IP between the access point and the authentication server</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">8.8.2 </span><span class="font23" style="font-weight:bold;">Authentication and Key Agreement in</span></p></li></ul>
<p><span class="font23" style="font-weight:bold;">4G/5G Cellular Networks</span></p>
<p><span class="font53">In this section, we describe mutual authentication and key-generation mechanisms in 4G/5G networks. Many of the approaches we’ll encounter here parallel those that we just studied in 802.11 networks, with the notable exception that in 4G/5G networks, mobile devices may be attached to their home network (i.e., the cellular carrier network to which they are subscribed), or may be roaming on a visited network. In this latter case, the visited and home networks will need to interact when authenticating a mobile device and generating encryption keys. Before continuing, you may want to re-familiarize yourself with 4G/5G network architecture by rereading Sections 7.4 and 7.7.1.</span></p>
<p class="font53">The goals of mutual authentication and key generation are the same in the 4G/5G setting as in the 802.11 setting. In order to encrypt the contents of frames being transmitted over the wireless channel, the mobile device and base station will need to derive a shared symmetric encryption key. In addition, the network to which the mobile device is attaching will need to authenticate the device’s identity and check its access privileges. Similarly, the mobile device will also want to authenticate the network to which it is attaching. While the network’s need to authenticate a mobile device may be obvious, the need for authentication in the reverse direction may not be so clear. However, there are documented cases of ne’er-do-wells operating rogue cellular base stations that entice unsuspecting mobile devices to attach to the rogue network, exposing a device to a number of attacks [Li 2017]. So, as in the case of</p>
<ul style="list-style:none;"><li>
<p class="font53">802.11 WLANs, a mobile device should exercise abundant caution when attaching to a cellular network!</p></li></ul>
<p><a name="bookmark468"></a><span class="font53">Figure 8.33 illustrates the scenario of mobile device attaching to a 4G cellular network. At the top of Figure 8.33, we see many of the 4G components that we encountered earlier in Section 7.4—the mobile device (M), the base station (BS), the mobility management entity (MME) in the network to which the mobile device wants to attach, and the home subscriber service (HSS) in the mobile device’s home network. A comparison of Figures 8.30 and 8.33 shows the similarities and differences between the 802.11 and 4G security settings. We again see a mobile device and a base station; the user session-key derived during network attachment, K<sub>BS-M</sub>, will be used to encrypt/decrypt frames transmitted over their wireless link. The 4G MME and HSS together will play a role similar to that of the authentication server in the 802.11 setting. Note that the HSS and the mobile device also share a common secret, K<sub>HSS M</sub>, known to both entities before authentication begins. This key is stored in the mobile device’s SIM card, and in the HSS database in the mobile device’s home network.</span></p>
<div>
<p><span class="font2" style="font-variant:small-caps;"><sup>k</sup>bs-m</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-612.jpg" alt="" style="width:121pt;height:42pt;">
</div><br clear="all">
<div>
<p><span class="font4" style="font-style:italic;">Home Network</span></p><img src="networking_files/networking-613.jpg" alt="" style="width:72pt;height:40pt;">
<p><span class="font4">Home Subscriber Service (HSS)</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Mobile Device Base Station Mobility Management</span></p>
</div><br clear="all">
<div>
<p><span class="font4">(M) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(BS) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Entity (MME)</span></p>
</div><br clear="all">
<div>
<p><span class="font4">attach</span></p>
<p><span class="font4">I-----------------------------------------------------------------------------------------------------------------------------------</span></p>
<p><span class="font4" style="font-style:italic;">auth token</span></p>
<p><span class="font56" style="font-weight:bold;">!◄----------------------</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-614.jpg" alt="" style="width:26pt;height:22pt;">
<p><span class="font4">OK ◄----</span></p>
</div><br clear="all">
<div>
<p><span class="font4">,</span><span class="font4" style="text-decoration:underline;">1 attach</span></p>
<p><span class="font53">i</span></p>
<p><span class="font53">i</span></p>
<p><span class="font4" style="font-style:italic;">auth token</span></p>
<p><span class="font59" style="font-weight:bold;">?-------</span></p>
<p><span class="font4">J &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font50" style="font-style:italic;"><sup>res</sup>M</span></p>
</div><br clear="all">
<div>
<p><span class="font4">AUTH_REQ (IMSI, VN info)</span></p><img src="networking_files/networking-615.jpg" alt="" style="width:118pt;height:17pt;">
</div><br clear="all">
<div>
<p><span class="font4">AUTH_RESP </span><span class="font4" style="font-style:italic;">(auth token,xres<sub>HSS</sub></span><span class="font4">,keys)</span></p><img src="networking_files/networking-616.jpg" alt="" style="width:114pt;height:22pt;">
</div><br clear="all">
<div>
<p><span class="font4">OK, keys</span></p><img src="networking_files/networking-617.jpg" alt="" style="width:47pt;height:14pt;">
</div><br clear="all">
<div>
<p><span class="font4">key derivation</span></p><img src="networking_files/networking-618.jpg" alt="" style="width:89pt;height:14pt;">
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 8.33 </span><span class="font50">♦ </span><span class="font5">Mutual authentication and key agreement in a 4G LTE cellular network</span></p>
<p><span class="font53">The 4G Authentication and Key Agreement (AKA) protocol consists of the following steps:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. </span><span class="font53" style="font-style:italic;">Authentication request to HSS.</span><span class="font53"> When the mobile device first requests, via a base station, to attach to the network, it sends an attach message containing its international mobile subscriber identity (IMSI) that is relayed to the Mobility Management Entity (MME). The MME will then send the IMSI and information about the visited network (shown as “VN info” in Figure 8.33) to the Home Subscriber Service (HSS) in the device’s home network. In Section 7.4, we described how the MME is able to communicate with the HSS through the all-IP global network of interconnected cellular networks.</span></p></li>
<li>
<p><span class="font53">b. </span><span class="font53" style="font-style:italic;">Authentication response from HSS.</span><span class="font53"> The HSS performs cryptographic operations using the shared-in-advance secret key, K<sub>HSS-M</sub>, to derive an authentication token, </span><span class="font53" style="font-style:italic;">auth_token,</span><span class="font53"> and an expected authentication response token, </span><span class="font53" style="font-style:italic;">xres<sub>HSS</sub>. auth_token</span><span class="font53"> contains information encrypted by the HSS using K<sub>HSS-M</sub> that will allow the mobile device to know that whoever computed </span><span class="font53" style="font-style:italic;">auth_token</span><span class="font53"> knows the secret key. For example, suppose the</span></p></li></ul>
<p><span class="font53">HSS computes K<sub>HSS </sub></span><span class="font38" style="font-variant:small-caps;"><sub>m</sub></span><span class="font53" style="font-variant:small-caps;">(IMSI), that is, encrypts the device’s IMSI using K</span><span class="font53"><sub>HSS M </sub>and sends that value as </span><span class="font53" style="font-style:italic;">auth_token</span><span class="font53">. When the mobile device receives that encrypted value and uses its secret key to decrypt this value, that is, to compute </span><span class="font53" style="font-variant:small-caps;">K</span><span class="font38" style="font-variant:small-caps;"><sub>hsS-M</sub></span><span class="font53" style="font-variant:small-caps;">(K</span><span class="font38" style="font-variant:small-caps;"><sub>hsS-M</sub></span><span class="font53" style="font-variant:small-caps;">(IMSI))</span><span class="font54"> = </span><span class="font53">IMSI, it knows that the HSS that generated </span><span class="font53" style="font-style:italic;">auth_ token</span><span class="font53"> knows its secret key. The mobile device can thus authenticate the HSS.</span></p>
<p><span class="font53">The expected authentication response token, </span><span class="font53" style="font-style:italic;">xres<sub>HSS</sub>,</span><span class="font53"> contains a value that the mobile device will need to be able to compute (using K<sub>HSS </sub></span><span class="font38" style="font-variant:small-caps;"><sub>m</sub></span><span class="font53" style="font-variant:small-caps;">) and return to the MME to prove that </span><span class="font53" style="font-style:italic;">it</span><span class="font53"> (the mobile device) knows the secret key, thus authenticating the mobile device to the MME.</span></p>
<p><span class="font53">Note that the MME only plays a middleman role here, receiving the authentication response message, keeping </span><span class="font53" style="font-style:italic;">xres<sub>HSS</sub></span><span class="font53"> for later use, extracting the authentication token and forwarding it to the mobile device. In particular it need not know, and will not learn, the secret key, K</span><span class="font38" style="font-variant:small-caps;"><sub>hsS-M</sub></span><span class="font53" style="font-variant:small-caps;">.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">c. </span><span class="font53" style="font-style:italic;">Authentication response from mobile device.</span><span class="font53"> The mobile device receives </span><span class="font53" style="font-style:italic;">auth_token</span><span class="font53"> and computes K</span><span class="font38" style="font-variant:small-caps;"><sub>hsS-M</sub></span><span class="font53" style="font-variant:small-caps;">(K</span><span class="font38" style="font-variant:small-caps;"><sub>hsS-M</sub></span><span class="font53" style="font-variant:small-caps;">(IMSI))</span><span class="font54"> = </span><span class="font53">IMSI, thus authenticating the HSS. The mobile device then computes a value </span><span class="font53" style="font-style:italic;">res<sub>M</sub></span><span class="font53">—using its secret key to make the exact same cryptographic calculation that the HSS had made to compute </span><span class="font53" style="font-style:italic;">xres<sub>HSS</sub>—</span><span class="font53">and sends this value to the MME.</span></p></li>
<li>
<p><span class="font53">d. </span><span class="font53" style="font-style:italic;">Mobile device authentication.</span><span class="font53"> The MMS compares the mobile-computed value of </span><span class="font53" style="font-style:italic;">res<sub>M</sub></span><span class="font53"> with the HSS-computed value of </span><span class="font53" style="font-style:italic;">xres<sub>HSS</sub>.</span><span class="font53"> If they match, the mobile device is authenticated, since the mobile has proven to the MME that it and the HSS both know the common secret key. The MMS informs the base station and mobile device that mutual authentication is complete, and sends the base station keys that will be used in step e.</span></p></li>
<li>
<p><span class="font53">e. </span><span class="font53" style="font-style:italic;">Data plane and control plane key derivation.</span><span class="font53"> The mobile device and the base station will each determine the keys used for encrypting/decrypting their frame transmissions over the wireless channel. Separate keys will be derived for data plane and control plane frame transmissions. The AES encryption algorithm that we saw in use in 802.11 networks is also used in 4G/5G networks.</span></p></li></ul>
<p><span class="font53">Our discussion above has focused on authentication and key agreement in 4G networks. Although much of the 4G security is being carried forward into 5G, there are some important changes:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;First, note that in our discussion above that it is the MME in the visited network that makes the authentication decision. A significant change underway in 5G network security is to allow authentication services to be provided by the home network, with the visited network playing an even smaller middleman role. While the visited network may still reject an authentication from a mobile device, it is up to the home network to accept the authentication request in this new 5G scenario.</span></p></li>
<li>
<p><span class="font53">• &nbsp;5G networks will support the Authentication and Key Agreement (AKA) protocol described above, as well as two new additional protocols for authentication and key agreement. One of these, known as AKA</span><span class="font55">'</span><span class="font53">, is closely related to the 4G AKA protocol. It also uses the shared-in-advance secret key, K<sub>HSS M</sub>. However, since it uses the EAP protocol that we encountered earlier in Figure 8.33 in the context of 802.11 authentication, 5G AKA</span><span class="font55">' </span><span class="font53">has different message flows than that of 4G AKA. The second new 5G protocol is meant for an loT environment, and does not require a shared-in-advance secret key.</span></p></li></ul>
<p><span class="font53">• An additional change in 5G is to use public key cryptography techniques to encrypt a device’s permanent identity (i.e., its IMSI) so that it is never transmitted in cleartext.</span></p>
<p><span class="font53">In this section, we have only briefly overviewed mutual authentication and key agreement in 4G /5G networks. As we have seen, they make extensive use of the security techniques that we studied earlier in this chapter. More details on 4G/5G security can be found in [3GPP SAE 2019; Cable Labs 2019; Cichonski 2017].</span></p>
<ul style="list-style:none;"><li>
<p><span class="font59" style="font-weight:bold;">8.9 </span><span class="font24" style="font-weight:bold;">Operational Security: Firewalls and Intrusion Detection Systems</span></p></li></ul>
<p><span class="font53">We’ve seen throughout this chapter that the Internet is not a very safe place—bad guys are out there, wreaking all sorts of havoc. Given the hostile nature of the Internet, let’s now consider an organization’s network and the network administrator who administers it. From a network administrator’s point of view, the world divides quite neatly into two camps—the good guys (who belong to the organization’s network, and who should be able to access resources inside the organization’s network in a relatively unconstrained manner) and the bad guys (everyone else, whose access to network resources must be carefully scrutinized). In many organizations, ranging from medieval castles to modern corporate office buildings, there is a single point of entry/exit where both good guys and bad guys entering and leaving the organization are security-checked. In a castle, this was done at a gate at one end of the drawbridge; in a corporate building, this is done at the security desk. In a computer network, when traffic entering/leaving a network is security-checked, logged, dropped, or forwarded, it is done by operational devices known as firewalls, intrusion detection systems (IDSs), and intrusion prevention systems (IPSs).</span></p>
<p><span class="font56" style="font-weight:bold;">8.9.1 </span><span class="font23" style="font-weight:bold;">Firewalls</span></p>
<p><span class="font53">A </span><span class="font53" style="font-weight:bold;">firewall </span><span class="font53">is a combination of hardware and software that isolates an organization’s internal network from the Internet at large, allowing some packets to pass and blocking others. A firewall allows a network administrator to control access between the outside world and resources within the administered network by managing the traffic flow to and from these resources. A firewall has three goals:</span></p>
<p><a name="bookmark469"></a><span class="font53">• </span><span class="font53" style="font-style:italic;">All trafficfrom outside to inside, and vice versa, passes through the firewall. </span><span class="font53">Figure 8.34 shows a firewall, sitting squarely at the boundary between the administered network and the rest of the Internet. While large organizations may use</span></p>
<div><img src="networking_files/networking-619.jpg" alt="" style="width:134pt;height:131pt;">
<p><span class="font4">Administered network</span></p>
</div><br clear="all">
<div><img src="networking_files/networking-620.jpg" alt="" style="width:108pt;height:191pt;">
</div><br clear="all">
<div>
<p><span class="font4">Public Internet</span></p>
</div><br clear="all">
<p><span class="font7" style="font-weight:bold;">Figure 8.34 </span><span class="font50">♦ </span><span class="font5">Firewall placement between the administered network and the outside world</span></p>
<p><span class="font53">multiple levels of firewalls or distributed firewalls [Skoudis 2006], locating a firewall at a single access point to the network, as shown in Figure 8.34, makes it easier to manage and enforce a security-access policy.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">Only authorized traffic, as defined by the local security policy, will be allowed to pass.</span><span class="font53"> With all traffic entering and leaving the institutional network passing through the firewall, the firewall can restrict access to authorized traffic.</span></p></li>
<li>
<p><span class="font53">• &nbsp;</span><span class="font53" style="font-style:italic;">The firewall itself is immune to penetration</span><span class="font53">. The firewall itself is a device connected to the network. If not designed or installed properly, it can be compromised, in which case it provides only a false sense of security (which is worse than no firewall at all!).</span></p></li></ul>
<p><span class="font53">Cisco and Check Point are two of the leading firewall vendors today. You can also easily create a firewall (packet filter) from a Linux box using iptables (public-domain software that is normally shipped with Linux). Furthermore, as discussed in Chapters 4 and 5, firewalls are now frequently implemented in routers and controlled remotely using SDNs.</span></p>
<p><span class="font53">Firewalls can be classified in three categories: </span><span class="font53" style="font-weight:bold;">traditional packet filters</span><span class="font53">, </span><span class="font53" style="font-weight:bold;">stateful filters</span><span class="font53">, and </span><span class="font53" style="font-weight:bold;">application gateways</span><span class="font53">. We’ll cover each of these in turn in the following subsections.</span></p>
<p><span class="font22" style="font-weight:bold;">Traditional Packet Filters</span></p>
<p><span class="font53">As shown in Figure 8.34, an organization typically has a gateway router connecting its internal network to its ISP (and hence to the larger public Internet). All traffic leaving and entering the internal network passes through this router, and it is at this router where </span><span class="font53" style="font-weight:bold;">packet filtering </span><span class="font53">occurs. A packet filter examines each datagram in isolation, determining whether the datagram should be allowed to pass or should be dropped based on administrator-specific rules. Filtering decisions are typically based on:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">• &nbsp;IP source or destination address</span></p></li>
<li>
<p><span class="font53">• &nbsp;Protocol type in IP datagram field: TCP, UDP, ICMP, OSPF, and so on</span></p></li>
<li>
<p><span class="font53">• &nbsp;TCP or UDP source and destination port</span></p></li>
<li>
<p><span class="font53">• &nbsp;TCP flag bits: SYN, ACK, and so on</span></p></li>
<li>
<p><span class="font53">• &nbsp;ICMP message type</span></p></li>
<li>
<p><span class="font53">• &nbsp;Different rules for datagrams leaving and entering the network</span></p></li>
<li>
<p><span class="font53">• &nbsp;Different rules for the different router interfaces</span></p></li></ul>
<p><span class="font53">A network administrator configures the firewall based on the policy of the organization. The policy may take user productivity and bandwidth usage into account as well as the security concerns of an organization. Table 8.5 lists a number of possible polices an organization may have, and how they would be addressed with a packet filter. For example, if the organization doesn’t want any incoming TCP connections except those for its public Web server, it can block all incoming TCP SYN segments except TCP SYN segments with destination port 80 and the destination IP address corresponding to the Web server. If the organization doesn’t want its users to monopolize access bandwidth with Internet radio applications, it can block all not-critical</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Policy</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Firewall Setting</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">No outside Web access.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Drop all outgoing packets to any IP address, port 80.</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">No incoming TCP connections, except those for organization's public Web server only.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Drop all incoming TCP SYN packets to any IP except 130.207.244.203, port 80.</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Prevent Web-radios from eating up the available bandwidth.</span></p></td><td>
<p><span class="font6">Drop all incoming UDP packets—except DNS packets.</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Prevent your network from being used for a smurf DoS attack.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Drop all ICMP ping packets going to a &quot;broadcast&quot; address (eg 130.207.255.255).</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">Prevent your network from being tracerouted.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">Drop all outgoing ICMP TTL expired traffic.</span></p></td></tr>
</table>
<p><span class="font7" style="font-weight:bold;">Table 8.5 </span><span class="font50">♦ </span><span class="font5">Policies and corresponding filtering rules for an organization's network 130.207/16 with Web server at 130.207.244.203</span></p>
<p><span class="font53">UDP traffic (since Internet radio is often sent over UDP). If the organization doesn’t want its internal network to be mapped (tracerouted) by an outsider, it can block all ICMP TTL expired messages leaving the organization’s network.</span></p>
<p><span class="font53">A filtering policy can be based on a combination of addresses and port numbers. For example, a filtering router could forward all Telnet datagrams (those with a port number of 23) except those going to and coming from a list of specific IP addresses. This policy permits Telnet connections to and from hosts on the allowed list. Unfortunately, basing the policy on external addresses provides no protection against datagrams that have had their source addresses spoofed.</span></p>
<p><span class="font53">Filtering can also be based on whether or not the TCP ACK bit is set. This trick is quite useful if an organization wants to let its internal clients connect to external servers but wants to prevent external clients from connecting to internal servers. Recall from Section 3.5 that the first segment in every TCP connection has the ACK bit set to 0, whereas all the other segments in the connection have the ACK bit set to 1. Thus, if an organization wants to prevent external clients from initiating connections to internal servers, it simply filters all incoming segments with the ACK bit set to 0. This policy kills all TCP connections originating from the outside, but permits connections originating internally.</span></p>
<p><span class="font53">Firewall rules are implemented in routers with access control lists, with each router interface having its own list. An example of an access control list for an organization 222.22/16 is shown in Table 8.6. This access control list is for an interface that connects the router to the organization’s external ISPs. Rules are applied to each datagram that passes through the interface from top to bottom. The first two rules together allow internal users to surf the Web: The first rule allows any TCP packet with destination port 80 to leave the organization’s network; the second rule allows any TCP packet with source port 80 and the ACK bit set to enter the organization’s network. Note that if an external source attempts to establish a TCP connection with</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font6">action</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">source address</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">dest address</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">protocol</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">source port</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">dest port</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">flag bit</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font6">allow</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">222.22/16</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">outside of</span></p>
<p><span class="font6">222.22/16</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">TCP</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">&gt; 1023</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">80</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">any</span></p></td></tr>
<tr><td>
<p><span class="font6">allow</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">outside of</span></p>
<p><span class="font6">222.22/16</span></p></td><td>
<p><span class="font6">222.22/16</span></p></td><td>
<p><span class="font6">TCP</span></p></td><td>
<p><span class="font6">80</span></p></td><td>
<p><span class="font6">&gt; 1023</span></p></td><td>
<p><span class="font6">ACK</span></p></td></tr>
<tr><td>
<p><span class="font6">allow</span></p></td><td>
<p><span class="font6">222.22/16</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">outside of</span></p>
<p><span class="font6">222.22/16</span></p></td><td>
<p><span class="font6">UDP</span></p></td><td>
<p><span class="font6">&gt; 1023</span></p></td><td>
<p><span class="font6">53</span></p></td><td>
<p><span class="font6">—</span></p></td></tr>
<tr><td>
<p><span class="font6">allow</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">outside of</span></p>
<p><span class="font6">222.22/16</span></p></td><td>
<p><span class="font6">222.22/16</span></p></td><td>
<p><span class="font6">UDP</span></p></td><td>
<p><span class="font6">53</span></p></td><td>
<p><span class="font6">&gt; 1023</span></p></td><td>
<p><span class="font6">—</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">deny</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">all</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">all</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">all</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">all</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">all</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">all</span></p></td></tr>
</table>
<p><span class="font7" style="font-weight:bold;">Table 8.6 </span><span class="font50">♦ </span><span class="font5">An access control list for a router interface</span></p>
<p><span class="font53">an internal host, the connection will be blocked, even if the source or destination port is 80. The second two rules together allow DNS packets to enter and leave the organization’s network. In summary, this rather restrictive access control list blocks all traffic except Web traffic initiated from within the organization and DNS traffic. [CERT Filtering 2012] provides a list of recommended port/protocol packet filterings to avoid a number of well-known security holes in existing network applications.</span></p>
<p><span class="font53">Readers with sharp memories may recall we encountered access control lists similar to Table 8.6 when we studied generalized forwarding in Section 4.4.3 of Chapter 4. Indeed, we provided an example there of how generalized forwarding rules can be used to build a packet-filtering firewall.</span></p>
<p><span class="font22" style="font-weight:bold;">Stateful Packet Filters</span></p>
<p><span class="font53">In a traditional packet filter, filtering decisions are made on each packet in isolation. Stateful filters actually track TCP connections, and use this knowledge to make filtering decisions.</span></p>
<p><span class="font53">To understand stateful filters, let’s reexamine the access control list in Table 8.6. Although rather restrictive, the access control list in Table 8.6 nevertheless allows any packet arriving from the outside with ACK = 1 and source port 80 to get through the filter. Such packets could be used by attackers in attempts to crash internal systems with malformed packets, carry out denial-of-service attacks, or map the internal network. The naive solution is to block TCP ACK packets as well, but such an approach would prevent the organization’s internal users from surfing the Web.</span></p>
<p><span class="font53">Stateful filters solve this problem by tracking all ongoing TCP connections in a connection table. This is possible because the firewall can observe the beginning of a new connection by observing a three-way handshake (SYN, SYNACK, and ACK); and it can observe the end of a connection when it sees a FIN packet for the connection. The firewall can also (conservatively) assume that the connection is over when it hasn’t seen any activity over the connection for, say, 60 seconds. An example connection table for a firewall is shown in Table 8.7. This connection table indicates that there are currently three ongoing TCP connections, all of which have been initiated from within the organization. Additionally, the stateful filter includes a new column, “check connection,” in its access control list, as</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font6">source address</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">dest address</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">source port</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">dest port</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">222.22.1.7</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">37.96.87.123</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">12699</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">80</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">222.22.93.2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">199.1.205.23</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">37654</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">80</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">222.22.65.143</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">203.77.240.43</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">48712</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">80</span></p></td></tr>
</table>
<p><span class="font7" style="font-weight:bold;">Table 8.7 </span><span class="font50">♦ </span><span class="font5">Connection table for stateful filter</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font6">action</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">source address</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">dest address</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">protocol</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">source port</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">dest port</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">flag bit</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">check conxion</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font6">allow</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">222.22/16</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">outside of</span></p>
<p><span class="font6">222.22/16</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">TCP</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">&gt; 1023</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">80</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">any</span></p></td><td></td></tr>
<tr><td>
<p><span class="font6">allow</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">outside of</span></p>
<p><span class="font6">222.22/16</span></p></td><td>
<p><span class="font6">222.22/16</span></p></td><td>
<p><span class="font6">TCP</span></p></td><td>
<p><span class="font6">80</span></p></td><td>
<p><span class="font6">&gt; 1023</span></p></td><td>
<p><span class="font6">ACK</span></p></td><td>
<p><span class="font6">X</span></p></td></tr>
<tr><td>
<p><span class="font6">allow</span></p></td><td>
<p><span class="font6">222.22/16</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">outside of</span></p>
<p><span class="font6">222.22/16</span></p></td><td>
<p><span class="font6">UDP</span></p></td><td>
<p><span class="font6">&gt; 1023</span></p></td><td>
<p><span class="font6">53</span></p></td><td>
<p><span class="font6">—</span></p></td><td></td></tr>
<tr><td>
<p><span class="font6">allow</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">outside of</span></p>
<p><span class="font6">222.22/16</span></p></td><td>
<p><span class="font6">222.22/16</span></p></td><td>
<p><span class="font6">UDP</span></p></td><td>
<p><span class="font6">53</span></p></td><td>
<p><span class="font6">&gt; 1023</span></p></td><td>
<p><span class="font6">—</span></p></td><td>
<p><span class="font6">X</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">deny</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">all</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">all</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">all</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">all</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">all</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">all</span></p></td><td></td></tr>
</table>
<p><span class="font7" style="font-weight:bold;">Table 8.8 </span><span class="font50">♦ </span><span class="font5">Access control list for stateful filter</span></p>
<p><span class="font53">shown in Table 8.8. Note that Table 8.8 is identical to the access control list in Table 8.6, except now it indicates that the connection should be checked for two of the rules.</span></p>
<p><span class="font53">Let’s walk through some examples to see how the connection table and the extended access control list work hand-in-hand. Suppose an attacker attempts to send a malformed packet into the organization’s network by sending a datagram with TCP source port 80 and with the ACK flag set. Further suppose that this packet has source port number 12543 and source IP address 150.23.23.155. When this packet reaches the firewall, the firewall checks the access control list in Table 8.7, which indicates that the connection table must also be checked before permitting this packet to enter the organization’s network. The firewall duly checks the connection table, sees that this packet is not part of an ongoing TCP connection, and rejects the packet. As a second example, suppose that an internal user wants to surf an external Web site. Because this user first sends a TCP SYN segment, the user’s TCP connection gets recorded in the connection table. When the Web server sends back packets (with the ACK bit necessarily set), the firewall checks the table and sees that a corresponding connection is in progress. The firewall will thus let these packets pass, thereby not interfering with the internal user’s Web surfing activity.</span></p>
<p><span class="font22" style="font-weight:bold;">Application Gateway</span></p>
<p><span class="font53">In the examples above, we have seen that packet-level filtering allows an organization to perform coarse-grain filtering on the basis of the contents of IP and TCP/UDP headers, including IP addresses, port numbers, and acknowledgment bits. But what if an organization wants to provide a Telnet service to a restricted set of internal users</span></p>
<p><span class="font53">(as opposed to IP addresses)? And what if the organization wants such privileged users to authenticate themselves first before being allowed to create Telnet sessions to the outside world? Such tasks are beyond the capabilities of traditional and stateful filters. Indeed, information about the identity of the internal users is application-layer data and is not included in the IP/TCP/UDP headers.</span></p>
<p><span class="font53">To have finer-level security, firewalls must combine packet filters with application gateways. Application gateways look beyond the IP/TCP/UDP headers and make policy decisions based on application data. An </span><span class="font53" style="font-weight:bold;">application gateway </span><span class="font53">is an application-specific server through which all application data (inbound and outbound) must pass. Multiple application gateways can run on the same host, but each gateway is a separate server with its own processes.</span></p>
<p><span class="font53">To get some insight into application gateways, let’s design a firewall that allows only a restricted set of internal users to Telnet outside and prevents all external clients from Telneting inside. Such a policy can be accomplished by implementing a combination of a packet filter (in a router) and a Telnet application gateway, as shown in Figure 8.35. The router’s filter is configured to block all Telnet connections except those that originate from the IP address of the application gateway. Such a filter configuration forces all outbound Telnet connections to pass through the application gateway. Consider now an internal user who wants to Telnet to the outside world. The user must first set up a Telnet session with the application gateway. An application running in the gateway, which listens for incoming Telnet sessions, prompts the</span></p><img src="networking_files/networking-621.jpg" alt="" style="width:250pt;height:215pt;">
<p><span class="font7" style="font-weight:bold;">Figure 8.35 </span><span class="font50">♦ </span><span class="font5">Firewall consisting of an application gateway and a filter</span></p>
<p><span class="font53">user for a user ID and password. When the user supplies this information, the application gateway checks to see if the user has permission to Telnet to the outside world. If not, the Telnet connection from the internal user to the gateway is terminated by the gateway. If the user has permission, then the gateway (1) prompts the user for the host name of the external host to which the user wants to connect, (2) sets up a Telnet session between the gateway and the external host, and (3) relays to the external host all data arriving from the user, and relays to the user all data arriving from the external host. Thus, the Telnet application gateway not only performs user authorization but also acts as a Telnet server and a Telnet client, relaying information between the user and the remote Telnet server. Note that the filter will permit step 2 because the gateway initiates the Telnet connection to the outside world.</span></p>
<div><img src="networking_files/networking-622.jpg" alt="" style="width:168pt;height:22pt;">
</div><br clear="all">
<div>
<p><span class="font23" style="font-weight:bold;">CASE HISTORY</span></p>
</div><br clear="all">
<p><span class="font4" style="font-weight:bold;">ANONYMITY AND PRIVACY</span></p>
<p><span class="font4">Suppose you want to visit a controversial Web site (for example, a political activist site) and you (1) don’t want to reveal your IP address to the Web site, (2) don’t want your local ISP (which may be your home or office ISP) to know that you are visiting the site, and (3) don’t want your local ISP to see the data you are exchanging with the site. If you use the traditional approach of connecting directly to the Web site without any encryption, you fail on all three counts. Even if you use SSL, you fail on the first two counts: Your source IP address is presented to the Web site in every datagram you send; and the destination address of every packet you send can easily be sniffed by your local ISP.</span></p>
<p><span class="font4">To obtain privacy and anonymity, you can instead use a combination of a trusted proxy server and SSL, as shown in Figure 8.36. With this approach, you first make an SSL connection to the trusted proxy. You then send, into this SSL connection, an HTTP request for a page at the desired site. When the proxy receives the SSL-encrypted HTTP request, it decrypts the request and forwards the cleartext HTTP request to the Web site. The Web site then responds to the proxy, which in turn forwards the response to you over SSL. Because the Web site only sees the IP address of the proxy, and not of your client's address, you are indeed obtaining anonymous access to the Web site. And because all traffic between you and the proxy is encrypted, your local ISP cannot invade your privacy by logging the site you visited or recording the data you are exchanging. Many companies today (such as</span><a href="http://proxify.com"><span class="font4"> proxify</span></a><span class="font4"> </span><a href="http://proxify.com"><span class="font4">.com)</span></a><span class="font4"> make available such proxy services.</span></p>
<div><img src="networking_files/networking-623.jpg" alt="" style="width:295pt;height:91pt;">
<p><span class="font5" style="font-weight:bold;">Figure 8.36 ♦ </span><span class="font4">Providing anonymity and privacy with a proxy</span></p>
</div><br clear="all">
<p><span class="font4">Of course, in this solution, your proxy knows everything: It knows your IP address and the IP address of the site you're surfing; and it can see all the traffic in cleartext exchanged between you and the Web site. Such a solution, therefore, is only as good as the trustworthiness of the proxy. A more robust approach, taken by the TOR anonymizing and privacy service, is to route your traffic through a series of non-colluding proxy servers [TOR 2020]. In particular, TOR allows independent individuals to contribute proxies to its proxy pool. When a user connects to a server using TOR, TOR randomly chooses (from its proxy pool) a chain of three proxies and routes all traffic between client and server over the chain. In this manner, assuming the proxies do not collude, no one knows that communication took place between your IP address and the target Web site. Furthermore, although cleartext is sent between the last proxy and the server, the last proxy doesn't know what IP address is sending and receiving the cleartext.</span></p>
<p><span class="font53">Internal networks often have multiple application gateways, for example, gateways for Telnet, HTTP, FTP, and e-mail. In fact, an organization’s mail server (see Section 2.3) and Web cache are application gateways.</span></p>
<p><span class="font53">Application gateways do not come without their disadvantages. First, a different application gateway is needed for each application. Second, there is a performance penalty to be paid, since all data will be relayed via the gateway. This becomes a concern particularly when multiple users or applications are using the same gateway machine. Finally, the client software must know how to contact the gateway when the user makes a request, and must know how to tell the application gateway what external server to connect to.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font56" style="font-weight:bold;">8.9.2 </span><span class="font23" style="font-weight:bold;">Intrusion Detection Systems</span></p></li></ul>
<p><a name="bookmark470"></a><span class="font53">We’ve just seen that a packet filter (traditional and stateful) inspects IP, TCP, UDP, and ICMP header fields when deciding which packets to let pass through the firewall. However, to detect many attack types, we need to perform </span><span class="font53" style="font-weight:bold;">deep packet inspection</span><span class="font53">, that is, look beyond the header fields and into the actual application data that the packets carry. As we saw in Section 8.9.1, application gateways often do deep packet inspection. But an application gateway only does this for a specific application.</span></p>
<p><span class="font53">Clearly, there is a niche for yet another device—a device that not only examines the headers of all packets passing through it (like a packet filter), but also performs deep packet inspection (unlike a packet filter). When such a device observes a suspicious packet, or a suspicious series of packets, it could prevent those packets from entering the organizational network. Or, because the activity is only deemed as suspicious, the device could let the packets pass, but send alerts to a network administrator, who can then take a closer look at the traffic and take appropriate actions. A device that generates alerts when it observes potentially malicious traffic is called an </span><span class="font53" style="font-weight:bold;">intrusion detection system (IDS)</span><span class="font53">. A device that filters out suspicious traffic is called an </span><span class="font53" style="font-weight:bold;">intrusion prevention system (IPS)</span><span class="font53">. In this section we study both systems—IDS and IPS—together, since the most interesting technical aspect of these systems is how they detect suspicious traffic (and not whether they send alerts or drop packets). We will henceforth collectively refer to IDS systems and IPS systems as IDS systems.</span></p>
<p><span class="font53">An IDS can be used to detect a wide range of attacks, including network mapping (emanating, for example, from nmap), port scans, TCP stack scans, DoS bandwidth-flooding attacks, worms and viruses, OS vulnerability attacks, and application vulnerability attacks. (See Section 1.6 for a survey of network attacks.) Today, thousands of organizations employ IDS systems. Many of these deployed systems are proprietary, marketed by Cisco, Check Point, and other security equipment vendors. But many of the deployed IDS systems are public-domain systems, such as the immensely popular Snort IDS system (which we’ll discuss shortly).</span></p>
<p><span class="font53">An organization may deploy one or more IDS sensors in its organizational network. Figure 8.37 shows an organization that has three IDS sensors. When multiple sensors are deployed, they typically work in concert, sending information about suspicious traffic activity to a central IDS processor, which collects and integrates the information and sends alarms to network administrators when deemed appropriate. In Figure 8.37, the organization has partitioned its network into two regions: a high-security region, protected by a packet filter and an application gateway and monitored by IDS sensors; and a lower-security region—referred to as the </span><span class="font53" style="font-weight:bold;">demilitarized zone (DMZ)</span><span class="font53">—which is protected only by the packet filter, but also monitored by IDS sensors. Note that the DMZ includes the organization’s servers that need to communicate with the outside world, such as its public Web server and its authoritative DNS server.</span></p>
<p><span class="font53">You may be wondering at this stage, why multiple IDS sensors? Why not just place one IDS sensor just behind the packet filter (or even integrated with the packet filter) in Figure 8.37? We will soon see that an IDS not only needs to do deep packet inspection, but must also compare each passing packet with tens of thousands of “signatures”; this can be a significant amount of processing, particularly if the organization receives gigabits/sec of traffic from the Internet. By placing the IDS sensors further downstream, each sensor sees only a fraction of the organization’s traffic, and can more easily keep up. Nevertheless, high-performance IDS and IPS systems are available today, and many organizations can actually get by with just one sensor located near its access router.</span></p>
<div><img src="networking_files/networking-624.jpg" alt="" style="width:50pt;height:26pt;">
<p><span class="font4">Filter</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Internal network</span></p>
<p><span class="font4">Application gateway</span></p><img src="networking_files/networking-625.jpg" alt="" style="width:347pt;height:236pt;">
<p><span class="font4">Internet</span></p>
<p><span class="font41">= IDS sensors</span></p>
<p><span class="font4">Demilitarized zone</span></p>
<p><span class="font4">Web server</span></p>
<p><span class="font4">FTP server</span></p>
<p><span class="font4">DNS server</span></p>
<p><span class="font7" style="font-weight:bold;">Figure 8.37 </span><span class="font50">♦ </span><span class="font5">An organization deploying a filter, an application gateway, and IDS sensors</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Key:</span></p><img src="networking_files/networking-626.jpg" alt="" style="width:29pt;height:17pt;">
</div><br clear="all">
<p><span class="font53">IDSsystemsarebroadlyclassifiedaseither </span><span class="font53" style="font-weight:bold;">signature-basedsystems </span><span class="font53">or </span><span class="font53" style="font-weight:bold;">anomalybased systems</span><span class="font53">. A signature-based IDS maintains an extensive database of attack signatures. Each signature is a set of rules pertaining to an intrusion activity. A signature may simply be a list of characteristics about a single packet (e.g., source and destination port numbers, protocol type, and a specific string of bits in the packet payload), or may relate to a series of packets. The signatures are normally created by skilled network security engineers who research known attacks. An organization’s network administrator can customize the signatures or add its own to the database.</span></p>
<p><span class="font53">Operationally, a signature-based IDS sniffs every packet passing by it, comparing each sniffed packet with the signatures in its database. If a packet (or series of packets) matches a signature in the database, the IDS generates an alert. The alert could be sent to the network administrator in an e-mail message, could be sent to the network management system, or could simply be logged for future inspection.</span></p>
<p><span class="font53">Signature-based IDS systems, although widely deployed, have a number of limitations. Most importantly, they require previous knowledge of the attack to generate an accurate signature. In other words, a signature-based IDS is completely blind to new attacks that have yet to be recorded. Another disadvantage is that even if a signature is matched, it may not be the result of an attack, so that a false alarm is generated. Finally, because every packet must be compared with an extensive collection of signatures, the IDS can become overwhelmed with processing and actually fail to detect many malicious packets.</span></p>
<p><span class="font53">An anomaly-based IDS creates a traffic profile as it observes traffic in normal operation. It then looks for packet streams that are statistically unusual, for example, an inordinate percentage of ICMP packets or a sudden exponential growth in port scans and ping sweeps. The great thing about anomaly-based IDS systems is that they don’t rely on previous knowledge about existing attacks—that is, they can potentially detect new, undocumented attacks. On the other hand, it is an extremely challenging problem to distinguish between normal traffic and statistically unusual traffic. To date, most IDS deployments are primarily signature-based, although some include some anomaly-based features.</span></p>
<p><span class="font22" style="font-weight:bold;">Snort</span></p>
<p><span class="font53">Snort is a public-domain, open source IDS with hundreds of thousands of existing deployments [Snort 2012; Koziol 2003]. It can run on Linux, UNIX, and Windows platforms. It uses the generic sniffing interface libpcap, which is also used by Wireshark and many other packet sniffers. It can easily handle 100 Mbps of traffic; for installations with gibabit/sec traffic rates, multiple Snort sensors may be needed.</span></p>
<p><span class="font53">To gain some insight into Snort, let’s take a look at an example of a Snort signature:</span></p>
<p><span class="font36">alert icmp $EXTERNAL_NET any -&gt; $HOME_NET any (msg:&quot;ICMP PING NMAP&quot;; dsize: 0; itype: 8;)</span></p>
<p><span class="font53">This signature is matched by any ICMP packet that enters the organization’s network (</span><span class="font36">$HOME_NET</span><span class="font53">) from the outside (</span><span class="font36">$EXTERNAL_NET</span><span class="font53">), is of type 8 (ICMP ping), and has an empty payload (dsize = 0). Since nmap (see Section 1.6) generates ping packets with these specific characteristics, this signature is designed to detect nmap ping sweeps. When a packet matches this signature, Snort generates an alert that includes the message “</span><span class="font36">ICMP PING NMAP</span><span class="font53">”.</span></p>
<p><span class="font53">Perhaps what is most impressive about Snort is the vast community of users and security experts that maintain its signature database. Typically within a few hours of a new attack, the Snort community writes and releases an attack signature, which is then downloaded by the hundreds of thousands of Snort deployments distributed around the world. Moreover, using the Snort signature syntax, network administrators can tailor the signatures to their own organization’s needs by either modifying existing signatures or creating entirely new ones.</span></p>
<p><span class="font59" style="font-weight:bold;">8.10 </span><span class="font24" style="font-weight:bold;">Summary</span></p>
<p><span class="font53">In this chapter, we’ve examined the various mechanisms that our secret lovers, Bob and Alice, can use to communicate securely. We’ve seen that Bob and Alice are interested in confidentiality (so they alone are able to understand the contents of a transmitted message), end-point authentication (so they are sure that they are talking with each other), and message integrity (so they are sure that their messages are not altered in transit). Of course, the need for secure communication is not confined to secret lovers. Indeed, we saw in Sections 8.5 through 8.8 that security can be used in various layers in a network architecture to protect against bad guys who have a large arsenal of possible attacks at hand.</span></p>
<p><span class="font53">The first part of this chapter presented various principles underlying secure communication. In Section 8.2, we covered cryptographic techniques for encrypting and decrypting data, including symmetric key cryptography and public key cryptography. DES and RSA were examined as specific case studies of these two major classes of cryptographic techniques in use in today’s networks.</span></p>
<p><span class="font53">In Section 8.3, we examined two approaches for providing message integrity: message authentication codes (MACs) and digital signatures. The two approaches have a number of parallels. Both use cryptographic hash functions and both techniques enable us to verify the source of the message as well as the integrity of the message itself. One important difference is that MACs do not rely on encryption whereas digital signatures require a public key infrastructure. Both techniques are extensively used in practice, as we saw in Sections 8.5 through 8.8. Furthermore, digital signatures are used to create digital certificates, which are important for verifying the validity of public keys. In Section 8.4, we examined endpoint authentication and introduced nonces to defend against the replay attack.</span></p>
<p><span class="font53">In Sections 8.5 through 8.8 we examined several security networking protocols that enjoy extensive use in practice. We saw that symmetric key cryptography is at the core of PGP, SSL, IPsec, and wireless security. We saw that public key cryptography is crucial for both PGP and TLS. We saw that PGP uses digital signatures for message integrity, whereas TLS and IPsec use MACs. We also explored security in wireless networks, including WiFi networks and 4G/5G cellular networks. Having now an understanding of the basic principles of cryptography, and having studied how these principles are actually used, you are now in position to design your own secure network protocols!</span></p>
<p><a name="bookmark471"></a><span class="font53">Armed with the techniques covered in Sections 8.2 through 8.8, Bob and Alice can communicate securely. But confidentiality is only a small part of the network security picture. As we learned in Section 8.9, increasingly, the focus in network security has been on securing the network infrastructure against a potential onslaught by the bad guys. In the latter part of this chapter, we thus covered firewalls and IDS systems which inspect packets entering and leaving an organization’s network.</span></p>
<p><span class="font24" style="font-weight:bold;">Homework Problems and Questions</span></p>
<p><span class="font23" style="font-weight:bold;">Chapter 8 Review Problems</span></p>
<p><span class="font43" style="font-weight:bold;">SECTION 8.1</span></p>
<p><span class="font53">R1. Operational devices such as firewalls and intrusion detection systems are used to counter attacks against an organization’s network. What is the basic difference between a firewall and an intrusion detection system?</span></p>
<p><span class="font53">R2. Internet entities (routers, switches, DNS servers, Web servers, user end systems, and so on) often need to communicate securely. Give three specific example pairs of Internet entities that may want secure communication.</span></p>
<p><span class="font43" style="font-weight:bold;">SECTION 8.2</span></p>
<p><span class="font53">R3. The encryption technique itself is known—published, standardized, and available to everyone, even a potential intruder. Then where does the security of an encryption technique come from?</span></p>
<p><span class="font53">R4. What is the difference between known plaintext attack and chosen plaintext attack?</span></p>
<p><span class="font53">R5. Consider a 16-block cipher. How many possible input blocks does this cipher have? How many possible mappings are there? If we view each mapping as a key, then how many possible keys does this cipher have?</span></p>
<p><span class="font53">R6. Suppose </span><span class="font53" style="font-style:italic;">N</span><span class="font53"> people want to communicate with each of </span><span class="font53" style="font-style:italic;">N —</span><span class="font53"> 1 other people using symmetric key encryption. All communication between any two people, </span><span class="font53" style="font-style:italic;">i</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">j,</span><span class="font53"> is visible to all other people in this group of </span><span class="font53" style="font-style:italic;">N</span><span class="font53">, and no other person in this group should be able to decode their communication. How many keys are required in the system as a whole? Now suppose that public key encryption is used. How many keys are required in this case?</span></p>
<p><span class="font53">R7. Suppose </span><span class="font53" style="font-style:italic;">n =</span><span class="font53"> 1,000, </span><span class="font53" style="font-style:italic;">a =</span><span class="font53"> 1,017, and </span><span class="font53" style="font-style:italic;">b =</span><span class="font53"> 1,006. Use an identity of modular arithmetic to calculate in your head (</span><span class="font53" style="font-style:italic;">a</span><span class="font60"> • </span><span class="font53" style="font-style:italic;">b</span><span class="font53">) mod </span><span class="font53" style="font-style:italic;">n</span><span class="font53">.</span></p>
<p><span class="font53">R8. Suppose you want to encrypt the message 10010111 by encrypting the decimal number that corresponds to the message. What is the decimal number?</span></p>
<p><span class="font43" style="font-weight:bold;">SECTIONS 8.3-8.4</span></p>
<p><span class="font53">R9. In what way does a hash provide a better message integrity check than a checksum (such as the Internet checksum)?</span></p>
<p><a name="bookmark472"></a><span class="font53">R10. Can you “decrypt” a hash of a message to get the original message? Explain your answer.</span></p>
<p><span class="font53">R11. Consider a variation of the MAC algorithm (Figure 8.9) where the sender sends </span><span class="font53" style="font-style:italic;">(m, H(m)</span><span class="font55"> + </span><span class="font53" style="font-style:italic;">s),</span><span class="font53"> where </span><span class="font53" style="font-style:italic;">H(m)</span><span class="font55"> + </span><span class="font53" style="font-style:italic;">s</span><span class="font53"> is the concatenation of </span><span class="font53" style="font-style:italic;">H(m)</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">s</span><span class="font53">. Is this variation flawed? Why or why not?</span></p>
<p><span class="font53">R12. What does it mean for a signed document to be verifiable and nonforgeable?</span></p>
<p><span class="font53">R13. In the link-state routing algorithm, we would somehow need to distribute the secret authentication key to each of the routers in the autonomous system. How do we distribute the shared authentication key to the communicating entities?</span></p>
<p><span class="font53">R14. Name two popular secure networking protocols in which public key certification is used.</span></p>
<p><span class="font53">R15. Suppose Alice has a message that she is ready to send to anyone who asks. Thousands of people want to obtain Alice’s message, but each wants to be sure of the integrity of the message. In this context, do you think a MACbased or a digital-signature-based integrity scheme is more suitable? Why?</span></p>
<p><span class="font53">R16. What is the purpose of a nonce in an end-point authentication protocol?</span></p>
<p><span class="font53">R17. What does it mean to say that a nonce is a once-in-a-lifetime value? In whose lifetime?</span></p>
<p><span class="font53">R18. Is the message integrity scheme based on HMAC susceptible to playback attacks? If so, how can a nonce be incorporated into the scheme to remove this susceptibility?</span></p>
<p><span class="font43" style="font-weight:bold;">SECTIONS 8.5-8.8</span></p>
<p><span class="font53">R19. What is the de facto e-mail encryption scheme? What does it use for authentication and message integrity?</span></p>
<p><span class="font53">R20. In the TLS record, there is a field for TLS sequence numbers. True or false?</span></p>
<p><span class="font53">R21. What is the purpose of the random nonces in the TLS handshake?</span></p>
<p><span class="font53">R22. Suppose an TLS session employs a block cipher with CBC. True or false: The server sends to the client the IV in the clear.</span></p>
<p><span class="font53">R23. Suppose Bob initiates a TCP connection to Trudy who is pretending to be Alice. During the handshake, Trudy sends Bob Alice’s certificate. In what step of the TLS handshake algorithm will Bob discover that he is not communicating with Alice?</span></p>
<p><span class="font53">R24. Consider sending a stream of packets from Host A to Host B using IPsec. Typically, a new SA will be established for each packet sent in the stream. True or false?</span></p>
<p><span class="font53">R25. Suppose that TCP is being run over IPsec between headquarters and the branch office in Figure 8.28. If TCP retransmits the same packet, then the two corresponding packets sent by R1 packets will have the same sequence number in the ESP header. True or false?</span></p>
<p><span class="font53">R26. Is there a fixed encryption algorithm in SSL?</span></p>
<p><span class="font53">R27. Consider WEP for 802.11. Suppose that the data is 10001101 and the keystream is 01101010. What is the resulting ciphertext?</span></p>
<p><span class="font43" style="font-weight:bold;">SECTION 8.9</span></p>
<p><span class="font53">R28. Stateful packet filters maintain two data structures. Name them and briefly describe what they do.</span></p>
<p><span class="font53">R29. Consider a traditional (stateless) packet filter. This packet filter may filter packets based on TCP flag bits as well as other header fields. True or false?</span></p>
<p><span class="font53">R30. In a traditional packet filter, each interface can have its own access control list. True or false?</span></p>
<p><span class="font53">R31. Why must an application gateway work in conjunction with a router filter to be effective?</span></p>
<p><span class="font53">R32. Signature-based IDSs and IPSs inspect into the payloads of TCP and UDP segments. True or false?</span></p>
<p><span class="font24" style="font-weight:bold;">Problems</span></p>
<p><span class="font53">P1. Using the monoalphabetic cipher in Figure 8.3, encode the message “This is a secret message.”</span></p>
<p><span class="font53">P2. Show that Trudy’s known-plaintext attack, in which she knows the (ciphertext, plaintext) translation pairs for seven letters, reduces the number of possible substitutions to be checked in the example in Section 8.2.1 by approximately 10<sup>9</sup>.</span></p>
<p><span class="font53">P3. Consider the polyalphabetic system shown in Figure 8.4. Will a chosen-plaintext attack that is able to get the plaintext encoding of the message “The quick brown fox jumps over the lazy dog.” be sufficient to decode all messages? Why or why not?</span></p>
<p><span class="font53">P4. Consider the block cipher in Figure 8.5. Suppose that each block cipher </span><span class="font53" style="font-style:italic;">T</span><span class="font53"> simply reverses the order of the eight input bits (so that, for example, 11110000 becomes 00001111). Further suppose that the 64-bit scrambler does not modify any bits (so that the output value of the </span><span class="font53" style="font-style:italic;">mth</span><span class="font53"> bit is equal to the input value of the </span><span class="font53" style="font-style:italic;">m</span><span class="font53">th bit). (a) With </span><span class="font53" style="font-style:italic;">n =</span><span class="font53"> 3 and the original 64-bit input equal to 10100000 repeated eight times, what is the value of the output? (b) Repeat part (a) but now change the last bit of the original 64-bit input from a 0 to a 1. (c) Repeat parts (a) and (b) but now suppose that the 64-bit scrambler inverses the order of the 64 bits.</span></p>
<p><span class="font53">P5. Encode the plaintext 000001011111 with the 3-bit block cipher in Table 8.1 and IV </span><span class="font54">= </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(0) </span><span class="font54">= </span><span class="font53">001. Then show that the receiver can decode the ciphertext, knowing IV and </span><span class="font53" style="font-style:italic;">K<sub>S</sub>.</span></p>
<p><span class="font53">P6. The ciphertext for the 3-bit block cipher in Table 8.1 with plaintext 010010010 and IV </span><span class="font54">= </span><span class="font53" style="font-style:italic;">c</span><span class="font53"> (0) </span><span class="font54">= </span><span class="font53">001 becomes:</span></p>
<p><span class="font53" style="font-style:italic;">c</span><span class="font53">(1) </span><span class="font54">= </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">s</span><span class="font53" style="font-style:italic;">(m(1)</span><span class="font54"> © </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(0)) </span><span class="font54">= </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">s</span><span class="font53">(010 </span><span class="font54">© </span><span class="font53">001) </span><span class="font54">= </span><span class="font53" style="font-style:italic;">K</span><span class="font50" style="font-style:italic;">s</span><span class="font53">(011) </span><span class="font54">= </span><span class="font53">100,</span></p>
<p><span class="font53" style="font-style:italic;">c</span><span class="font53">(2) </span><span class="font54">= </span><span class="font53" style="font-style:italic;">K<sub>s</sub></span><span class="font53">(</span><span class="font53" style="font-style:italic;">m</span><span class="font53">(2) </span><span class="font54">© </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(1)) </span><span class="font54">= </span><span class="font53" style="font-style:italic;">K<sub>s</sub></span><span class="font53">(010 </span><span class="font54">© </span><span class="font53">100) </span><span class="font54">= </span><span class="font53" style="font-style:italic;">K<sub>s</sub></span><span class="font53">(110) </span><span class="font54">= </span><span class="font53">000, and</span></p>
<p><span class="font53" style="font-style:italic;">c</span><span class="font53">(3) </span><span class="font54">= </span><span class="font53" style="font-style:italic;">K<sub>s</sub></span><span class="font53">(</span><span class="font53" style="font-style:italic;">m</span><span class="font53">(3) </span><span class="font54">© </span><span class="font53" style="font-style:italic;">c</span><span class="font53">(2)) </span><span class="font54">= </span><span class="font53" style="font-style:italic;">K<sub>s</sub></span><span class="font53">(010 </span><span class="font54">© </span><span class="font53">000) </span><span class="font54">= </span><span class="font53" style="font-style:italic;">K<sub>s</sub></span><span class="font53">(010) </span><span class="font54">= </span><span class="font53">101.</span></p>
<p><span class="font53">Verify that the receiver, knowing IV and </span><span class="font53" style="font-style:italic;">K<sub>s</sub></span><span class="font53">, can recover the original plaintext from the ciphertext 100000101.</span></p>
<p><span class="font53">P7. a. Using RSA, choose </span><span class="font53" style="font-style:italic;">p =</span><span class="font53"> 5 and </span><span class="font53" style="font-style:italic;">q =</span><span class="font53"> 7, and encode the numbers 12, 19, and 27 separately. Apply the decryption algorithm to the encrypted version to recover the original plaintext message.</span></p>
<ul style="list-style:none;"><li>
<p class="font53">b. Choose <span class="font53" style="font-style:italic;">p</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">q</span><span class="font53"> of your own and encrypt 1834 as one message </span><span class="font53" style="font-style:italic;">m</span><span class="font53">.</span></p></li></ul>
<p><span class="font53">P8. Consider RSA with </span><span class="font53" style="font-style:italic;">p =</span><span class="font53"> 7 and </span><span class="font53" style="font-style:italic;">q =</span><span class="font53"> 13.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. What are </span><span class="font53" style="font-style:italic;">n</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">z?</span></p></li>
<li>
<p><span class="font53">b. Let </span><span class="font53" style="font-style:italic;">e</span><span class="font53"> be 17. Why is this an acceptable choice for </span><span class="font53" style="font-style:italic;">e?</span></p></li>
<li>
<p><span class="font53">c. Find </span><span class="font53" style="font-style:italic;">d</span><span class="font53"> such that </span><span class="font53" style="font-style:italic;">de =</span><span class="font53"> 1 (mod </span><span class="font53" style="font-style:italic;">z</span><span class="font53">).</span></p></li>
<li>
<p><span class="font53">d. Encrypt the message </span><span class="font53" style="font-style:italic;">m =</span><span class="font53"> 9 using the key (</span><span class="font53" style="font-style:italic;">n</span><span class="font53">, </span><span class="font53" style="font-style:italic;">e</span><span class="font53">). Let </span><span class="font53" style="font-style:italic;">c</span><span class="font53"> denote the corresponding ciphertext. Show all work.</span></p></li></ul>
<p><span class="font53">P9. In this problem, we explore the Diffie-Hellman (DH) public-key encryption algorithm, which allows two entities to agree on a shared key. The DH algorithm makes use of a large prime number </span><span class="font53" style="font-style:italic;">p</span><span class="font53"> and another large number </span><span class="font53" style="font-style:italic;">g</span><span class="font53"> less than </span><span class="font53" style="font-style:italic;">p</span><span class="font53">. Both </span><span class="font53" style="font-style:italic;">p</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">g</span><span class="font53"> are made public (so that an attacker would know them). In DH, Alice and Bob each independently choose secret keys, </span><span class="font53" style="font-style:italic;">s<sub>A</sub></span><span class="font53"> and </span><span class="font53" style="font-style:italic;">s<sub>B</sub>, </span><span class="font53">respectively. Alice then computes her public key, </span><span class="font53" style="font-style:italic;">T</span><span class="font50" style="font-style:italic;">A</span><span class="font53" style="font-style:italic;">,</span><span class="font53"> by raising </span><span class="font53" style="font-style:italic;">g</span><span class="font53"> to </span><span class="font53" style="font-style:italic;">s<sub>A</sub></span><span class="font53"> and then taking mod</span><span class="font53" style="font-style:italic;">p</span><span class="font53">. Bob similarly computes his own public key </span><span class="font53" style="font-style:italic;">T</span><span class="font50" style="font-style:italic;">B</span><span class="font53"> by raising </span><span class="font53" style="font-style:italic;">g</span><span class="font53"> to </span><span class="font53" style="font-style:italic;">s<sub>B</sub></span><span class="font53"> and then taking mod</span><span class="font53" style="font-style:italic;">p</span><span class="font53">. Alice and Bob then exchange their public keys over the Internet. Alice then calculates the shared secret key </span><span class="font53" style="font-style:italic;">s</span><span class="font53"> by raising </span><span class="font53" style="font-style:italic;">T<sub>B </sub></span><span class="font53">to </span><span class="font53" style="font-style:italic;">s<sub>A</sub></span><span class="font53"> and then taking mod</span><span class="font53" style="font-style:italic;">p</span><span class="font53">. Similarly, Bob calculates the shared key </span><span class="font53" style="font-style:italic;">s'</span><span class="font53"> by raising </span><span class="font53" style="font-style:italic;">T<sub>A</sub></span><span class="font53"> to </span><span class="font53" style="font-style:italic;">s<sub>B</sub></span><span class="font53"> and then taking mod </span><span class="font53" style="font-style:italic;">p</span><span class="font53">.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Prove that, in general, Alice and Bob obtain the same symmetric key, that is, prove </span><span class="font53" style="font-style:italic;">s</span><span class="font54"> = </span><span class="font53" style="font-style:italic;">s</span><span class="font54"> '</span><span class="font53">.</span></p></li>
<li>
<p><span class="font53">b. With </span><span class="font53" style="font-style:italic;">p</span><span class="font53"> = 11 and </span><span class="font53" style="font-style:italic;">g</span><span class="font53"> = 2, suppose Alice and Bob choose private keys </span><span class="font53" style="font-style:italic;">s<sub>A</sub> =</span><span class="font53"> 5 and </span><span class="font53" style="font-style:italic;">s<sub>B</sub> =</span><span class="font53"> 12, respectively. Calculate Alice’s and Bob’s public keys, </span><span class="font53" style="font-style:italic;">T<sub>A </sub></span><span class="font53">and </span><span class="font53" style="font-style:italic;font-variant:small-caps;">T</span><span class="font11" style="font-style:italic;font-variant:small-caps;"><sub>b</sub></span><span class="font54" style="font-style:italic;font-variant:small-caps;">.</span><span class="font53"> Show all work.</span></p></li>
<li>
<p><span class="font53">c. Following up on part (b), now calculate </span><span class="font53" style="font-style:italic;">s</span><span class="font53"> as the shared symmetric key. Show all work.</span></p></li>
<li>
<p><span class="font53">d. Provide a timing diagram that shows how Diffie-Hellman can be attacked by a man-in-the-middle. The timing diagram should have three vertical lines, one for Alice, one for Bob, and one for the attacker Trudy.</span></p></li></ul>
<p><span class="font53">P10. Suppose Alice wants to communicate with Bob using symmetric key cryptography using a session key </span><span class="font53" style="font-style:italic;">K<sub>S</sub>.</span><span class="font53"> In Section 8.2, we learned how public-key cryptography can be used to distribute the session key from Alice to Bob. In this problem, we explore how the session key can be distributed—without public key cryptography—using a key distribution center (KDC). The KDC is a server that shares a unique secret symmetric key with each registered user. For Alice and Bob, denote these keys by </span><span class="font53" style="font-style:italic;font-variant:small-caps;">K<sub>a</sub></span><span class="font48" style="font-style:italic;font-variant:small-caps;">@</span><span class="font11" style="font-style:italic;font-variant:small-caps;"><sub>kdc</sub></span><span class="font53"> and </span><span class="font53" style="font-style:italic;font-variant:small-caps;">K</span><span class="font11" style="font-style:italic;font-variant:small-caps;"><sub>b</sub></span><span class="font48" style="font-style:italic;font-variant:small-caps;">@</span><span class="font11" style="font-style:italic;font-variant:small-caps;"><sub>kdc</sub></span><span class="font54" style="font-style:italic;font-variant:small-caps;">.</span><span class="font53"> Design a scheme that uses the KDC to distribute </span><span class="font53" style="font-style:italic;">K<sub>S</sub></span><span class="font53"> to Alice and Bob. Your scheme should use three messages to distribute the session key: a message from Alice to the KDC; a message from the KDC to Alice; and finally a message from Alice to Bob. The first message is </span><span class="font53" style="font-style:italic;font-variant:small-caps;">K<sub>a</sub></span><span class="font48" style="font-style:italic;font-variant:small-caps;">@</span><span class="font11" style="font-style:italic;font-variant:small-caps;"><sub>kdc</sub></span><span class="font53" style="font-style:italic;"> (A, B).</span><span class="font53"> Using the notation, </span><span class="font53" style="font-style:italic;font-variant:small-caps;">K</span><span class="font11" style="font-style:italic;font-variant:small-caps;"><sub>a</sub></span><span class="font48" style="font-style:italic;font-variant:small-caps;">@</span><span class="font11" style="font-style:italic;font-variant:small-caps;"><sub>kdc</sub></span><span class="font54" style="font-style:italic;font-variant:small-caps;">, </span><span class="font53" style="font-style:italic;font-variant:small-caps;">K</span><span class="font11" style="font-style:italic;font-variant:small-caps;"><sub>b</sub></span><span class="font48" style="font-style:italic;font-variant:small-caps;">@</span><span class="font11" style="font-style:italic;font-variant:small-caps;"><sub>kdc</sub></span><span class="font53" style="font-style:italic;font-variant:small-caps;">, S, A,</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">B</span><span class="font53"> answer the following questions.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. What is the second message?</span></p></li>
<li>
<p><span class="font53">b. What is the third message?</span></p></li></ul>
<p><span class="font53">P11. Compute a third message, different from the two messages in Figure 8.8, that has the same checksum as the messages in Figure 8.8.</span></p>
<p><span class="font53">P12. The sender can mix some randomness into the ciphertext so that identical plaintext blocks produce different ciphertext blocks. But for each cipher bit, the sender must now also send a random bit, doubling the required bandwidth. Is there any way around this?</span></p>
<p><span class="font53">P13. In the BitTorrent P2P file distribution protocol (see Chapter 2), the seed breaks the file into blocks, and the peers redistribute the blocks to each other. Without any protection, an attacker can easily wreak havoc in a torrent by masquerading as a benevolent peer and sending bogus blocks to a small subset of peers in the torrent. These unsuspecting peers then redistribute the bogus blocks to other peers, which in turn redistribute the bogus blocks to even more peers. Thus, it is critical for BitTorrent to have a mechanism that allows a peer to verify the integrity of a block, so that it doesn’t redistribute bogus blocks. Assume that when a peer joins a torrent, it initially gets a </span><span class="font36">.torrent </span><span class="font53">file from a </span><span class="font53" style="font-style:italic;">fully</span><span class="font53"> trusted source. Describe a simple scheme that allows peers to verify the integrity of blocks.</span></p>
<p><span class="font53">P14. Solving factorization in polynomial time implies breaking the RSA cryptosystem. Is the converse true?</span></p>
<p><span class="font53">P15. Consider our authentication protocol in Figure 8.18 in which Alice authenticates herself to Bob, which we saw works well (i.e., we found no flaws in it). Now suppose that while Alice is authenticating herself to Bob, Bob must authenticate himself to Alice. Give a scenario by which Trudy, pretending to be Alice, can now authenticate herself to Bob as Alice. </span><span class="font53" style="font-style:italic;">(Hint:</span><span class="font53"> Consider that the sequence of operations of the protocol, one with Trudy initiating and one with Bob initiating, can be arbitrarily interleaved. Pay particular attention to the fact that both Bob and Alice will use a nonce, and that if care is not taken, the same nonce can be used maliciously.)</span></p>
<p><span class="font53">P16. A natural question is whether we can use a nonce and public key cryptography to solve the end-point authentication problem in Section 8.4. Consider the following natural protocol: (1) Alice sends the message </span><span class="font36">&quot;I am Alice” </span><span class="font53">to Bob. (2) Bob chooses a nonce, </span><span class="font53" style="font-style:italic;">R,</span><span class="font53"> and sends it to Alice. (3) Alice uses her </span><span class="font53" style="font-style:italic;">private</span><span class="font53"> key to encrypt the nonce and sends the resulting value to Bob. (4) Bob applies Alice’s public key to the received message. Thus, Bob computes </span><span class="font53" style="font-style:italic;">R</span><span class="font53"> and authenticates Alice.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Diagram this protocol, using the notation for public and private keys employed in the textbook.</span></p></li>
<li>
<p><span class="font53">b. Suppose that certificates are not used. Describe how Trudy can become a “woman-in-the-middle” by intercepting Alice’s messages and then pretending to be Alice to Bob.</span></p></li></ul>
<p><span class="font53">P17. Figure 8.21 shows the operations that Alice must perform with PGP to provide confidentiality, authentication, and integrity. Diagram the corresponding operations that Bob must perform on the package received from Alice.</span></p>
<p><span class="font53">P18. Suppose Alice wants to send an e-mail to Bob. Bob has a public-private key pair </span><span class="font53" style="font-style:italic;">(K</span><span class="font50">B</span><span class="font53">, </span><span class="font53" style="font-style:italic;">K</span><span class="font3">-</span><span class="font53">), and Alice has Bob’s certificate. But Alice does not have a public, private key pair. Alice and Bob (and the entire world) share the same hash function H(</span><span class="font60">-</span><span class="font53">).</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. In this situation, is it possible to design a scheme so that Bob can verify that Alice created the message? If so, show how with a block diagram for Alice and Bob.</span></p></li>
<li>
<p><span class="font53">b. Is it possible to design a scheme that provides confidentiality for sending the message from Alice to Bob? If so, show how with a block diagram for Alice and Bob.</span></p></li></ul>
<p><span class="font53">P19. Consider the Wireshark output below for a portion of an SSL session.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Is Wireshark packet 112 sent by the client or server?</span></p></li>
<li>
<p><span class="font53">b. What is the server’s IP address and port number?</span></p></li>
<li>
<p><span class="font53">c. Assuming no loss and no retransmissions, what will be the sequence number of the next TCP segment sent by the client?</span></p></li>
<li>
<p><span class="font53">d. How many SSL records does Wireshark packet 112 contain?</span></p></li>
<li>
<p><span class="font53">e. Does packet 112 contain a Master Secret or an Encrypted Master Secret or neither?</span></p></li>
<li>
<p><span class="font53">f. Assuming that the handshake type field is 1 byte and each length field is 3 bytes, what are the values of the first and last bytes of the Master Secret (or Encrypted Master Secret)?</span></p></li>
<li>
<p><span class="font53">g. The client encrypted handshake message takes into account how many SSL records?</span></p></li>
<li>
<p><span class="font53">h. The server encrypted handshake message takes into account how many SSL records?</span></p></li></ul>
<p><span class="font53">P20. In Section 8.6.1, it is shown that without sequence numbers, Trudy (a woman-in-the middle) can wreak havoc in a TLS session by interchanging TCP segments. Can Trudy do something similar by deleting a TCP segment? What does she need to do to succeed at the deletion attack? What effect will it have?</span></p><img src="networking_files/networking-627.jpg" alt="" style="width:432pt;height:302pt;">
<p><span class="font5">(Wireshark screenshot reprinted by permission of the Wireshark Foundation.)</span></p>
<p><span class="font53">P21. A router’s link-state message includes a list of its directly connected neighbors and the direct costs to these neighbors. Once a router receives link-state messages from all of the other routers, it can create a complete map of the network, run its least-cost routing algorithm, and configure its forwarding table. One relatively easy attack on the routing algorithm is for the attacker to distribute bogus linkstate messages with incorrect link-state information. How can this be prevented?</span></p>
<p><span class="font53">P22. The following true/false questions pertain to Figure 8.28.</span></p>
<p><span class="font53">a. When a host in 172.16.1/24 sends a datagram to an </span><a href="http://Amazon.com"><span class="font53">Amazon.com</span></a><span class="font53"> server, the router R1 will encrypt the datagram using IPsec.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">b. When a host in 172.16.1/24 sends a datagram to a host in 172.16.2/24, the router R1 will change the source and destination address of the IP datagram.</span></p></li>
<li>
<p><span class="font53">c. Suppose a host in 172.16.1/24 initiates a TCP connection to a Web server in 172.16.2/24. As part of this connection, all datagrams sent by R1 will have protocol number 50 in the left-most IPv4 header field.</span></p></li>
<li>
<p><span class="font53">d. Consider sending a TCP segment from a host in 172.16.1/24 to a host in 172.16.2/24. Suppose the acknowledgment for this segment gets lost, so that TCP resends the segment. Because IPsec uses sequence numbers, R1 will not resend the TCP segment.</span></p></li></ul>
<p><span class="font53">P23. When Bob signs a message, Bob must put something on the message that is unique to him. Bob could consider attaching a MAC for the signature, where the MAC is created by appending his key (unique to him) to the message, and then taking the hash. Will it cause any problem when Alice would try verification?</span></p>
<p><span class="font53">P24. Provide a filter table and a connection table for a stateful firewall that is as restrictive as possible but accomplishes the following:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Allows all internal users to establish Telnet sessions with external hosts.</span></p></li>
<li>
<p><span class="font53">b. Allows external users to surf the company Web site at 222.22.0.12.</span></p></li>
<li>
<p><span class="font53">c. But otherwise blocks all inbound and outbound traffic.</span></p></li></ul>
<p><span class="font53">The internal network is 222.22/16. In your solution, suppose that the connection table is currently caching three connections, all from inside to outside. You’ll need to invent appropriate IP addresses and port numbers.</span></p>
<p><span class="font53">P25. Suppose Alice wants to visit the Web site </span><a href="http://activist.com"><span class="font53">activist.com </span></a><span class="font53">using a TOR-like service. This service uses two non-colluding proxy servers, Proxy1 and Proxy2. Alice first obtains the certificates (each containing a public key) for Proxy1 and Proxy2 from some central server. Denote </span><span class="font53" style="font-style:italic;">K</span><span class="font3" style="font-style:italic;">+</span><span class="font53" style="font-style:italic;">(</span><span class="font53"> ), </span><span class="font53" style="font-style:italic;">K</span><span class="font3" style="font-style:italic;">+</span><span class="font53" style="font-style:italic;">(</span><span class="font53"> ), </span><span class="font53" style="font-style:italic;">K</span><span class="font3" style="font-style:italic;">-</span><span class="font53" style="font-style:italic;">(</span><span class="font53"> ), and </span><span class="font53" style="font-style:italic;">K</span><span class="font3">-</span><span class="font53">( ) for the encryption/decryption with public and private RSA keys.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">a. Using a timing diagram, provide a protocol (as simple as possible) that enables Alice to establish a shared session key </span><span class="font53" style="font-style:italic;">S</span><span class="font53"><sub>1</sub> with Proxy1. Denote </span><span class="font53" style="font-style:italic;">S<sub>1</sub>(m)</span><span class="font53"> for encryption/decryption of data </span><span class="font53" style="font-style:italic;">m</span><span class="font53"> with the shared key </span><span class="font53" style="font-style:italic;">S</span><span class="font53"><sub>1</sub>.</span></p></li>
<li>
<p><span class="font53">b. Using a timing diagram, provide a protocol (as simple as possible) that allows Alice to establish a shared session key </span><span class="font53" style="font-style:italic;">S</span><span class="font53"><sub>2</sub> with Proxy2 </span><span class="font53" style="font-style:italic;">without revealing her IP address to Proxy2.</span></p></li>
<li>
<p><span class="font53">c. Assume now that shared keys </span><span class="font53" style="font-style:italic;">S</span><span class="font53"><sub>1</sub> and </span><span class="font53" style="font-style:italic;">S</span><span class="font53"><sub>2</sub> are now established. Using a timing diagram, provide a protocol (as simple as possible and </span><span class="font53" style="font-style:italic;">not using public-key cryptography</span><span class="font53">) that allows Alice to request an html page from </span><a href="http://activist.com"><span class="font53">activist.com </span></a><span class="font53" style="font-style:italic;">without revealing her IP address to Proxy2</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">without revealing to Proxy1 which site she is visiting.</span><span class="font53"> Your diagram should end with an HTTP request arriving at </span><a href="http://activist.com"><span class="font53">activist.com</span></a><span class="font53">.</span></p></li></ul>
<p><span class="font24" style="font-weight:bold;">Wireshark Lab: SSL</span></p>
<p><span class="font53">In this lab (available from the book Web site), we investigate the Secure Sockets Layer (SSL) protocol. Recall from Section 8.6 that SSL is used for securing a TCP connection, and that it is extensively used in practice for secure Internet transactions. In this lab, we will focus on the SSL records sent over the TCP connection. We will attempt to delineate and classify each of the records, with a goal of understanding the why and how for each record. We investigate the various SSL record types as well as the fields in the SSL messages. We do so by analyzing a trace of the SSL records sent between your host and an e-commerce server.</span></p>
<p><span class="font24" style="font-weight:bold;">IPsec Lab</span></p>
<p><a name="bookmark473"></a><span class="font53">In this lab (available from the book Web site), we will explore how to create IPsec SAs between linux boxes. You can do the first part of the lab with two ordinary linux boxes, each with one Ethernet adapter. But for the second part of the lab, you will need four linux boxes, two of which having two Ethernet adapters. In the second half of the lab, you will create IPsec SAs using the ESP protocol in the tunnel mode. You will do this by first manually creating the SAs, and then by having IKE create the SAs.</span></p>
<p><span class="font23" style="font-weight:bold;">AN INTERVIEW WITH...</span></p>
<div><img src="networking_files/networking-628.jpg" alt="" style="width:86pt;height:110pt;">
<p><span class="font3">Courtesy of Steven Bellovin</span></p>
</div><br clear="all">
<p><span class="font11" style="font-weight:bold;">Steven M. Bellovin</span></p>
<p><span class="font46">Steven M. Bellovin joined the faculty at Columbia University after many years at the Network Services Research Lab at AT&amp;T Labs Research in Florham Park, New Jersey. His focus is on networks, security, and why the two are incompatible. In 1995, he was awarded the Usenix Lifetime Achievement Award for his work in the creation of Usenet, the first newsgroup exchange network that linked two or more computers and allowed users to share information and join in discussions. Steve is also an elected member of the National Academy of Engineering. He received his BA from Columbia University and his PhD from the University of North Carolina at Chapel Hill.</span></p>
<p><span class="font4" style="font-weight:bold;">What led you to specialize in the networking security area?</span></p>
<p><span class="font52">This is going to sound odd, but the answer is simple: It was fun. My background was in systems programming and systems administration, which leads fairly naturally to security. And I’ve always been interested in communications, ranging back to part-time systems programming jobs when I was in college.</span></p>
<p><span class="font52">My work on security continues to be motivated by two things—a desire to keep computers useful, which means that their function can’t be corrupted by attackers, and a desire to protect privacy.</span></p>
<p><span class="font4" style="font-weight:bold;">What was your vision for Usenet at the time that you were developing it? And now?</span></p>
<p><span class="font52">We originally viewed it as a way to talk about computer science and computer programming around the country, with a lot of local use for administrative matters, for-sale ads, and so on. In fact, my original prediction was one to two messages per day, from 50 to 100 sites at the most—ever. However, the real growth was in people-related topics, including—but not limited to—human interactions with computers. My favorite newsgroups, over the years, have been things like rec.woodworking, as well as sci.crypt.</span></p>
<p><span class="font52">To some extent, netnews has been displaced by the Web. Were I to start designing it today, it would look very different. But it still excels as a way to reach a very broad audience that is interested in the topic, without having to rely on particular Web sites.</span></p>
<p><span class="font4" style="font-weight:bold;">Has anyone inspired you professionally? In what ways?</span></p>
<p><a name="bookmark474"></a><span class="font52">Professor Fred Brooks—the founder and original chair of the computer science department at the University of North Carolina at Chapel Hill, the manager of the team that developed the IBM S/360 and OS/360, and the author of </span><span class="font52" style="font-style:italic;">The Mythical Man-Month—</span><span class="font52">was a tremendous influence on my career. More than anything else, he taught outlook and trade-offs—how to look at problems in the context of the real world (and how much messier the real world is than a theorist would like), and how to balance competing interests in designing a solution. Most computer work is engineering—the art of making the right trade-offs to satisfy many contradictory objectives.</span></p>
<p><span class="font4" style="font-weight:bold;">What is your vision for the future of networking and security?</span></p>
<p><span class="font52">Thus far, much of the security we have has come from isolation. A firewall, for example, works by cutting off access to certain machines and services. But we’re in an era of increasing connectivity—it’s gotten harder to isolate things. Worse yet, our production systems require far more separate pieces, interconnected by networks. Securing all that is one of our biggest challenges.</span></p>
<p><span class="font4" style="font-weight:bold;">What would you say have been the greatest advances in security? How much further do we have to go?</span></p>
<p><span class="font52">At least scientifically, we know how to do cryptography. That’s been a big help. But most security problems are due to buggy code, and that’s a much harder problem. In fact, it’s the oldest unsolved problem in computer science, and I think it will remain that way. The challenge is figuring out how to secure systems when we have to build them out of insecure components. We can already do that for reliability in the face of hardware failures; can we do the same for security?</span></p>
<p><span class="font4" style="font-weight:bold;">Do you have any advice for students about the Internet and networking security?</span></p>
<p><span class="font52">Learning the mechanisms is the easy part. Learning how to “think paranoid” is harder. You have to remember that probability distributions don’t apply—the attackers can and will find improbable conditions. And the details matter—a lot.</span></p>
<h1><a name="bookmark9"></a><span class="font27" style="font-weight:bold;">References</span></h1>
<p><span class="font53" style="font-weight:bold;">A note on URLs. </span><span class="font53">In the references below, we have provided URLs for Web pages, Web-only documents, and other material that has not been published in a conference or journal (when we have been able to locate a URL for such material). We have not provided URLs for conference and journal publications, as these documents can usually be located via a search engine, from the conference Web site (e.g., papers in all </span><span class="font53" style="font-style:italic;">ACM SIGCOMM</span><span class="font53"> conferences and workshops can be located via </span><a href="http://www.acm.org/sigcomm"><span class="font53">http://www.acm.org/sigcomm)</span></a><span class="font53">, or via a digital library subscription. While all URLs provided below were valid (and tested) in Jan. 2020, URLs can become out of date.</span></p>
<p><span class="font53" style="font-weight:bold;">A note on Internet Request for Comments (RFCs): </span><span class="font53">Copies of Internet RFCs are available at many sites. The RFC Editor of the Internet Society (the body that oversees the RFCs) maintains the site, </span><a href="http://www.rfc-editor.org"><span class="font53">http://www.rfc-editor.org</span></a><span class="font53">. This site allows you to search for a specific RFC by title, number, or authors, and will show updates to any RFCs listed. Internet RFCs can be updated or obsoleted by later RFCs. Our favorite site for getting RFCs is the original source—</span><a href="http://www.rfc-editor.org"><span class="font53">http://www.rfc-editor.org</span></a><span class="font53">.</span></p>
<p><span class="font53" style="font-weight:bold;">[3GPP 2020] </span><span class="font53">3GPP, 3GPP Specification Set, </span><a href="https://www.3gpp.org/dynareport/SpecList.htm"><span class="font53">https://www.3gpp.org/dynareport/</span></a><span class="font53"> </span><a href="https://www.3gpp.org/dynareport/SpecList.htm"><span class="font53">SpecList.htm</span></a></p>
<p><span class="font53" style="font-weight:bold;">[3GPP GTPv1-U 2019] </span><span class="font53">3GPP, “Tunnelling Protocol User Plane (GTPv1-U),” 3GPP Technical Specification 29.281version 15.3.0, 2018.</span></p>
<p><span class="font53" style="font-weight:bold;">[3GPP PDCP 2019] </span><span class="font53">3GPP, “Packet Data Convergence Protocol (PDCP) Specification,” 3GPP Technical Specification 36.323 version 15.4.0, 2019.</span></p>
<p><span class="font53" style="font-weight:bold;">[3GPP RLCP 2018] </span><span class="font53">3GPP, “Radio Link Control (RLC) protocol specification,” 3GPP Technical Specification 25.322 version 15.0.0, 2018.</span></p>
<p><span class="font53" style="font-weight:bold;">[3GPP SAE 2019] </span><span class="font53">3GPP, “System Architecture Evolution (SAE); Security architecture,” Technical Specification 33.401, version 15.9.0, October 2019.”</span></p>
<p><span class="font53" style="font-weight:bold;">[Abramson 1970] </span><span class="font53">N. Abramson, “The Aloha System—Another Alternative for Computer Communications,” </span><span class="font53" style="font-style:italic;">Proc. 1970 Fall Joint Computer Conference, AFIPS Conference,</span><span class="font53"> p. 37, 1970.</span></p>
<p><span class="font53" style="font-weight:bold;">[Abramson 1985] </span><span class="font53">N. Abramson, “Development of the Alohanet,” </span><span class="font53" style="font-style:italic;">IEEE Transactions on Information Theory,</span><span class="font53"> Vol. IT-31, No. 3 (Mar. 1985), pp. 119-123.</span></p>
<p><a name="bookmark475"></a><span class="font53" style="font-weight:bold;">[Abramson 2009] </span><span class="font53">N. Abramson, “The Alohanet—Surfing for Wireless Data,” </span><span class="font53" style="font-style:italic;">IEEE Communications Magazine,</span><span class="font53"> Vol. 47, No. 12, pp. 21-25.</span></p>
<p><span class="font53" style="font-weight:bold;">[Adhikari 2011a] </span><span class="font53">V. K. Adhikari, S. Jain, Y. Chen, Z. L. Zhang, “Vivisecting YouTube: An Active Measurement Study,” Technical Report, University of Minnesota, 2011.</span></p>
<p><span class="font53" style="font-weight:bold;">[Adhikari 2012] </span><span class="font53">V. K. Adhikari, Y. Gao, F. Hao, M. Varvello, V. Hilt, M. Steiner, Z. L. Zhang, “Unreeling Netflix: Understanding and Improving Multi-CDN Movie Delivery,” Technical Report, University of Minnesota, 2012.</span></p>
<p><span class="font53" style="font-weight:bold;">[Afanasyev 2010] </span><span class="font53">A. Afanasyev, N. Tilley, P. Reiher, L. Kleinrock, “Host-to-Host Congestion Control for TCP,” </span><span class="font53" style="font-style:italic;">IEEE Communications Surveys &amp;&nbsp;Tutorials,</span><span class="font53"> Vol. 12, No. 3, pp. 304-342.</span></p>
<p><span class="font53" style="font-weight:bold;">[Agarwal 2009] </span><span class="font53">S. Agarwal, J. Lorch, “Matchmaking for Online Games and Other Latency-sensitive P2P Systems,” </span><span class="font53" style="font-style:italic;">Proc. 2009 ACM SIGCOMM.</span></p>
<p><span class="font53" style="font-weight:bold;">[Ager 2012] </span><span class="font53">B. Ager, N. Chatzis, A. Feldmann, N. Sarrar, S. Uhlig, W. Willinger, “Anatomy of a Large European ISP,” </span><span class="font53" style="font-style:italic;">Proc. 2012 ACM SIGCOMM.</span></p>
<p><span class="font53" style="font-weight:bold;">[Akamai 2020] </span><span class="font53">Akamai homepage, </span><a href="http://www.akamai.com"><span class="font53">http://www.akamai.com</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Akella 2003] </span><span class="font53">A. Akella, S. Seshan, A. Shaikh, “An Empirical Evaluation of Wide-Area Internet Bottlenecks,” </span><span class="font53" style="font-style:italic;">Proc. 2003 ACM Internet Measurement Conference </span><span class="font53">(Miami, FL, Nov. 2003).</span></p>
<p><span class="font53" style="font-weight:bold;">[Akhshabi 2011] </span><span class="font53">S. Akhshabi, A. C. Begen, C. Dovrolis, “An Experimental Evaluation of Rate-Adaptation Algorithms in Adaptive Streaming over HTTP,” </span><span class="font53" style="font-style:italic;">Proc. 2011 ACM Multimedia Systems Conf</span><span class="font53">.</span></p>
<p><span class="font53" style="font-weight:bold;">[Akhshabi 2011] </span><span class="font53">S. Akhshabi, C. Dovrolis, “The evolution of layered protocol stacks leads to an hourglass-shaped architecture,” </span><span class="font53" style="font-style:italic;">Proceedings 2011 ACM SIGCOMM,</span><span class="font53"> pp. 206-217.</span></p>
<p><span class="font53" style="font-weight:bold;">[Akyildiz 2010] </span><span class="font53">I. Akyildiz, D. Gutierrex-Estevez, E. Reyes, “The Evolution to 4G Cellular Systems, LTE Advanced,” </span><span class="font53" style="font-style:italic;">Physical Communication,</span><span class="font53"> Elsevier, 3 (2010), pp. 217-244.</span></p>
<p><span class="font53" style="font-weight:bold;">[Albitz 1993] </span><span class="font53">P. Albitz and C. Liu, </span><span class="font53" style="font-style:italic;">DNS and BIND,</span><span class="font53"> O’Reilly &amp;&nbsp;Associates, Petaluma, CA, 1993.</span></p>
<p><span class="font53" style="font-weight:bold;">[Alexandris 2016] </span><span class="font53">K. Alexandris, N. Nikaein, R. Knopp and C. Bonnet, “Analyzing X2 handover in LTE/LTE-A,” </span><span class="font53" style="font-style:italic;">201614th International Symposium on Modeling and Optimization in Mobile, Ad Hoc, and Wireless Networks (WiOpt),</span><span class="font53"> Tempe, AZ, pp. 1-7.</span></p>
<p><span class="font53" style="font-weight:bold;">[Alizadeh 2010] </span><span class="font53">M. Alizadeh, A. Greenberg, D. Maltz, J. Padhye, P. Patel,</span></p>
<p><span class="font53">B. Prabhakar, S. Sengupta, M. Sridharan. “Data center TCP (DCTCP),” </span><span class="font53" style="font-style:italic;">Proc. 2010 ACM SIGCOMM Conference,</span><span class="font53"> ACM, New York, NY, USA, pp. 63-74.</span></p>
<p><span class="font53" style="font-weight:bold;">[Alizadeh 2013] </span><span class="font53">M. Alizadeh, S. Yang, M. Sharif, S. Katti, N. McKeown, B. Prabhakar, S. Shenker, “pFabric: Minimal Near-Optimal Datacenter Transport,” </span><span class="font53" style="font-style:italic;">Proc. 2013 ACM SIGCOMM Conference.</span></p>
<p><span class="font53" style="font-weight:bold;">[Alizadeh 2014] </span><span class="font53">M. Alizadeh, T. Edsall, S. Dharmapurikar, K. Chu, A. Fingerhut, V. T. Lam, F. Matus, R. Pan, N. Yadav, G. Varghese , “CONGA: Distributed Congestion-Aware Load Balancing for Datacenters,” </span><span class="font53" style="font-style:italic;">Proc. 2014 ACM SIGCOMM Conference.</span></p>
<p><span class="font53" style="font-weight:bold;">[Allman 2011] </span><span class="font53">E. Allman, “The Robustness Principle Reconsidered: Seeking a Middle Ground,” </span><span class="font53" style="font-style:italic;">Communications of the ACM,</span><span class="font53"> Vol. 54, No. 8 (Aug. 2011), pp. 40-45.</span></p>
<p><span class="font53" style="font-weight:bold;">[Aimers 2007] </span><span class="font53">P. Almers, et al., “Survey of Channel and Radio Propagation Models for Wireless MIMO Systems,” </span><span class="font53" style="font-style:italic;">Journal on Wireless Communications and Networking,</span><span class="font53"> 2007.</span></p>
<p><span class="font53" style="font-weight:bold;">[Amazon 2014] </span><span class="font53">J. Hamilton, </span><span class="font53" style="font-style:italic;">“AWS: Innovation at Scale,</span><span class="font53"> YouTube video, </span><a href="https://www.youtube.com/watch?v=JIQETrFC_SQ"><span class="font53">https://</span></a><span class="font53"> </span><a href="https://www.youtube.com/watch?v=JIQETrFC_SQ"><span class="font53">www.youtube.com/watch?v=JIQETrFC_SQ</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Anderson 1995] </span><span class="font53">J. B. Andersen, T. S. Rappaport, S. Yoshida, “Propagation Measurements and Models for Wireless Communications Channels,” </span><span class="font53" style="font-style:italic;">IEEE Communications Magazine,</span><span class="font53"> (Jan. 1995), pp. 42-49.</span></p>
<p><span class="font53" style="font-weight:bold;">[Appenzeller 2004] </span><span class="font53">G. Appenzeller, I. Keslassy, N. McKeown, “Sizing Router Buffers,” </span><span class="font53" style="font-style:italic;">Proc. 2004 ACM SIGCOMM Conference</span><span class="font53"> (Portland, OR, Aug. 2004).</span></p>
<p><span class="font53" style="font-weight:bold;">[Arkko 2012] </span><span class="font53">J. Arkko, “Analysing IP Mobility Protocol Deployment Difficulties,” 83rd IETF meeting, March, 2012.</span></p>
<p><span class="font53" style="font-weight:bold;">[ASO-ICANN 2020] </span><span class="font53">The Address Supporting Organization homepage, </span><a href="http://www.aso.icann.org"><span class="font53">http://www.aso.icann.org</span></a></p>
<p><span class="font53" style="font-weight:bold;">[AT&amp;T 2019] </span><span class="font53">A, Fuetsch, “From Next-Gen to Now: SDN, White Box and Open Source Go Mainstream,” </span><a href="https://about.att.com/innovationblog/2019/09/sdn_white_box_and_open_source_go_mainstream.html"><span class="font53">https://about.att.com/innovationblog/2019/09/sdn_white_</span></a><span class="font53"> </span><a href="https://about.att.com/innovationblog/2019/09/sdn_white_box_and_open_source_go_mainstream.html"><span class="font53">box_and_open_source_go_mainstream.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Atheros 2020] </span><span class="font53">Atheros Communications Inc., “Atheros AR5006 WLAN Chipset Product Bulletins,” </span><a href="http://www.atheros.com/pt/AR5006Bulletins.htm"><span class="font53">http://www.atheros.com/pt/AR5006Bulletins.htm</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Ayanoglu 1995] </span><span class="font53">E. Ayanoglu, S. Paul, T. F. La Porta, K. K. Sabnani, R. D. Gitlin, “AIRMAIL: A Link-Layer Protocol for Wireless Networks,” </span><span class="font53" style="font-style:italic;">ACM ACM/Baltzer Wireless Networks Journal</span><span class="font53">, 1: 47-60, Feb. 1995.</span></p>
<p><span class="font53" style="font-weight:bold;">[Bakre 1995] </span><span class="font53">A. Bakre, B. R. Badrinath, “I-TCP: Indirect TCP for Mobile Hosts,” </span><span class="font53" style="font-style:italic;">Proc. 1995 Int. Conf. on Distributed Computing Systems (ICDCS)</span><span class="font53"> (May 1995), pp. 136-143.</span></p>
<p><span class="font53" style="font-weight:bold;">[Baldauf 2007</span><span class="font53">] M. Baldauf, S. Dustdar, F. Rosenberg, “A Survey on Context-Aware Systems,” </span><span class="font53" style="font-style:italic;">Int. J. Ad Hoc and Ubiquitous Computing,</span><span class="font53"> Vol. 2, No. 4 (2007), pp. 263-277.</span></p>
<p><span class="font53" style="font-weight:bold;">[Baran 1964] </span><span class="font53">P. Baran, “On Distributed Communication Networks,” </span><span class="font53" style="font-style:italic;">IEEE Transactions on Communication Systems</span><span class="font53">, Mar. 1964. Rand Corporation Technical report with the same title (Memorandum RM-3420-PR, 1964). </span><a href="http://www.rand.org/publications/RM/RM3420/"><span class="font53">http://www.rand.org/publi-</span></a><span class="font53"></span><a href="http://www.rand.org/publications/RM/RM3420/"><span class="font53">cations/RM/RM3420/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Bardwell 2004] </span><span class="font53">J. Bardwell, “You Believe You Understand What You Think I Said . . . The Truth About 802.11 Signal and Noise Metrics: A Discussion Clarifying Often-Misused 802.11 WLAN Terminologies,” </span><a href="http://www.connect802.com/download/techpubs/2004/you_believe_D100201.pdf"><span class="font53">http://www.connect802.com/</span></a><span class="font53"> </span><a href="http://www.connect802.com/download/techpubs/2004/you_believe_D100201.pdf"><span class="font53">download/techpubs/2004/you_believe_D100201.pdf</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Barford 2009] </span><span class="font53">P. Barford, N. Duffield, A. Ron, J. Sommers, “Network Performance Anomaly Detection and Localization,” </span><span class="font53" style="font-style:italic;">Proc. 2009 IEEE INFOCOM </span><span class="font53">(Apr. 2009).</span></p>
<p><span class="font53" style="font-weight:bold;">[Beck 2019] </span><span class="font53">M. Beck, “On the hourglass model,” </span><span class="font53" style="font-style:italic;">Commun. ACM,</span><span class="font53"> Vol. 62, No. 7 (June 2019), pp. 48-57.</span></p>
<p><span class="font53" style="font-weight:bold;">[Beheshti 2008] </span><span class="font53">N. Beheshti, Y. Ganjali, M. Ghobadi, N. McKeown, G. Salmon, “Experimental Study of Router Buffer Sizing,” </span><span class="font53" style="font-style:italic;">Proc. ACM Internet Measurement Conference</span><span class="font53"> (Oct. 2008, Vouliagmeni, Greece).</span></p>
<p><span class="font53" style="font-weight:bold;">[Bender 2000] </span><span class="font53">P. Bender, P. Black, M. Grob, R. Padovani, N. Sindhushayana, A. Viterbi, “CDMA/HDR: A Bandwidth-Efficient High-Speed Wireless Data Service for Nomadic Users,” </span><span class="font53" style="font-style:italic;">IEEE Commun. Mag.,</span><span class="font53"> Vol. 38, No. 7 (July 2000), pp. 70-77.</span></p>
<p><span class="font53" style="font-weight:bold;">[Berners-Lee 1989] </span><span class="font53">T. Berners-Lee, CERN, “Information Management: A Proposal,” Mar. 1989, May 1990. </span><a href="http://www.w3.org/History/1989/proposal.html"><span class="font53">http://www.w3.org/History/1989/proposal.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Berners-Lee 1994] </span><span class="font53">T. Berners-Lee, R. Cailliau, A. Luotonen, H. Frystyk Nielsen, A. Secret, “The World-Wide Web,” </span><span class="font53" style="font-style:italic;">Communications of the ACM,</span><span class="font53"> Vol. 37, No. 8 (Aug. 1994), pp. 76-82.</span></p>
<p><span class="font53" style="font-weight:bold;">[Bertsekas 1991] </span><span class="font53">D. Bertsekas, R. Gallagher, </span><span class="font53" style="font-style:italic;">Data Networks,</span><span class="font53"> 2nd Ed., Prentice Hall, Englewood Cliffs, NJ, 1991.</span></p>
<p><span class="font53" style="font-weight:bold;">[Biersack 1992] </span><span class="font53">E. W. Biersack, “Performance Evaluation of Forward Error Correction in ATM Networks,” </span><span class="font53" style="font-style:italic;">Proc. 1999 ACM SIGCOMM Conference</span><span class="font53"> (Baltimore, MD, Aug. 1992), pp. 248-257.</span></p>
<p><span class="font53" style="font-weight:bold;">[BIND 2020] </span><span class="font53">Internet Software Consortium page on BIND, </span><a href="http://www.isc.org/bind.html"><span class="font53">http://www.isc.org/</span></a><span class="font53"> </span><a href="http://www.isc.org/bind.html"><span class="font53">bind.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Bisdikian 2001] </span><span class="font53">C. Bisdikian, “An Overview of the Bluetooth Wireless Technology,” </span><span class="font53" style="font-style:italic;">IEEE Communications Magazine,</span><span class="font53"> No. 12 (Dec. 2001), pp. 86-94.</span></p>
<p><span class="font53" style="font-weight:bold;">[Bishop 2003] </span><span class="font53">M. Bishop, </span><span class="font53" style="font-style:italic;">Computer Security: Art and Science,</span><span class="font53"> Boston: Addison Wesley, Boston MA, 2003.</span></p>
<p><span class="font53" style="font-weight:bold;">[Bishop 2004] </span><span class="font53">M. Bishop, </span><span class="font53" style="font-style:italic;">Introduction to Computer Security,</span><span class="font53"> Addison-Wesley, 2004.</span></p>
<p><span class="font53" style="font-weight:bold;">[Bjornson 2017] </span><span class="font53">E. Bjornson, J. Hoydis, L. Sanguinetti, </span><span class="font53" style="font-style:italic;">Massive MIMO Networks: Spectral, Energy, and Hardware Efficiency,</span><span class="font53"> Now Publishers, 2017.</span></p>
<p><span class="font53" style="font-weight:bold;">[Black 1995] </span><span class="font53">U. Black, </span><span class="font53" style="font-style:italic;">ATM Volume I: Foundation for Broadband Networks, </span><span class="font53">Prentice Hall, 1995.</span></p>
<p><span class="font53" style="font-weight:bold;">[Bluetooth 2020] </span><span class="font53" style="font-style:italic;">The Bluetooth Special Interest Group, </span><a href="http://www.bluetooth.com/"><span class="font53" style="font-style:italic;">http://www.bluetooth.com/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Blumenthal 2001] </span><span class="font53">M. Blumenthal, D. Clark, “Rethinking the Design of the Internet: The End-to-end Arguments vs. the Brave New World,” </span><span class="font53" style="font-style:italic;">ACM Transactions on Internet Technology,</span><span class="font53"> Vol. 1, No. 1 (Aug. 2001), pp. 70-109.</span></p>
<p><span class="font53" style="font-weight:bold;">[Bochman 1984] </span><span class="font53">G. V. Bochmann, C. A. Sunshine, “Formal Methods in Communication Protocol Design,” </span><span class="font53" style="font-style:italic;">IEEE Transactions on Communications,</span><span class="font53"> Vol. 28, No. 4 (Apr. 1980) pp. 624-631.</span></p>
<p><span class="font53" style="font-weight:bold;">[Bosshart 2013] </span><span class="font53">P. Bosshart, G. Gibb, H. Kim, G. Varghese, N. McKeown, M. Izzard, F. Mujica, M. Horowitz, “Forwarding Metamorphosis: Fast Programmable Match-Action Processing in Hardware for SDN,” </span><span class="font53" style="font-style:italic;">Proc. 2013 SIGCOMM Conference,</span><span class="font53"> pp. 99-110.</span></p>
<p><span class="font53" style="font-weight:bold;">[Bosshart 2014] </span><span class="font53">P. Bosshart, D. Daly, G. Gibb, M. Izzard, N. McKeown, J. Rexford, C. Schlesinger, D. Talayco, A. Vahdat, G. Varghese, D. Walker, “P4: Programming Protocol-Independent Packet Processors,” </span><span class="font53" style="font-style:italic;">Proc. 2014 ACM SIGCOMM Conference, </span><span class="font53">pp. 87-95.</span></p>
<p><span class="font53" style="font-weight:bold;">[Bottger 2018] </span><span class="font53">T. Bottger, F. Cuadrado, G. Tyson, I. Castro, S. Uhlig, Open connect everywhere: A glimpse at the internet ecosystem through the lens of the Netflix CDN, </span><span class="font53" style="font-style:italic;">Proc. 2018 ACM SIGCOMM Conference.</span></p>
<p><span class="font53" style="font-weight:bold;">[Brakmo 1995] </span><span class="font53">L. Brakmo, L. Peterson, “TCP Vegas: End to End Congestion Avoidance on a Global Internet,” </span><span class="font53" style="font-style:italic;">IEEE Journal of Selected Areas in Communications,</span><span class="font53"> Vol. 13, No. 8 (Oct. 1995), pp. 1465-1480.</span></p>
<p><span class="font53" style="font-weight:bold;">[Bryant 1988] </span><span class="font53">B. Bryant, “Designing an Authentication System: A Dialogue in Four Scenes,” </span><a href="http://web.mit.edu/kerberos/www/dialogue.html"><span class="font53">http://web.mit.edu/kerberos/www/dialogue.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Bush 1945] </span><span class="font53">V. Bush, “As We May Think,” </span><span class="font53" style="font-style:italic;">The Atlantic Monthly,</span><span class="font53"> July 1945.</span></p>
<p><a href="http://www.theatlantic.com/unbound/flashbks/computer/bushf.htm"><span class="font53">http://www.theatlantic.com/unbound/flashbks/computer/bushf.htm</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Byers 1998] </span><span class="font53">J. Byers, M. Luby, M. Mitzenmacher, A. Rege, “A Digital Fountain Approach to Reliable Distribution of Bulk Data,” </span><span class="font53" style="font-style:italic;">Proc. 1998 ACM SIGCOMM Conference</span><span class="font53"> (Vancouver, Canada, Aug. 1998), pp. 56-67.</span></p>
<p><span class="font53" style="font-weight:bold;">[Cable Labs 2019] </span><span class="font53">Cable Labs, “A Comparative Introduction to 4G and 5G Authentication,” </span><a href="https://www.cablelabs.com/insights/a-comparative-introduction-to-4g-and-5g-authentication"><span class="font53">https://www.cablelabs.com/insights/a-comparative-introduction-</span></a><span class="font53"></span><a href="https://www.cablelabs.com/insights/a-comparative-introduction-to-4g-and-5g-authentication"><span class="font53">to-4g-and-5g-authentication</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Caesar 2005b] </span><span class="font53">M. Caesar, D. Caldwell, N. Feamster, J. Rexford, A. Shaikh, J. van der Merwe, “Design and implementation of a Routing Control Platform,” </span><span class="font53" style="font-style:italic;">Proc.</span></p>
<p><span class="font53" style="font-style:italic;">Networked Systems Design and Implementation</span><span class="font53"> (May 2005).</span></p>
<p><span class="font53" style="font-weight:bold;">[Caesar 2005b] </span><span class="font53">M. Caesar, J. Rexford, “BGP Routing Policies in ISP Networks,” </span><span class="font53" style="font-style:italic;">IEEE Network Magazine,</span><span class="font53"> Vol. 19, No. 6 (Nov. 2005).</span></p>
<p><span class="font53" style="font-weight:bold;">[CAIDA 2020] </span><span class="font53">Center for Applied Internet Data Analysis, </span><a href="http://www.caida.org"><span class="font53">www.caida.org</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Caldwell 2020] </span><span class="font53">C. Caldwell, “The Prime Pages,” </span><a href="http://www.utm.edu/research/primes/prove"><span class="font53">http://www.utm.edu/research/</span></a><span class="font53"> </span><a href="http://www.utm.edu/research/primes/prove"><span class="font53">primes/prove</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Cardwell 2017] </span><span class="font53">N. Cardwell, Y. Cheng, C. S. Gunn, S. H. Yeganeh, V. Jacobson. “BBR: congestion-based congestion control,” </span><span class="font53" style="font-style:italic;">Commun. ACM,</span><span class="font53"> Vol. 60, No. 2 (Jan. 2017), pp. 58-66.</span></p>
<p><span class="font53" style="font-weight:bold;">[Casado 2007] </span><span class="font53">M. Casado, M. Freedman, J. Pettit, J. Luo, N. McKeown,</span></p>
<p><span class="font53">S. Shenker, “Ethane: Taking Control of the Enterprise,” </span><span class="font53" style="font-style:italic;">Proc. 2007 ACM SIGCOMM Conference,</span><span class="font53"> New York, pp. 1-12. See also </span><span class="font53" style="font-style:italic;">IEEE/ACM Trans. Networking,</span><span class="font53"> Vol. 17, No. 4 (Aug. 2007), pp. 270-1283.</span></p>
<p><span class="font53" style="font-weight:bold;">[Casado 2009] </span><span class="font53">M. Casado, M. Freedman, J. Pettit, J. Luo, N. Gude, N. McKeown, S. Shenker, “Rethinking Enterprise Network Control,” </span><span class="font53" style="font-style:italic;">IEEE/ACM Transactions on Networking (ToN),</span><span class="font53"> Vol. 17, No. 4 (Aug. 2009), pp. 1270-1283.</span></p>
<p><span class="font53" style="font-weight:bold;">[Casado 2014] </span><span class="font53">M. Casado, N. Foster, A. Guha, “Abstractions for Software-Defined Networks,” </span><span class="font53" style="font-style:italic;">Communications of the ACM,</span><span class="font53"> Vol. 57, No. 10, (Oct. 2014), pp. 86-95.</span></p>
<p><span class="font53" style="font-weight:bold;">[Cerf 1974] </span><span class="font53">V. Cerf, R. Kahn, “A Protocol for Packet Network Interconnection,” </span><span class="font53" style="font-style:italic;">IEEE Transactions on Communications Technology</span><span class="font53">, Vol. COM-22, No. 5, pp. 627-641.</span></p>
<p><span class="font53" style="font-weight:bold;">[CERT 2001-09] </span><span class="font53">CERT, “Advisory 2001-09: Statistical Weaknesses in TCP/IP Initial Sequence Numbers,” </span><a href="http://www.cert.org/advisories/CA-2001-09.html"><span class="font53">http://www.cert.org/advisories/CA-2001-09.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[CERT 2003-04] </span><span class="font53">CERT, “CERT Advisory CA-2003-04 MS-SQL Server Worm,” </span><a href="http://www.cert.org/advisories/CA-2003-04.html"><span class="font53">http://www.cert.org/advisories/CA-2003-04.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[CERT 2020] </span><span class="font53">The CERT division of the Software Engineering Institute, </span><a href="https://www.sei.cmu.edu/about/divisions/cert"><span class="font53">https://</span></a><span class="font53"> </span><a href="https://www.sei.cmu.edu/about/divisions/cert"><span class="font53">www.sei.cmu.edu/about/divisions/cert,</span></a><span class="font53"> 2020</span></p>
<p><span class="font53" style="font-weight:bold;">[CERT Filtering 2012] </span><span class="font53">CERT, “Packet Filtering for Firewall Systems,” </span><a href="http://www.cert.org/tech_tips/packet_filtering.html"><span class="font53">http://</span></a><span class="font53"> </span><a href="http://www.cert.org/tech_tips/packet_filtering.html"><span class="font53">www.cert.org/tech_tips/packet_filtering.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Cert SYN 1996] </span><span class="font53">CERT, “Advisory CA-96.21: TCP SYN Flooding and IP Spoofing Attacks,” </span><a href="http://www.cert.org/advisories/CA-1998-01.html"><span class="font53">http://www.cert.org/advisories/CA-1998-01.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Chandra 2007] </span><span class="font53">T. Chandra, R. Greisemer, J. Redstone, “Paxos Made Live: an Engineering Perspective,” </span><span class="font53" style="font-style:italic;">Proc. of2007 ACM Symposium on Principles of Distributed Computing (PODC),</span><span class="font53"> pp. 398-407.</span></p>
<p><span class="font53" style="font-weight:bold;">[Chao 2011] </span><span class="font53">C. Zhang, P. Dunghel, D. Wu, K. W. Ross, “Unraveling the BitTorrent Ecosystem,” </span><span class="font53" style="font-style:italic;">IEEE Transactions on Parallel and Distributed Systems, </span><span class="font53">Vol. 22, No. 7 (July 2011).</span></p>
<p><span class="font53" style="font-weight:bold;">[Chen 2011] </span><span class="font53">Y. Chen, S. Jain, V. K. Adhikari, Z. Zhang, “Characterizing Roles of Front-End Servers in End-to-End Performance of Dynamic Content Distribution,” </span><span class="font53" style="font-style:italic;">Proc. 2011 ACM Internet Measurement Conference</span><span class="font53"> (Berlin, Germany, Nov. 2011).</span></p>
<p><span class="font53" style="font-weight:bold;">[Chiu 1989] </span><span class="font53">D. Chiu, R. Jain, “Analysis of the Increase and Decrease Algorithms for Congestion Avoidance in Computer Networks,” </span><span class="font53" style="font-style:italic;">Computer Networks and ISDN Systems,</span><span class="font53"> Vol. 17, No. 1, pp. 1-14. </span><a href="http://www.cs.wustl.edu/~jain/papers/cong_av.htm"><span class="font53">http://www.cs.wustl.edu/~jain/papers/cong_</span></a><span class="font53"> </span><a href="http://www.cs.wustl.edu/~jain/papers/cong_av.htm"><span class="font53">av.htm</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Christiansen 2001] </span><span class="font53">M. Christiansen, K. Jeffay, D. Ott, F. D. Smith, “Tuning Red for Web Traffic,” </span><span class="font53" style="font-style:italic;">IEEE/ACM Transactions on Networking,</span><span class="font53"> Vol. 9, No. 3 (June 2001), pp. 249-264.</span></p>
<p><span class="font53" style="font-weight:bold;">[Cichonski 2017] </span><span class="font53">J. Cichonski, J. Franklin, M. Bartock, Guide to LTE Security, NIST Special Publication 800-187, Dec. 2017.</span></p>
<p><span class="font53" style="font-weight:bold;">[Cisco 2012] </span><span class="font53">Cisco 2012, Data Centers, </span><a href="http://www.cisco.com/go/dce"><span class="font53">http://www.cisco.com/go/dce</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Cisco 2020] </span><span class="font53">Cisco Visual Networking Index: Forecast and Trends, 2017-2022 White Paper.</span></p>
<p><span class="font53" style="font-weight:bold;">[Cisco 6500 2020] </span><span class="font53">Cisco Systems, “Cisco Catalyst 6500 Architecture White Paper,” </span><a href="http://www.cisco.com/c/en/us/products/collateral/switches/catalyst-6500-series-switches/prod_white_paper0900aecd80673385.html"><span class="font53">http://www.cisco.com/c/en/us/products/collateral/switches/</span></a><span class="font53"> </span><a href="http://www.cisco.com/c/en/us/products/collateral/switches/catalyst-6500-series-switches/prod_white_paper0900aecd80673385.html"><span class="font53">catalyst-6500-series-switches/prod_white_paper0900aecd80673385.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Cisco 7600 2020] </span><span class="font53">Cisco Systems, “Cisco 7600 Series Solution and Design Guide,” </span><a href="http://www.cisco.com/en/US/products/hw/routers/ps368/prod_technical_reference09186a0080092246.html"><span class="font53">http://www.cisco.com/en/US/products/hw/routers/ps368/prod_technical_</span></a><span class="font53"> </span><a href="http://www.cisco.com/en/US/products/hw/routers/ps368/prod_technical_reference09186a0080092246.html"><span class="font53">reference09186a0080092246.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Cisco 8500 2020] </span><span class="font53">Cisco Systems Inc., “Catalyst 8500 Campus Switch Router Architecture,” </span><a href="http://www.cisco.com/univercd/cc/td/doc/product/l3sw/8540/rel_12_0/w5_6f/softcnfg/1cfg8500.pdf"><span class="font53">http://www.cisco.com/univercd/cc/td/doc/product/l3sw/8540/</span></a><span class="font53"> </span><a href="http://www.cisco.com/univercd/cc/td/doc/product/l3sw/8540/rel_12_0/w5_6f/softcnfg/1cfg8500.pdf"><span class="font53">rel_12_0/w5_6f/softcnfg/1cfg8500.pdf</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Cisco 12000 2020] </span><span class="font53">Cisco Systems Inc., “Cisco XR 12000 Series and Cisco 12000 Series Routers,” </span><a href="http://www.cisco.com/en/US/products/ps6342/index.html"><span class="font53">http://www.cisco.com/en/US/products/ps6342/index.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Cisco Queue 2016] </span><span class="font53">Cisco Systems Inc., “Congestion Management Overview,” </span><a href="http://www.cisco.com/en/US/docs/ios/12_2/qos/configuration/guide/qcfconmg.html"><span class="font53">http://www.cisco.com/en/US/docs/ios/12_2/qos/configuration/guide/qcfconmg.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Cisco SYN 2016] </span><span class="font53">Cisco Systems Inc., “Defining Strategies to Protect Against TCP SYN Denial of Service Attacks,” </span><a href="http://www.cisco.com/en/US/tech/tk828/technologies_tech_note09186a00800f67d5.shtml"><span class="font53">http://www.cisco.com/en/US/tech/tk828/</span></a><span class="font53"> </span><a href="http://www.cisco.com/en/US/tech/tk828/technologies_tech_note09186a00800f67d5.shtml"><span class="font53">technologies_tech_note09186a00800f67d5.shtml</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Cisco TCAM 2014] </span><span class="font53">Cisco Systems Inc., “CAT 6500 and 7600 Series Routers and Switches TCAM Allocation Adjustment Procedures,” </span><a href="http://www.cisco.com/c/en/us/support/docs/switches/catalyst-6500-series-switches/117712-problemsolution-cat6500-00.html"><span class="font53">http://www.cisco.Com/c/en/</span></a><span class="font53"> </span><a href="http://www.cisco.com/c/en/us/support/docs/switches/catalyst-6500-series-switches/117712-problemsolution-cat6500-00.html"><span class="font53">us/support/docs/switches/catalyst-6500-series-switches/117712-problemsolution-</span></a><span class="font53"></span><a href="http://www.cisco.com/c/en/us/support/docs/switches/catalyst-6500-series-switches/117712-problemsolution-cat6500-00.html"><span class="font53">cat6500-00.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Cisco VNI 2020] </span><span class="font53">Cisco Systems Inc., “Visual Networking Index,” </span><a href="https://www.cisco.com/c/en/us/solutions/collateral/service-provider/visual-networking-index-vni/white-paper-c11-741490.html"><span class="font53">https://www.</span></a><span class="font53"> </span><a href="https://www.cisco.com/c/en/us/solutions/collateral/service-provider/visual-networking-index-vni/white-paper-c11-741490.html"><span class="font53">cisco.com/c/en/us/solutions/collateral/service-provider/visual-networking-index-</span></a><span class="font53"></span><a href="https://www.cisco.com/c/en/us/solutions/collateral/service-provider/visual-networking-index-vni/white-paper-c11-741490.html"><span class="font53">vni/white-paper-c11-741490.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Claise 2019] </span><span class="font53">B. Calise, J. Clarke, J. Lindblad, </span><span class="font53" style="font-style:italic;">Network Programmability with YANG,</span><span class="font53"> Pearson, 2019.</span></p>
<p><span class="font53" style="font-weight:bold;">[Clark 1988] </span><span class="font53">D. Clark, “The Design Philosophy of the DARPA Internet Protocols,” </span><span class="font53" style="font-style:italic;">Proc. 1988 ACM SIGCOMM Conference</span><span class="font53"> (Stanford, CA, Aug. 1988).</span></p>
<p><span class="font53" style="font-weight:bold;">[Clark 1997] </span><span class="font53">D. Clark, “ Interoperation, open interfaces and protocol architecture,” in </span><span class="font53" style="font-style:italic;">The Unpredictable Certainty,</span><span class="font53"> The National Academies Press, 1997, pp. 133-144.</span></p>
<p><span class="font53" style="font-weight:bold;">[Clark 2005] </span><span class="font53">D. Clark, J. Wroclawski, K. R. Sollins, R. Braden, “Tussle in cyberspace: defining tomorrow’s internet,” </span><span class="font53" style="font-style:italic;">IEEE/ACM Trans. Networking,</span><span class="font53"> Vol. 13, No. 3 (June 2005), pp. 462-475.</span></p>
<p><span class="font53" style="font-weight:bold;">[Clos 1953] </span><span class="font53">C. Clos, “A study of non-blocking switching networks,” </span><span class="font53" style="font-style:italic;">Bell System Technical Journal,</span><span class="font53"> Vol. 32, No. 2 (Mar. 1953), pp. 406-424.</span></p>
<p><span class="font53" style="font-weight:bold;">[Cohen 2003] </span><span class="font53">B. Cohen, “Incentives to Build Robustness in BitTorrent,” First Workshop on the Economics of Peer-to-Peer Systems, Berkeley, CA, June 2003.</span></p>
<p><span class="font53" style="font-weight:bold;">[Colbach 2017] </span><span class="font53">G. Colbach, </span><span class="font53" style="font-style:italic;">Wireless Technologies: An introduction to Bluetooth and WiFi, 2017.</span></p>
<p><span class="font53" style="font-weight:bold;">[Condoluci 2018] </span><span class="font53">M. Condoluci, T. Mahmoodi,, “Softwarization and virtualization in 5G mobile networks: Benefits, trends and challenges,” </span><span class="font53" style="font-style:italic;">Computer Networks,</span></p>
<p><span class="font53">Vol. 146 (2018), pp. 65-84.</span></p>
<p><span class="font53" style="font-weight:bold;">[Cormen 2001] </span><span class="font53">T. H. Cormen, </span><span class="font53" style="font-style:italic;">Introduction to Algorithms,</span><span class="font53"> 2nd Ed., MIT Press, Cambridge, MA, 2001.</span></p>
<p><span class="font53" style="font-weight:bold;">[Crow 1997] </span><span class="font53">B. Crow, I. Widjaja, J. Kim, P. Sakai, “IEEE 802.11 Wireless Local Area Networks,” </span><span class="font53" style="font-style:italic;">IEEE Communications Magazine</span><span class="font53"> (Sept. 1997), pp. 116-126.</span></p>
<p><span class="font53" style="font-weight:bold;">[Cusumano 1998] </span><span class="font53">M. A. Cusumano, D. B. Yoffie, </span><span class="font53" style="font-style:italic;">Competing on Internet Time: Lessons from Netscape and Its Battle with Microsoft,</span><span class="font53"> Free Press, New York, NY, 1998.</span></p>
<p><span class="font53" style="font-weight:bold;">[Czyz 2014] </span><span class="font53">J. Czyz, M. Allman, J. Zhang, S. Iekel-Johnson, E. Osterweil, M. Bailey, “Measuring IPv6 Adoption,” </span><span class="font53" style="font-style:italic;">Proc. ACM SIGCOMM 2014 Conference,</span><span class="font53"> ACM, New York, NY, USA, pp. 87-98.</span></p>
<p><span class="font53" style="font-weight:bold;">[Dahlman 2018] </span><span class="font53">E. Dahlman, S. Parkvall, J. Skold, </span><span class="font53" style="font-style:italic;">5G NR: The Next Generation Wireless Access Technology,</span><span class="font53"> Academic Press, 2018.</span></p>
<p><span class="font53" style="font-weight:bold;">[DAM 2020] </span><span class="font53">Digital Attack Map, </span><a href="http://www.digitalattackmap.com"><span class="font53">http://www.digitalattackmap.com</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Davie 2000] </span><span class="font53">B. Davie and Y. Rekhter, </span><span class="font53" style="font-style:italic;">MPLS: Technology and Applications</span><span class="font53">, Morgan Kaufmann Series in Networking, 2000.</span></p>
<p><span class="font53" style="font-weight:bold;">[DEC 1990] </span><span class="font53">Digital Equipment Corporation, “In Memoriam: J. C. R. Licklider 1915-1990,” SRC Research Report 61, Aug. 1990. </span><a href="http://www.memex.org/licklider.pdf"><span class="font53">http://www.memex.org/</span></a><span class="font53"> </span><a href="http://www.memex.org/licklider.pdf"><span class="font53">licklider.pdf</span></a></p>
<p><span class="font53" style="font-weight:bold;">[DeClercq 2002] </span><span class="font53">J. DeClercq, O. Paridaens, “Scalability Implications of Virtual Private Networks,” </span><span class="font53" style="font-style:italic;">IEEE Communications Magazine,</span><span class="font53"> Vol. 40, No. 5 (May 2002), pp. 151-157.</span></p>
<p><span class="font53" style="font-weight:bold;">[Demers 1990] </span><span class="font53">A. Demers, S. Keshav, S. Shenker, “Analysis and Simulation of a Fair Queuing Algorithm,” </span><span class="font53" style="font-style:italic;">Internetworking: Research and Experience,</span><span class="font53"> Vol. 1, No. 1 (1990), pp. 3-26.</span></p>
<p><span class="font53" style="font-weight:bold;">[dhc 2020] </span><span class="font53">IETF Dynamic Host Configuration working group homepage, </span><a href="https://datatracker.ietf.org/wg/dhc/about/"><span class="font53">https://datatracker.ietf.org/wg/dhc/about/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Diffie 1976] </span><span class="font53">W. Diffie, M. E. Hellman, “New Directions in Cryptography,” </span><span class="font53" style="font-style:italic;">IEEE Transactions on Information Theory,</span><span class="font53"> Vol IT-22 (1976), pp. 644-654.</span></p>
<p><span class="font53" style="font-weight:bold;">[Diggavi 2004] </span><span class="font53">S. N. Diggavi, N. Al-Dhahir, A. Stamoulis, R. Calderbank, “Great Expectations: The Value of Spatial Diversity in Wireless Networks,” </span><span class="font53" style="font-style:italic;">Proceedings of the IEEE</span><span class="font53">, Vol. 92, No. 2 (Feb. 2004).</span></p>
<p><span class="font53" style="font-weight:bold;">[Dilley 2002] </span><span class="font53">J. Dilley, B. Maggs, J. Parikh, H. Prokop, R. Sitaraman, B. Weihl, “Globally Distributed Content Delivery,” </span><span class="font53" style="font-style:italic;">IEEE Internet Computing</span></p>
<p><span class="font53">(Sept.-Oct. 2002).</span></p>
<p><span class="font53" style="font-weight:bold;">[Dmitiropoulos 2007] </span><span class="font53">X. Dmitiropoulos, D. Krioukov, M. Fomenkov, B. Huffaker, Y. Hyun, K. C. Claffy, G. Riley, “AS Relationships: Inference and Validation,” </span><span class="font53" style="font-style:italic;">ACM Computer Communication Review,</span><span class="font53"> Vol. 37, No. 1 (Jan. 2007).</span></p>
<p><span class="font53" style="font-weight:bold;">[DOCSIS3.1 2014] </span><span class="font53" style="font-style:italic;">Data-Over-Cable Service Interface Specification, MAC and Upper Layer Protocols Interface Specification DOCSIS 3.1</span><span class="font53"> (CM-SP-MUL-PIv3.1-104-141218), and </span><span class="font53" style="font-style:italic;">Data-Over-Cable Service Interface Specification, Physical Layer Specification DOCSIS 3.1</span><span class="font53"> (CM-SP-PHYv3.1-104-141218), Dec. 2014.</span></p>
<p><span class="font53" style="font-weight:bold;">[Donahoo 2001] </span><span class="font53">M. Donahoo, K. Calvert, </span><span class="font53" style="font-style:italic;">TCP/IP Sockets in C: Practical Guide for Programmers</span><span class="font53">, Morgan Kaufman, 2001.</span></p>
<p><span class="font53" style="font-weight:bold;">[Droms 2002] </span><span class="font53">R. Droms, T. Lemon, </span><span class="font53" style="font-style:italic;">The DHCP Handbook,</span><span class="font53"> 2nd edition, SAMS Publishing, 2002.</span></p>
<p><span class="font53" style="font-weight:bold;">[Eckel 2017] </span><span class="font53">C. Eckel, Using OpenDaylight, </span><a href="https://www.youtube.com/watch?v=rAm48gVv8_A"><span class="font53">https://www.youtube.com/</span></a><span class="font53"> </span><a href="https://www.youtube.com/watch?v=rAm48gVv8_A"><span class="font53">watch?v=rAm48gVv8_A</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Economides 2017] </span><span class="font53">N. Economides, “A Case for Net Neutrality,” </span><span class="font53" style="font-style:italic;">IEEE Spectrum, </span><span class="font53">Dec. 2017, </span><a href="https://spectrum.ieee.org/tech-talk/telecom/internet/a-case-for-net-neutrality"><span class="font53">https://spectrum.ieee.org/tech-talk/telecom/internet/a-case-for-net-neutrality</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Edney 2003] </span><span class="font53">J. Edney and W. A. Arbaugh, </span><span class="font53" style="font-style:italic;">Real 802.11 Security: Wi-Fi Protected Access and 802.11i,</span><span class="font53"> Addison-Wesley Professional, 2003.</span></p>
<p><span class="font53" style="font-weight:bold;">[Eduroam 2020</span><span class="font53">] Eduroam, </span><a href="https://www.eduroam.org/"><span class="font53">https://www.eduroam.org/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Eisenbud 2016] </span><span class="font53">D. Eisenbud, C. Yi, C. Contavalli, C. Smith, R. Kononov, E.</span></p>
<p><span class="font53">Mann-Hielscher, Cilingiroglu, and B. Cheyney, W. Shang, J.D. Hosein, “Maglev: A Fast and Reliable Software Network Load Balancer,” </span><span class="font53" style="font-style:italic;">NSDI2016.</span></p>
<p><span class="font53" style="font-weight:bold;">[Ellis 1987] </span><span class="font53">H. Ellis, “The Story of Non-Secret Encryption,” </span><a href="http://jya.com/ellis-doc.htm"><span class="font53">http://jya.com/ellis-</span></a><span class="font53"></span><a href="http://jya.com/ellis-doc.htm"><span class="font53">doc.htm</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Erickson 2013] </span><span class="font53">D. Erickson, “ The Beacon Openflow Controller,” 2nd </span><span class="font53" style="font-style:italic;">ACM SIGCOMM Workshop on Hot Topics in Software Defined Networking</span><span class="font53"> (HotSDN ’13). ACM, New York, NY, USA, pp. 13-18.</span></p>
<p><span class="font53" style="font-weight:bold;">[Facebook 2014] </span><span class="font53">A. Andreyev, “Introducing Data Center Fabric, the NextGeneration Facebook Data Center Network,” </span><a href="https://code.facebook.com/posts/360346274145943/introducing-data-center-fabric-the-next-generation-facebook-data-center-network"><span class="font53">https://code.facebook.com/</span></a><span class="font53"> </span><a href="https://code.facebook.com/posts/360346274145943/introducing-data-center-fabric-the-next-generation-facebook-data-center-network"><span class="font53">posts/360346274145943/introducing-data-center-fabric-the-next-generation-face-</span></a><span class="font53"></span><a href="https://code.facebook.com/posts/360346274145943/introducing-data-center-fabric-the-next-generation-facebook-data-center-network"><span class="font53">book-data-center-network</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Faloutsos 1999] </span><span class="font53">C. Faloutsos, M. Faloutsos, P. Faloutsos, “What Does the Internet Look Like? Empirical Laws of the Internet Topology,” </span><span class="font53" style="font-style:italic;">Proc. 1999 ACM SIGCOMM Conference</span><span class="font53"> (Boston, MA, Aug. 1999).</span></p>
<p><span class="font53" style="font-weight:bold;">[Farrington 2010] </span><span class="font53">N. Farrington, G. Porter, S. Radhakrishnan, H. Bazzaz, V.</span></p>
<p><span class="font53">Subramanya, Y. Fainman, G. Papen, A. Vahdat, “Helios: A Hybrid Electrical/Opti-cal Switch Architecture for Modular Data Centers,” </span><span class="font53" style="font-style:italic;">Proc. 2010 ACM SIGCOMM</span></p>
<p><span class="font53" style="font-style:italic;">Conference</span><span class="font53">.</span></p>
<p><span class="font53" style="font-weight:bold;">[Faulhaber 2012] </span><span class="font53">G. Faulhaber, “The Economics of Network Neutrality: Are ‘Prophylactic’ Remedies to Nonproblems Needed?,” </span><span class="font53" style="font-style:italic;">Regulation,</span><span class="font53"> Vol. 34, No. 4, p. 18, Winter 2011-2012.</span></p>
<p><span class="font53" style="font-weight:bold;">[FB 2014] </span><span class="font53">Facebook, “Introducing data center fabric, the next-generation Facebook data center network.” </span><a href="https://engineering.fb.com/production-engineering/introducing-data-center-fabric-the-next-generation-facebook-data-center-network/"><span class="font53">https://engineering.fb.com/production-engineering/introduc-</span></a><span class="font53"></span><a href="https://engineering.fb.com/production-engineering/introducing-data-center-fabric-the-next-generation-facebook-data-center-network/"><span class="font53">ing-data-center-fabric-the-next-generation-facebook-data-center-network/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[FB 2019] </span><span class="font53">Facebook, “Reinventing Facebook’s Data Center Network,” </span><a href="https://engineering.fb.com/data-center-engineering/f16-minipack/"><span class="font53">https://engineering.fb.com/data-center-engineering/f16-minipack/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[FCC 2008] </span><span class="font53">US Federal Communications Commission, </span><span class="font53" style="font-style:italic;">Memorandum Opinion and Order: Formal Complaint of Free Press and Public Knowledge Against</span></p>
<p><span class="font53" style="font-style:italic;">Comcast Corporation for Secretly Degrading Peer-to-Peer Applications,</span></p>
<p><span class="font53">FCC 08-083.</span></p>
<p><span class="font53" style="font-weight:bold;">[FCC 2015] </span><span class="font53">US Federal Communications Commission, Protecting and Promoting the Open Internet, Report and Order on Remand, Declaratory Ruling, and Order, GN Docket No. 14-28. (March 12, 2015), </span><a href="https://apps.fcc.gov/edocs_public/attach-match/FCC-15-24A1.pdf"><span class="font53">https://apps.fcc.gov/edocs_public/attach-</span></a><span class="font53"></span><a href="https://apps.fcc.gov/edocs_public/attach-match/FCC-15-24A1.pdf"><span class="font53">match/FCC-15-24A1.pdf</span></a></p>
<p><span class="font53" style="font-weight:bold;">[FCC 2017] </span><span class="font53" style="font-style:italic;">Restoring Internet Freedom,</span><span class="font53"> Declaratory Ruling, Report and Order and Order, WC Docket No. 17-108, December 14, 2017. </span><a href="https://transition.fcc.gov/Daily_Releases/Daily_Business/2018/db0105/FCC-17-166A1.pdf"><span class="font53">https://transition.fcc.gov/</span></a><span class="font53"> </span><a href="https://transition.fcc.gov/Daily_Releases/Daily_Business/2018/db0105/FCC-17-166A1.pdf"><span class="font53">Daily_Releases/Daily_Business/2018/db0105/FCC-17-166A1.pdf</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Feamster 2004] </span><span class="font53">N. Feamster, H. Balakrishnan, J. Rexford, A. Shaikh, K. van der Merwe, “The Case for Separating Routing from Routers,” </span><span class="font53" style="font-style:italic;">ACM SIGCOMM Workshop on Future Directions in Network Architecture,</span><span class="font53"> Sept. 2004.</span></p>
<p><span class="font53" style="font-weight:bold;">[Feamster 2004] </span><span class="font53">N. Feamster, J. Winick, J. Rexford, “A Model for BGP Routing for Network Engineering,” </span><span class="font53" style="font-style:italic;">Proc. 2004 ACM SIGMETRICS Conference</span><span class="font53"> (New York, NY, June 2004).</span></p>
<p><span class="font53" style="font-weight:bold;">[Feamster 2005] </span><span class="font53">N. Feamster, H. Balakrishnan, “Detecting BGP Configuration Faults with Static Analysis,” </span><span class="font53" style="font-style:italic;">NSDI</span><span class="font53"> (May 2005).</span></p>
<p><span class="font53" style="font-weight:bold;">[Feamster 2013] </span><span class="font53">N. Feamster, J. Rexford, E. Zegura, “The Road to SDN,” </span><span class="font53" style="font-style:italic;">ACM Queue,</span><span class="font53"> Volume 11, Issue 12, (Dec. 2013).</span></p>
<p><span class="font53" style="font-weight:bold;">[Feamster 2018] </span><span class="font53">N. Feamster, J. Rexford, “Why (and How) Networks Should Run Themselves,” </span><span class="font53" style="font-style:italic;">Proc. 2018 ACM Applied Networking Research Workshop </span><span class="font53">(ANRW ’18).</span></p>
<p><span class="font53" style="font-weight:bold;">[Feldmeier 1995] </span><span class="font53">D. Feldmeier, “Fast Software Implementation of Error Detection Codes,” </span><span class="font53" style="font-style:italic;">IEEE/ACM Transactions on Networking,</span><span class="font53"> Vol. 3, No. 6 (Dec. 1995), pp. 640-652.</span></p>
<p><span class="font53" style="font-weight:bold;">[Fiber Broadband 2020] </span><span class="font53">Fiber Broadband Association </span><a href="https://www.fiberbroadband.org/"><span class="font53">https://www</span></a><span class="font53"> </span><a href="https://www.fiberbroadband.org/"><span class="font53">.fiberbroadband.org/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Fielding 2000] </span><span class="font53">R. Fielding, “Architectural Styles and the Design of Networkbased Software Architectures,” 2000. PhD Thesis, UC Irvine, 2000.</span></p>
<p><span class="font53" style="font-weight:bold;">[FIPS 1995] </span><span class="font53">Federal Information Processing Standard, “Secure Hash Standard,” FIPS Publication 180-1. </span><a href="http://www.itl.nist.gov/fipspubs/fip180-1.htm"><span class="font53">http://www.itl.nist.gov/fipspubs/fip180-1.htm</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Floyd 1999] </span><span class="font53">S. Floyd, K. Fall, “Promoting the Use of End-to-End Congestion Control in the Internet,” </span><span class="font53" style="font-style:italic;">IEEE/ACM Transactions on Networking</span><span class="font53">, Vol. 6, No. 5 (Oct. 1998), pp. 458-472.</span></p>
<p><span class="font53" style="font-weight:bold;">[Floyd 2000] </span><span class="font53">S. Floyd, M. Handley, J. Padhye, J. Widmer, “Equation-Based Congestion Control for Unicast Applications,” </span><span class="font53" style="font-style:italic;">Proc. 2000 ACM SIGCOMM Conference</span><span class="font53"> (Stockholm, Sweden, Aug. 2000).</span></p>
<p><span class="font53" style="font-weight:bold;">[Floyd 2016] </span><span class="font53">S. Floyd, “References on RED (Random Early Detection) Queue Management,” </span><a href="http://www.icir.org/floyd/red.html"><span class="font53">http://www.icir.org/floyd/red.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Floyd Synchronization 1994] </span><span class="font53">S. Floyd, V. Jacobson, “Synchronization of Periodic Routing Messages,” </span><span class="font53" style="font-style:italic;">IEEE/ACM Transactions on Networking,</span><span class="font53"> Vol. 2, No. 2 (Apr. 1997) pp. 122-136.</span></p>
<p><span class="font53" style="font-weight:bold;">[Floyd TCP 1994] </span><span class="font53">S. Floyd, “TCP and Explicit Congestion Notification,” </span><span class="font53" style="font-style:italic;">ACM SIGCOMM Computer Communications Review,</span><span class="font53"> Vol. 24, No. 5 (Oct. 1994), pp. 10-23.</span></p>
<p><span class="font53" style="font-weight:bold;">[Fluhrer 2001] </span><span class="font53">S. Fluhrer, I. Mantin, A. Shamir, “Weaknesses in the Key Scheduling Algorithm of RC4,” </span><span class="font53" style="font-style:italic;">Eighth Annual Workshop on Selected Areas in Cryptography</span><span class="font53"> (Toronto, Canada, Aug. 2002).</span></p>
<p><span class="font53" style="font-weight:bold;">[Ford 2005] </span><span class="font53">Bryan Ford, Pyda Srisuresh, and Dan Kegel. 2005. Peer-to-peer communication across network address translators. </span><span class="font53" style="font-style:italic;">In Proceedings of the annual conference on USENIX Annual Technical Conference</span><span class="font53"> (ATEC ’05).</span></p>
<p><span class="font53" style="font-weight:bold;">[Fortz 2000] </span><span class="font53">B. Fortz, M. Thorup, “Internet Traffic Engineering by Optimizing OSPF Weights,” </span><span class="font53" style="font-style:italic;">Proc. 2000 IEEE INFOCOM</span><span class="font53"> (Tel Aviv, Israel, Apr. 2000).</span></p>
<p><span class="font53" style="font-weight:bold;">[Fortz 2002] </span><span class="font53">B. Fortz, J. Rexford, M. Thorup, “Traffic Engineering with Traditional IP Routing Protocols,” </span><span class="font53" style="font-style:italic;">IEEE Communication Magazine,</span><span class="font53"> Vol. 40, No. 10 (Oct. 2002).</span></p>
<p><span class="font53" style="font-weight:bold;">[Frost 1994] </span><span class="font53">J. Frost, “BSD Sockets: A Quick and Dirty Primer,” </span><a href="http://world.std.com/~jimf/papers/sockets/sockets.html"><span class="font53">http://world.std</span></a><span class="font53"> </span><a href="http://world.std.com/~jimf/papers/sockets/sockets.html"><span class="font53">.com/~jimf/papers/sockets/sockets.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Gao 2001] </span><span class="font53">L. Gao, J. Rexford, “Stable Internet Routing Without Global Coordination,” </span><span class="font53" style="font-style:italic;">IEEE/ACM Transactions on Networking,</span><span class="font53"> Vol. 9, No. 6 (Dec. 2001), pp. 681-692.</span></p>
<p><span class="font53" style="font-weight:bold;">[Garfinkel 2003] </span><span class="font53">S. Garfinkel, “The End of End-to-End?,” MIT Technology Review, July 2003.</span></p>
<p><span class="font53" style="font-weight:bold;">[Gauthier 1999] </span><span class="font53">L. Gauthier, C. Diot, and J. Kurose, “End-to-End Transmission Control Mechanisms for Multiparty Interactive Applications on the Internet,” </span><span class="font53" style="font-style:italic;">Proc. 1999 IEEE INFOCOM</span><span class="font53"> (New York, NY, Apr. 1999).</span></p>
<p><span class="font53" style="font-weight:bold;">[Gieben 2004] </span><span class="font53">M. Gieben, “DNSSEC,” </span><span class="font53" style="font-style:italic;">The Internet Protocol Journal,</span><span class="font53"> 7 [2] (June 2004), </span><a href="http://ipj.dreamhosters.com/internet-protocol-journal/issues/back-issues/"><span class="font53">http://ipj.dreamhosters.com/internet-protocol-journal/issues/back-issues/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Giust 2015] </span><span class="font53">F. Giust, L. Cominardi and C. J. Bernardos, “Distributed mobility management for future 5G networks: overview and analysis of existing approaches,” in </span><span class="font53" style="font-style:italic;">IEEE Communications Magazine,</span><span class="font53"> Vol. 53, No. 1, pp. 142-149, January 2015.</span></p>
<p><span class="font53" style="font-weight:bold;">[Goldsmith 2005] </span><span class="font53">A. Goldsmith, </span><span class="font53" style="font-style:italic;">Wireless Communications,</span><span class="font53"> Cambridge University Press, 2005.</span></p>
<p><span class="font53" style="font-weight:bold;">[Goodman 1997] </span><span class="font53">David J. Goodman, </span><span class="font53" style="font-style:italic;">Wireless Personal Communications Systems, </span><span class="font53">Prentice-Hall, 1997.</span></p>
<p><span class="font53" style="font-weight:bold;">[Google CDN 2020] </span><span class="font53">Google Data Center Locations </span><a href="https://cloud.google.com/cdn/docs/locations"><span class="font53">https://cloud.google.com/cdn/</span></a><span class="font53"> </span><a href="https://cloud.google.com/cdn/docs/locations"><span class="font53">docs/locations</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Google IPv6 2020] </span><span class="font53">Google Inc. “IPv6 Statistics,” </span><a href="https://www.google.com/intl/en/ipv6/statistics.html"><span class="font53">https://www.google.com/intl/en/</span></a><span class="font53"> </span><a href="https://www.google.com/intl/en/ipv6/statistics.html"><span class="font53">ipv6/statistics.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Google Locations 2020] </span><span class="font53">Google data centers. </span><a href="http://www.google.com/corporate/datacenter/locations.html"><span class="font53">http://www.google.com/corporate/</span></a><span class="font53"> </span><a href="http://www.google.com/corporate/datacenter/locations.html"><span class="font53">datacenter/locations.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Goralski 1999] </span><span class="font53">W. Goralski, </span><span class="font53" style="font-style:italic;">Frame Relay for High-Speed Networks,</span><span class="font53"> John Wiley, New York, 1999.</span></p>
<p><span class="font53" style="font-weight:bold;">[Greenberg 2009a] </span><span class="font53">A. Greenberg, J. Hamilton, D. Maltz, P. Patel, “The Cost of a Cloud: Research Problems in Data Center Networks,” </span><span class="font53" style="font-style:italic;">ACM Computer Communications Review</span><span class="font53"> (Jan. 2009).</span></p>
<p><span class="font53" style="font-weight:bold;">[Greenberg 2009b] </span><span class="font53">A. Greenberg, N. Jain, S. Kandula, C. Kim, P. Lahiri, D.</span></p>
<p><span class="font53">Maltz, P. Patel, S. Sengupta, “VL2: A Scalable and Flexible Data Center Network,” </span><span class="font53" style="font-style:italic;">Proc. 2009 ACM SIGCOMM Conference.</span></p>
<p><span class="font53" style="font-weight:bold;">[Greenberg 2015] </span><span class="font53">A. Greenberg, “SDN for the Cloud,” 2015 ACM SIGCOMM Conference 2015 Keynote Address, </span><a href="http://conferences.sigcomm.org/sigcomm/2015/pdf/papers/keynote.pdf"><span class="font53">http://conferences.sigcomm.org/sigcomm/2015/</span></a><span class="font53"> </span><a href="http://conferences.sigcomm.org/sigcomm/2015/pdf/papers/keynote.pdf"><span class="font53">pdf/papers/keynote.pdf</span></a></p>
<p><span class="font53" style="font-weight:bold;">[GSMA 2018a] </span><span class="font53">GSM Association, “Guidelines for IPX Provider networks,” Document IR.34, Version 14.0, August 2018.</span></p>
<p><span class="font53" style="font-weight:bold;">[GSMA 2018b] </span><span class="font53">GSM Association, “Migration from Physical to Virtual Network Functions: Best Practices and Lessons Learned,” July 2019.</span></p>
<p><span class="font53" style="font-weight:bold;">[GSMA 2019a] </span><span class="font53">GSM Association, “LTE and EPC Roaming Guidelines,” Document IR.88, June 2019.</span></p>
<p><span class="font53" style="font-weight:bold;">[GSMA 2019b] </span><span class="font53">GSM Association, “IMS Roaming, Interconnection and Interworking Guidelines,” Document IR.65, April 2019.</span></p>
<p><span class="font53" style="font-weight:bold;">[GSMA 2019c] </span><span class="font53">GSM Association, “5G Implementation Guidelines,” July 2019.</span></p>
<p><span class="font53" style="font-weight:bold;">[Gude 2008] </span><span class="font53">N. Gude, T. Koponen, J. Pettit, B. Pfaff, M. Casado, N. McKeown, and S. Shenker, “NOX: Towards an Operating System for Networks,” </span><span class="font53" style="font-style:italic;">ACM SIGCOMM Computer Communication Review</span><span class="font53">, July 2008.</span></p>
<p><span class="font53" style="font-weight:bold;">[Guo 2009] </span><span class="font53">C. Guo, G. Lu, D. Li, H. Wu, X. Zhang, Y. Shi, C. Tian, Y. Zhang, S. Lu, “BCube: A High Performance, Server-centric Network Architecture for Modular Data Centers,” </span><span class="font53" style="font-style:italic;">Proc. 2009 ACM SIGCOMM Conference</span><span class="font53">.</span></p>
<p><span class="font53" style="font-weight:bold;">[Guo 2016] </span><span class="font53">C. Guo, H. Wu, Z. Deng, G. Soni, J. Ye, J. Padhye, M. Lipshteyn, “RDMA over Commodity Ethernet at Scale,” </span><span class="font53" style="font-style:italic;">Proc. 2016 ACM SIGCOMM Conference.</span></p>
<p><span class="font53" style="font-weight:bold;">[Gupta 2001] </span><span class="font53">P. Gupta, N. McKeown, “Algorithms for Packet Classification,” </span><span class="font53" style="font-style:italic;">IEEE Network Magazine,</span><span class="font53"> Vol. 15, No. 2 (Mar./Apr. 2001), pp. 24-32.</span></p>
<p><span class="font53" style="font-weight:bold;">[Gupta 2014] </span><span class="font53">A. Gupta, L. Vanbever, M. Shahbaz, S. Donovan, B. Schlinker, N. Feamster, J. Rexford, S. Shenker, R. Clark, E. Katz-Bassett, “SDX: A Software Defined Internet Exchange, “ </span><span class="font53" style="font-style:italic;">Proc. 2014 ACM SIGCOMM Conference</span><span class="font53"> (Aug. 2014), pp. 551-562.</span></p>
<p><span class="font53" style="font-weight:bold;">[Ha 2008] </span><span class="font53">S. Ha, I. Rhee, L. Xu, “CUBIC: A New TCP-Friendly High-Speed TCP Variant,” </span><span class="font53" style="font-style:italic;">ACM SIGOPS Operating System Review,</span><span class="font53"> 2008.</span></p>
<p><span class="font53" style="font-weight:bold;">[Halabi 2000] </span><span class="font53">S. Halabi, </span><span class="font53" style="font-style:italic;">Internet Routing Architectures,</span><span class="font53"> 2nd Ed., Cisco Press, 2000.</span></p>
<p><span class="font53" style="font-weight:bold;">[Hamzeh 2015] </span><span class="font53">B. Hamzeh, M. Toy, Y. Fu and J. Martin, “DOCSIS 3.1: scaling broadband cable to Gigabit speeds,” </span><span class="font53" style="font-style:italic;">IEEE Communications Magazine,</span><span class="font53"> Vol. 53, No. 3, pp. 108-113, March 2015.</span></p>
<p><span class="font53" style="font-weight:bold;">[Hanabali 2005] </span><span class="font53">A. A. Hanbali, E. Altman, P. Nain, “A Survey of TCP over Ad Hoc Networks,</span><span class="font53" style="font-style:italic;">” IEEE Commun. Surveys and Tutorials,</span><span class="font53"> Vol. 7, No. 3 (2005), pp. 22-36.</span></p>
<p><span class="font53" style="font-weight:bold;">[He 2015] </span><span class="font53">K. He , E. Rozner , K. Agarwal , W. Felter , J. Carter , A. Akella, “Presto: Edge-based Load Balancing for Fast Datacenter Networks,” </span><span class="font53" style="font-style:italic;">Proc. 2015 ACM SIGCOMM Conference.</span></p>
<p><span class="font53" style="font-weight:bold;">[Heidemann 1997] </span><span class="font53">J. Heidemann, K. Obraczka, J. Touch, “Modeling the Performance of HTTP over Several Transport Protocols,” </span><span class="font53" style="font-style:italic;">IEEE/ACM Transactions on Networking,</span><span class="font53"> Vol. 5, No. 5 (Oct. 1997), pp. 616-630.</span></p>
<p><span class="font53" style="font-weight:bold;">[Held 2001] </span><span class="font53">G. Held, </span><span class="font53" style="font-style:italic;">Data Over Wireless Networks: Bluetooth, WAP, and Wireless LANs,</span><span class="font53"> McGraw-Hill, 2001.</span></p>
<p><span class="font53" style="font-weight:bold;">[Holland 2001] </span><span class="font53">G. Holland, N. Vaidya, V. Bahl, “A Rate-Adaptive MAC Protocol for Multi-Hop Wireless Networks,” </span><span class="font53" style="font-style:italic;">Proc. 2001 ACM Int. Conference of Mobile Computing and Networking</span><span class="font53"> (Rome, Italy, July 2001).</span></p>
<p><span class="font53" style="font-weight:bold;">[Hollot 2002] </span><span class="font53">C.V. Hollot, V. Misra, D. Towsley, W. Gong, “Analysis and Design of Controllers for AQM Routers Supporting TCP Flows,” </span><span class="font53" style="font-style:italic;">IEEE Transactions on Automatic Control</span><span class="font53">, Vol. 47, No. 6 (June 2002), pp. 945-959.</span></p>
<p><span class="font53" style="font-weight:bold;">[Hong 2012] </span><span class="font53">C.Y. Hong, M. Caesar, P. B. Godfrey, “Finishing Flows Quickly with Preemptive Scheduling,” </span><span class="font53" style="font-style:italic;">Proc. 2012 ACM SIGCOMM Conference.</span></p>
<p><span class="font53" style="font-weight:bold;">[Hong 2013] </span><span class="font53">C. Hong, S, Kandula, R. Mahajan, M.Zhang, V. Gill, M. Nanduri, R. Wattenhofer, “Achieving High Utilization with Software-driven WAN,” </span><span class="font53" style="font-style:italic;">Proc. ACM SIGCOMM Conference</span><span class="font53"> (Aug. 2013), pp.15-26.</span></p>
<p><span class="font53" style="font-weight:bold;">[Hong 2018] </span><span class="font53">C. Hong et al., “B4 and after: managing hierarchy, partitioning, and asymmetry for availability and scale in Google’s software-defined WAN,” </span><span class="font53" style="font-style:italic;">Proc. 2018 ACM SIGCOMM Conference,</span><span class="font53"> pp. 74-87.</span></p>
<p><span class="font53" style="font-weight:bold;">[HTTP/3 2020] </span><span class="font53" style="font-style:italic;">M. Bishop. Ed,</span><span class="font53"> “Hypertext Transfer Protocol Version 3 (HTTP/3),” Internet Draft draft-ietf-quic-http-23, expires March 15, 2020.</span></p>
<p><span class="font53" style="font-weight:bold;">[Huang 2002] </span><span class="font53">C. Haung, V. Sharma, K. Owens, V. Makam, “Building Reliable MPLS Networks Using a Path Protection Mechanism,” </span><span class="font53" style="font-style:italic;">IEEE Communications Magazine,</span><span class="font53"> Vol. 40, No. 3 (Mar. 2002), pp. 156-162.</span></p>
<p><span class="font53" style="font-weight:bold;">[Huang 2008] </span><span class="font53">C. Huang, J. Li, A. Wang, K. W. Ross, “Understanding Hybrid CDN-P2P: Why Limelight Needs Its Own Red Swoosh,” </span><span class="font53" style="font-style:italic;">Proc. 2008 NOSSDAV, </span><span class="font53">Braunschweig, Germany.</span></p>
<p><span class="font53" style="font-weight:bold;">[Huang 2013] </span><span class="font53">J. Huang, F. Qian, Y. Guo, Yu. Zhou, Q. Xu, Z. Mao, S. Sen, O. Spatscheck, “An in-depth study of LTE: effect of network protocol and application behavior on performance,” </span><span class="font53" style="font-style:italic;">Proc. 2013 ACM SIGCOMM Conference.</span></p>
<p><span class="font53" style="font-weight:bold;">[Huitema 1998] </span><span class="font53">C. Huitema, </span><span class="font53" style="font-style:italic;">IPv6: The New Internet Protocol,</span><span class="font53"> 2nd Ed., Prentice Hall, Englewood Cliffs, NJ, 1998.</span></p>
<p><span class="font53" style="font-weight:bold;">[Huston 1999a] </span><span class="font53">G. Huston, “Interconnection, Peering, and Settlements—Part I,” </span><span class="font53" style="font-style:italic;">The Internet Protocol Journal</span><span class="font53">, Vol. 2, No. 1 (Mar. 1999).</span></p>
<p><span class="font53" style="font-weight:bold;">[Huston 2004] </span><span class="font53">G. Huston, “NAT Anatomy: A Look Inside Network Address Translators,” </span><span class="font53" style="font-style:italic;">The Internet Protocol Journal,</span><span class="font53"> Vol. 7, No. 3 (Sept. 2004).</span></p>
<p><span class="font53" style="font-weight:bold;">[Huston 2008b] </span><span class="font53">G. Huston, G. Michaelson, “IPv6 Deployment: Just where are we?” </span><a href="http://www.potaroo.net/ispcol/2008-04/ipv6.html"><span class="font53">http://www.potaroo.net/ispcol/2008-04/ipv6.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Huston 2011a] </span><span class="font53">G. Huston, “A Rough Guide to Address Exhaustion,” </span><span class="font53" style="font-style:italic;">The Internet Protocol Journal</span><span class="font53">, Vol. 14, No. 1 (Mar. 2011).</span></p>
<p><span class="font53" style="font-weight:bold;">[Huston 2011b] </span><span class="font53">G. Huston, “Transitioning Protocols,” </span><span class="font53" style="font-style:italic;">The Internet Protocol Journal,</span><span class="font53"> Vol. 14, No. 1 (Mar. 2011).</span></p>
<p><span class="font53" style="font-weight:bold;">[Huston 2012</span><span class="font53">] G. Huston, “A Quick Primer on Internet Peering and Settlements,” April 2012, </span><a href="http://www.potaroo.net/ispcol/2012-04/interconnection-primer.html"><span class="font53">http://www.potaroo.net/ispcol/2012-04/interconnection-primer.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Huston 2017] </span><span class="font53">G. Huston, “BBR, the new kid on the TCP block,” </span><a href="https://blog.apnic.net/2017/05/09/bbr-new-kid-tcp-block/"><span class="font53">https://blog.</span></a><span class="font53"> </span><a href="https://blog.apnic.net/2017/05/09/bbr-new-kid-tcp-block/"><span class="font53">apnic.net/2017/05/09/bbr-new-kid-tcp-block/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Huston 2017] </span><span class="font53">G. Huston, “An Opinion in Defence of NAT,” </span><a href="https://www.potaroo.net/ispcol/2017-09/natdefence.html"><span class="font53">https://www.potaroo.</span></a><span class="font53"> </span><a href="https://www.potaroo.net/ispcol/2017-09/natdefence.html"><span class="font53">net/ispcol/2017-09/natdefence.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Huston 2019] </span><span class="font53">G. Huston, “Addressing 2018,” </span><a href="https://www.potaroo.net/ispcol/2019-01/addr2018.html"><span class="font53">https://www.potaroo.net/ispcol/2019-01/</span></a><span class="font53"> </span><a href="https://www.potaroo.net/ispcol/2019-01/addr2018.html"><span class="font53">addr2018.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Huston 2019a] </span><span class="font53">G. Huston, “Happy Birthday BGP,” June 2019, </span><a href="http://www.potaroo.net/ispcol/2019-06/bgp30.html"><span class="font53">http://www.potaroo.net/ispcol/2019-06/bgp30.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Huston 2019b] </span><span class="font53">G. Huston, “BGP in 2018, Part 1 - The BGP Table,” </span><a href="https://www.potaroo.net/ispcol/2019-01/bgp2018-part1.html"><span class="font53">https://www.potaroo.net/ispcol/2019-01/bgp2018-part1.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Hwang 2009] </span><span class="font53">T. Hwang, C. Yang, G. Wu, S. Li and G. Ye Li, “OFDM and Its Wireless Applications: A Survey,” </span><span class="font53" style="font-style:italic;">IEEE Transactions on Vehicular Technology, </span><span class="font53">Vol. 58, No. 4, pp. 1673-1694, May 2009.</span></p>
<p><span class="font53" style="font-weight:bold;">[IAB 2020] </span><span class="font53">Internet Architecture Board homepage, </span><a href="http://www.iab.org/"><span class="font53">http://www.iab.org/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[IANA 2020] </span><span class="font53">Internet Assigned Names Authority, </span><a href="https://www.iana.org/"><span class="font53">https://www.iana.org/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[IANA Protocol Numbers 2016] </span><span class="font53">Internet Assigned Numbers Authority, Protocol Numbers, </span><a href="http://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml"><span class="font53">http://www.iana.org/assignments/protocol-numbers/protocol-</span></a><span class="font53"></span><a href="http://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml"><span class="font53">numbers.xhtml</span></a></p>
<p><span class="font53" style="font-weight:bold;">[ICANN 2020] </span><span class="font53">The Internet Corporation for Assigned Names and Numbers homepage, </span><a href="http://www.icann.org"><span class="font53">http://www.icann.org</span></a></p>
<p><span class="font53" style="font-weight:bold;">[IEEE 802 2020] </span><span class="font53">IEEE 802 LAN/MAN Standards Committee homepage, </span><a href="http://www.ieee802.org/"><span class="font53">http://</span></a><span class="font53"> </span><a href="http://www.ieee802.org/"><span class="font53">www.ieee802.org/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[IEEE 802.11 1999] </span><span class="font53">IEEE 802.11, “1999 Edition (ISO/IEC 8802-11: 1999) IEEE Standards for Information Technology—Telecommunications and Information Exchange Between Systems—Local and Metropolitan Area Network— Specific Requirements—Part 11: Wireless LAN Medium Access Control (MAC) and Physical Layer (PHY) Specification,” </span><a href="http://standards.ieee.org/getieee802/download/802.11-1999.pdf"><span class="font53">http://standards.ieee.org/getieee802/</span></a><span class="font53"> </span><a href="http://standards.ieee.org/getieee802/download/802.11-1999.pdf"><span class="font53">download/802.11-1999.pdf</span></a></p>
<p><span class="font53" style="font-weight:bold;">[IEEE 802.1q 2005] </span><span class="font53">IEEE, “IEEE Standard for Local and Metropolitan Area Networks: Virtual Bridged Local Area Networks,” </span><a href="http://standards.ieee.org/getieee802/download/802.1Q-2005.pdf"><span class="font53">http://standards.ieee.org/</span></a><span class="font53"> </span><a href="http://standards.ieee.org/getieee802/download/802.1Q-2005.pdf"><span class="font53">getieee802/download/802.1Q-2005.pdf</span></a></p>
<p><span class="font53" style="font-weight:bold;">[IEEE 802.3 2020] </span><span class="font53">IEEE, “IEEE 802.3 CSMA/CD (Ethernet),” </span><a href="http://grouper.ieee.org/groups/802/3/"><span class="font53">http://grouper.ieee.</span></a><span class="font53"> </span><a href="http://grouper.ieee.org/groups/802/3/"><span class="font53">org/groups/802/3/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[IEEE 802.5 2012</span><span class="font53">] IEEE, IEEE 802.5 homepage, </span><a href="http://www.ieee802.org/5/www8025org/"><span class="font53">http://www.ieee802.org/5/</span></a><span class="font53"> </span><a href="http://www.ieee802.org/5/www8025org/"><span class="font53">www8025org/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[IEEE 802.11 2020] </span><span class="font53">IEEE 802.11 Wireless Local Area Networks, the Working Group for WLAN Standards, </span><a href="http://www.ieee802.org/11/"><span class="font53">http://www.ieee802.org/11/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[IETF 2020] </span><span class="font53">Internet Engineering Task Force homepage, </span><a href="http://www.ietf.org"><span class="font53">http://www.ietf.org</span></a></p>
<p><span class="font53" style="font-weight:bold;">[IETF QUIC2020] </span><span class="font53">Internet Engineering Task Force, QUIC Working Group, </span><a href="https://datatracker.ietf.org/wg/quic/about/"><span class="font53">https://datatracker.ietf.org/wg/quic/about/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Intel 2020] </span><span class="font53">Intel Corp., “Intel 710 Ethernet Adapter,” </span><a href="http://www.intel.com/content/www/us/en/ethernet-products/converged-network-adapters/ethernet-xl710.html"><span class="font53">http://www.intel.com/</span></a><span class="font53"> </span><a href="http://www.intel.com/content/www/us/en/ethernet-products/converged-network-adapters/ethernet-xl710.html"><span class="font53">content/www/us/en/ethernet-products/converged-network-adapters/ethernet-xl710</span></a><span class="font53"> </span><a href="http://www.intel.com/content/www/us/en/ethernet-products/converged-network-adapters/ethernet-xl710.html"><span class="font53">.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[ISC 2020] </span><span class="font53">Internet Systems Consortium homepage, </span><a href="http://www.isc.org"><span class="font53">http://www.isc.org</span></a></p>
<p><span class="font53" style="font-weight:bold;">[ITU 2005a] </span><span class="font53">International Telecommunication Union, “ITU-T X.509, The Directory: Public-key and attribute certificate frameworks” (Aug. 2005).</span></p>
<p><span class="font53" style="font-weight:bold;">[ITU 2014] </span><span class="font53">ITU, “G.fast broadband standard approved and on the market,” </span><a href="http://www.itu.int/net/pressoffice/press_releases/2014/70.aspx"><span class="font53">http://www.itu.int/net/pressoffice/press_releases/2014/70.aspx</span></a></p>
<p><span class="font53" style="font-weight:bold;">[ITU 2020] </span><span class="font53">The ITU homepage, </span><a href="http://www.itu.int/"><span class="font53">http://www.itu.int/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Iyer 2008] </span><span class="font53">S. Iyer, R. R. Kompella, N. McKeown, “Designing Packet Buffers for Router Line Cards,” </span><span class="font53" style="font-style:italic;">IEEE/ACM Transactions on Networking,</span><span class="font53"> Vol. 16, No. 3 (June 2008), pp. 705-717.</span></p>
<p><span class="font53" style="font-weight:bold;">[Jacobson 1988] </span><span class="font53">V. Jacobson, “Congestion Avoidance and Control,” </span><span class="font53" style="font-style:italic;">Proc. 1988 ACM SIGCOMM Conference</span><span class="font53"> (Stanford, CA, Aug. 1988), pp. 314-329.</span></p>
<p><span class="font53" style="font-weight:bold;">[Jain 1986] </span><span class="font53">R. Jain, “A Timeout-Based Congestion Control Scheme for Window Flow-Controlled Networks,” </span><span class="font53" style="font-style:italic;">IEEE Journal on Selected Areas in Communications SAC-4,</span><span class="font53"> 7 (Oct. 1986).</span></p>
<p><span class="font53" style="font-weight:bold;">[Jain 1989] </span><span class="font53">R. Jain, “A Delay-Based Approach for Congestion Avoidance in Interconnected Heterogeneous Computer Networks,” </span><span class="font53" style="font-style:italic;">ACM SIGCOMM Computer Communications Review</span><span class="font53">, Vol. 19, No. 5 (1989), pp. 56-71.</span></p>
<p><span class="font53" style="font-weight:bold;">[Jain 1994] </span><span class="font53">R. Jain, </span><span class="font53" style="font-style:italic;">FDDI Handbook: High-Speed Networking Using Fiber and Other Media</span><span class="font53">, Addison-Wesley, Reading, MA, 1994.</span></p>
<p><span class="font53" style="font-weight:bold;">[Jain 1996] </span><span class="font53">R. Jain. S. Kalyanaraman, S. Fahmy, R. Goyal, S. Kim, “Tutorial Paper on ABR Source Behavior,” </span><span class="font53" style="font-style:italic;">ATM Forum</span><span class="font53">/96-1270, Oct. 1996. </span><a href="http://www.cse.wustl.edu/~jain/atmf/ftp/atm96-1270.pdf"><span class="font53">http://www.cse.</span></a><span class="font53"> </span><a href="http://www.cse.wustl.edu/~jain/atmf/ftp/atm96-1270.pdf"><span class="font53">wustl.edu/~jain/atmf/ftp/atm96-1270.pdf</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Jain 2013] </span><span class="font53">S. Jain, A. Kumar, S. Mandal, J. Ong, L. Poutievski, A. Singh, S.Venkata, J. Wanderer, J. Zhou, M. Zhu, J. Zolla, U. Holzle, S. Stuart, A, Vahdat, “B4: Experience with a Globally Deployed Software Defined Wan,” </span><span class="font53" style="font-style:italic;">Proc. 2013 ACM SIGCOMM Conference,</span><span class="font53"> pp. 3-14.</span></p>
<p><span class="font53" style="font-weight:bold;">[Jimenez 1997] </span><span class="font53">D. Jimenez, “Outside Hackers Infiltrate MIT Network, Compromise Security,” </span><span class="font53" style="font-style:italic;">The Tech,</span><span class="font53"> Vol. 117, No. 49 (Oct. 1997), p. 1, </span><a href="http://www-tech.mit.edu/V117/N49/hackers.49n.html"><span class="font53">http://www-tech.mit.</span></a><span class="font53"> </span><a href="http://www-tech.mit.edu/V117/N49/hackers.49n.html"><span class="font53">edu/V117/N49/hackers.49n.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Juniper MX2020 2020] </span><span class="font53">Juniper Networks, “MX2020 and MX2010 3D Universal Edge Routers,” </span><a href="https://www.juniper.net/us/en/products-services/routing/mx-series/mx2020/"><span class="font53">https://www.juniper.net/us/en/products-services/routing/mx-series/</span></a><span class="font53"> </span><a href="https://www.juniper.net/us/en/products-services/routing/mx-series/mx2020/"><span class="font53">mx2020/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Kaaranen 2001] </span><span class="font53">H. Kaaranen, S. Naghian, L. Laitinen, A. Ahtiainen, V. Niemi, </span><span class="font53" style="font-style:italic;">Networks: Architecture, Mobility and Services,</span><span class="font53"> New York: John Wiley &amp;&nbsp;Sons, 2001.</span></p>
<p><span class="font53" style="font-weight:bold;">[Kahn 1967] </span><span class="font53">D. Kahn, </span><span class="font53" style="font-style:italic;">The Codebreakers: The Story of Secret Writing</span><span class="font53">, The Macmillan Company, 1967.</span></p>
<p><span class="font53" style="font-weight:bold;">[Kahn 1978] </span><span class="font53">R. E. Kahn, S. Gronemeyer, J. Burchfiel, R. Kunzelman, “Advances in Packet Radio Technology,” </span><span class="font53" style="font-style:italic;">Proc. IEEE,</span><span class="font53"> Vol. 66, No. 11 (Nov. 1978), pp. 1468-1496.</span></p>
<p><span class="font53" style="font-weight:bold;">[Kamerman 1997] </span><span class="font53">A. Kamerman, L. Monteban, “WaveLAN-II: A High-Performance Wireless LAN for the Unlicensed Band,” </span><span class="font53" style="font-style:italic;">Bell Labs Technical Journal </span><span class="font53">(Summer 1997), pp. 118-133.</span></p>
<p><span class="font53" style="font-weight:bold;">[Kar 2000] </span><span class="font53">K. Kar, M. Kodialam, T. V. Lakshman, “Minimum Interference Routing of Bandwidth Guaranteed Tunnels with MPLS Traffic Engineering Applications,” </span><span class="font53" style="font-style:italic;">IEEE J. Selected Areas in Communications</span><span class="font53"> (Dec. 2000).</span></p>
<p><span class="font53" style="font-weight:bold;">[Karn 1987] </span><span class="font53">P. Karn, C. Partridge, “Improving Round-Trip Time Estimates in Reliable Transport Protocols,” </span><span class="font53" style="font-style:italic;">Proc. 1987 ACM SIGCOMM Conference.</span></p>
<p><span class="font53" style="font-weight:bold;">[Karol 1987] </span><span class="font53">M. Karol, M. Hluchyj, A. Morgan, “Input Versus Output Queuing on a Space-Division Packet Switch,” </span><span class="font53" style="font-style:italic;">IEEE Transactions on Communications,</span><span class="font53"> Vol. 35, No. 12 (Dec. 1987), pp. 1347-1356.</span></p>
<p><span class="font53" style="font-weight:bold;">[Kaufman 2002] </span><span class="font53">C. Kaufman, R. Perlman, M. Speciner, </span><span class="font53" style="font-style:italic;">Network Security: Private Communication in a Public World,</span><span class="font53"> 2nd edition, Prentice Hall, 2002.</span></p>
<p><span class="font53" style="font-weight:bold;">[Kelly 1998] </span><span class="font53">F. P. Kelly, A. Maulloo, D. Tan, “Rate Control for Communication Networks: Shadow Prices, Proportional Fairness and Stability,” </span><span class="font53" style="font-style:italic;">J. Operations Res. Soc.,</span><span class="font53"> Vol. 49, No. 3 (Mar. 1998), pp. 237-252.</span></p>
<p><span class="font53" style="font-weight:bold;">[Kim 2008] </span><span class="font53">C. Kim, M. Caesar, J. Rexford, “Floodless in SEATTLE: A Scalable Ethernet Architecture for Large Enterprises,” </span><span class="font53" style="font-style:italic;">Proc. 2008 ACM SIGCOMM Conference</span><span class="font53"> (Seattle, WA, Aug. 2008).</span></p>
<p><span class="font53" style="font-weight:bold;">[Kleinrock 1961] </span><span class="font53">L. Kleinrock, “Information Flow in Large Communication Networks,” RLE Quarterly Progress Report, July 1961.</span></p>
<p><span class="font53" style="font-weight:bold;">[Kleinrock 1964] </span><span class="font53">L. Kleinrock, </span><span class="font53" style="font-style:italic;">1964 Communication Nets: Stochastic Message Flow and Delay,</span><span class="font53"> McGraw-Hill, New York, NY, 1964.</span></p>
<p><span class="font53" style="font-weight:bold;">[Kleinrock 1975] </span><span class="font53">L. Kleinrock, </span><span class="font53" style="font-style:italic;">Queuing Systems, Vol. 1,</span><span class="font53"> John Wiley, New York,</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">1975.</span></p></li></ul>
<p><span class="font53" style="font-weight:bold;">[Kleinrock 1975b] </span><span class="font53">L. Kleinrock, F. A. Tobagi, “Packet Switching in Radio Channels: Part I—Carrier Sense Multiple-Access Modes and Their ThroughputDelay Characteristics,” </span><span class="font53" style="font-style:italic;">IEEE Transactions on Communications,</span><span class="font53"> Vol. 23, No. 12 (Dec. 1975), pp. 1400-1416.</span></p>
<p><span class="font53" style="font-weight:bold;">[Kleinrock 1976] </span><span class="font53">L. Kleinrock, </span><span class="font53" style="font-style:italic;">Queuing Systems, Vol. 2</span><span class="font53">, John Wiley, New York,</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">1976.</span></p></li></ul>
<p><span class="font53" style="font-weight:bold;">[Kleinrock 2004] </span><span class="font53">L. Kleinrock, “The Birth of the Internet,” </span><a href="http://www.lk.cs.ucla.edu/LK/Inet/birth.html"><span class="font53">http://www.lk.cs.ucla.</span></a><span class="font53"> </span><a href="http://www.lk.cs.ucla.edu/LK/Inet/birth.html"><span class="font53">edu/LK/Inet/birth.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Kleinrock 2018] </span><span class="font53">L. Kleinrock, “Internet congestion control using the power metric: Keep the pipe just full, but no fuller,” </span><span class="font53" style="font-style:italic;">Ad Hoc Networks,</span><span class="font53"> Vol. 80, 2018, pp. 142-157.</span></p>
<p><span class="font53" style="font-weight:bold;">[Kohler 2006] </span><span class="font53">E. Kohler, M. Handley, S. Floyd, “DDCP: Designing DCCP: Congestion Control Without Reliability,” </span><span class="font53" style="font-style:italic;">Proc. 2006 ACM SIGCOMM Conference </span><span class="font53">(Pisa, Italy, Sept. 2006).</span></p>
<p><span class="font53" style="font-weight:bold;">[Kohlios 2018] </span><span class="font53">C. Kohlios, T. Hayajneh, “A Comprehensive Attack Flow Model and Security Analysis for Wi-Fi and WPA3,” </span><span class="font53" style="font-style:italic;">Electronics,</span><span class="font53"> Vol. 7, No. 11, 2018.</span></p>
<p><span class="font53" style="font-weight:bold;">[Kolding 2003] </span><span class="font53">T. Kolding, K. Pedersen, J. Wigard, F. Frederiksen, P. Mogensen, “High Speed Downlink Packet Access: WCDMA Evolution,” </span><span class="font53" style="font-style:italic;">IEEE Vehicular Technology Society News</span><span class="font53"> (Feb. 2003), pp. 4-10.</span></p>
<p><span class="font53" style="font-weight:bold;">[Koponen 2010] </span><span class="font53">T. Koponen, M. Casado, N. Gude, J. Stribling, L. Poutievski, M. Zhu, R. Ramanathan, Y. Iwata, H. Inoue, T. Hama, S. Shenker, “Onix: A Distributed Control Platform for Large-Scale Production Networks,” </span><span class="font53" style="font-style:italic;">9th USENIX conference on Operating systems design and implementation (OSDI’10), </span><span class="font53">pp. 1-6.</span></p>
<p><span class="font53" style="font-weight:bold;">[Koponen 2011] </span><span class="font53">T. Koponen, S. Shenker, H. Balakrishnan, N. Feamster, I. Ganichev, A. Ghodsi, P. B. Godfrey, N. McKeown, G. Parulkar, B. Raghavan, J. Rexford, S. Arianfar, D. Kuptsov, “Architecting for Innovation,” </span><span class="font53" style="font-style:italic;">ACM Computer Communications Review</span><span class="font53">, 2011.</span></p>
<p><span class="font53" style="font-weight:bold;">[Korhonen 2003] </span><span class="font53">J. Korhonen, </span><span class="font53" style="font-style:italic;">Introduction to 3G Mobile Communications,</span><span class="font53"> 2nd edition, Artech House, 2003.</span></p>
<p><span class="font53" style="font-weight:bold;">[Koziol 2003] </span><span class="font53">J. Koziol, </span><span class="font53" style="font-style:italic;">Intrusion Detection with Snort,</span><span class="font53"> Sams Publishing, 2003.</span></p>
<p><span class="font53" style="font-weight:bold;">[Kreutz 2015] </span><span class="font53">D. Kreutz, F.M.V. Ramos, P. Esteves Verissimo, C. Rothenberg, S. Azodolmolky, S. Uhlig, “Software-Defined Networking: A Comprehensive Survey,” </span><span class="font53" style="font-style:italic;">Proceedings of the IEEE,</span><span class="font53"> Vol. 103, No. 1 (Jan. 2015), pp. 14-76.</span></p>
<p><span class="font53">This paper is also being updated at </span><a href="https://github.com/SDN-Survey/latex/wiki"><span class="font53">https://github.com/SDN-Survey/latex/wiki</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Krishnamurthy 2001] </span><span class="font53">B. Krishnamurthy, J. Rexford, </span><span class="font53" style="font-style:italic;">Web Protocols and Practice: HTTP/1.1, Networking Protocols, and Traffic Measurement,</span><span class="font53"> Addison-Wesley, Boston, MA, 2001.</span></p>
<p><span class="font53" style="font-weight:bold;">[Kuhlewind 2013] </span><span class="font53">M. Kuhlewind, S. Neuner, B, Trammell, “On the state of ECN and TCP options on the internet,” </span><span class="font53" style="font-style:italic;">Proc. 14th International Conference on Passive and Active Measurement (PAM’13),</span><span class="font53"> pp. 135-144.</span></p>
<p><span class="font53" style="font-weight:bold;">[Kulkarni 2005] </span><span class="font53">S. Kulkarni, C. Rosenberg, “Opportunistic Scheduling: Generalizations to Include Multiple Constraints, Multiple Interfaces, and Short Term Fairness,” </span><span class="font53" style="font-style:italic;">Wireless Networks,</span><span class="font53"> 11 (2005), pp. 557-569.</span></p>
<p><span class="font53" style="font-weight:bold;">[Kumar 2006] </span><span class="font53">R. Kumar, K.W. Ross, “Optimal Peer-Assisted File Distribution: Single and Multi-Class Problems,” </span><span class="font53" style="font-style:italic;">IEEE Workshop on Hot Topics in Web Systems and Technologies</span><span class="font53"> (Boston, MA, 2006).</span></p>
<p><span class="font53" style="font-weight:bold;">[Labovitz 1997] </span><span class="font53">C. Labovitz, G. R. Malan, F. Jahanian, “Internet Routing Instability,” </span><span class="font53" style="font-style:italic;">Proc. 1997 ACM SIGCOMM Conference</span><span class="font53"> (Cannes, France, Sept. 1997), pp. 115-126.</span></p>
<p><span class="font53" style="font-weight:bold;">[Labovitz 2010] </span><span class="font53">C. Labovitz, S. lekel-Johnson, D. McPherson, J. Oberheide, F. Jahanian, “Internet Inter-Domain Traffic,” </span><span class="font53" style="font-style:italic;">Proc. 2010 ACM SIGCOMM Conference.</span></p>
<p><span class="font53" style="font-weight:bold;">[Labrador 1999] </span><span class="font53">M. Labrador, S. Banerjee, “Packet Dropping Policies for ATM and IP Networks,” </span><span class="font53" style="font-style:italic;">IEEE Communications Surveys,</span><span class="font53"> Vol. 2, No. 3 (Third Quarter 1999), pp. 2-14.</span></p>
<p><span class="font53" style="font-weight:bold;">[Lacage 2004] </span><span class="font53">M. Lacage, M.H. Manshaei, T. Turletti, “IEEE 802.11 Rate Adaptation: A Practical Approach,” </span><span class="font53" style="font-style:italic;">ACM Int. Symposium on Modeling, Analysis, and Simulation of Wireless and Mobile Systems (MSWiM)</span><span class="font53"> (Venice, Italy, Oct. 2004).</span></p>
<p><span class="font53" style="font-weight:bold;">[Lakhina 2005] </span><span class="font53">A. Lakhina, M. Crovella, C. Diot, “Mining Anomalies Using Traffic Feature Distributions,” </span><span class="font53" style="font-style:italic;">Proc. 2005 ACM SIGCOMM Conference.</span></p>
<p><span class="font53" style="font-weight:bold;">[Lakshman 1997] </span><span class="font53">T. V. Lakshman, U. Madhow, “The Performance of TCP/IP for Networks with High Bandwidth-Delay Products and Random Loss,” </span><span class="font53" style="font-style:italic;">IEEE/ACM Transactions on Networking,</span><span class="font53"> Vol. 5, No. 3 (1997), pp. 336-350.</span></p>
<p><span class="font53" style="font-weight:bold;">[Lakshman 2004] </span><span class="font53">T. V. Lakshman, T. Nandagopal, R. Ramjee, K. Sabnani, T.</span></p>
<p><span class="font53">Woo, “The SoftRouter Architecture,” </span><span class="font53" style="font-style:italic;">Proc. 3nd ACM Workshop on Hot Topics in Networks (Hotnets-III)</span><span class="font53">, Nov. 2004.</span></p>
<p><span class="font53" style="font-weight:bold;">[Lam 1980] </span><span class="font53">S. Lam, “A Carrier Sense Multiple Access Protocol for Local Networks,” </span><span class="font53" style="font-style:italic;">Computer Networks</span><span class="font53">, Vol. 4 (1980), pp. 21-32.</span></p>
<p><span class="font53" style="font-weight:bold;">[Lamport 1989] </span><span class="font53">L. Lamport, “The Part-Time Parliament,” Technical Report 49, Systems Research Center, Digital Equipment Corp., Palo Alto, Sept. 1989.</span></p>
<p><span class="font53" style="font-weight:bold;">[Lampson 1983] </span><span class="font53">Lampson, Butler W. “Hints for computer system design,” </span><span class="font53" style="font-style:italic;">ACM SIGOPS Operating Systems Review</span><span class="font53">, Vol. 17, No. 5, 1983.</span></p>
<p><span class="font53" style="font-weight:bold;">[Lampson 1996] </span><span class="font53">B. Lampson, “How to Build a Highly Available System Using Consensus,” </span><span class="font53" style="font-style:italic;">Proc. 10th International Workshop on Distributed Algorithms</span></p>
<p><span class="font53">(WDAG ’96), Ozalp Babaoglu and Keith Marzullo (Eds.), Springer-Verlag, pp. 1-17.</span></p>
<p><span class="font53" style="font-weight:bold;">[Langley 2017] </span><span class="font53">A. Langley, A. Riddoch, A. Wilk, A. Vicente, C. Krasic, D. Zhang, F. Yang, F. Kouranov, I. Swett, J. Iyengar, J. Bailey, J. Dorfman, J. Roskind, J.</span></p>
<p><span class="font53">Kulik, P. Westin, R. Tenneti, R. Shade, R. Hamilton, V. Vasiliev, W. Chang, Z. Shi, “The QUIC Transport Protocol: Design and Internet-Scale Deployment,” </span><span class="font53" style="font-style:italic;">Proc. 2017 ACM SIGCOMM Conference.</span></p>
<p><span class="font53" style="font-weight:bold;">[Lawton 2001] </span><span class="font53">G. Lawton, “Is IPv6 Finally Gaining Ground?” </span><span class="font53" style="font-style:italic;">IEEE Computer Magazine</span><span class="font53"> (Aug. 2001), pp. 11-15.</span></p>
<p><span class="font53" style="font-weight:bold;">[Leighton 2009] </span><span class="font53">T. Leighton, “Improving Performance on the Internet,” </span><span class="font53" style="font-style:italic;">Communications of the ACM,</span><span class="font53"> Vol. 52, No. 2 (Feb. 2009), pp. 44-51.</span></p>
<p><span class="font53" style="font-weight:bold;">[Leiner 1998] </span><span class="font53">B. Leiner, V. Cerf, D. Clark, R. Kahn, L. Kleinrock, D. Lynch, J. Postel, L. Roberts, S. Woolf, “A Brief History of the Internet,” </span><a href="http://www.isoc.org/internet/history/brief.html"><span class="font53">http://www.isoc.</span></a><span class="font53"> </span><a href="http://www.isoc.org/internet/history/brief.html"><span class="font53">org/internet/history/brief.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Leung 2006] </span><span class="font53">K. Leung, V. O. K. Li, “TCP in Wireless Networks: Issues, Approaches, and Challenges,” </span><span class="font53" style="font-style:italic;">IEEE Commun. Surveys and Tutorials,</span><span class="font53"> Vol. 8, No. 4 (2006), pp. 64-79.</span></p>
<p><span class="font53" style="font-weight:bold;">[Levin 2012] </span><span class="font53">D. Levin, A. Wundsam, B. Heller, N. Handigol, A. Feldmann, “Logically Centralized?: State Distribution Trade-offs in Software Defined Networks,” </span><span class="font53" style="font-style:italic;">Proc. First Workshop on Hot Topics in Software Defined Networks</span><span class="font53"> (Aug. 2012), pp. 1-6.</span></p>
<p><span class="font53" style="font-weight:bold;">[Li 2004] </span><span class="font53">L. Li, D. Alderson, W. Willinger, J. Doyle, “A First-Principles Approach to Understanding the Internet’s Router-Level Topology,” </span><span class="font53" style="font-style:italic;">Proc. 2004 ACM SIGCOMM Conference</span><span class="font53"> (Portland, OR, Aug. 2004).</span></p>
<p><span class="font53" style="font-weight:bold;">[Li 2007] </span><span class="font53">J. Li, M. Guidero, Z. Wu, E. Purpus, T. Ehrenkranz, “BGP Routing Dynamics Revisited.” </span><span class="font53" style="font-style:italic;">ACM Computer Communication Review</span><span class="font53"> (Apr. 2007).</span></p>
<p><span class="font53" style="font-weight:bold;">[Li 2015] </span><span class="font53">S. Q. Li, “Building Softcom Ecosystem Foundation,” Open Networking Summit, 2015.</span></p>
<p><span class="font53" style="font-weight:bold;">[Li 2017] </span><span class="font53">Z. Li, W. Wang, C. Wilson, J. Chen, C. Qian, T. Jung, L. Zhang, K. Liu, X.Li, Y. Liu, “FBS-Radar: Uncovering Fake Base Stations at Scale in the Wild,” </span><span class="font53" style="font-style:italic;">ISOC Symposium on Network and Distributed System Security (NDSS),</span><span class="font53"> February 2017.</span></p>
<p><span class="font53" style="font-weight:bold;">[Li 2018] </span><span class="font53">Z. Li, D. Levin, N. Spring, B. Bhattacharjee, “Internet anycast: performance, problems, &amp;&nbsp;potential,” </span><span class="font53" style="font-style:italic;">Proc. 2018 ACM SIGCOMM Conference,</span><span class="font53"> pp. 59-73.</span></p>
<p><span class="font53" style="font-weight:bold;">[Lin 2001] </span><span class="font53">Y. Lin, I. Chlamtac, </span><span class="font53" style="font-style:italic;">Wireless and Mobile Network Architectures</span><span class="font53">, John Wiley and Sons, New York, NY, 2001.</span></p>
<p><span class="font53" style="font-weight:bold;">[Liogkas 2006] </span><span class="font53">N. Liogkas, R. Nelson, E. Kohler, L. Zhang, “Exploiting BitTorrent for Fun (but Not Profit),” </span><span class="font53" style="font-style:italic;">6th International Workshop on Peer-to-Peer Systems (IPTPS 2006).</span></p>
<p><span class="font53" style="font-weight:bold;">[Liu 2003] </span><span class="font53">J. Liu, I. Matta, M. Crovella, “End-to-End Inference of Loss Nature in a Hybrid Wired/Wireless Environment,” </span><span class="font53" style="font-style:italic;">Proc. WiOpt’03: Modeling and Optimization in Mobile, Ad Hoc and Wireless Networks</span><span class="font53">.</span></p>
<p><span class="font53" style="font-weight:bold;">[Locher 2006] </span><span class="font53">T. Locher, P. Moor, S. Schmid, R. Wattenhofer, “Free Riding in BitTorrent is Cheap,” </span><span class="font53" style="font-style:italic;">Proc. ACM HotNets 2006</span><span class="font53"> (Irvine CA, Nov. 2006).</span></p>
<p><span class="font53" style="font-weight:bold;">[Madhyastha 2017] </span><span class="font53">H. Madhyastha, “A Case Against Net Neutrality,” </span><span class="font53" style="font-style:italic;">IEEE Spectrum,</span><span class="font53"> Dec. 2017, </span><a href="https://spectrum.ieee.org/tech-talk/telecom/internet/a-case-against-net-neutrality"><span class="font53">https://spectrum.ieee.org/tech-talk/telecom/internet/a-case-</span></a><span class="font53"></span><a href="https://spectrum.ieee.org/tech-talk/telecom/internet/a-case-against-net-neutrality"><span class="font53">against-net-neutrality</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Mahdavi 1997] </span><span class="font53">J. Mahdavi, S. Floyd, “TCP-Friendly Unicast Rate-Based Flow Control,” unpublished note (Jan. 1997).</span></p>
<p><span class="font53" style="font-weight:bold;">[Mao 2002] </span><span class="font53">Z. Mao, C. Cranor, F. Douglis, M. Rabinovich, O. Spatscheck,</span></p>
<p class="font53">J. Wang, “A Precise and Efficient Evaluation of the Proximity Between Web Clients and Their Local DNS Servers,” <span class="font53" style="font-style:italic;">2002 USENIX Annual Technical Conference, </span><span class="font53">pp. 229-242.</span></p>
<p><span class="font53" style="font-weight:bold;">[Mathis 1997] </span><span class="font53">M. Mathis, J. Semke, J. Mahdavi, T. Ott, T. 1997, “The macroscopic behavior of the TCP congestion avoidance algorithm,” </span><span class="font53" style="font-style:italic;">ACM SIGCOMM Computer Communication Review,</span><span class="font53"> 27(3): pp. 67-82.</span></p>
<p><span class="font53" style="font-weight:bold;">[MaxMind 2020] </span><a href="http://www.maxmind.com/app/ip-location"><span class="font53">http://www.maxmind.com/app/ip-location</span></a></p>
<p><span class="font53" style="font-weight:bold;">[McKeown 1997a] </span><span class="font53">N. McKeown, M. Izzard, A. Mekkittikul, W. Ellersick, M. Horowitz, “The Tiny Tera: A Packet Switch Core,” </span><span class="font53" style="font-style:italic;">IEEE Micro Magazine </span><span class="font53">(Jan.-Feb. 1997).</span></p>
<p><span class="font53" style="font-weight:bold;">[McKeown 1997b] </span><span class="font53">N. McKeown, “A Fast Switched Backplane for a Gigabit Switched Router,” </span><span class="font53" style="font-style:italic;">Business Communications Review,</span><span class="font53"> Vol. 27, No. 12. </span><a href="http://tiny-tera.stanford.edu/~nickm/papers/cisco_fasts_wp.pdf"><span class="font53">http://tiny-</span></a><span class="font53"></span><a href="http://tiny-tera.stanford.edu/~nickm/papers/cisco_fasts_wp.pdf"><span class="font53">tera.stanford.edu/~nickm/papers/cisco_fasts_wp.pdf</span></a></p>
<p><span class="font53" style="font-weight:bold;">[McKeown 2008] </span><span class="font53">N. McKeown, T. Anderson, H. Balakrishnan, G. Parulkar, L. Peterson, J. Rexford, S. Shenker, J. Turner. 2008. OpenFlow: Enabling Innovation in Campus Networks. </span><span class="font53" style="font-style:italic;">SIGCOMM Comput. Commun. Rev.</span><span class="font53"> 38, 2 (Mar. 2008), pp. 69-74.</span></p>
<p><span class="font53" style="font-weight:bold;">[McQuillan 1980] </span><span class="font53">J. McQuillan, I. Richer, E. Rosen, “The New Routing Algorithm for the Arpanet,” </span><span class="font53" style="font-style:italic;">IEEE Transactions on Communications,</span><span class="font53"> Vol. 28, No. 5 (May 1980), pp. 711-719.</span></p>
<p><span class="font53" style="font-weight:bold;">[Metcalfe 1976] </span><span class="font53">R. M. Metcalfe, D. R. Boggs. “Ethernet: Distributed Packet Switching for Local Computer Networks,” </span><span class="font53" style="font-style:italic;">Communications of the Association for Computing Machinery</span><span class="font53">, Vol. 19, No. 7 (July 1976), pp. 395-404.</span></p>
<p><span class="font53" style="font-weight:bold;">[Meyers 2004] </span><span class="font53">A. Myers, T. Ng, H. Zhang, “Rethinking the Service Model: Scaling Ethernet to a Million Nodes, </span><span class="font53" style="font-style:italic;">” ACM Hotnets Conference,</span><span class="font53"> 2004.</span></p>
<p><span class="font53" style="font-weight:bold;">[Mijumbi 2016] </span><span class="font53">R. Mijumbi, J. Serrat, J. Gorricho, N. Bouten, F. De Turck and R. Boutaba, “Network Function Virtualization: State-of-the-Art and Research Challenges,” </span><span class="font53" style="font-style:italic;">IEEE Communications Surveys &amp;&nbsp;Tutorials,</span><span class="font53"> Vol. 18, No. 1, pp. 236-262, 2016.</span></p>
<p><span class="font53" style="font-weight:bold;">[MIT TR 2019] </span><span class="font53">MIT Technology Review, “How a quantum computer could break 2048-bit RSA encryption in 8 hours,” May 2019, </span><a href="https://www.technologyreview.com/s/613596/how-a-quantum-computer-could-break-2048-bit-rsa-encryption-in-8-hours/"><span class="font53">https://www.technologyreview</span></a><span class="font53"> </span><a href="https://www.technologyreview.com/s/613596/how-a-quantum-computer-could-break-2048-bit-rsa-encryption-in-8-hours/"><span class="font53">.com/s/613596/how-a-quantum-computer-could-break-2048-bit-rsa-encryption-</span></a><span class="font53"></span><a href="https://www.technologyreview.com/s/613596/how-a-quantum-computer-could-break-2048-bit-rsa-encryption-in-8-hours/"><span class="font53">in-8-hours/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Mittal 2015] </span><span class="font53">R. Mittal, V. Lam, N. Dukkipati, E. Blem, H. Wassel, M. Ghobadi, A. Vahdat, Y. Wang, D. Wetherall, D. Zats, “TIMELY: RTT-based Congestion Control for the Datacenter,” </span><span class="font53" style="font-style:italic;">Proc. 2015 ACM SIGCOMM Conference,</span><span class="font53"> pp. 537-550.</span></p>
<p><span class="font53" style="font-weight:bold;">[Mockapetris 1988] </span><span class="font53">P. V. Mockapetris, K. J. Dunlap, “Development of the Domain Name System,” </span><span class="font53" style="font-style:italic;">Proc. 1988 ACM SIGCOMM Conference</span><span class="font53"> (Stanford, CA, Aug. 1988).</span></p>
<p><span class="font53" style="font-weight:bold;">[Mockapetris 2005] </span><span class="font53">P. Mockapetris, Sigcomm Award Lecture, video available at </span><a href="http://www.postel.org/sigcomm"><span class="font53">http://www.postel.org/sigcomm</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Molinero-Fernandez 2002] </span><span class="font53">P. Molinaro-Fernandez, N. McKeown, H. Zhang, “Is IP Going to Take Over the World (of Communications)?” </span><span class="font53" style="font-style:italic;">Proc. 2002 ACM Hotnets.</span></p>
<p><span class="font53" style="font-weight:bold;">[Molle 1987] </span><span class="font53">M. L. Molle, K. Sohraby, A. N. Venetsanopoulos, “Space-Time Models of Asynchronous CSMA Protocols for Local Area Networks,” </span><span class="font53" style="font-style:italic;">IEEE Journal on Selected Areas in Communications</span><span class="font53">, Vol. 5, No. 6 (1987), pp. 956-968.</span></p>
<p><span class="font53" style="font-weight:bold;">[Moshref 2016] </span><span class="font53">M. Moshref, M. Yu, R, Govindan, A. Vahdat, “Trumpet: Timely and Precise Triggers in Data Centers,” </span><span class="font53" style="font-style:italic;">Proc. 2016 ACM SIGCOMM Conference.</span></p>
<p><span class="font53" style="font-weight:bold;">[Motorola 2007] </span><span class="font53">Motorola, “Long Term Evolution (LTE): A Technical Overview,” </span><a href="http://www.motorola.com/staticfiles/Business/Solutions/Industry%20Solutions/Service%20Providers/Wireless%20Operators/LTE/_Document/Static%20Files/6834_MotDoc_New.pdf"><span class="font53">http://www.motorola.com/staticfiles/Business/Solutions/Industry%20Solutions/</span></a></p>
<p><a href="http://www.motorola.com/staticfiles/Business/Solutions/Industry%20Solutions/Service%20Providers/Wireless%20Operators/LTE/_Document/Static%20Files/6834_MotDoc_New.pdf"><span class="font53">Service%20Providers/Wireless%20Operators/LTE/_Document/Static%20</span></a></p>
<p><a href="http://www.motorola.com/staticfiles/Business/Solutions/Industry%20Solutions/Service%20Providers/Wireless%20Operators/LTE/_Document/Static%20Files/6834_MotDoc_New.pdf"><span class="font53">FilesA5834_MotDoc_New.pdf</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Mouly 1992] </span><span class="font53">M. Mouly, M. Pautet, </span><span class="font53" style="font-style:italic;">The GSM System for Mobile Communications, </span><span class="font53">Cell and Sys, Palaiseau, France, 1992.</span></p>
<p><span class="font53" style="font-weight:bold;">[Moy 1998] </span><span class="font53">J. Moy, </span><span class="font53" style="font-style:italic;">OSPF: Anatomy of An Internet Routing Protocol</span><span class="font53">, Addison-Wesley, Reading, MA, 1998.</span></p>
<p><span class="font53" style="font-weight:bold;">[Mysore 2009] </span><span class="font53">R. N. Mysore, A. Pamboris, N. Farrington, N. Huang, P. Miri,</span></p>
<p><span class="font53">S. Radhakrishnan, V. Subramanya, A. Vahdat, “PortLand: A Scalable Fault-Tolerant Layer 2 Data Center Network Fabric,” </span><span class="font53" style="font-style:italic;">Proc. 2009 ACM SIGCOMM Conference.</span></p>
<p><span class="font53" style="font-weight:bold;">[Nahum 2002] </span><span class="font53">E. Nahum, T. Barzilai, D. Kandlur, “Performance Issues in WWW Servers,” </span><span class="font53" style="font-style:italic;">IEEE/ACM Transactions on Networking,</span><span class="font53"> Vol 10, No. 1 (Feb. 2002).</span></p>
<p><span class="font53" style="font-weight:bold;">[Narayan 2018] </span><span class="font53">A. Narayan, F. Cangialosi, D. Raghavan, P. Goyal, S. Narayana, R. Mittal, M. Alizadeh, H. Balakrishnan, “Restructuring endpoint congestion control,” </span><span class="font53" style="font-style:italic;">Proc. ACM SIGCOMM 2018 Conference,</span><span class="font53"> pp. 30-43.</span></p>
<p><span class="font53" style="font-weight:bold;">[Netflix Open Connect 2020] </span><span class="font53">Netflix Open Connect CDN, 2016, </span><a href="https://openconnect.netflix.com/"><span class="font53">https://</span></a><span class="font53"> </span><a href="https://openconnect.netflix.com/"><span class="font53">openconnect.netflix.com/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Netflix Video 1] </span><span class="font53">Designing Netflix’s Content Delivery System, D. Fulllager, 2014, </span><a href="https://www.youtube.com/watch?v=LkLLpYdDINA"><span class="font53">https://www.youtube.com/watch?v=LkLLpYdDINA</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Netflix Video 2] </span><span class="font53">Scaling the Netflix Global CDN, D. Temkin, 2015, </span><a href="https://www.youtube.com/watch?v=tbqcsHg-Q_o"><span class="font53">https://www</span></a><span class="font53"> </span><a href="https://www.youtube.com/watch?v=tbqcsHg-Q_o"><span class="font53">.youtube.com/watch?v=tbqcsHg-Q_o</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Neumann 1997] </span><span class="font53">R. Neumann, “Internet Routing Black Hole,” </span><span class="font53" style="font-style:italic;">The Risks Digest: Forum on Risks to the Public in Computers and Related Systems,</span><span class="font53"> Vol. 19, No. 12 (May 1997). </span><a href="http://catless.ncl.ac.uk/Risks/19.12.html%23subj1.1"><span class="font53">http://catless.ncl.ac.uk/Risks/19.12.html#subj1.1</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Neville-Neil 2009] </span><span class="font53">G. Neville-Neil, “Whither Sockets?” </span><span class="font53" style="font-style:italic;">Communications of the ACM,</span><span class="font53"> Vol. 52, No. 6 (June 2009), pp. 51-55.</span></p>
<p><span class="font53" style="font-weight:bold;">[Nguyen 2016] </span><span class="font53">T. Nguyen, C. Bonnet and J. Harri, “SDN-based distributed mobility management for 5G networks,” </span><span class="font53" style="font-style:italic;">2016 IEEE Wireless Communications and Networking Conference,</span><span class="font53"> Doha, 2016, pp. 1-7.</span></p>
<p><span class="font53" style="font-weight:bold;">[Nichols 2012] </span><span class="font53">K. Nichols, V. Jacobson. Controlling Queue Delay. </span><span class="font53" style="font-style:italic;">ACM Queue, </span><span class="font53">Vol. 10, No. 5, May 2012.</span></p>
<p><span class="font53" style="font-weight:bold;">[Nicholson 2006] </span><span class="font53">A Nicholson, Y. Chawathe, M. Chen, B. Noble, D. Wetherall, “Improved Access Point Selection,” </span><span class="font53" style="font-style:italic;">Proc. 2006 ACM Mobisys Conference </span><span class="font53">(Uppsala Sweden, 2006).</span></p>
<p><span class="font53" style="font-weight:bold;">[Nielsen 1997] </span><span class="font53">H. F. Nielsen, J. Gettys, A. Baird-Smith, E. Prud’hommeaux, H. W. Lie, C. Lilley, “Network Performance Effects of HTTP/1.1, CSS1, and PNG,” </span><span class="font53" style="font-style:italic;">W3C Document,</span><span class="font53"> 1997 (also appears in </span><span class="font53" style="font-style:italic;">Proc. 1997 ACM SIGCOM Conference</span><span class="font53"> (Cannes, France, Sept 1997), pp. 155-166.</span></p>
<p><span class="font53" style="font-weight:bold;">[NIST 2001] </span><span class="font53">National Institute of Standards and Technology, “Advanced Encryption Standard (AES),” Federal Information Processing Standards 197, Nov. 2001, </span><a href="http://csrc.nist.gov/publications/fips/fips197/fips-197.pdf"><span class="font53">http://csrc.nist.gov/publications/fips/fips197/fips-197.pdf</span></a></p>
<p><span class="font53" style="font-weight:bold;">[NIST IPv6 2020] </span><span class="font53">US National Institute of Standards and Technology, “Estimating IPv6 &amp;&nbsp;DNSSEC Deployment SnapShots,” </span><a href="http://fedv6-deployment.antd.nist.gov/snap-all.html"><span class="font53">http://fedv6-deployment.antd.nist.gov/</span></a><span class="font53"> </span><a href="http://fedv6-deployment.antd.nist.gov/snap-all.html"><span class="font53">snap-all.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Nmap 2020] </span><span class="font53">Nmap homepage, </span><a href="https://nmap.org"><span class="font53">https://nmap.org</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Nonnenmacher 1998] </span><span class="font53">J. Nonnenmacher, E. Biersak, D. Towsley, “Parity-Based Loss Recovery for Reliable Multicast Transmission,” </span><span class="font53" style="font-style:italic;">IEEE/ACM Transactions on Networking,</span><span class="font53"> Vol. 6, No. 4 (Aug. 1998), pp. 349-361.</span></p>
<p><span class="font53" style="font-weight:bold;">[Noormohammadpour 2018] </span><span class="font53">M. Noormohammadpour, C. Raghavendra, Cauligi, “Datacenter Traffic Control: Understanding Techniques and Trade-offs,” </span><span class="font53" style="font-style:italic;">IEEE Communications Surveys &amp;&nbsp;Tutorials,</span><span class="font53"> Vol. 20 (2018), pp. 1492-1525.</span></p>
<p><span class="font53" style="font-weight:bold;">[Nygren 2010] </span><span class="font53">Erik Nygren, Ramesh K. Sitaraman, and Jennifer Sun, “The Akamai Network: A Platform for High-performance Internet Applications,” </span><span class="font53" style="font-style:italic;">SIGOPS Oper. Syst. Rev.</span><span class="font53"> 44, 3 (Aug. 2010), pp. 2-19.</span></p>
<p><span class="font53" style="font-weight:bold;">[ONF 2020] </span><span class="font53">Open Networking Foundation, Specification, </span><a href="https://www.opennetworking.org/software-defined-standards/specifications/"><span class="font53">https://www.opennet-</span></a><span class="font53">working.org/software-defined-standards/specifications/</span></p>
<p><span class="font53" style="font-weight:bold;">[ONOS 2020] </span><span class="font53">ONOS, </span><a href="https://onosproject.org/collateral/"><span class="font53">https://onosproject.org/collateral/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[OpenDaylight 2020] </span><span class="font53">OpenDaylight, </span><a href="https://www.opendaylight.org/"><span class="font53">https://www.opendaylight.org/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[OpenDaylight 2020] </span><span class="font53">OpenDaylight, </span><a href="https://www.opendaylight.org/what-we-do/current-release/sodium"><span class="font53">https://www.opendaylight.org/what-we-do/</span></a><span class="font53"> </span><a href="https://www.opendaylight.org/what-we-do/current-release/sodium"><span class="font53">current-release/sodium</span></a></p>
<p><span class="font53" style="font-weight:bold;">[OpenSignal 2019] </span><span class="font53">Opensignal, </span><a href="https://www.opensignal.com/"><span class="font53">https://www.opensignal.com/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Ordonez-Lucena 2017] </span><span class="font53">J. Ordonez-Lucena, P. Ameigeiras, D. Lopez, J. J.</span></p>
<p><span class="font53">Ramos-Munoz, J. Lorca and J. Folgueira, “Network Slicing for 5G with SDN/NFV: Concepts, Architectures, and Challenges,” </span><span class="font53" style="font-style:italic;">IEEE Communications Magazine,</span><span class="font53"> Vol. 55, No. 5, pp. 80-87, May 2017.</span></p>
<p><span class="font53" style="font-weight:bold;">[Osterweil 2012] </span><span class="font53">E. Osterweil, D. McPherson, S. DiBenedetto, C. Papadopoulos, D. Massey, “Behavior of DNS Top Talkers,” </span><span class="font53" style="font-style:italic;">Passive and Active Measurement Conference</span><span class="font53">, 2012.</span></p>
<p><span class="font53" style="font-weight:bold;">[P4 2020] </span><span class="font53">P4 Language Consortium, </span><a href="https://p4.org/"><span class="font53">https://p4.org/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Padhye 2000] </span><span class="font53">J. Padhye, V. Firoiu, D. Towsley, J. Kurose, “Modeling TCP Reno Performance: A Simple Model and Its Empirical Validation,” </span><span class="font53" style="font-style:italic;">IEEE/ACM Transactions on Networking,</span><span class="font53"> Vol. 8, No. 2 (Apr. 2000), pp. 133-145.</span></p>
<p><span class="font53" style="font-weight:bold;">[Padhye 2001] </span><span class="font53">J. Padhye, S. Floyd, “On Inferring TCP Behavior,” </span><span class="font53" style="font-style:italic;">Proc. 2001 ACM SIGCOMM Conference</span><span class="font53"> (San Diego, CA, Aug. 2001).</span></p>
<p><span class="font53" style="font-weight:bold;">[Palat 2009] </span><span class="font53">S. Palat, P. Godin, “The LTE Network Architecture: A Comprehensive Tutorial,” in </span><span class="font53" style="font-style:italic;">LTE—The UMTS Long Term Evolution: From Theory to Practice. </span><span class="font53">Also available as a standalone Alcatel white paper.</span></p>
<p><span class="font53" style="font-weight:bold;">[Panda 2013] </span><span class="font53">A. Panda, C. Scott, A. Ghodsi, T. Koponen, S. Shenker, “CAP for Networks,” </span><span class="font53" style="font-style:italic;">Proc. 2013 ACM HotSDN Conference,</span><span class="font53"> pp. 91-96.</span></p>
<p><span class="font53" style="font-weight:bold;">[Parekh 1993] </span><span class="font53">A. Parekh, R. Gallagher, “A Generalized Processor Sharing Approach to Flow Control in Integrated Services Networks: The Single-Node Case,” </span><span class="font53" style="font-style:italic;">IEEE/ACM Transactions on Networking,</span><span class="font53"> Vol. 1, No. 3 (June 1993), pp. 344-357.</span></p>
<p><span class="font53" style="font-weight:bold;">[Partridge 1998] </span><span class="font53">C. Partridge, et al. “A Fifty Gigabit per second IP Router,” </span><span class="font53" style="font-style:italic;">IEEE/ ACM Transactions on Networking,</span><span class="font53"> Vol. 6, No. 3 (Jun. 1998), pp. 237-248.</span></p>
<p><span class="font53" style="font-weight:bold;">[Patel 2013] </span><span class="font53">P. Patel, D. Bansal, L. Yuan, A. Murthy, A. Greenberg, D. Maltz, R. Kern, H. Kumar, M. Zikos, H. Wu, C. Kim, N. Karri, “Ananta: Cloud Scale Load Balancing,” </span><span class="font53" style="font-style:italic;">Proc. 2013 ACM SIGCOMM Conference.</span></p>
<p><span class="font53" style="font-weight:bold;">[Pathak 2010] </span><span class="font53">A. Pathak, Y. A. Wang, C. Huang, A. Greenberg, Y. C. Hu, J. Li,</span></p>
<p class="font53">K. W. Ross, “Measuring and Evaluating TCP Splitting for Cloud Services,” <span class="font53" style="font-style:italic;">Passive and Active Measurement (PAM) Conference</span><span class="font53"> (Zurich, 2010).</span></p>
<p><span class="font53" style="font-weight:bold;">[Peering DB 2020] </span><span class="font53">“The Interconnection Database,” </span><a href="https://www.peeringdb.com/"><span class="font53">https://www.peeringdb.com/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Peha 2006] </span><span class="font53">J. Peha, “The Benefits and Risks of Mandating Network Neutrality, and the Quest for a Balanced Policy,” </span><span class="font53" style="font-style:italic;">Proc. 2006 Telecommunication Policy Research Conference (TPRC),</span><span class="font53"> </span><a href="https://ssrn.com/abstract=2103831"><span class="font53">https://ssrn.com/abstract=2103831</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Perkins 1994] </span><span class="font53">A. Perkins, “Networking with Bob Metcalfe,” </span><span class="font53" style="font-style:italic;">The Red Herring Magazine</span><span class="font53"> (Nov. 1994).</span></p>
<p><span class="font53" style="font-weight:bold;">[Perkins 1998b] </span><span class="font53">C. Perkins, </span><span class="font53" style="font-style:italic;">Mobile IP: Design Principles and Practice</span><span class="font53">, Addison-Wesley, Reading, MA, 1998.</span></p>
<p><span class="font53" style="font-weight:bold;">[Perkins 2000] </span><span class="font53">C. Perkins, </span><span class="font53" style="font-style:italic;">Ad Hoc Networking</span><span class="font53">, Addison-Wesley, Reading, MA, 2000.</span></p>
<p><span class="font53" style="font-weight:bold;">[Perlman 1999] </span><span class="font53">R. Perlman, </span><span class="font53" style="font-style:italic;">Interconnections: Bridges, Routers, Switches, and Internetworking Protocols</span><span class="font53">, 2nd edition, Addison-Wesley Professional Computing Series, Reading, MA, 1999.</span></p>
<p><span class="font53" style="font-weight:bold;">[PGP 2020] </span><span class="font53">Symantec PGP, </span><a href="https://www.symantec.com/products/encryption"><span class="font53">https://www.symantec.com/products/encryption,</span></a><span class="font53"> 2020</span></p>
<p><span class="font53" style="font-weight:bold;">[Phifer 2000] </span><span class="font53">L. Phifer, “The Trouble with NAT,” </span><span class="font53" style="font-style:italic;">The Internet Protocol Journal, </span><span class="font53">Vol. 3, No. 4 (Dec. 2000), </span><a href="http://www.cisco.com/warp/public/759/ipj_3-4/ipj_3-4_nat.html"><span class="font53">http://www.cisco.com/warp/public/759/ipj_3-4/ipj_</span></a><span class="font53"> </span><a href="http://www.cisco.com/warp/public/759/ipj_3-4/ipj_3-4_nat.html"><span class="font53">3-4_nat.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Piatek 2008] </span><span class="font53">M. Piatek, T. Isdal, A. Krishnamurthy, T. Anderson, “One Hop Reputations for Peer-to-peer File Sharing Workloads,” </span><span class="font53" style="font-style:italic;">Proc. NSDI</span><span class="font53"> (2008).</span></p>
<p><span class="font53" style="font-weight:bold;">[Pickholtz 1982] </span><span class="font53">R. Pickholtz, D. Schilling, L. Milstein, “Theory of Spread Spectrum Communication—a Tutorial,” </span><span class="font53" style="font-style:italic;">IEEE Transactions on Communications,</span></p>
<p><span class="font53">Vol. 30, No. 5 (May 1982), pp. 855-884.</span></p>
<p><span class="font53" style="font-weight:bold;">[PingPlotter 2020] </span><span class="font53">PingPlotter homepage, </span><a href="http://www.pingplotter.com"><span class="font53">http://www.pingplotter.com</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Pomeranz 2010] </span><span class="font53">H. Pomeranz, “Practical, Visual, Three-Dimensional Pedagogy for Internet Protocol Packet Header Control Fields,” </span><a href="https://righteousit.wordpress.com/2010/06/27/practical-visual-three-dimensional-pedagogy-for-internet-protocol-packet-header-control-fields/"><span class="font53">https://righteousit.wordpress.</span></a></p>
<p><a href="https://righteousit.wordpress.com/2010/06/27/practical-visual-three-dimensional-pedagogy-for-internet-protocol-packet-header-control-fields/"><span class="font53">com/2010/06/27/practical-visual-three-dimensional-pedagogy-for-internet-protocol-</span></a><span class="font53"></span><a href="https://righteousit.wordpress.com/2010/06/27/practical-visual-three-dimensional-pedagogy-for-internet-protocol-packet-header-control-fields/"><span class="font53">packet-header-control-fields/</span></a><span class="font53">, June 2010.</span></p>
<p><span class="font53" style="font-weight:bold;">[Quagga 2012] </span><span class="font53">Quagga, “Quagga Routing Suite,” </span><a href="http://www.quagga.net/"><span class="font53">http://www.quagga.net/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Qualcomm 2019] </span><span class="font53" style="font-style:italic;">Qualcomm,</span><span class="font53"> “Everything you want to know about 5G,” </span><a href="https://www.qualcomm.com/invention/5g/what-is-5g"><span class="font53">https://www.qualcomm.com/invention/5g/what-is-5g</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Qazi 2013] </span><span class="font53">Z. Qazi, C. Tu, L. Chiang, R. Miao, V. Sekar, M. Yu, “SIMPLE-fying Middlebox Policy Enforcement Using SDN,” </span><span class="font53" style="font-style:italic;">Proc. ACM SIGCOMM Conference </span><span class="font53">(Aug. 2013), pp. 27-38.</span></p>
<p><span class="font53" style="font-weight:bold;">[Quic 2020] </span><a href="https://quicwg.org/"><span class="font53">https://quicwg.org/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[QUIC-recovery 2020] </span><span class="font53">J. Iyengar, Ed.,I. Swett, Ed., “QUIC Loss Detection and Congestion Control,” Internet Draft draft-ietf-quic-recovery-latest, April 20, 2020.</span></p>
<p><span class="font53" style="font-weight:bold;">[Quittner 1998] </span><span class="font53">J. Quittner, M. Slatalla, </span><span class="font53" style="font-style:italic;">Speeding the Net: The Inside Story of Netscape and How It Challenged Microsoft,</span><span class="font53"> Atlantic Monthly Press, 1998.</span></p>
<p><span class="font53" style="font-weight:bold;">[Quova 2020] </span><a href="http://www.quova.com"><span class="font53">www.quova.com</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Raiciu 2010] </span><span class="font53">C. Raiciu, C. Pluntke, S. Barre, A. Greenhalgh, D. Wischik, M. Handley, “Data Center Networking with Multipath TCP,” </span><span class="font53" style="font-style:italic;">Proc. 2010 ACM SIGCOMM Conference.</span></p>
<p><span class="font53" style="font-weight:bold;">[Ramakrishnan 1990] </span><span class="font53">K. K. Ramakrishnan, R. Jain, “A Binary Feedback Scheme for Congestion Avoidance in Computer Networks,” </span><span class="font53" style="font-style:italic;">ACM Transactions on Computer Systems,</span><span class="font53"> Vol. 8, No. 2 (May 1990), pp. 158-181.</span></p>
<p><span class="font53" style="font-weight:bold;">[Raman 2007] </span><span class="font53">B. Raman, K. Chebrolu, “Experiences in Using WiFi for Rural Internet in India,” </span><span class="font53" style="font-style:italic;">IEEE Communications Magazine,</span><span class="font53"> Special Issue on New Directions in Networking Technologies in Emerging Economies (Jan. 2007).</span></p>
<p><span class="font53" style="font-weight:bold;">[Ramjee 1994] </span><span class="font53">R. Ramjee, J. Kurose, D. Towsley, H. Schulzrinne, “Adaptive Playout Mechanisms for Packetized Audio Applications in Wide-Area Networks,” </span><span class="font53" style="font-style:italic;">Proc. 1994 IEEE INFOCOM.</span></p>
<p><span class="font53" style="font-weight:bold;">[Rescorla 2001] </span><span class="font53">E. Rescorla, </span><span class="font53" style="font-style:italic;">SSL and TLS: Designing and Building Secure Systems</span><span class="font53">, Addison-Wesley, Boston, 2001.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 001] </span><span class="font53">S. Crocker, “Host Software,” RFC 001 (the </span><span class="font53" style="font-style:italic;">very first</span><span class="font53"> RFC!).</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 768] </span><span class="font53">J. Postel, “User Datagram Protocol,” RFC 768, Aug. 1980.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 791] </span><span class="font53">J. Postel, “Internet Protocol: DARPA Internet Program Protocol Specification,” RFC 791, Sept. 1981.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 792] </span><span class="font53">J. Postel, “Internet Control Message Protocol,” RFC 792, Sept. 1981.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 793] </span><span class="font53">J. Postel, “Transmission Control Protocol,” RFC 793, Sept. 1981.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 801] </span><span class="font53">J. Postel, “NCP/TCP Transition Plan,” RFC 801, Nov. 1981.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 826] </span><span class="font53">D. C. Plummer, “An Ethernet Address Resolution Protocol—or— Converting Network Protocol Addresses to 48-bit Ethernet Address for Transmission on Ethernet Hardware,” RFC 826, Nov. 1982.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 829] </span><span class="font53">V. Cerf, “Packet Satellite Technology Reference Sources,” RFC 829, Nov. 1982.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 854] </span><span class="font53">J. Postel, J. Reynolds, “TELNET Protocol Specification,” RFC 854, May 1993.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 950] </span><span class="font53">J. Mogul, J. Postel, “Internet Standard Subnetting Procedure,” RFC 950, Aug. 1985.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 959] </span><span class="font53">J. Postel and J. Reynolds, “File Transfer Protocol (FTP),” RFC 959, Oct. 1985.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 1034] </span><span class="font53">P. V. Mockapetris, “Domain Names—Concepts and Facilities,” RFC 1034, Nov. 1987.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 1035] </span><span class="font53">P. Mockapetris, “Domain Names—Implementation and Specification,” RFC 1035, Nov. 1987.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 1071] </span><span class="font53">R. Braden, D. Borman, and C. Partridge, “Computing the Internet Checksum,” RFC 1071, Sept. 1988.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 1122] </span><span class="font53">R. Braden, “Requirements for Internet Hosts—Communication Layers,” RFC 1122, Oct. 1989.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 1191] </span><span class="font53">J. Mogul, S. Deering, “Path MTU Discovery,” RFC 1191, Nov. 1990.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 1320] </span><span class="font53">R. Rivest, “The MD4 Message-Digest Algorithm,” RFC 1320, Apr. 1992.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 1321] </span><span class="font53">R. Rivest, “The MD5 Message-Digest Algorithm,” RFC 1321, Apr. 1992.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 1422] </span><span class="font53">S. Kent, “Privacy Enhancement for Internet Electronic Mail: Part II: Certificate-Based Key Management,” RFC 1422.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 1546] </span><span class="font53">C. Partridge, T. Mendez, W. Milliken, “Host Anycasting Service,” RFC 1546, 1993.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 1584] </span><span class="font53">J. Moy, “Multicast Extensions to OSPF,” RFC 1584, Mar. 1994.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 1633] </span><span class="font53">R. Braden, D. Clark, S. Shenker, “Integrated Services in the Internet Architecture: an Overview,” RFC 1633, June 1994.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 1752] </span><span class="font53">S. Bradner, A. Mankin, “The Recommendations for the IP Next Generation Protocol,” RFC 1752, Jan. 1995.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 1918] </span><span class="font53">Y. Rekhter, B. Moskowitz, D. Karrenberg, G. J. de Groot, E. Lear, “Address Allocation for Private Internets,” RFC 1918, Feb. 1996.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 1930] </span><span class="font53">J. Hawkinson, T. Bates, “Guidelines for Creation, Selection, and Registration of an Autonomous System (AS),” RFC 1930, Mar. 1996.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 1945] </span><span class="font53">T. Berners-Lee, R. Fielding, H. Frystyk, “Hypertext Transfer Protocol—HTTP/1.0,” RFC 1945, May 1996.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 1958] </span><span class="font53">B. Carpenter, “Architectural Principles of the Internet,” RFC 1958, June 1996.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 2003] </span><span class="font53">C. Perkins, “IP Encapsulation Within IP,” RFC 2003, Oct. 1996.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 2004] </span><span class="font53">C. Perkins, “Minimal Encapsulation Within IP,” RFC 2004, Oct. 1996.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 2018] </span><span class="font53">M. Mathis, J. Mahdavi, S. Floyd, A. Romanow, “TCP Selective Acknowledgment Options,” RFC 2018, Oct. 1996.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 2104] </span><span class="font53">H. Krawczyk, M. Bellare, R. Canetti, “HMAC: Keyed-Hashing for Message Authentication,” RFC 2104, Feb. 1997.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 2131] </span><span class="font53">R. Droms, “Dynamic Host Configuration Protocol,” RFC 2131, Mar. 1997.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 2136] </span><span class="font53">P. Vixie, S. Thomson, Y. Rekhter, J. Bound, “Dynamic Updates in the Domain Name System,” RFC 2136, Apr. 1997.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 2328] </span><span class="font53">J. Moy, “OSPF Version 2,” RFC 2328, Apr. 1998.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 2420] </span><span class="font53">H. Kummert, “The PPP Triple-DES Encryption Protocol (3DESE),” RFC 2420, Sept. 1998.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 2460] </span><span class="font53">S. Deering, R. Hinden, “Internet Protocol, Version 6 (IPv6) Specification,” RFC 2460, Dec. 1998.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 2578] </span><span class="font53">K. McCloghrie, D. Perkins, J. Schoenwaelder, “Structure of Management Information Version 2 (SMIv2),” RFC 2578, Apr. 1999.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 2579] </span><span class="font53">K. McCloghrie, D. Perkins, J. Schoenwaelder, “Textual Conventions for SMIv2,” RFC 2579, Apr. 1999.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 2580] </span><span class="font53">K. McCloghrie, D. Perkins, J. Schoenwaelder, “Conformance Statements for SMIv2,” RFC 2580, Apr. 1999.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 2581] </span><span class="font53">M. Allman, V. Paxson, W. Stevens, “TCP Congestion Control,” RFC 2581, Apr. 1999.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 2663] </span><span class="font53">P. Srisuresh, M. Holdrege, “IP Network Address Translator (NAT) Terminology and Considerations,” RFC 2663.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 2702] </span><span class="font53">D. Awduche, J. Malcolm, J. Agogbua, M. O’Dell, J. McManus, “Requirements for Traffic Engineering Over MPLS,” RFC 2702, Sept. 1999.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 2827] </span><span class="font53">P. Ferguson, D. Senie, “Network Ingress Filtering: Defeating Denial of Service Attacks which Employ IP Source Address Spoofing,” RFC 2827, May 2000.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 2865] </span><span class="font53">C. Rigney, S. Willens, A. Rubens, W. Simpson, “Remote Authentication Dial In User Service (RADIUS),” RFC 2865, June 2000.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 2992] </span><span class="font53">C. Hopps, “Analysis of an Equal-Cost Multi-Path Algorithm,” RFC 2992, Nov 2000.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 3007] </span><span class="font53">B. Wellington, “Secure Domain Name System (DNS) Dynamic Update,” RFC 3007, Nov. 2000.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 3022] </span><span class="font53">P. Srisuresh, K. Egevang, “Traditional IP Network Address Translator (Traditional NAT),” RFC 3022, Jan. 2001.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 3031] </span><span class="font53">E. Rosen, A. Viswanathan, R. Callon, “Multiprotocol Label Switching Architecture,” RFC 3031, Jan. 2001.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 3032] </span><span class="font53">E. Rosen, D. Tappan, G. Fedorkow, Y. Rekhter, D. Farinacci, T. Li, A. Conta, “MPLS Label Stack Encoding,” RFC 3032, Jan. 2001.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 3168] </span><span class="font53">K. Ramakrishnan, S. Floyd, D. Black, “The Addition of Explicit Congestion Notification (ECN) to IP,” RFC 3168, Sept. 2001.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 3209] </span><span class="font53">D. Awduche, L. Berger, D. Gan, T. Li, V. Srinivasan, G. Swallow, “RSVP-TE: Extensions to RSVP for LSP Tunnels,” RFC 3209, Dec. 2001.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 3232] </span><span class="font53">J. Reynolds, “Assigned Numbers: RFC 1700 Is Replaced by an Online Database,” RFC 3232, Jan. 2002.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 3234] </span><span class="font53">B. Carpenter, S. Brim, “Middleboxes: Taxonomy and Issues,” RFC 3234, Feb. 2002.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 3261] </span><span class="font53">J. Rosenberg, H. Schulzrinne, G. Carmarillo, A. Johnston, J. Peterson, R. Sparks, M. Handley, E. Schooler, “SIP: Session Initiation Protocol,” RFC 3261, July 2002.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 3272] </span><span class="font53">J. Boyle, V. Gill, A. Hannan, D. Cooper, D. Awduche, B. Christian, W. S. Lai, “Overview and Principles of Internet Traffic Engineering,” RFC 3272, May 2002.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 3286] </span><span class="font53">L. Ong, J. Yoakum, “An Introduction to the Stream Control Transmission Protocol (SCTP),” RFC 3286, May 2002.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 3346] </span><span class="font53">J. Boyle, V. Gill, A. Hannan, D. Cooper, D. Awduche, B. Christian, W. S. Lai, “Applicability Statement for Traffic Engineering with MPLS,” RFC 3346, Aug. 2002.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 3390] </span><span class="font53">M. Allman, S. Floyd, C. Partridge, “Increasing TCP’s Initial Window,” RFC 3390, Oct. 2002.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 3410] </span><span class="font53">J. Case, R. Mundy, D. Partain, “Introduction and Applicability Statements for Internet Standard Management Framework,” RFC 3410, Dec. 2002.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 3439] </span><span class="font53">R. Bush, D. Meyer, “Some Internet Architectural Guidelines and Philosophy,” RFC 3439, Dec. 2003.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 3447] </span><span class="font53">J. Jonsson, B. Kaliski, “Public-Key Cryptography Standards (PKCS) #1: RSA Cryptography Specifications Version 2.1,” RFC 3447, Feb. 2003.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 3468] </span><span class="font53">L. Andersson, G. Swallow, “The Multiprotocol Label Switching (MPLS) Working Group Decision on MPLS Signaling Protocols,” RFC 3468, Feb. 2003.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 3469] </span><span class="font53">V. Sharma, Ed., F. Hellstrand, Ed, “Framework for Multi-Protocol Label Switching (MPLS)-based Recovery,” RFC 3469, Feb. 2003.</span></p>
<p><a href="ftp://ftp.rfc-editor.org/in-notes/rfc3469.txt"><span class="font53">ftp://ftp.rfc-editor.org/in-notes/rfc3469.txt</span></a></p>
<p><span class="font53" style="font-weight:bold;">[RFC 3535] </span><span class="font53">J. Schonwalder, “Overview of the 2002 IAB Network Management Workshop,” RFC 3535, May 2003.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 3550] </span><span class="font53">H. Schulzrinne, S. Casner, R. Frederick, V. Jacobson, “RTP: A Transport Protocol for Real-Time Applications,” RFC 3550, July 2003.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 3588] </span><span class="font53">P. Calhoun, J. Loughney, E. Guttman, G. Zorn, J. Arkko, “Diameter Base Protocol,” RFC 3588, Sept. 2003.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 3746] </span><span class="font53">L. Yang, R. Dantu, T. Anderson, R. Gopal, “Forwarding and Control Element Separation (ForCES) Framework,” Internet, RFC 3746, Apr. 2004.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 3748] </span><span class="font53">B. Aboba, L. Blunk, J. Vollbrecht, J. Carlson, H. Levkowetz, Ed., “Extensible Authentication Protocol (EAP),” RFC 3748, June 2004.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 4022] </span><span class="font53">R. Raghunarayan, Ed., “Management Information Base for the Transmission Control Protocol (TCP),” RFC 4022, March 2005.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 4033] </span><span class="font53">R. Arends, R. Austein, M. Larson, D. Massey, S. Rose, “DNS Security Introduction and Requirements, RFC 4033, March 2005.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 4113] </span><span class="font53">B. Fenner, J. Flick, “Management Information Base for the User Datagram Protocol (UDP),” RFC 4113, June 2005.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 4213] </span><span class="font53">E. Nordmark, R. Gilligan, “Basic Transition Mechanisms for IPv6 Hosts and Routers,” RFC 4213, Oct. 2005.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 4271] </span><span class="font53">Y. Rekhter, T. Li, S. Hares, Ed., “A Border Gateway Protocol 4 (BGP-4),” RFC 4271, Jan. 2006.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 4291] </span><span class="font53">R. Hinden, S. Deering, “IP Version 6 Addressing Architecture,” RFC 4291, Feb. 2006.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 4293] </span><span class="font53">S. Routhier, Ed., “Management Information Base for the Internet Protocol (IP),” RFC 4293, April 2006.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 4340] </span><span class="font53">E. Kohler, M. Handley, S. Floyd, “Datagram Congestion Control Protocol (DCCP),” RFC 4340, Mar. 2006.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 4346] </span><span class="font53">T. Dierks, E. Rescorla, “The Transport Layer Security (TLS) Protocol Version 1.1,” RFC 4346, Apr. 2006.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 4514] </span><span class="font53">K. Zeilenga, Ed., “Lightweight Directory Access Protocol (LDAP): String Representation of Distinguished Names,” RFC 4514, June 2006.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 4632] </span><span class="font53">V. Fuller, T. Li, “Classless Inter-domain Routing (CIDR): The Internet Address Assignment and Aggregation Plan,” RFC 4632, Aug. 2006.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 4960] </span><span class="font53">R. Stewart, ed., “Stream Control Transmission Protocol,” RFC 4960, Sept. 2007.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 4987] </span><span class="font53">W. Eddy, “TCP SYN Flooding Attacks and Common Mitigations,” RFC 4987, Aug. 2007.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 5128] </span><span class="font53">P. Srisuresh, B. Ford, D. Kegel, “State of Peer-to-Peer (P2P) Communication across Network Address Translators (NATs),” March 2008, RFC 5128.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 5246] </span><span class="font53">T. Dierks, E. Rescorla, “The Transport Layer Security (TLS) Protocol, Version 1.2,” RFC 5246, Aug. 2008.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 5277] </span><span class="font53">S. Chisholm H. Trevino, “NETCONF Event Notifications,” RFC 5277, July 2008.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 5321] </span><span class="font53">J. Klensin, “Simple Mail Transfer Protocol,” RFC 5321, Oct. 2008.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 5389] </span><span class="font53">J. Rosenberg, R. Mahy, P. Matthews, D. Wing, “Session Traversal Utilities for NAT (STUN),” RFC 5389, Oct. 2008.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 5681] </span><span class="font53">M. Allman, V. Paxson, E. Blanton, “TCP Congestion Control,” RFC 5681, Sept. 2009.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 5944] </span><span class="font53">C. Perkins, Ed., “IP Mobility Support for IPv4, Revised,” RFC 5944, Nov. 2010.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 6020] </span><span class="font53">M. Bjorklund, “YANG—A Data Modeling Language for the Network Configuration Protocol (NETCONF),” RFC 6020, Oct. 2010.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 6241] </span><span class="font53">R. Enns, M. Bjorklund, J. Schonwalder, A. Bierman, “Network Configuration Protocol (NETCONF),” RFC 6241, June 2011.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 6265] </span><span class="font53">A Barth, “HTTP State Management Mechanism,” RFC 6265, Apr. 2011.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 6298] </span><span class="font53">V. Paxson, M. Allman, J. Chu, M. Sargent, “Computing TCP’s Retransmission Timer,” RFC 6298, June 2011.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 6582] </span><span class="font53">T. Henderson, S. Floyd, A. Gurtov, Y. Nishida, “The NewReno Modification to TCP’s Fast Recovery Algorithm,” RFC 6582, April 2012.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 6733] </span><span class="font53">V. Fajardo, J. Arkko, J. Loughney, G. Zorn, “Diameter Base Protocol,” RFC 6733, Oct. 2012.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 7020] </span><span class="font53">R. Housley, J. Curran, G. Huston, D. Conrad, “The Internet Numbers Registry System,” RFC 7020, Aug. 2013.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 7094] </span><span class="font53">D. McPherson, D. Oran, D. Thaler, E. Osterweil, “Architectural Considerations of IP Anycast,” RFC 7094, Jan. 2014.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 7230] </span><span class="font53">R. Fielding, Ed., J. Reschke, “Hypertext Transfer Protocol (HTTP/1.1): Message Syntax and Routing,” RFC 7230, June 2014.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 7232] </span><span class="font53">R. Fielding, Ed., J. Reschke, Ed., “Hypertext Transfer Protocol (HTTP/1.1): Conditional Requests,” RFC 7232, June 2014.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 7234] </span><span class="font53">R. Fielding, Ed., M. Nottingham, Ed., J. Reschke, Ed., “Hypertext Transfer Protocol (HTTP/1.1): Caching,” RFC 7234, June 2014.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 7323] </span><span class="font53">D. Borman, S. Braden, V. Jacobson, R. Scheffenegger, “TCP Extensions for High Performance,” RFC 7323, Sept. 2014.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 7540] </span><span class="font53">M. Belshe, R. Peon, M. Thomson (Eds), “Hypertext Transfer Protocol Version 2 (HTTP/2),” RFC 7540, May 2015.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 8033] </span><span class="font53">R. Pan, P. Natarajan, F. Baker, G. White, “Proportional Integral Controller Enhanced (PIE): A Lightweight Control Scheme to Address the Bufferbloat Problem,” RFC 8033, Feb. 2017.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 8034] </span><span class="font53">G. White, R. Pan, “Active Queue Management (AQM) Based on Proportional Integral Controller Enhanced (PIE) for Data-Over-Cable Service Interface Specifications (DOCSIS) Cable Modems,” RFC 8034, Feb. 2017.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 8257] </span><span class="font53">S. Bensley, D. Thaler, P. Balasubramanian, L. Eggert, G. Judd, “Data Center TCP (DCTCP): TCP Congestion Control for Data Centers, RFC 8257, October 2017.</span></p>
<p><span class="font53" style="font-weight:bold;">[RFC 8312] </span><span class="font53">L. Xu, S. Ha, A. Zimmermann,L. Eggert, R. Scheffenegger, “CUBIC for Fast Long-Distance Networks,” RFC 8312, Feb. 2018.</span></p>
<p><span class="font53" style="font-weight:bold;">[Richter 2015] </span><span class="font53">P. Richter, M. Allman, R. Bush, V. Paxson, “A Primer on IPv4 Scarcity,” </span><span class="font53" style="font-style:italic;">ACM SIGCOMM Computer Communication Review,</span><span class="font53"> Vol. 45, No. 2 (Apr. 2015), pp. 21-32.</span></p>
<p><span class="font53" style="font-weight:bold;">[Roberts 1967] </span><span class="font53">L. Roberts, T. Merril, “Toward a Cooperative Network of Time-Shared Computers,” </span><span class="font53" style="font-style:italic;">AFIPS Fall Conference</span><span class="font53"> (Oct. 1966).</span></p>
<p><span class="font53" style="font-weight:bold;">[Rom 1990] </span><span class="font53">R. Rom, M. Sidi, </span><span class="font53" style="font-style:italic;">Multiple Access Protocols: Performance and Analysis,</span><span class="font53"> Springer-Verlag, New York, 1990.</span></p>
<p><span class="font53" style="font-weight:bold;">[Rommer 2019] </span><span class="font53">S. Rommer, P. Hedman, M. Olsson, L. Frid, S. Sultana, C. Mulligan, </span><span class="font53" style="font-style:italic;">5G Core Networks: Powering Digitalization,</span><span class="font53"> Academic Press, 2019.</span></p>
<p><span class="font53" style="font-weight:bold;">[Root Servers 2020] </span><span class="font53">Root Servers home page, </span><a href="http://www.root-servers.org/"><span class="font53">http://www.root-servers.org/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Roy 2015] </span><span class="font53">A. Roy, H.i Zeng, J. Bagga, G. Porter, A. Snoeren, “Inside the Social Network’s (Datacenter) Network,” </span><span class="font53" style="font-style:italic;">Proc. 2015 ACM SIGCOMM Conference,</span><span class="font53"> pp. 123-137.</span></p>
<p><span class="font53" style="font-weight:bold;">[RSA 1978] </span><span class="font53">R. Rivest, A. Shamir, L. Adelman, “A Method for Obtaining Digital Signatures and Public-key Cryptosystems,” </span><span class="font53" style="font-style:italic;">Communications of the ACM,</span><span class="font53"> Vol. 21, No. 2 (Feb. 1978), pp. 120-126.</span></p>
<p><span class="font53" style="font-weight:bold;">[Rubenstein 1998] </span><span class="font53">D. Rubenstein, J. Kurose, D. Towsley, “Real-Time Reliable Multicast Using Proactive Forward Error Correction,” </span><span class="font53" style="font-style:italic;">Proceedings of NOSSDAV ’98</span><span class="font53"> (Cambridge, UK, July 1998).</span></p>
<p><span class="font53" style="font-weight:bold;">[Ruiz-Sanchez 2001</span><span class="font53">] M. Ruiz-Sanchez, E. Biersack, W. Dabbous, “Survey and Taxonomy of IP Address Lookup Algorithms,” </span><span class="font53" style="font-style:italic;">IEEE Network Magazine,</span><span class="font53"> Vol. 15, No. 2 (Mar./Apr. 2001), pp. 8-23.</span></p>
<p><span class="font53" style="font-weight:bold;">[Saltzer 1984] </span><span class="font53">J. Saltzer, D. Reed, D. Clark, “End-to-End Arguments in System Design,” </span><span class="font53" style="font-style:italic;">ACM Transactions on Computer Systems (TOCS),</span><span class="font53"> Vol. 2, No. 4 (Nov. 1984).</span></p>
<p><span class="font53" style="font-weight:bold;">[Saroiu 2002] </span><span class="font53">S. Saroiu, P. K. Gummadi, S. D. Gribble, “A Measurement Study of Peer-to-Peer File Sharing Systems,” </span><span class="font53" style="font-style:italic;">Proc. of Multimedia Computing and Networking (MMCN)</span><span class="font53"> (2002).</span></p>
<p><span class="font53" style="font-weight:bold;">[Sauter 2014] </span><span class="font53">M. Sauter, </span><span class="font53" style="font-style:italic;">From GSM to LTE-Advanced,</span><span class="font53"> John Wiley and Sons, 2014.</span></p>
<p><span class="font53" style="font-weight:bold;">[Savage 2015] </span><span class="font53">D. Savage, J. Ng, S. Moore, D. Slice, P. Paluch, R. White, “Enhanced Interior Gateway Routing Protocol,” Internet Draft, draft-savage-eigrp-04.txt, Aug. 2015.</span></p>
<p><span class="font53" style="font-weight:bold;">[Saydam 1996] </span><span class="font53">T. Saydam, T. Magedanz, “From Networks and Network Management into Service and Service Management,” </span><span class="font53" style="font-style:italic;">Journal of Networks and System Management,</span><span class="font53"> Vol. 4, No. 4 (Dec. 1996), pp. 345-348.</span></p>
<p><span class="font53" style="font-weight:bold;">[Schiller 2003] </span><span class="font53">J. Schiller, </span><span class="font53" style="font-style:italic;">Mobile Communications,</span><span class="font53"> 2nd edition, Addison Wesley, 2003.</span></p>
<p><span class="font53" style="font-weight:bold;">[Schneier 2015] </span><span class="font53">B. Schneier, </span><span class="font53" style="font-style:italic;">Applied Cryptography: Protocols, Algorithms, and Source Code in C,</span><span class="font53"> Wiley, 2015.</span></p>
<p><span class="font53" style="font-weight:bold;">[Schonwalder 2010] </span><span class="font53">J. Schonwalder, M. Bjorklund, P. Shafer, “Network configuration management using NETCONF and YANG,” </span><span class="font53" style="font-style:italic;">IEEE Communications Magazine,</span><span class="font53"> 2010, Vol. 48, No. 9, pp. 166-173.</span></p>
<p><span class="font53" style="font-weight:bold;">[Schwartz 1977] </span><span class="font53">M. Schwartz, </span><span class="font53" style="font-style:italic;">Computer-Communication Network Design and Analysis</span><span class="font53">, Prentice-Hall, Englewood Cliffs, NJ, 1997.</span></p>
<p><span class="font53" style="font-weight:bold;">[Schwartz 1980] </span><span class="font53">M. Schwartz, </span><span class="font53" style="font-style:italic;">Information, Transmission, Modulation, and Noise, </span><span class="font53">McGraw Hill, New York, NY 1980.</span></p>
<p><span class="font53" style="font-weight:bold;">[Schwartz 1982] </span><span class="font53">M. Schwartz, “Performance Analysis of the SNA Virtual Route Pacing Control,” </span><span class="font53" style="font-style:italic;">IEEE Transactions on Communications,</span><span class="font53"> Vol. 30, No. 1 (Jan. 1982), pp. 172-184.</span></p>
<p><span class="font53" style="font-weight:bold;">[Scourias 2012] </span><span class="font53">J. Scourias, “Overview of the Global System for Mobile Communications: GSM.” </span><a href="http://www.privateline.com/PCS/GSM0.html"><span class="font53">http://www.privateline.com/PCS/GSM0.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Segaller 1998] </span><span class="font53">S. Segaller, </span><span class="font53" style="font-style:italic;">Nerds 2.0.1, A Brief History of the Internet,</span><span class="font53"> TV Books, New York, 1998.</span></p>
<p><span class="font53" style="font-weight:bold;">[Serpanos 2011] </span><span class="font53">D. Serpanos, T. Wolf, </span><span class="font53" style="font-style:italic;">Architecture of Network Systems,</span><span class="font53"> Morgan Kaufmann Publishers, 2011.</span></p>
<p><span class="font53" style="font-weight:bold;">[Shacham 1990] </span><span class="font53">N. Shacham, P. McKenney, “Packet Recovery in High-Speed Networks Using Coding and Buffer Management,” </span><span class="font53" style="font-style:italic;">Proc. 1990 IEEE Infocom</span><span class="font53"> (San Francisco, CA, Apr. 1990), pp. 124-131.</span></p>
<p><span class="font53" style="font-weight:bold;">[Shaikh 2001] </span><span class="font53">A. Shaikh, R. Tewari, M. Agrawal, “On the Effectiveness of DNSbased Server Selection,” </span><span class="font53" style="font-style:italic;">Proc. 2001 IEEE INFOCOM.</span></p>
<p><span class="font53" style="font-weight:bold;">[Sherry 2012] </span><span class="font53">J. Sherry, S. Hasan, C. Scott, A. Krishnamurthy, S. Ratnasamy, V. Sekar, “Making middleboxes someone else’s problem: network processing as a cloud service,” </span><span class="font53" style="font-style:italic;">Proc. 2012 ACM SIGCOMM Conference.</span></p>
<p><span class="font53" style="font-weight:bold;">[Singh 1999] </span><span class="font53">S. Singh, </span><span class="font53" style="font-style:italic;">The Code Book: The Evolution of Secrecy from Mary, Queen of Scotsto Quantum Cryptography</span><span class="font53">, Doubleday Press, 1999.</span></p>
<p><span class="font53" style="font-weight:bold;">[Singh 2015] </span><span class="font53">A. Singh et al., “Jupiter Rising: A Decade of Clos Topologies and Centralized Control in Google’s Datacenter Network,” </span><span class="font53" style="font-style:italic;">Proc. 2015 ACM SIGCOMM Conference,</span><span class="font53"> pp. 183-197.</span></p>
<p><span class="font53" style="font-weight:bold;">[Smith 2009] </span><span class="font53">J. Smith, “Fighting Physics: A Tough Battle,” </span><span class="font53" style="font-style:italic;">Communications of the ACM,</span><span class="font53"> Vol. 52, No. 7 (July 2009), pp. 60-65.</span></p>
<p><span class="font53" style="font-weight:bold;">[Smithsonian 2017] </span><span class="font53">Smithsonian Magazine, “How Other Countries Deal with Net Neutrality,” </span><a href="https://www.smithsonianmag.com/innovation/how-other-countries-deal-net-neutrality-180967558/"><span class="font53">https://www.smithsonianmag.com/innovation/how-other-countries-</span></a><span class="font53"></span><a href="https://www.smithsonianmag.com/innovation/how-other-countries-deal-net-neutrality-180967558/"><span class="font53">deal-net-neutrality-180967558/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Snort 2012] </span><span class="font53">Sourcefire Inc., Snort homepage, </span><a href="http://www.snort.org/"><span class="font53">http://www.snort.org/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Solensky 1996] </span><span class="font53">F. Solensky, “IPv4 Address Lifetime Expectations,” in </span><span class="font53" style="font-style:italic;">IPng: Internet Protocol Next Generation</span><span class="font53"> (S. Bradner, A. Mankin, ed.), Addison-Wesley, Reading, MA, 1996.</span></p>
<p><span class="font53" style="font-weight:bold;">[Speedtest 2020] </span><a href="https://www.speedtest.net/"><span class="font53">https://www.speedtest.net/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Spragins 1991] </span><span class="font53">J. D. Spragins, </span><span class="font53" style="font-style:italic;">Telecommunications Protocols and Design, </span><span class="font53">Addison-Wesley, Reading, MA, 1991.</span></p>
<p><span class="font53" style="font-weight:bold;">[Srikant 2012] </span><span class="font53">R. Srikant, </span><span class="font53" style="font-style:italic;">The mathematics of Internet congestion control, </span><span class="font53">Springer Science &amp;&nbsp;Business Media, 2012.</span></p>
<p><span class="font53" style="font-weight:bold;">[Statista 2019] </span><span class="font53">“Mobile internet usage worldwide - Statistics &amp;&nbsp;Facts,” </span><a href="https://www.statista.com/topics/779/mobile-internet/"><span class="font53">https://</span></a><span class="font53"> </span><a href="https://www.statista.com/topics/779/mobile-internet/"><span class="font53">www.statista.com/topics/779/mobile-internet/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Steinder 2002] </span><span class="font53">M. Steinder, A. Sethi, “Increasing Robustness of Fault Localization Through Analysis of Lost, Spurious, and Positive Symptoms,” </span><span class="font53" style="font-style:italic;">Proc. 2002 IEEE INFOCOM.</span></p>
<p><span class="font53" style="font-weight:bold;">[Stevens 1990] </span><span class="font53">W. R. Stevens, </span><span class="font53" style="font-style:italic;">Unix Network Programming,</span><span class="font53"> Prentice-Hall, Englewood Cliffs, NJ.</span></p>
<p><span class="font53" style="font-weight:bold;">[Stevens 1994] </span><span class="font53">W. R. Stevens, </span><span class="font53" style="font-style:italic;">TCP/IP Illustrated, Vol. 1: The Protocols,</span><span class="font53"> Addison-Wesley, Reading, MA, 1994.</span></p>
<p><span class="font53" style="font-weight:bold;">[Stevens 1997] </span><span class="font53">W. R. Stevens, </span><span class="font53" style="font-style:italic;">Unix Network Programming, Volume 1: Networking APIs-Sockets and XTI</span><span class="font53">, 2nd edition, Prentice-Hall, Englewood Cliffs, NJ, 1997.</span></p>
<p><span class="font53" style="font-weight:bold;">[Stewart 1999] </span><span class="font53">J. Stewart, </span><span class="font53" style="font-style:italic;">BGP4: Interdomain Routing in the Internet,</span><span class="font53"> Addison-Wesley, 1999.</span></p>
<p><span class="font53" style="font-weight:bold;">[Stone 1998] </span><span class="font53">J. Stone, M. Greenwald, C. Partridge, J. Hughes, “Performance of Checksums and CRC’s Over Real Data,” </span><span class="font53" style="font-style:italic;">IEEE/ACM Transactions on Networking, </span><span class="font53">Vol. 6, No. 5 (Oct. 1998), pp. 529-543.</span></p>
<p><span class="font53" style="font-weight:bold;">[Stone 2000] </span><span class="font53">J. Stone, C. Partridge, “When Reality and the Checksum Disagree,” </span><span class="font53" style="font-style:italic;">Proc. 2000 ACM SIGCOMM Conference</span><span class="font53"> (Stockholm, Sweden, Aug. 2000).</span></p>
<p><span class="font53" style="font-weight:bold;">[Strayer 1992] </span><span class="font53">W. T. Strayer, B. Dempsey, A. Weaver, </span><span class="font53" style="font-style:italic;">XTP: The Xpress Transfer Protocol</span><span class="font53">, Addison-Wesley, Reading, MA, 1992.</span></p>
<p><span class="font53" style="font-weight:bold;">[Stubblefield 2002] </span><span class="font53">A. Stubblefield, J. loannidis, A. Rubin, “Using the Fluhrer, Mantin, and Shamir Attack to Break WEP,” </span><span class="font53" style="font-style:italic;">Proceedings of2002 Network and Distributed Systems Security Symposium</span><span class="font53"> (2002), pp. 17-22.</span></p>
<p><span class="font53" style="font-weight:bold;">[Subramanian 2000] </span><span class="font53">M. Subramanian, </span><span class="font53" style="font-style:italic;">Network Management: Principles and Practice</span><span class="font53">, Addison-Wesley, Reading, MA, 2000.</span></p>
<p><span class="font53" style="font-weight:bold;">[Subramanian 2002] </span><span class="font53">L. Subramanian, S. Agarwal, J. Rexford, R. Katz, “Characterizing the Internet Hierarchy from Multiple Vantage Points,” </span><span class="font53" style="font-style:italic;">Proc. 2002 IEEE INFOCOM</span><span class="font53">.</span></p>
<p><span class="font53" style="font-weight:bold;">[Sundaresan 2006] </span><span class="font53">K. Sundaresan, K. Papagiannaki, “The Need for Cross-layer Information in Access Point Selection,” </span><span class="font53" style="font-style:italic;">Proc. 2006 ACM Internet Measurement Conference</span><span class="font53"> (Rio De Janeiro, Oct. 2006).</span></p>
<p><span class="font53" style="font-weight:bold;">[Sunshine 1978] </span><span class="font53">C. Sunshine, Y. Dalal, “Connection Management in Transport Protocols,” </span><span class="font53" style="font-style:italic;">Computer Networks,</span><span class="font53"> North-Holland, Amsterdam, 1978.</span></p>
<p><span class="font53" style="font-weight:bold;">[Tan 2006] </span><span class="font53">K. Tan, J. Song, Q. Zhang and M. Sridharan, “A Compound TCP Approach for High-Speed and Long Distance Networks,” </span><span class="font53" style="font-style:italic;">Proc. 2006 IEEE INFOCOM.</span></p>
<p><span class="font53" style="font-weight:bold;">[Tariq 2008] </span><span class="font53">M. Tariq, A. Zeitoun, V. Valancius, N. Feamster, M. Ammar, “Answering What-If Deployment and Configuration Questions with WISE,” </span><span class="font53" style="font-style:italic;">Proc. 2008 ACM SIGCOMM Conference</span><span class="font53"> (Aug. 2008).</span></p>
<p><span class="font53" style="font-weight:bold;">[Teixeira 2006] </span><span class="font53">R. Teixeira, J. Rexford, “Managing Routing Disruptions in Internet Service Provider Networks,” </span><span class="font53" style="font-style:italic;">IEEE Communications Magazine</span></p>
<p><span class="font53">Vol. 44, No. 3 (Mar. 2006) pp. 160-165.</span></p>
<p><span class="font53" style="font-weight:bold;">[Think 2012] </span><span class="font53">Technical History of Network Protocols, “Cyclades,” </span><a href="http://www.cs.utexas.edu/users/chris/think/Cyclades/index.shtml"><span class="font53">http://www.cs.utexas.edu/users/chris/think/Cyclades/index.shtml</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Tian 2012] </span><span class="font53">Y. Tian, R. Dey, Y. Liu, K. W. Ross, “China’s Internet: Topology Mapping and Geolocating,” </span><span class="font53" style="font-style:italic;">IEEE INFOCOM Mini-Conference 2012</span><span class="font53"> (Orlando, FL, 2012).</span></p>
<p><span class="font53" style="font-weight:bold;">[TLD list 2020] </span><span class="font53">TLD list maintained by Wikipedia, </span><a href="https://en.wikipedia.org/wiki/List_of_Internet_top-level_domains"><span class="font53">https://en.wikipedia.org/wiki/</span></a><span class="font53"> </span><a href="https://en.wikipedia.org/wiki/List_of_Internet_top-level_domains"><span class="font53">List_of_Internet_top-level_domains</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Tobagi 1990] </span><span class="font53">F. Tobagi, “Fast Packet Switch Architectures for Broadband Integrated Networks,” </span><span class="font53" style="font-style:italic;">Proc. IEEE,</span><span class="font53"> Vol. 78, No. 1 (Jan. 1990), pp. 133-167.</span></p>
<p><span class="font53" style="font-weight:bold;">[TOR 2020] </span><span class="font53">Tor: Anonymity Online, </span><a href="http://www.torproject.org"><span class="font53">http://www.torproject.org</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Torres 2011] </span><span class="font53">R. Torres, A. Finamore, J. R. Kim, M. M. Munafo, S. Rao, “Dissecting Video Server Selection Strategies in the YouTube CDN,” </span><span class="font53" style="font-style:italic;">Proc. 2011 Int. Conf. on Distributed Computing Systems</span><span class="font53">.</span></p>
<p><span class="font53" style="font-weight:bold;">[Tourrilhes 2014] </span><span class="font53">J. Tourrilhes, P. Sharma, S. Banerjee, J. Petit, “SDN and Openflow Evolution: A Standards Perspective,” </span><span class="font53" style="font-style:italic;">IEEE Computer Magazine,</span><span class="font53"> Nov. 2014, Vol. 47, No. 11, pp. 22-29.</span></p>
<p><span class="font53" style="font-weight:bold;">[Turner 1988] </span><span class="font53">J. S. Turner, “Design of a Broadcast packet switching network,” </span><span class="font53" style="font-style:italic;">IEEE Transactions on Communications</span><span class="font53">, Vol. 36, No. 6 (June 1988), pp. 734-743.</span></p>
<p><span class="font53" style="font-weight:bold;">[Turner 2012] </span><span class="font53">B. Turner, “2G, 3G, 4G Wireless Tutorial,” </span><a href="http://blogs.nmscommunications.com/communications/2008/10/2g-3g-4g-wireless-tutorial.html"><span class="font53">http://blogs.nmscom-</span></a><span class="font53"></span><a href="http://blogs.nmscommunications.com/communications/2008/10/2g-3g-4g-wireless-tutorial.html"><span class="font53">munications.com/communications/2008/10/2g-3g-4g-wireless-tutorial.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[van der Berg 2008] </span><span class="font53">R. van der Berg, “How the ’Net Works: An Introduction to Peering and Transit,” </span><a href="http://arstechnica.com/guides/other/peering-and-transit.ars"><span class="font53">http://arstechnica.com/guides/other/peering-and-transit.ars</span></a></p>
<p><span class="font53" style="font-weight:bold;">[van der Merwe 1998] </span><span class="font53">J. van der Merwe, S. Rooney, I. Leslie, S. Crosby, “The Tempest: A Practical Framework for Network Programmability,” </span><span class="font53" style="font-style:italic;">IEEE Network</span><span class="font53">, Vol. 12, No. 3 (May 1998), pp. 20-28.</span></p>
<p><span class="font53" style="font-weight:bold;">[Vanhoef 2017] </span><span class="font53">M. Vanhoef, F. Piessens, “ Key Reinstallation Attacks: Forcing Nonce Reuse in WPA2,” </span><span class="font53" style="font-style:italic;">2017 ACM SIGSAC Conference on Computer and Communications Security (CCS ’17),</span><span class="font53"> pp. 1313-1328.</span></p>
<p><span class="font53" style="font-weight:bold;">[Varghese 1997] </span><span class="font53">G. Varghese, A. Lauck, “Hashed and Hierarchical Timing Wheels: Efficient Data Structures for Implementing a Timer Facility,” </span><span class="font53" style="font-style:italic;">IEEE/ACM Transactions on Networking,</span><span class="font53"> Vol. 5, No. 6 (Dec. 1997), pp. 824-834.</span></p>
<p><span class="font53" style="font-weight:bold;">[Vasudevan 2005] </span><span class="font53">S. Vasudevan, C. Diot, J. Kurose, D. Towsley, “Facilitating Access Point Selection in IEEE 802.11 Wireless Networks,” </span><span class="font53" style="font-style:italic;">Proc. 2005 ACM Internet Measurement Conference,</span><span class="font53"> (San Francisco CA, Oct. 2005).</span></p>
<p><span class="font53" style="font-weight:bold;">[Venkataramani 2014] </span><span class="font53">A. Venkataramani, J. Kurose, D. Raychaudhuri, K. Naga-raja, M. Mao, S. Banerjee, “MobilityFirst: A Mobility-Centric and Trustworthy Internet Architecture,” </span><span class="font53" style="font-style:italic;">ACM Computer Communication Review,</span><span class="font53"> July 2014.</span></p>
<p><span class="font53" style="font-weight:bold;">[Villamizar 1994] </span><span class="font53">C. Villamizar, C. Song. “High Performance TCP in ANSNET,” </span><span class="font53" style="font-style:italic;">ACM SIGCOMM Computer Communications Review</span><span class="font53">, Vol. 24, No. 5 (1994), pp. 45-60.</span></p>
<p><span class="font53" style="font-weight:bold;">[Viterbi 1995] </span><span class="font53">A. Viterbi, </span><span class="font53" style="font-style:italic;">CDMA: Principles of Spread Spectrum Communication</span><span class="font53">, Addison-Wesley, Reading, MA, 1995.</span></p>
<p><span class="font53" style="font-weight:bold;">[Vixie 2009] </span><span class="font53">P. Vixie, “What DNS Is Not,” </span><span class="font53" style="font-style:italic;">Communications of the ACM,</span><span class="font53"> Vol. 52, No. 12 (Dec. 2009), pp. 43-47.</span></p>
<p><span class="font53" style="font-weight:bold;">[Wakeman 1992] </span><span class="font53">I. Wakeman, J. Crowcroft, Z. Wang, D. Sirovica, “Is Layering Harmful (remote procedure call),” </span><span class="font53" style="font-style:italic;">IEEE Network,</span><span class="font53"> Vol. 6, No. 1 (Jan. 1992), pp. 20-24.</span></p>
<p><span class="font53" style="font-weight:bold;">[Waldrop 2007] </span><span class="font53">M. Waldrop, “Data Center in a Box,” </span><span class="font53" style="font-style:italic;">Scientific American</span><span class="font53"> (July 2007).</span></p>
<p><span class="font53" style="font-weight:bold;">[Walfish 2004] </span><span class="font53">M. Walfish, J. Stribling, M. Krohn, H. Balakrishnan, R. Morris, S. Shenker, “Middleboxes No Longer Considered Harmful,” </span><span class="font53" style="font-style:italic;">USENIX OSDI2004 </span><span class="font53">San Francisco, CA, December 2004.</span></p>
<p><span class="font53" style="font-weight:bold;">[Wang 2011] </span><span class="font53">Z. Wang, Z. Qian, Q. Xu, Z. Mao, M. Zhang, “An untold story of middleboxes in cellular networks,” </span><span class="font53" style="font-style:italic;">Proc. 2011 ACM SIGCOMM Conference.</span></p>
<p><span class="font53" style="font-weight:bold;">[Wei 2006] </span><span class="font53">D. X. Wei, C. Jin, S. H. Low and S. Hegde, “FAST TCP: Motivation, Architecture, Algorithms, Performance,” </span><span class="font53" style="font-style:italic;">IEEE/ACM Transactions on Networking, </span><span class="font53">Vol. 14, No. 6, pp. 1246-1259, Dec. 2006.</span></p>
<p><span class="font53" style="font-weight:bold;">[Wei 2006] </span><span class="font53">W. Wei, C. Zhang, H. Zang, J. Kurose, D. Towsley, “Inference and Evaluation of Split-Connection Approaches in Cellular Data Networks,” </span><span class="font53" style="font-style:italic;">Proc. Active and Passive Measurement Workshop</span><span class="font53"> (Adelaide, Australia, Mar. 2006).</span></p>
<p><span class="font53" style="font-weight:bold;">[Weiser 1991] </span><span class="font53">M. Weiser, “The Computer for the Twenty-First Century,” </span><span class="font53" style="font-style:italic;">Scientific American</span><span class="font53"> (Sept. 1991): 94-10. </span><a href="http://www.ubiq.com/hypertext/weiser/SciAmDraft3.html"><span class="font53">http://www.ubiq.com/hypertext/weiser/</span></a><span class="font53"> </span><a href="http://www.ubiq.com/hypertext/weiser/SciAmDraft3.html"><span class="font53">SciAmDraft3.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Wifi 2019] </span><span class="font53">The WiFi Alliance, “WPA3™ Security Considerations Overview,” April 2019.</span></p>
<p><span class="font53" style="font-weight:bold;">[WiFi 2020] </span><span class="font53">The WiFi Alliance, </span><a href="https://www.wi-fi.org/"><span class="font53">https://www.wi-fi.org/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Williams 1993] </span><span class="font53">R. Williams, “A Painless Guide to CRC Error Detection Algorithms,” </span><a href="http://www.ross.net/crc/crcpaper.html"><span class="font53">http://www.ross.net/crc/crcpaper.html</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Wireshark 2020] </span><span class="font53">Wireshark homepage, </span><a href="http://www.wireshark.org"><span class="font53">http://www.wireshark.org</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Wischik 2005] </span><span class="font53">D. Wischik, N. McKeown, “Part I: Buffer Sizes for Core</span></p>
<p><span class="font53">Routers,” </span><span class="font53" style="font-style:italic;">ACM SIGCOMM Computer Communications Review,</span><span class="font53"> Vol. 35, No. 3 (July 2005).</span></p>
<p><span class="font53" style="font-weight:bold;">[Woo 1994] </span><span class="font53">T. Woo, R. Bindignavle, S. Su, S. Lam, “SNP: an interface for secure network programming,” </span><span class="font53" style="font-style:italic;">Proc. 1994 Summer USENIX</span><span class="font53"> (Boston, MA, June 1994), pp. 45-58.</span></p>
<p><span class="font53" style="font-weight:bold;">[Wright 2015] </span><span class="font53">J. Wright, J., </span><span class="font53" style="font-style:italic;">Hacking Exposed Wireless,</span><span class="font53"> McGraw-Hill Education, 2015.</span></p>
<p><span class="font53" style="font-weight:bold;">[Wu 2005] </span><span class="font53">J. Wu, Z. M. Mao, J. Rexford, J. Wang, “Finding a Needle in a Haystack: Pinpointing Significant BGP Routing Changes in an IP Network,” </span><span class="font53" style="font-style:italic;">Proc. USENIX NSDI</span><span class="font53"> (2005).</span></p>
<p><span class="font53" style="font-weight:bold;">[W3Techs] </span><span class="font53">World Wide Web Technology Surveys, 2020. </span><a href="https://w3techs.com/technologies/details/ce-http2/all/all"><span class="font53">https://w3techs.com/</span></a><span class="font53"> </span><a href="https://w3techs.com/technologies/details/ce-http2/all/all"><span class="font53">technologies/details/ce-http2/all/all.</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Xanadu 2012] </span><span class="font53">Xanadu Project homepage, </span><a href="http://www.xanadu.com/"><span class="font53">http://www.xanadu.com/</span></a></p>
<p><span class="font53" style="font-weight:bold;">[Xiao 2000] </span><span class="font53">X. Xiao, A. Hannan, B. Bailey, L. Ni, “Traffic Engineering with MPLS in the Internet,” </span><span class="font53" style="font-style:italic;">IEEE Network</span><span class="font53"> (Mar./Apr. 2000).</span></p>
<p><span class="font53" style="font-weight:bold;">[Xu 2004] </span><span class="font53">L. Xu, K Harfoush, I. Rhee, “Binary Increase Congestion Control (BIC) for Fast Long-Distance Networks,” </span><span class="font53" style="font-style:italic;">IEEE INFOCOM 2004,</span><span class="font53"> pp. 2514-2524.</span></p>
<p><span class="font53" style="font-weight:bold;">[Yang 2014] </span><span class="font53">P. Yang, J. Shao, W. Luo, L. Xu, J. Deogun, Y. Lu, “TCP congestion avoidance algorithm identification,” </span><span class="font53" style="font-style:italic;">IEEE/ACM Trans. Netw</span><span class="font53">. Vol. 22, No. 4 (Aug. 2014), pp. 1311-1324.</span></p>
<p><span class="font53" style="font-weight:bold;">[Yavatkar 1994] </span><span class="font53">R. Yavatkar, N. Bhagwat, “Improving End-to-End Performance of TCP over Mobile Internetworks,” </span><span class="font53" style="font-style:italic;">Proc. Mobile 94 Workshop on Mobile Computing Systems and Applications</span><span class="font53"> (Dec. 1994).</span></p>
<p><span class="font53" style="font-weight:bold;">[YouTube 2009] </span><span class="font53">YouTube 2009, Google container data center tour, 2009.</span></p>
<p><span class="font53" style="font-weight:bold;">[Yu 2004] </span><span class="font53">Yu, Fang, H. Katz, Tirunellai V. Lakshman. “Gigabit Rate Packet Pattern-Matching Using TCAM,” </span><span class="font53" style="font-style:italic;">Proc. 2004 Int. Conf. Network Protocols, </span><span class="font53">pp. 174-183.</span></p>
<p><span class="font53" style="font-weight:bold;">[Yu 2011] </span><span class="font53">M. Yu, J. Rexford, X. Sun, S. Rao, N. Feamster, “A Survey of VLAN Usage in Campus Networks,” </span><span class="font53" style="font-style:italic;">IEEE Communications Magazine</span><span class="font53">, July 2011.</span></p>
<p><span class="font53" style="font-weight:bold;">[Zegura 1997] </span><span class="font53">E. Zegura, K. Calvert, M. Donahoo, “A Quantitative Comparison of Graph-based Models for Internet Topology,” </span><span class="font53" style="font-style:italic;">IEEE/ACM Transactions on Networking, </span><span class="font53">Vol. 5, No. 6, (Dec. 1997). See also </span><a href="http://www.cc.gatech.edu/projects/gtitm"><span class="font53">http://www.cc.gatech.edu/projects/gtitm</span></a><span class="font53"> for a software package that generates networks with a transit-stub structure.</span></p>
<p><span class="font53" style="font-weight:bold;">[Zhang 2007] </span><span class="font53">L. Zhang, “A Retrospective View of NAT,” </span><span class="font53" style="font-style:italic;">The IETF Journal, </span><span class="font53">Vol. 3, No. 2 (Oct. 2007).</span></p>
<p><span class="font53" style="font-weight:bold;">[Zheng 2008] </span><span class="font53">N. Zheng and J. Wigard, “On the Performance of Integrator Handover Algorithm in LTE Networks,” </span><span class="font53" style="font-style:italic;">2008 IEEE 68th Vehicular Technology Conference, </span><span class="font53">Calgary, BC, 2008, pp. 1-5.</span></p>
<p><span class="font53" style="font-weight:bold;">[Zhu 2015] </span><span class="font53">Y. Zhu, H. Eran, D. Firestone, D. Firestone, C. Guo, M. Lipshteyn, Y. Liron, J. Padhye, S. Raindel Mohamad, H. Yahia, M. Zhang, J. Padhye, “Congestion Control for Large-Scale RDMA Deployments,” </span><span class="font53" style="font-style:italic;">Proc. 2015 ACM SIGCOMM Conference.</span></p>
<p><span class="font53" style="font-weight:bold;">[Zilberman 2019] </span><span class="font53">N. Zilberman, G. Bracha, G. Schzukin. “Stardust: Divide and conquer in the data center network,” </span><span class="font53" style="font-style:italic;">2019 USENIX Symposium on Networked Systems Design and Implementation.</span></p>
<p><span class="font53" style="font-weight:bold;">[Zink 2009] </span><span class="font53">M. Zink, K. Suh, Y. Gu, J. Kurose, “Characteristics of YouTube Network Traffic at a Campus Network—Measurements, Models, and Implications,” </span><span class="font53" style="font-style:italic;">Computer Networks,</span><span class="font53"> Vol. 53, No. 4, pp. 501-514, 2009.</span></p>
<p><span class="font53" style="font-weight:bold;">[Zou 2016] </span><span class="font53">Y. Zou, J. Zhu, X. Wang, L. Hanzo, “A Survey on Wireless Security: Technical Challenges, Recent Advances, and Future Trends,” </span><span class="font53" style="font-style:italic;">Proceedings of the IEEE,</span><span class="font53"> Vol. 104, No. 9, 2016.</span></p>
<h1><a name="bookmark10"></a><span class="font27" style="font-weight:bold;">Index</span></h1>
<p><span class="font55" style="font-weight:bold;">A</span></p>
<p><span class="font53">Abramson, Norman, 91, 500 access and mobility management function (AMF), 608 access control lists, 700 access networks, 42-48, 438 cable, 44-45, 93 DSL, 43-44, 93 enterprise, 46-47 Ethernet, 46-47 FTTH, 45-46, 93 3G, 48 4G, 48 5G, 48 5G cellular networks, 46 5G fixed wireless, 46 HFC, 45 LTE, 48 WiFi, 46-47</span></p>
<p><span class="font53">access points (AP), 574 in infrastructure LANs, 574 MAC addresses, 574 mobility between, 587 power management and, 590 scanning for, 577 SSID,575 WiFi, 480 wireless LANs, 563</span></p>
<p><span class="font53">ACK (positive acknowledgments), 234-238</span></p>
<p><a name="bookmark476"></a><span class="font53">corrupted, 236 DHCP, 374 duplicate, 238, 273 in 802.11 RTC/CTS system, 590</span></p>
<p><span class="font53">TCP generation recommendation, 274</span></p>
<p><span class="font53">ACK bit, 260</span></p>
<p><span class="font53">TCP, 700</span></p>
<p><span class="font53">ack clocking, 331</span></p>
<p><span class="font53">ACK frames, 582</span></p>
<p><span class="font53">acknowledged segments, 295 acknowledgments</span></p>
<p><span class="font53">cumulative, 248, 262 negative, 234-238, 265 piggybacked, 265</span></p>
<p><span class="font53">positive, 234-238, 273, 374</span></p>
<p><span class="font53">TCP, 261-263, 276</span></p>
<p><span class="font53">acknowledgment number, 261-263 piggybacked, 265 Telnet and, 263-265</span></p>
<p><span class="font53">acknowledgment number field, 260 ACK received events, 269, 270 active optical networks (AONs), 46 active queue management (AQM), 352</span></p>
<p><span class="font53">active scanning, 576</span></p>
<p><span class="font53">adapters</span></p>
<p><span class="font53">802.11, 563</span></p>
<p><span class="font53">ARP query and, 512</span></p>
<p><span class="font53">CSMA/CD operation and, 515 datagram transmission and, 516 error detection in, 482 Ethernet frames and, 524 frames, 494 jabbering, 524</span></p>
<p><span class="font53">MAC addresses, 508 monitors, 502 motherboard chipset, 483 network, 483</span></p>
<p><span class="font53">adaptive congestion</span></p>
<p><span class="font53">control, 227 additive-increase, multiplicative-</span></p>
<p><span class="font53">decrease (AIMD), 301 fairness of, 306-309</span></p>
<p><span class="font53">address aggregation, 368</span></p>
<p><span class="font53">addresses. </span><span class="font53" style="font-style:italic;">See also</span><span class="font53"> IP addresses;</span></p>
<p><span class="font53">MAC addresses</span></p>
<p><span class="font53">anycast, 378 broadcast, 510 care-of, 623, 624</span></p>
<p><span class="font53">foreign, 623</span></p>
<p><span class="font53">IEEE 802.11 wireless LAN, 584-586</span></p>
<p><span class="font53">IP broadcast, 370, 372-373</span></p>
<p><span class="font53">LAN, 508</span></p>
<p><span class="font53">MAC, 574</span></p>
<p><span class="font53">mobile node, 623</span></p>
<p><span class="font53">obtaining with DHCP, 371-374</span></p>
<p><span class="font53">permanent, 160</span></p>
<p><span class="font53">physical, 508</span></p>
<p><span class="font53">realm with private, 374</span></p>
<p><span class="font53">SIP, 123</span></p>
<p><span class="font53">temporary IP, 371</span></p>
<p><span class="font53">addressing, 363-374</span></p>
<p><span class="font53">classful, 367-368</span></p>
<p><span class="font53">IP, 216</span></p>
<p><span class="font53">IPv4, 363-374</span></p>
<p><span class="font53">link-layer, 483, 508-514</span></p>
<p><span class="font53">mobility management and, 596 subnet, 366</span></p>
<p><span class="font53">address lease time, 373</span></p>
<p><span class="font53">Address Resolution Protocol (ARP), 510</span></p>
<p><span class="font53">MAC address, 508-513</span></p>
<p><span class="font53">packet, 512</span></p>
<p><span class="font53">table, 512</span></p>
<p><span class="font53">Address Supporting Organization of</span></p>
<p><span class="font53">ICANN, 370-371</span></p>
<p><span class="font53">ad hoc networks, 564</span></p>
<p><span class="font53">mobile, 565</span></p>
<p><span class="font53">vehicular, 565</span></p>
<p><span class="font53">Adleman, Leonard, 650</span></p>
<p><span class="font53">administrative autonomy, 426</span></p>
<p><span class="font53">Advanced Research Projects Agency (ARPA), 89, 405</span></p>
<p><span class="font53">AES (Advanced Encryption</span></p>
<p><span class="font53">Standard), 645</span></p>
<p><span class="font53">agent discovery, 624</span></p>
<p><span class="font53">aging time, 523</span></p>
<p><span class="font53">AH protocol. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Authentication Header protocol</span></p>
<p><span class="font53">AIMD. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> additive-increase, multiplicative-decrease</span></p>
<p><span class="font53">Akamai, 142, 155</span></p>
<p><span class="font53">aliasing</span></p>
<p><span class="font53">host, 154</span></p>
<p><span class="font53">mail server, 154</span></p>
<p><span class="font53">Alibaba Cloud, 94</span></p>
<p><span class="font53">ALOHAnet, 89, 91, 500</span></p>
<p><span class="font53">ALOHA protocol, 498</span></p>
<p><span class="font53">carrier sense multiple access</span></p>
<p><span class="font53">(CSMA), 499-501</span></p>
<p><span class="font53">carrier sense multiple access with collision detection (CSMA/CD), 501-504</span></p>
<p><span class="font53">efficiency, 497</span></p>
<p><span class="font53">pure, 551</span></p>
<p><span class="font53">slotted, 496-498</span></p>
<p><span class="font53">successful slot, 497</span></p>
<p><span class="font53">alternating-bit protocol, 241, 242</span></p>
<p><span class="font53">Alto computers, 518</span></p>
<p><span class="font53">Amazon, 93</span></p>
<p><span class="font53">cloud services, 535, 536</span></p>
<p><span class="font53">DNS vulnerabilities, 165</span></p>
<p><span class="font53">video streaming, 173</span></p>
<p><span class="font53">Andreessen, Marc, 92</span></p>
<p><span class="font53">Android devices, 48</span></p>
<p><span class="font53">anomaly-based systems, 707 anonymity, 704-705</span></p>
<p><span class="font53">anycast address, 378 AONs. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> active optical networks</span></p>
<p><span class="font53">Apache Web server, 223 API. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Application Programming Interface</span></p>
<p><span class="font53">application architecture, 114 application delay, 73 application gateways, 698 application layer, 80, 111 application-layer message, 83 application-layer</span></p>
<p><span class="font53">protocols, 124 DNS, 80 FTP, 80 HTTP, 80 Skype, 124 SMTP, 80</span></p>
<p><span class="font53">application-level transport reliability, 227-228</span></p>
<p><span class="font53">Application Programming Interface (API), 117</span></p>
<p><span class="font53">application protocols, well-known, 218-219</span></p>
<p><span class="font53">applications. </span><span class="font53" style="font-style:italic;">See also</span><span class="font53"> multimedia applications; network applications bandwidth-sensitive, 119 control, 444-446 delays, 73 distributed, 35 elastic, 120 loss-tolerant, 119 multimedia, 226 network, 112-125 network-service, 450 SDN control, 444-446</span></p>
<p><span class="font53">APs. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> access points AQM. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> active queue management</span></p>
<p><span class="font53">architectural evolution from 2G to 3G to 4G, 598-599</span></p>
<p><span class="font53">ARP. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Address Resolution Protocol</span></p>
<p><span class="font53">ARPA. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Advanced Research</span></p>
<p><span class="font53">Projects Agency</span></p>
<p><span class="font53">ARPAnet, 258</span></p>
<p><span class="font53">ALOHAnet connection to, 89</span></p>
<p><span class="font53">Cerf on, 405 development of, 89-92 routing algorithms,</span></p>
<p><span class="font53">413, 420</span></p>
<p><span class="font53">ARP packet, 583</span></p>
<p><span class="font53">ARP protocol, 545</span></p>
<p><span class="font53">ARP query, 545</span></p>
<p><span class="font53">ARP reply, 545</span></p>
<p><span class="font53">ARP table, 512</span></p>
<p><span class="font53">ARQ (Automatic Repeat reQuest) protocols, 234</span></p>
<p><span class="font53">ASN. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> autonomous system number</span></p>
<p><span class="font53">AS numbers. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> autonomous system number</span></p>
<p><span class="font53">AS-PATH, 433, 435</span></p>
<p><span class="font53">ASs. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> autonomous systems associate, 533 associations</span></p>
<p><span class="font53">IEEE 802.11 wireless LAN, 575-578</span></p>
<p><span class="font53">security, 683-685</span></p>
<p><span class="font53">Atheros AR5006, 483</span></p>
<p><span class="font53">ATM</span></p>
<p><span class="font53">congestion control, 292</span></p>
<p><span class="font53">delay and bandwidth guarantees, 340</span></p>
<p><span class="font53">frame-relay and, 532</span></p>
<p><span class="font53">SDN and, 449</span></p>
<p><span class="font53">ATM Available Bite Rate</span></p>
<p><span class="font53">(ABR), 292</span></p>
<p><span class="font53">congestion control, 292</span></p>
<p><span class="font53">AT&amp;T, 62, 410, 476</span></p>
<p><span class="font53">authentication, 428</span></p>
<p><span class="font53">end-point, 87-88, 639</span></p>
<p><span class="font53">4G/5G cellular networks, 694-697</span></p>
<p><span class="font53">4G LTE cellular networks, 596, 694-697</span></p>
<p><span class="font53">MD5, 428</span></p>
<p><span class="font53">mutual, 690</span></p>
<p><span class="font53">in OSPF, 428</span></p>
<p><span class="font53">sender, 639</span></p>
<p><span class="font53">shared common secret, 691</span></p>
<p><span class="font53">simple, 428</span></p>
<p><span class="font53">wireless LANs, 690</span></p>
<p><span class="font53">Authentication and Key Agreement (AKA) protocol</span></p>
<p><span class="font53">4G, 695</span></p>
<p><span class="font53">Authentication Header (AH) protocol, 683</span></p>
<p><span class="font53">authentication key, 657</span></p>
<p><span class="font53">authentication protocol,</span></p>
<p><span class="font53">666-669</span></p>
<p><span class="font53">authentication server (AS), 690</span></p>
<p><span class="font53">authoritative DNS servers, 157, 546</span></p>
<p><span class="font53">autonomous system number (ASN), 426</span></p>
<p><span class="font53">autonomous systems (ASs), 426 in BGP route advertisement, 430-432</span></p>
<p><span class="font53">hierarchy within, 428-429</span></p>
<p><span class="font53">iBGP connections within, 431</span></p>
<p><span class="font53">routing between, 425-429,</span></p>
<p><span class="font53">439, 450</span></p>
<p><span class="font53">availability zones, 542</span></p>
<p><span class="font53">average throughput, 74</span></p>
<p><span class="font53">Azure, 94</span></p>
<p><span class="font55" style="font-weight:bold;">B</span></p>
<p><span class="font53">B4, 410, 447</span></p>
<p><span class="font53">backbone providers, 438</span></p>
<p><span class="font53">backoff</span></p>
<p><span class="font53">binary exponential, 503 random, 580</span></p>
<p><span class="font53">bandwidth, 58-59</span></p>
<p><span class="font53">ATM guarantees, 340 best-effort service and, 340 channel, 603</span></p>
<p><span class="font53">congestion control and, 295 DoS, 706</span></p>
<p><span class="font53">downstream, 602 fairness and, 306-309 flooding, 85 FM radio, 58</span></p>
<p><span class="font53">guaranteed minimal, 339-340 memory, 347</span></p>
<p><span class="font53">probing, 295, 301 wireless, 576</span></p>
<p><span class="font53">Baran, Paul, 89</span></p>
<p><span class="font53">base HTML file, 126 base station, 563, 593, 594 basic service set (BSS), 574 BBN, 89</span></p>
<p><span class="font53">BBR. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> TCP BBR beacon frames, 546 beam forming, 607 Bellman-Ford equation, 418-419</span></p>
<p><span class="font53">Bellovin, Steven M., 719 BER. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> bit error rate</span></p>
<p><span class="font53">Berners-Lee, Tim, 92 best-effort delivery services, 216</span></p>
<p><span class="font53">best-effort services, 340</span></p>
<p><span class="font53">BGP, 546. </span><span class="font53" style="font-style:italic;">See also</span><span class="font53"> Border Gateway Protocol</span></p>
<p><span class="font53">bidirectional data transfer, 232</span></p>
<p><span class="font53">binary exponential backoff algorithm, 503</span></p>
<p><span class="font53">bind(), 219</span></p>
<p><span class="font53">bit error rate (BER), 567</span></p>
<p><span class="font53">bit errors</span></p>
<p><span class="font53">data transfer over channel with, 233-238</span></p>
<p><span class="font53">data transfer over lossy channel with, 238-241</span></p>
<p><span class="font53">bit-level error detection and correction, 484</span></p>
<p><span class="font53">BITNET, 91</span></p>
<p><span class="font53">BitTorrent</span></p>
<p><span class="font53">chunks, 170</span></p>
<p><span class="font53">DHT, 173</span></p>
<p><span class="font53">file distribution with, 171 optimistically unchoked, 172 rarest first, 172</span></p>
<p><span class="font53">torrent, defined, 170</span></p>
<p><span class="font53">tracker, 171</span></p>
<p><span class="font53">unchoked, 172</span></p>
<p><span class="font53">blades, 535</span></p>
<p><span class="font53">block ciphers</span></p>
<p><span class="font53">3-bit, 645</span></p>
<p><span class="font53">full-table, 645</span></p>
<p><span class="font53" style="font-style:italic;">k</span><span class="font53">-bit block, 644</span></p>
<p><span class="font53">Bluetooth</span></p>
<p><span class="font53">as cable replacement technology, 590 neighbor discovery problem, 592 paging, 592</span></p>
<p><span class="font53">piconet, 591</span></p>
<p><span class="font53">self-organizing, 592</span></p>
<p><span class="font53">standards, transmission rates, and range, 564</span></p>
<p><span class="font53">Boggs, David, 515</span></p>
<p><span class="font53">Border Gateway Protocol (BGP), 407, 413, 420, 429-441, 546</span></p>
<p><span class="font53">attributes, 432-433 connection, 431 determining best routes, 432-436 in Google SDN, 447 hot potato routing, 434-435 internal BGP, 431-432</span></p>
<p><span class="font53">IP-anycast implementation with, 436-437 outside-AS destinations, 434 role of, 429-430 route attributes, 433 route information advertisement, 430-432</span></p>
<p><span class="font53">route-selection algorithm, 435-436</span></p>
<p><span class="font53">routing policy, 437-440 routing tables, 435-436</span></p>
<p><span class="font53">border routers, 428-429, 536 botnets, 85</span></p>
<p><span class="font53">bottleneck link, 75</span></p>
<p><span class="font53">TCP fairness and, 306-308</span></p>
<p><span class="font53">bounded delay, 339 bright line rules, 358 broadband Internet, 93 broadcast</span></p>
<p><span class="font53">in ALOHA, 91 Ethernet as, 519 forwarding to, 387 link, 491 link-state, 413, 425 MAC address, 510 multiple access protocols, 492 in OSPF, 427-428 packet sniffing and, 87 broadcast address, 510</span></p>
<p><span class="font53">IP, 370, 372-373 MAC, 510 broadcast link, 491 broadcast media, 331 broadcast storms, 526 Brooks, Fred, 719 browsers, 92, 126 BS. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> base station bufferbloat, 354 buffered distributors, 520 buffering, 353-354 buffer overflows, congestion causing, 290-291</span></p>
<p><span class="font53">buffers</span></p>
<p><span class="font53">finite, 288 infinite, 286 output, 54 receive, 259, 277, 278 send, 259</span></p>
<p><span class="font53">sizing for routers, 353</span></p>
<p><span class="font53">TCP, 130</span></p>
<p><span class="font53">Bush, Vannevar, 92</span></p>
<p><span class="font53">bus, switching via, 348</span></p>
<p><span class="font55" style="font-weight:bold;">C</span></p>
<p><span class="font53">CA. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Certification Authority cable Internet access, 44-45, 93 cable modem termination system</span></p>
<p><span class="font53">(CMTS), 45 caching, 331</span></p>
<p><span class="font53">DNS, 160</span></p>
<p><span class="font53">pull, 181</span></p>
<p><span class="font53">push, 182</span></p>
<p><span class="font53">Web, 135, 138</span></p>
<p><span class="font53">Caesar cipher, 642, 644</span></p>
<p><span class="font53">canonical hostname, 154 care-of address (COA), 623, 624 carrier sense multiple access (CSMA), 499-501</span></p>
<p><span class="font53">carrier sense multiple access with collision detection (CSMA/CD), 501-504</span></p>
<p><span class="font53">efficiency, 504 carrier sensing, 499 CBC. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Cipher Block Chaining CDMA. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> code division multiple</span></p>
<p><span class="font53">access</span></p>
<p><span class="font53">CDNs. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Content Distribution Networks</span></p>
<p><span class="font53">cell location tracking, 597 cells, 593</span></p>
<p><span class="font53">cellular networks</span></p>
<p><span class="font53">3G, 48</span></p>
<p><span class="font53">4G, 48</span></p>
<p><span class="font53">5G, 48</span></p>
<p><span class="font53">4G/5G, transmission rates and range, 564</span></p>
<p><span class="font53">LTE, 48</span></p>
<p><span class="font53">cellular telephony, 48</span></p>
<p><span class="font53">centralized routing algorithm, 412</span></p>
<p><span class="font53">in LS algorithm, 414</span></p>
<p><span class="font53">central office (CO), 43-44</span></p>
<p><span class="font53">Cerf, Vinton, 91, 258, 405-406</span></p>
<p><span class="font53">certificate, 662</span></p>
<p><span class="font53">Certification Authority (CA), 662</span></p>
<p><span class="font53">channel partitioning protocols, 493</span></p>
<p><span class="font53">CDMA, 495</span></p>
<p><span class="font53">FDM, 493-494</span></p>
<p><span class="font53">TDM, 493-494</span></p>
<p><span class="font53">channel propagation delay, 501 channels</span></p>
<p><span class="font53">with bit errors, 233-240</span></p>
<p><span class="font53">IEEE 802.11 wireless LAN, 575-578</span></p>
<p><span class="font53">lossy, 238-241</span></p>
<p><span class="font53">perfectly reliable, 232-233</span></p>
<p><span class="font53">satellite radio, 51</span></p>
<p><span class="font53">terrestrial radio, 51</span></p>
<p><span class="font53">channel utilization, 243</span></p>
<p><span class="font53">checksum field, 260</span></p>
<p><span class="font53">checksumming methods, 488 checksums</span></p>
<p><span class="font53">corrupted ACK and NAK packet detection, 236</span></p>
<p><span class="font53">IPv4 headers, 362-363</span></p>
<p><span class="font53">UDP, 228-230</span></p>
<p><span class="font53">China Telecom, 410</span></p>
<p><span class="font53">China Unicom, 410</span></p>
<p><span class="font53">chipping rate, 569</span></p>
<p><span class="font53">choke packets, 292</span></p>
<p><span class="font53">chosen-plaintext attack, 643 chunks, 170</span></p>
<p><span class="font53">CIDR. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Classless Interdomain</span></p>
<p><span class="font53">Routing</span></p>
<p><span class="font53">Cipher Block Chaining (CBC), 646</span></p>
<p><span class="font53">ciphertext, 641 ciphertext-only attack, 643 circuit, 57</span></p>
<p><span class="font53">circuit switching, 57-61</span></p>
<p><span class="font53">packet switching </span><span class="font53" style="font-style:italic;">versus,</span><span class="font53"> 60-61</span></p>
<p><span class="font53">Cisco, 34, 93</span></p>
<p><span class="font53">Cisco Catalyst 6500 Series, 346 switching bus, 348</span></p>
<p><span class="font53">Cisco Catalyst 7600 Series, 346 switching fabric, 349</span></p>
<p><span class="font53">Cisco Catalyst 8500 Series, switching fabric, 348</span></p>
<p><span class="font53">Cisco CRS, switching strategy, 349</span></p>
<p><span class="font53">Cisco 12000 series, switching fabric, 348-349</span></p>
<p><span class="font53">Clark, Jim, 92</span></p>
<p><span class="font53">classful addressing, 367-368</span></p>
<p><span class="font53">Classless Interdomain Routing (CIDR), 366-367, 544</span></p>
<p><span class="font53">“class” of traffic, 358 cleartext, 641</span></p>
<p><span class="font53">Clear to Send (CTS) control frame, 581</span></p>
<p><span class="font53">client process, 257</span></p>
<p><span class="font53">clients, 41, 116</span></p>
<p><span class="font53">client-server architecture, 114 cloud computing, 41, 94, 535</span></p>
<p><span class="font53">cloud services, response time of, 299 cluster selection strategy, 179 CMTS. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> cable modem termination system</span></p>
<p><span class="font53">CO. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> central office</span></p>
<p><span class="font53">COA. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> care-of address coaxial cable, 50 code division multiple access (CDMA), 495, 562, 569-572 collide, 492 collisions</span></p>
<p><span class="font53">detection, 499 elimination of, 524</span></p>
<p><span class="font53">3Com, 518</span></p>
<p><span class="font53">COMCAST, 410</span></p>
<p><span class="font53">Command Line Interface (CLI), 457-458</span></p>
<p><span class="font53">communication</span></p>
<p><span class="font53">secure, 638</span></p>
<p><span class="font53">communication layer, SDN, 444 communication links, 34 Compound TCP (CTPC), 306 computational complexity, of LS</span></p>
<p><span class="font53">algorithm, 416 computer networks, 32</span></p>
<p><span class="font53">graph model of, 410-411 history of, 88-94 throughput in, 73-76 conditional GET, 142 confidentiality, 638, 670 configuration data, 456 congestion</span></p>
<p><span class="font53">buffer overflows from, 290-291 causes and costs of, 285-291 delays from, 287</span></p>
<p><span class="font53">lost segments and, 295 multihop paths and, 289-291 retransmission and, 288-289 routers and, 286-291 throughput and, 286-291</span></p>
<p><span class="font53">congestion avoidance, 297-298 congestion control, 216, 277</span></p>
<p><span class="font53">ABR, 227 adaptive, 227 AIMD, 301 approaches to, 292-293 bandwidth and, 295 end-to-end, 292 network-assisted, 292, 293 principles of, 285-293 TCP, 293-309</span></p>
<p><span class="font53">congestion window, 294, 300 Congestion Window Reduced</span></p>
<p><span class="font53">(CWR) bit, 304 connection flooding, 85</span></p>
<p><span class="font53">connectionless demultiplexing,</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">219- 220</span></p></li></ul>
<p><span class="font53">connectionless multiplexing, 219-220 connectionless transport, 224-230 connection management, TCP, 279-283, 285</span></p>
<p><span class="font53">connection-oriented and secure, 310-311</span></p>
<p><span class="font53">connection-oriented demultiplexing,</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">220- 223</span></p></li></ul>
<p><span class="font53">connection-oriented multiplexing, 220-223</span></p>
<p><span class="font53">connection-oriented transport, 257-285</span></p>
<p><span class="font53">connection requests, 221 connection state, 226</span></p>
<p><span class="font53">Content Distribution Networks</span></p>
<p><span class="font53">(CDNs), 142, 175 bring home, 176 cluster selection strategies, 179 DNS redirects user’s request</span></p>
<p><span class="font53">to, 178</span></p>
<p><span class="font53">enter deep, 176</span></p>
<p><span class="font53">geographically closest, 179</span></p>
<p><span class="font53">Google, 177</span></p>
<p><span class="font53">IP-anycast and, 436-437</span></p>
<p><span class="font53">Netflix, 180-182 operation, 176 private, 176 real-time measurements, 179 third-party, 176</span></p>
<p><span class="font53">uploading versions to, 180</span></p>
<p><span class="font53">YouTube, 182</span></p>
<p><span class="font53">content ingestion, 180 content processing, 180</span></p>
<p><span class="font53">content provider networks, 64 control packets, 342</span></p>
<p><span class="font53">control plane, 333, 343, 407</span></p>
<p><span class="font53">SDN, 441-450</span></p>
<p><span class="font53">convergence, routing algorithm speed of, 425</span></p>
<p><span class="font53">cookies, 135-138</span></p>
<p><span class="font53">SYN, 284</span></p>
<p><span class="font53">cost reduction, 539-540 countdown timer, 240 CRC. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> cyclic redundancy check crossbar switches, 348-349 cryptographic hash function, 655-656 cryptography</span></p>
<p><span class="font53">components, 641 principles of, 640-654 public-key, 649</span></p>
<p><span class="font53">CSMA. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> carrier sense multiple access</span></p>
<p><span class="font53">CSMA with collision avoidance, 578</span></p>
<p><span class="font53">CSNET, 91</span></p>
<p><span class="font53">CTS. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Clear to Send</span></p>
<p><span class="font53">CUBIC. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> TCP CUBIC</span></p>
<p><span class="font53">cumulative acknowledgment, 248, 262 customer, 62</span></p>
<p><span class="font53">cwnd, 294, 296-301</span></p>
<p><span class="font53">Cyclades, 90</span></p>
<p><span class="font53">cyclic redundancy check (CRC), 489-491</span></p>
<p><span class="font53">codes, 489, 517</span></p>
<p><span class="font53">error-detection techniques, 489-491</span></p>
<p><span class="font53">IEEE 802.11 wireless LAN, 583-584</span></p>
<p><span class="font55" style="font-weight:bold;">D</span></p>
<p><span class="font53">DARPA. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Defense Advanced</span></p>
<p><span class="font53">Research Projects Agency DASH. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Dynamic Adaptive</span></p>
<p><span class="font53">Streaming over HTTP data, 456 data center, 114</span></p>
<p><span class="font53">cost reduction, 539-540</span></p>
<p><span class="font53">hardware modularity and customization, 541-542</span></p>
<p><span class="font53">physical constraints, 541</span></p>
<p><span class="font53">SDN control and management, 540 virtualization, 540-541</span></p>
<p><span class="font53">data center network design, 536 data center networking</span></p>
<p><span class="font53">data center architectures, 535-539 trends in, 539-542</span></p>
<p><span class="font53">data center networks, 535</span></p>
<p><span class="font53">Data Center Quantized Congestion</span></p>
<p><span class="font53">Notification (DCQCN), 305 data centers, 41</span></p>
<p><span class="font53">Data Center TCP (DCTCP), 304, 309 Data Encryption Standard (DES), 645 Datagram Congestion Control</span></p>
<p><span class="font53">Protocol (DCCP), 304 datagrams, 81, 215</span></p>
<p><span class="font53">indirect routing of, 624</span></p>
<p><span class="font53">inspecting, 376</span></p>
<p><span class="font53">IPv4 format, 361-363</span></p>
<p><span class="font53">IPv6 format, 378-380</span></p>
<p><span class="font53">NAT and, 376</span></p>
<p><span class="font53">network-layer, 83</span></p>
<p><span class="font53">reassembly of, 380 transmission, 516</span></p>
<p><span class="font53">data-over-cable service interface specifications (DOCSIS), 505-507</span></p>
<p><span class="font53">data plane, 333, 394</span></p>
<p><span class="font53">4G, 614</span></p>
<p><span class="font53">generalized forwarding and SDN, 383-390</span></p>
<p><span class="font53">IP, 360-383</span></p>
<p><span class="font53">routers, 341-360</span></p>
<p><span class="font53">SDN and, 442, 448-449 data received events, 269, 270 Davies, Donald, 89</span></p>
<p><span class="font53">DCCP. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Datagram Congestion Control Protocol</span></p>
<p><span class="font53">DCTCP. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Data Center TCP</span></p>
<p><span class="font53">DDoS. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> distributed DoS decentralized routing algorithm, 412-413</span></p>
<p><span class="font53">decryption, 653</span></p>
<p><span class="font53">decryption algorithm, 641</span></p>
<p><span class="font53">deep packet inspection (DPI), 390, 639, 705</span></p>
<p><span class="font53">Defense Advanced Research Projects</span></p>
<p><span class="font53">Agency (DARPA), 90, 91, 405 delayed-based congestion control, 305-306</span></p>
<p><span class="font53">delays</span></p>
<p><span class="font53">application, 73 bounded, 339</span></p>
<p><span class="font53">in end systems, 73 end-to-end, 71-73</span></p>
<p><span class="font53">network congestion and, 287 nodal, 66</span></p>
<p><span class="font53">nodal processing, 65</span></p>
<p><span class="font53">in packet-switched networks, 65-76</span></p>
<p><span class="font53">processing, 66</span></p>
<p><span class="font53">propagation, 65, 67-69 queuing, 54-55, 65, 66,</span></p>
<p><span class="font53">69-71, 287</span></p>
<p><span class="font53">in shared medium, 73</span></p>
<p><span class="font53">total nodal, 65</span></p>
<p><span class="font53">transmission, 65-69</span></p>
<p><span class="font53">types of, 65-69</span></p>
<p><span class="font53">deletion, message content, 640 demilitarized zone (DMZ), 706 demultiplexing, 217-224, 544 connectionless, 219-220 connection-oriented, 220-223 transport-layer, 216</span></p>
<p><span class="font53">denial-of-service (DoS) attacks, 85-86 distributed, 86, 87 SYN floods for, 284</span></p>
<p><span class="font53">destination-based forwarding, 343-346</span></p>
<p><span class="font53">destination port number, 260</span></p>
<p><span class="font53">destination port number field, 218</span></p>
<p><span class="font53">Deutsche Telecom, 410 device statistics, 456</span></p>
<p><span class="font53">DHCP. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Dynamic Host Configuration Protocol</span></p>
<p><span class="font53">DHCP ACK message, 374, 544 DHCP discover message, 372 DHCP offer message, 372-373 DHCP request message, 374, 543 DHT. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Distributed Hast Table Diffie-Hellman algorithm, 654 DIFS. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Distributed Inter-frame</span></p>
<p><span class="font53">Space</span></p>
<p><span class="font53">Digital Attack Map, 85 digital ethernet, 518 digital signatures, 658-661 digital subscriber line (DSL), 43-44, 93</span></p>
<p><span class="font53">digital subscriber line access multiplexer (DSLAM), 43-44</span></p>
<p><span class="font53">Dijkstra’s algorithm, 413, 420</span></p>
<p><span class="font53">in OSPF, 426 direct routing, 615 distance-vector algorithm</span></p>
<p><span class="font53">(DV algorithm), 418-425 decentralization, 420 link-cost changes and link failure,</span></p>
<p><span class="font53">422-424</span></p>
<p><span class="font53">LS compared with, 424-425 message complexity, 424-425 poisoned reverse, 424 robustness, 425 speed of convergence, 425 distant centralized database, 156 distributed applications, 35 distributed DoS (DDoS), 86</span></p>
<p><span class="font53">Distributed Hast Table (DHT), 173 Distributed Inter-frame Space</span></p>
<p><span class="font53">(DIFS), 580 distribution time, 168 DMZ. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> demilitarized zone DNS. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> domain name system DNS protocol, 545 DNS query message, 545</span></p>
<p><span class="font53">DNS reply message, 546 DNS resource record, 546 DOCSIS. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Data-Over-Cable</span></p>
<p><span class="font53">Service Interface Specifications DOCSIS 2.0, 45 domain names, 440</span></p>
<p><span class="font53">domain name system (DNS), 80, 153</span></p>
<p><span class="font53">additional section, 164 answer section, 164 and ARP, 544-545 authoritative servers, 157 authority section, 164 caching, 160</span></p>
<p><span class="font53">distant centralized database, 156 distributed, hierarchical database, 156-160</span></p>
<p><span class="font53">header section, 163 hierarchy, 157</span></p>
<p><span class="font53">interaction, 159</span></p>
<p><span class="font53">Internet presence and, 440-441 intra-domain routing, 545-546 IP-anycast in, 436-437 iterative queries, 160 local server, 158 maintenance, 156 messages, 163</span></p>
<p><span class="font53">operation of, 155-161 peer-to-peer file distribution, 166-173</span></p>
<p><span class="font53">question section, 163 records insertion, 164 recursive queries, 160 resource records (RRs), 161 root servers, 157 servers, 153</span></p>
<p><span class="font53">servers in 2020, 158 services provided by, 153-155 single point of failure, 156 top-level domain (TLD),</span></p>
<p><span class="font53">156, 157</span></p>
<p><span class="font53">traffic volume, 156</span></p>
<p><span class="font53">UDP usage by, 225 vulnerabilities, 165 dotted-decimal notation, 364 DPI. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> deep packet inspection drop, packet, 71 dropping</span></p>
<p><span class="font53">OpenFlow, 387 packets, strategies for, 352 drop-tail, 352</span></p>
<p><span class="font53">DSL. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> digital subscriber line DSLAM. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> digital subscriber line</span></p>
<p><span class="font53">access multiplexer duplicate ACKs, 238, 273 duplicate data packets, 240 duplicate packets, 236</span></p>
<p><span class="font53">DV algorithm. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> distance-vector algorithm</span></p>
<p><span class="font53">Dynamic Adaptive Streaming over HTTP (DASH), 174</span></p>
<p><span class="font53">Dynamic Host Configuration Protocol (DHCP), 371-374 address obtainment with, 371-374</span></p>
<p><span class="font53">messages, 372-373 mobile nodes and, 374 NAT and, 374</span></p>
<p><span class="font53">dynamic routing algorithms, 413</span></p>
<p><span class="font55" style="font-weight:bold;">E</span></p>
<p><span class="font53">EAP. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Extensible Authentication Protocol</span></p>
<p><span class="font53">eavesdropping, 640 e-Bay, 93 eBGP. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> external BGP EC2, 94</span></p>
<p><span class="font53">ECE. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Explicit Congestion Notification Echo</span></p>
<p><span class="font53">echo request, 453 ECN. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Explicit Congestion</span></p>
<p><span class="font53">Notification edge routers, 342 efficiency</span></p>
<p><span class="font53">ALOHA protocol, 497</span></p>
<p><span class="font53">CSMA/CD, 504</span></p>
<p><span class="font53">802.11. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> IEEE 802.11</span></p>
<p><span class="font53">EIGRP protocol, 426 elastic applications, 120 e-mail</span></p>
<p><span class="font53">components, 146</span></p>
<p><span class="font53">high-level view of, 147</span></p>
<p><span class="font53">in internet, 146</span></p>
<p><span class="font53">mail access protocols,</span></p>
<p><span class="font53">151-152</span></p>
<p><span class="font53">mail message formats, 151</span></p>
<p><span class="font53">PGP, 673-674 protocols, 152 secure, 670-673 SMTP, 80, 147-150 encapsulation, 82-84 Encapsulation Security Payload (ESP) protocol, 683</span></p>
<p><span class="font53">encrypted, 638 encryption</span></p>
<p><span class="font53">public key, 642, 648-654 symmetric key, 642-648 encryption algorithm, 641 end-end principle, 229 end-point authentication, 87-88, 639,</span></p>
<p><span class="font53">664-666</span></p>
<p><span class="font53">end systems, 32, 34, 39-41</span></p>
<p><span class="font53">delay in, 73</span></p>
<p><span class="font53">end-to-end argument, 393 end-to-end congestion control, 292 end-to-end connection, 57</span></p>
<p><span class="font53">end-to-end delay, 71-73 enhanced mobile broadband</span></p>
<p><span class="font53">(eMBB), 606 eNode-B, 595 entity body, 133 Equal Cost Multi Path</span></p>
<p><span class="font53">(ECMP), 539</span></p>
<p><span class="font53">error checking, UDP checksums and, 228-230</span></p>
<p><span class="font53">error-correction techniques, 482, 484, 485</span></p>
<p><span class="font53">error detection, 234</span></p>
<p><span class="font53">error-detection techniques, 482, 484, 485</span></p>
<p><span class="font53">checksumming methods, 488</span></p>
<p><span class="font53">cyclic redundancy check (CRC), 489-491</span></p>
<p><span class="font53">parity checks, 486-488</span></p>
<p><span class="font53">ESP. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Encapsulation Security Payload</span></p>
<p><span class="font53">EstimatedRTT, 266</span></p>
<p><span class="font53">Estrin, Deborah, 633</span></p>
<p><span class="font53">Ethane project, 449-450</span></p>
<p><span class="font53">Ethernet, 35, 46-47, 392</span></p>
<p><span class="font53">buffered distributors, 520</span></p>
<p><span class="font53">challenges, 514</span></p>
<p><span class="font53">development of, 91 frame, 543</span></p>
<p><span class="font53">frame structure, 516-518</span></p>
<p><span class="font53">gigabit, 520</span></p>
<p><span class="font53">installations, 515</span></p>
<p><span class="font53">MTU, 259</span></p>
<p><span class="font53">packet sniffing, 87 standards, 519 technologies, 518-521</span></p>
<p><span class="font53">event-based programming, 249</span></p>
<p><span class="font53">EWMA. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> exponential weighted moving average</span></p>
<p><span class="font53">Explicit Congestion Notification (ECN), 304-305</span></p>
<p><span class="font53">Explicit Congestion Notification Echo (ECE), 305</span></p>
<p><span class="font53">exponential weighted moving average</span></p>
<p><span class="font53">(EWMA), 266</span></p>
<p><span class="font53">extended FSM, 248</span></p>
<p><span class="font53">extensible authentication protocol (EAP), 693-694</span></p>
<p><span class="font53">external BGP (eBGP), 431</span></p>
<p><span class="font55" style="font-weight:bold;">F</span></p>
<p><span class="font53">Facebook, 666</span></p>
<p><span class="font53">Facetime, video conferencing, 111 fading, 569 fairness</span></p>
<p><span class="font53">of AIMD, 306-309</span></p>
<p><span class="font53">parallel TCP connections and, 309</span></p>
<p><span class="font53">TCP and, 306-309</span></p>
<p><span class="font53">UDP and, 308-309</span></p>
<p><span class="font53">fast recovery, 298-300</span></p>
<p><span class="font53">fast retransmit, 273-275</span></p>
<p><span class="font53">FCFS. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> first-come-first-served</span></p>
<p><span class="font53">FDM. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> frequency-division multiplexing</span></p>
<p><span class="font53">FEC. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> forward error correction</span></p>
<p><span class="font53">Feynman, Richard, 332</span></p>
<p><span class="font53">FHSS. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> frequency-hopping spread spectrum</span></p>
<p><span class="font53">fiber optics, 93</span></p>
<p><span class="font53">in cable systems, 44-45</span></p>
<p><span class="font53">physical media, 50</span></p>
<p><span class="font53">fiber to the home (FTTH), 45-46, 93</span></p>
<p><span class="font53">FIFO. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> first-in-first-out</span></p>
<p><span class="font53">5G, 48</span></p>
<p><span class="font53">5G cellular networks, 46</span></p>
<p><span class="font53">5G fixed wireless, 46 filtering, 521</span></p>
<p><span class="font53">link-layer switches, 521-522 filters</span></p>
<p><span class="font53">stateful, 698</span></p>
<p><span class="font53">traditional packet, 698</span></p>
<p><span class="font53">FIN bit, 261</span></p>
<p><span class="font53">finite-state machine (FSM), 232</span></p>
<p><span class="font53">for data transfer over channel with bit errors, 234-240</span></p>
<p><span class="font53">for data transfer over lossy channel with bit errors, 240-241</span></p>
<p><span class="font53">for data transfer over perfectly reliable channel, 232-233</span></p>
<p><span class="font53">extended, 248</span></p>
<p><span class="font53">for GBN protocol, 246-248</span></p>
<p><span class="font53">TCP congestion control, 297, 298 firewalls, 377, 383</span></p>
<p><span class="font53">application gateways, 698 stateful filters, 698</span></p>
<p><span class="font53">traditional packet filters, 698 first-come-first-served (FCFS), 355 first-in-first-out (FIFO), 355-356 5G cellular networks, 605</span></p>
<p><span class="font53">core network, 607-608</span></p>
<p><span class="font53">eMBB, 606</span></p>
<p><span class="font53">FR2 frequencies, 606</span></p>
<p><span class="font53">millimeter wave frequencies, 606 and millimeter wave frequencies,</span></p>
<p><span class="font53">606-607</span></p>
<p><span class="font53">mMTC, 606 standards, 606 URLLC, 606</span></p>
<p><span class="font53">5G Core network, 607</span></p>
<p><span class="font53">flag days, 381</span></p>
<p><span class="font53">flag field, 260</span></p>
<p><span class="font53">flow, 378</span></p>
<p><span class="font53">flow-based forwarding, 441-442 flow-control service, 276 flow control, TCP, 276-278 flow table, 384</span></p>
<p><span class="font53">match-plus-action, 449 SDN, 444</span></p>
<p><span class="font53">wildcards in, 386</span></p>
<p><span class="font53">forward error correction</span></p>
<p><span class="font53">(FEC), 488</span></p>
<p><span class="font53">forwarding, 60, 334, 341, 521 to broadcast, 387 destination-based, 343-346 flow-based, 441-442 generalized, 343, 383-390 link-layer switches, 521-522</span></p>
<p><span class="font53">longest prefix matching rule, 345, 368</span></p>
<p><span class="font53">OpenFlow, 387</span></p>
<p><span class="font53">packets, 336</span></p>
<p><span class="font53">SDN, 441-442</span></p>
<p><span class="font53">forwarding plane, 342-343</span></p>
<p><span class="font53">forwarding tables, 55-56, 336, 337 in input processing, 345-346 line cards, 345</span></p>
<p><span class="font53">in LS algorithm, 415-416 match-plus-action, 384 prefixes, 345 routers, 336, 337</span></p>
<p><span class="font53">in SDN, 342, 344</span></p>
<p><span class="font53">4G LTE cellular networks authentication, 596 base station, 594-595 cell location tracking, 597 elements of, 595 functions, 597</span></p>
<p><span class="font53">home subscriber server (HSS), 595 mobile device, 594</span></p>
<p><span class="font53">mobility management entity</span></p>
<p><span class="font53">(MME), 596</span></p>
<p><span class="font53">network attachment, 602-603 network of networks, 604-605 packet data network gateway, 595 path setup, 596</span></p>
<p><span class="font53">power management, 603-604 protocols stacks, 600-601 radio access network, 601-602 serving gateway, 595</span></p>
<p><span class="font53">4G, 48</span></p>
<p><span class="font53">fragmentation, 380 frames, 82</span></p>
<p><span class="font53">ACK, 582 beacon, 576 CTS, 581 Ethernet, 543 IEEE 802.11 wireless LAN, 583-586</span></p>
<p><span class="font53">link-layer, 83 time, 494 VLANs, 530 framing, 482 frequency-division multiplexing</span></p>
<p><span class="font53">(FDM), 58-59, 493-494 frequency-hopping spread spectrum</span></p>
<p><span class="font53">(FHSS), 591</span></p>
<p><span class="font53">FSM. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> finite-state machine</span></p>
<p><span class="font53">FTP protocol, 80</span></p>
<p><span class="font53">FTTH. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> fiber to the home full-duplex service, 257 fully connected topology, 541</span></p>
<p><span class="font55" style="font-weight:bold;">G</span></p>
<p><span class="font53">gateway router, 430</span></p>
<p><span class="font53">gateways, 343</span></p>
<p><span class="font53">GBN protocol. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Go-Back-N (GBN) protocol</span></p>
<p><span class="font53">GE Information Services, 90 generalized forwarding, 343, 383-390</span></p>
<p><span class="font53">action, 386-387</span></p>
<p><span class="font53">match, 385-386</span></p>
<p><span class="font53">match-plus-action, 387-390 generator, 489</span></p>
<p><span class="font53">geostationary satellites, 51 4G/5G cellular networks authentication and key agreement,</span></p>
<p><span class="font53">694-697</span></p>
<p><span class="font53">security, 689</span></p>
<p><span class="font53">Gigabit Ethernet, 520</span></p>
<p><span class="font53">Github, 165</span></p>
<p><span class="font53">Global Positioning System</span></p>
<p><span class="font53">(GPS), 588</span></p>
<p><span class="font53">Go-Back-N (GBN) protocol, 245-250</span></p>
<p><span class="font53">events, 248</span></p>
<p><span class="font53">TCP as, 276</span></p>
<p><span class="font53">Google, 41, 93, 306, 310</span></p>
<p><span class="font53">CDN infrastructure, 177 private network, 64, 94, 410</span></p>
<p><span class="font53">SDN use by, 410, 447 video streaming, 173</span></p>
<p><span class="font53">Google Chrome browser</span></p>
<p><span class="font53">QUIC protocol, 226</span></p>
<p><span class="font53">graph, 410</span></p>
<p><span class="font53">graph algorithms, 413</span></p>
<p><span class="font53">Greenberg, Albert, 558</span></p>
<p><span class="font53">guaranteed delivery, 339 guaranteed delivery with bounded</span></p>
<p><span class="font53">delay, 339</span></p>
<p><span class="font53">guaranteed minimal bandwidth, 339-340</span></p>
<p><span class="font53">guided media, 49</span></p>
<p><span class="font55" style="font-weight:bold;">H</span></p>
<p><span class="font53">Handley, Mark, 633</span></p>
<p><span class="font53">handoff, 564</span></p>
<p><span class="font53">handover, 564, 609</span></p>
<p><span class="font53">handover management, 620 handshaking</span></p>
<p><span class="font53">TCP three-way, 258, 280-281</span></p>
<p><span class="font53">TLS, 676</span></p>
<p><span class="font53">hash functions</span></p>
<p><span class="font53">checksum, 655-656 cryptographic, 655-656 digital signatures using, 660 MD5, 656</span></p>
<p><span class="font53">SHA-1, 656</span></p>
<p><span class="font53">header length field, 260</span></p>
<p><span class="font53">header lines, 131, 133</span></p>
<p><span class="font53">headers, 362-363</span></p>
<p><span class="font53">AH protocol, 683</span></p>
<p><span class="font53">DNS, 163</span></p>
<p><span class="font53">IPv4, 361-362</span></p>
<p><span class="font53">head-of-the-line blocking</span></p>
<p><span class="font53">(HOL blocking), 144, 350</span></p>
<p><span class="font53">HELLO message, 428</span></p>
<p><span class="font53">Heterogeneous links, 524 HFC. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> hybrid fiber coax hidden terminal problem, 569 hierarchical architectures,</span></p>
<p><span class="font53">537-539</span></p>
<p><span class="font53">within ASs, 428-429</span></p>
<p><span class="font53">high-speed wireless Internet</span></p>
<p><span class="font53">access, 93</span></p>
<p><span class="font53">HMAC, 658</span></p>
<p><span class="font53">HOL blocking. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> head-of-the-line blocking</span></p>
<p><span class="font53">home agent</span></p>
<p><span class="font53">in mobile IP, 623</span></p>
<p><span class="font53">registration with, 624</span></p>
<p><span class="font53">home network, 604, 610</span></p>
<p><span class="font53">Home Subscriber Server (HSS), 595, 609</span></p>
<p><span class="font53">hop limit, 380</span></p>
<p><span class="font53">Host</span></p>
<p><span class="font53">aliasing, 154</span></p>
<p><span class="font53">host addresses, obtaining with DHCP, 371-374</span></p>
<p><span class="font53">host aliasing, 154</span></p>
<p><span class="font53">hostname, 153</span></p>
<p><span class="font53">hosts, 32, 40, 41</span></p>
<p><span class="font53">hot potato routing, 434-435 hourglass, Internet Protocol, 392-393 HTML, development of, 92</span></p>
<p><span class="font53">HTTP</span></p>
<p><span class="font53">manifest file, 175</span></p>
<p><span class="font53">TCP and, 546-547</span></p>
<p><span class="font53">HTTP GET message, 546</span></p>
<p><span class="font53">HTTP request, 544</span></p>
<p><span class="font53">HTTP response, 547</span></p>
<p><span class="font53">hub, 515</span></p>
<p><span class="font53">hybrid fiber coax (HFC),</span></p>
<p><span class="font53">44-45</span></p>
<p><span class="font53">HyperText Transfer Protocol (HTTP), 80, 92, 126</span></p>
<p><span class="font53">conditional GET, 142-143</span></p>
<p><span class="font53">HTTP/2, 143-144</span></p>
<p><span class="font53">HTTP/3, 146</span></p>
<p><span class="font53">HTTP/2 framing, 144-145</span></p>
<p><span class="font53">ICMP and, 453</span></p>
<p><span class="font53">message format, 131-135</span></p>
<p><span class="font53">with non-persistent connections, 128-130</span></p>
<p><span class="font53">overview of, 126-128</span></p>
<p><span class="font53">with persistent connections, 130-131</span></p>
<p><span class="font53">ports, 223-224</span></p>
<p><span class="font53">Quick UDP Internet Connections, 311-312</span></p>
<p><span class="font53">request message, 131-133</span></p>
<p><span class="font53">request-response behavior, 127 response message, 133-135</span></p>
<p><span class="font53">response message</span></p>
<p><span class="font53">prioritization, 145</span></p>
<p><span class="font53">server, manifest file, 175</span></p>
<p><span class="font53">server pushing, 145</span></p>
<p><span class="font53">stateless protocol, 128</span></p>
<p><span class="font53">user-server interaction, 135-138 web and, 125-126</span></p>
<p><span class="font53">web caching, 138-142</span></p>
<p><span class="font55" style="font-weight:bold;">I</span></p>
<p><span class="font53">LANA, 378</span></p>
<p><span class="font53">iBGP. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> internal BGP</span></p>
<p><span class="font53">IBM, 90</span></p>
<p><span class="font53">ICANN. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Internet Corporation</span></p>
<p><span class="font53">for Assigned Names and Numbers</span></p>
<p><span class="font53">ICMP. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Internet Control Message Protocol</span></p>
<p><span class="font53">IEEE 802.11ac, 573</span></p>
<p><span class="font53">IEEE 802.11ax, 573</span></p>
<p><span class="font53">IEEE 802.11b, 573</span></p>
<p><span class="font53">IEEE 802.11g, 573</span></p>
<p><span class="font53">IEEE 802 LAN/MAN Standards</span></p>
<p><span class="font53">Committee, 35</span></p>
<p><span class="font53">IEEE 802.11n, 573</span></p>
<p><span class="font53">IEEE 802.11 wireless LAN, 47, 573 address fields, 584-586 advanced features in, 589-590 architecture, 574-578 channels and association, 575-578 clear to send (CTS) control frame, 581 collision avoidance, 582 duration, 586 frame control fields, 586 frames, 583-586 hidden terminals, dealing with, 581-583</span></p>
<p><span class="font53">link-layer acknowledgments, 579 MAC protocol, 578-583 mobility in same IP subnet, 586-588</span></p>
<p><span class="font53">payload and CRC fields, 583-584 personal area networks, 590-592 as point-to-point link, 583 power management, 590 public access, 93 rate adaptation, 589-590</span></p>
<p><span class="font53">request to send (RTS) control, 581 sequence number, 586 standards, 573</span></p>
<p><span class="font53">IETF. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Internet Engineering Task Force</span></p>
<p><span class="font53">IKE. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Internet Key Exchange IKE SA, 688</span></p>
<p><span class="font53">IMAP. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Internet Mail Access Protocol</span></p>
<p><span class="font53">indirect routing approach, 613 information propagation, 331 infrastructure mode, 564 infrastructure wireless LANs, 574 Initialization Vector (IV), 647 in-order packet delivery, 339 input port, 342 input port processing, 344-346 forwarding tables in, 345-346 input queuing, 350 insertion, message content, 640 instantaneous throughput, 73 Intel Ethernet, 518 intelligent software agents, 109 inter-area routing, 428-429 inter-autonomous system routing protocol, 429, 439 interconnection networks switching via, 348-349 inter-domain protocol, 546 interface, 364</span></p>
<p><span class="font53">SDN controller, 444-445 socket, 36</span></p>
<p><span class="font53">internal BGP (iBGP), 431-432 internal router, 430</span></p>
<p><span class="font53">International Mobile Subscriber</span></p>
<p><span class="font53">Identity (IMSI), 594 International Telecommunication</span></p>
<p><span class="font53">Union (ITU), 663 Internet. </span><span class="font53" style="font-style:italic;">See also</span><span class="font53"> access networks</span></p>
<p><span class="font53">architectural principles of, 391 best-effort service in, 340 broadband, 93 Cerf on, 405-406 commercialization of, 92 components of, 32-35</span></p>
<p><span class="font53">DNS and presence on, 440-441 enterprise access, 46-47 history of, 88-94 home access, 43-46 network core, 52 network edges, 39-41 network layer, 340 obtaining presence on, 440-441 registries, 370</span></p>
<p><span class="font53">router self-synchronization, 417 routing algorithms used in, 413 as service infrastructure, 35-37 transport layer, 215-217</span></p>
<p><span class="font53">Internet applications, transport protocols used by, 227</span></p>
<p><span class="font53">Internet checksum, 488</span></p>
<p><span class="font53">Internet-connected smartphones, 93 Internet Control Message Protocol</span></p>
<p><span class="font53">(ICMP), 453-455, 461</span></p>
<p><span class="font53">IPv6 and, 455 message types, 454</span></p>
<p><span class="font53">Internet Corporation for Assigned Names and Numbers (ICANN), 164, 370, 426</span></p>
<p><span class="font53">Internet Engineering Task Force (IETF), 35, 377</span></p>
<p><span class="font53">Internet Exchange Points (IXPs), 63-64</span></p>
<p><span class="font53">internet key exchange (IKE) protocol, 688</span></p>
<p><span class="font53">Internet Mail Access Protocol (IMAP), 152</span></p>
<p><span class="font53">Internet Protocol (IP), 35, 81, 405</span></p>
<p><span class="font53">ICMP and, 453 mobile, 622-624 service model, 216 stack for, 80 total annual traffic using, 34 transition to, 91</span></p>
<p><span class="font53">Internet Protocol Packet eXchange (IPX) Network, 605</span></p>
<p><span class="font53">Internet registrars, 440</span></p>
<p><span class="font53">Internet Service Providers</span></p>
<p><span class="font53">(ISPs), 34-35 access, 62 backbone, 438 AS configurations, 426 global transit, 62 multi-home, 63</span></p>
<p><span class="font53">multi-homed access, 438 peering agreements among,</span></p>
<p><span class="font53">438-439</span></p>
<p><span class="font53">PoP, 63 routing among, 429-441</span></p>
<p><span class="font53">Internet standards, 35</span></p>
<p><span class="font53">Internet Systems Consortium, 374</span></p>
<p><span class="font53">Internet telephony, 123 internetworking, 89-91 intra-autonomous system routing, 425-429, 439</span></p>
<p><span class="font53">SDN in, 450</span></p>
<p><span class="font53">intruder, security attacks, 640 intrusion detection system (IDS), 377, 639, 705-708</span></p>
<p><span class="font53">intrusion prevention systems (IPSs), 377, 706</span></p>
<p><span class="font53">Intserv, 340</span></p>
<p><span class="font53">IP. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Internet Protocol</span></p>
<p><span class="font53">IP addresses, 92, 118, 153, 363-374, 378</span></p>
<p><span class="font53">broadcast, 370, 372-373 classes of, 367-368</span></p>
<p><span class="font53">DHCP, 371-374</span></p>
<p><span class="font53">Internet presence and, 440</span></p>
<p><span class="font53">IPv4, 363-374</span></p>
<p><span class="font53">IPv6, 378</span></p>
<p><span class="font53">NAT and, 374-376</span></p>
<p><span class="font53">obtaining blocks of, 370-371 temporary, 371</span></p>
<p><span class="font53">IP-anycast, 436-437</span></p>
<p><span class="font53">IP datagram, 543</span></p>
<p><span class="font53">IP forwarding table, 544</span></p>
<p><span class="font53">IP fragmentation, 380</span></p>
<p><span class="font53">IPv6, 380</span></p>
<p><span class="font53">iPhones, 48</span></p>
<p><span class="font53">IP hourglass, 392-393</span></p>
<p><span class="font53">IPsec, 681-683</span></p>
<p><span class="font53">IPsec datagram, 685-687</span></p>
<p><span class="font53">IP spoofing, 87-88</span></p>
<p><span class="font53">IPSs. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> intrusion prevention systems</span></p>
<p><span class="font53">IP traffic, volume of, 34</span></p>
<p><span class="font53">IPv4</span></p>
<p><span class="font53">addressing, 363-374 datagram format, 361-363 transitioning to IPv6 from, 381-383 IPv6, 377 adoption of, 381-382 datagram format, 378-380 ICMP, 455 transitioning to, 381-383 tunneling, 381-382</span></p>
<p><span class="font53">IPX, 420</span></p>
<p><span class="font53">IS-IS, 426, 447, 546</span></p>
<p><span class="font53">ISO IDRP, 420</span></p>
<p><span class="font53">ISPs. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Internet Service Providers iterative queries, 160 ITU. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> International</span></p>
<p><span class="font53">Telecommunication Union IV. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Initialization Vector IXPs. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Internet Exchange Points</span></p>
<p><span class="font55" style="font-weight:bold;">J</span></p>
<p><span class="font53">jabbering adapters, 524 Jacobson, Van, 331-332 Juniper MX2020, 342</span></p>
<p><span class="font55" style="font-weight:bold;">K</span></p>
<p><span class="font53">Kahn, Bob, 405, 406</span></p>
<p><span class="font53">Kahn, Robert</span></p>
<p><span class="font53">ARPAnet development and, 89-91 TCP/IP creation and, 258</span></p>
<p><span class="font53">Karels, Mike, 331 key, 641 key agreement</span></p>
<p><span class="font53">4G/5G cellular networks, 694-697 Kleinrock, Leonard, 89, 108-110, 405 known-plaintext attack, 643</span></p>
<p><span class="font55" style="font-weight:bold;">L</span></p>
<p><span class="font53">label-switched router, 533</span></p>
<p><span class="font53">Lampson, Butler, 386 LAN. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> local area network LAN address, 508 layered architectures, 77-82 encapsulation, 82-84</span></p>
<p><span class="font53">layers, 79</span></p>
<p><span class="font53">layer 4 switching, 343</span></p>
<p><span class="font53">layer 5 switching, 343</span></p>
<p><span class="font53">least-cost path, 412</span></p>
<p><span class="font53">Bellman-Ford equation for, 418-419</span></p>
<p><span class="font53">in LS algorithm, 414-416</span></p>
<p><span class="font53">LEO satellites. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> low-earth orbiting satellites</span></p>
<p><span class="font53">Level 3 Communications, 62</span></p>
<p><span class="font53">Licklider, J. C. R., 89</span></p>
<p><span class="font53">line cards</span></p>
<p><span class="font53">forwarding tables in, 345</span></p>
<p><span class="font53">input and output ports, 342</span></p>
<p><span class="font53">processing on, 348</span></p>
<p><span class="font53">line speeds, queuing and,</span></p>
<p><span class="font53">349-350</span></p>
<p><span class="font53">link access, 482</span></p>
<p><span class="font53">link capacity</span></p>
<p><span class="font53">buffer sizing and, 353</span></p>
<p><span class="font53">network congestion and, 287</span></p>
<p><span class="font53">link failure, 422-424</span></p>
<p><span class="font53">link layer, 81-82</span></p>
<p><span class="font53">broadcast, 482</span></p>
<p><span class="font53">cable internet access, 505-507</span></p>
<p><span class="font53">implementation locations,</span></p>
<p><span class="font53">483-484</span></p>
<p><span class="font53">network as, 531-534</span></p>
<p><span class="font53">network types, 491-493</span></p>
<p><span class="font53">services provided by, 482-483</span></p>
<p><span class="font53">wireless host </span><span class="font53" style="font-style:italic;">vs.</span><span class="font53"> server, 481</span></p>
<p><span class="font53">link-layer acknowledgment</span></p>
<p><span class="font53">scheme, 579</span></p>
<p><span class="font53">link-layer frame, 83, 480</span></p>
<p><span class="font53">link-layer switches, 34, 53, 341</span></p>
<p><span class="font53">destination address lookup</span></p>
<p><span class="font53">in, 346</span></p>
<p><span class="font53">filtering, 521-522</span></p>
<p><span class="font53">forwarding, 521-522</span></p>
<p><span class="font53">properties of, 524-525 </span><span class="font53" style="font-style:italic;">vs.</span><span class="font53"> routers, 525-527 self-learning, 523-524</span></p>
<p><span class="font53">links, 480</span></p>
<p><span class="font53">link-state algorithms (LS algorithms), 412-417, 420</span></p>
<p><span class="font53">centralized routing algorithm, 414 computational complexity</span></p>
<p><span class="font53">of, 416</span></p>
<p><span class="font53">DV compared with, 424-425 forwarding tables, 415-416 message complexity, 424-425 oscillations in, 416-417 OSPF, 426 robustness, 425 speed of convergence, 425 steps of, 414-415</span></p>
<p><span class="font53">link-state broadcast, 413 erroneous, 425</span></p>
<p><span class="font53">link virtualization, 531 dialup modem connection, 531 multiprotocol label switching</span></p>
<p><span class="font53">(MPLS), 532-534 link weights, in OSPF, 427 Linux, Snort, 708 load balancing, 536-537 load balancing packets, 383 load distribution, 154 load-insensitive algorithms, 413 load-sensitive algorithm, 413 local area network (LAN), 46-47.</span></p>
<p><span class="font53" style="font-style:italic;">See also</span><span class="font53"> virtual local area networks; wireless LANs local area networks</span></p>
<p><span class="font53">switched, 507-531 local breakout, 614, 620 Local DNS Server (LDNS), 158, 178 local preference, 435 logical communication, 212 logically centralized control,</span></p>
<p><span class="font53">409-410</span></p>
<p><span class="font53">logically centralized routing controllers, 338</span></p>
<p><span class="font53">longest prefix matching rule, 345, 368 Long-Term Evolution (LTE), 48 lookup algorithms, 346</span></p>
<p><span class="font53">loss-tolerant applications, 119 lossy channels, 238-241 lost, packet, 71</span></p>
<p><span class="font53">lost segments, 295</span></p>
<p><span class="font53">low-earth orbiting (LEO) satellites, 51 LS algorithms. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> link-state</span></p>
<p><span class="font53">algorithms</span></p>
<p><span class="font53">LTE. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Long-Term Evolution</span></p>
<p><span class="font55" style="font-weight:bold;">M</span></p>
<p><span class="font53">MAC. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> message authentication code</span></p>
<p><span class="font53">MAC addresses, 508 and ARP, 508-513 subnets, 513-514</span></p>
<p><span class="font53">mail servers, 146</span></p>
<p><span class="font53">aliasing, 154 malware, 84-85</span></p>
<p><span class="font53">self-replicating, 85 managed device, 456 managed objects, 461 Management Information Base (MIB), 458-462</span></p>
<p><span class="font53">managing server, 456</span></p>
<p><span class="font53">MANETs. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> mobile ad hoc networks</span></p>
<p><span class="font53">manifest file, HTTP, 175 massive machine type communica</span></p>
<p><span class="font53">tions (mMTC), 606 match-plus-action, 346</span></p>
<p><span class="font53">forwarding table, 384 in generalized forwarding,</span></p>
<p><span class="font53">383-384</span></p>
<p><span class="font53">OpenFlow, 387-390 match-plus-action flow tables, 449 maximum segment size (MSS), 259 negotiating, 260</span></p>
<p><span class="font53">maximum transmission unit (MTU), 259, 465-466</span></p>
<p><span class="font53">MD5 authentication, 428</span></p>
<p><span class="font53">MD5 hash algorithm, 656</span></p>
<p><span class="font53">medium access control (MAC), 601 memory</span></p>
<p><span class="font53">access times, 346</span></p>
<p><span class="font53">bandwidth of, 347 switching via, 347-348</span></p>
<p><span class="font53">message authentication code (MAC), 656-658</span></p>
<p><span class="font53">broadcast address, 510 digital signatures, 658-661</span></p>
<p><span class="font53">message integrity, 638-639, 654-664, 670</span></p>
<p><span class="font53">message queue, 147 messages, 53, 80</span></p>
<p><span class="font53">application-layer, 83 complexity in LS algorithms, 424-425</span></p>
<p><span class="font53">DHCP, 372-373</span></p>
<p><span class="font53">HELLO, 428</span></p>
<p><span class="font53">OpenFlow, 449</span></p>
<p><span class="font53">port-status, 449</span></p>
<p><span class="font53">source quench, 453-454</span></p>
<p><span class="font53">Metcalfe,Bob, 515, 518</span></p>
<p><span class="font53">MIB. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Management</span></p>
<p><span class="font53">Information Base</span></p>
<p><span class="font53">Microsoft, 93</span></p>
<p><span class="font53">private network, 94</span></p>
<p><span class="font53">Microsoft Research, 410</span></p>
<p><span class="font53">Microsoft’s Azure, 94 middleboxes, 340, 376, 390-391 millimeter wave frequencies, 606 Minitel, 92</span></p>
<p><span class="font53">MME. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Mobility Management</span></p>
<p><span class="font53">Entity mobile ad hoc networks</span></p>
<p><span class="font53">(MANETs), 565 mobile devices, 593, 594 mobile-device-to-PDN-gateway data path configuration, 603</span></p>
<p><span class="font53">mobile nodes, DHCP and, 374 Mobility management</span></p>
<p><span class="font53">device mobility, 608-609</span></p>
<p><span class="font53">direct and indirect routing to/from a mobile device,</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">610- 611</span></p></li></ul>
<p><span class="font53">direct routing to mobile device, 615-616</span></p>
<p><span class="font53">in 4G/5G networks, 617-622 home networks and roaming on visited networks, 609-610 indirect routing to mobile device, 613-615</span></p>
<p><span class="font53">IP address infrastructure,</span></p>
<ul style="list-style:none;"><li>
<p><span class="font53">611- 613</span></p></li></ul>
<p><span class="font53">mobile IP, 622-624</span></p>
<p><span class="font53">in practice, 617-624</span></p>
<p><span class="font53">wireless and, 624-626</span></p>
<p><span class="font53">mobility management entity (MME), 596, 603</span></p>
<p><span class="font53">modification, message content, 640 modify-field action, 387 monoalphabetic cipher, 642</span></p>
<p><span class="font53">Mosaic Communications, 92 MOSPF. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> multicast OSPF</span></p>
<p><span class="font53">MP3, 75</span></p>
<p><span class="font53">multicast OSPF (MOSPF), 428 multicast routing in OSPF, 428 multi-home, 63</span></p>
<p><span class="font53">multi-homed access ISP, 438</span></p>
<p><span class="font53">Multi-hop, infrastructure-based networks, 565</span></p>
<p><span class="font53">Multi-hop, infrastructure-less networks, 565</span></p>
<p><span class="font53">multihop path, 289-291</span></p>
<p><span class="font53">multimedia applications</span></p>
<p><span class="font53">TCP use by, 226</span></p>
<p><span class="font53">UDP use by, 226-227</span></p>
<p><span class="font53">multipath propagation, 566 multiple access problem, 491 multiple access protocols, 492 multiple same-cost paths, in</span></p>
<p><span class="font53">OSPF, 428 multiplexing, 217-224 connectionless, 219-220 connection-oriented, 220-223 transport-layer, 216</span></p>
<p><span class="font53">multiprotocol label switching (MPLS) networks, 531-534</span></p>
<p><span class="font53">mutual authentication, 603, 689</span></p>
<p><span class="font55" style="font-weight:bold;">N</span></p>
<p><span class="font53">NAK (negative acknowledgments), 234-238</span></p>
<p><span class="font53">corrupted, 236 narrow waist, 392, 393 NASA, 406</span></p>
<p><span class="font53">NAT. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> network address translation; network address translator</span></p>
<p><span class="font53">National Physical Laboratory, 89 NAT translation table, 376 NAT traversal, 376</span></p>
<p><span class="font53">NCP. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> network-control protocol NCS. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> network control server negative acknowledgments, 234 neighbor, 411 neighboring peers, 171 Nelson, Ted, 92</span></p>
<p><span class="font53">Netflix</span></p>
<p><span class="font53">CDN and, 180-182 components, 181 DNS vulnerabilities, 165 video streaming, 173, 180</span></p>
<p><span class="font53">net neutrality, 357-358</span></p>
<p><span class="font53">Netscape Communications, 92-93 network adapter, 483, 484</span></p>
<p><span class="font53">network address translation (NAT), 374-376, 383, 390 network address translator</span></p>
<p><span class="font53">(NAT), 346 network applications principles,</span></p>
<p><span class="font53">112-125</span></p>
<p><span class="font53">network-assisted congestion control, 292, 293</span></p>
<p><span class="font53">network attachment, 602</span></p>
<p><span class="font53">Network Configuration Protocol</span></p>
<p><span class="font53">(NETCONF), 458, 462-466 managed network devices, 462 MTU, 465-466 operations, 464 session, 463</span></p>
<p><span class="font53">XML format, 464-465 network control functions, in</span></p>
<p><span class="font53">SDN, 442 network-control protocol (NCP),</span></p>
<p><span class="font53">89, 91</span></p>
<p><span class="font53">network control server (NCS), 447 network core, 52</span></p>
<p><span class="font53">circuit switching, 57-61 network of networks, 61-64 packet switching, 53-56,</span></p>
<p><span class="font53">60-61</span></p>
<p><span class="font53">network functions virtualization</span></p>
<p><span class="font53">(NFV), 391, 450</span></p>
<p><span class="font53">Network Information Base</span></p>
<p><span class="font53">(NIB) , 447 network infrastructure, 565 network interface controller</span></p>
<p><span class="font53">(NIC) , 483</span></p>
<p><span class="font53">network layer, 81. </span><span class="font53" style="font-style:italic;">See also</span><span class="font53"> control plane; data plane</span></p>
<p><span class="font53">best-effort service, 340 forwarding and routing,</span></p>
<p><span class="font53">334-339 security, 340 services, 339-340 transport layer relationship to,</span></p>
<p><span class="font53">212-215</span></p>
<p><span class="font53">network-layer datagram, 83</span></p>
<p><span class="font53">network-layer security</span></p>
<p><span class="font53">AH protocols, 683 ESP protocols, 683 internet key exchange (IKE) protocol, 688</span></p>
<p><span class="font53">IPsec, 681-683</span></p>
<p><span class="font53">IPsec datagram, 685-687 security associations, 683-685 virtual private networks (VPNs), 681-683</span></p>
<p><span class="font53">network management, 455-466 defining, 455 framework for, 456-458</span></p>
<p><span class="font53">network management agent, 456 network management protocol, 457 network managers, 456 network of networks, 61-64, 91 network operations center (NOC), 456 network prefix, 366 network protocols, 38-39 networks. </span><span class="font53" style="font-style:italic;">See also</span><span class="font53"> access networks;</span></p>
<p><span class="font53">cellular networks; Internet; local area network; wireless networks attacks against, 84-88 cellular, 48</span></p>
<p><span class="font53">content provider, 64 edges, 39-41 packet-radio, 89 packet-satellite, 89 private, 64, 94, 374, 410 programmable, 442 proliferation of, 91-92 proprietary, 89-91 provider, 438 throughput in, 73-76 network security, 638-640 network service model, 339-340 NEXT-HOP, 433-435 NFV. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> network functions</span></p>
<p><span class="font53">virtualization</span></p>
<p><span class="font53">NIB. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Network Information Base</span></p>
<p><span class="font53">NIST, 381</span></p>
<p><span class="font53">nmap, 222, 285</span></p>
<p><span class="font53">NOC. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> network operations center nodal delay, 66 nodal processing delay, 65 node, 480 non-blocking switches, 348 nonce, 668 non-persistent connections, 128 non-preemptive priority queuing, 357 Novell IPX, 420</span></p>
<p><span class="font53">NOX controller, 446, 450</span></p>
<p><span class="font53">NSFNET, 91, 92 nslookup program, 164 NTT, 62</span></p>
<p><span class="font55" style="font-weight:bold;">O</span></p>
<p><span class="font53">OC. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Optical Carrier standard ODL’s Basic Network Functions, 450 OFA. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Open Flow Agent OFC. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Open Flow Controller OFDM. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> orthogonal frequency division multiplexing</span></p>
<p><span class="font53">offered load, 288</span></p>
<p><span class="font53">OLT. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> optical line terminator one-bit even parity, 486 ONIX SDN controller, 447 ONOS, 446, 450, 452-453 ONT. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> optical network terminator</span></p>
<p><span class="font53">OpenDaylight, 446, 450-451 OpenDaylight controller, 451 OpenDaylight Lithium, 450 OpenFlow, 444, 446-449 action, 387 flow table, 384 match, 385-386 match-plus-action, 387-390</span></p>
<p><span class="font53">Open Flow Agent (OFA), 447 Open Flow Controller</span></p>
<p><span class="font53">(OFC), 447</span></p>
<p><span class="font53">Open Shortest Path First (OSPF), 407, 413, 426-429, 546 authentication in, 428 broadcast in, 427-428 Dijkstra’s algorithm, 426 link weights, 427 multicast, 428 security and, 428 subnets, 426</span></p>
<p><span class="font53">operational data, 456</span></p>
<p><span class="font53">operational security, 639</span></p>
<p><span class="font53">IDSs, 377</span></p>
<p><span class="font53">Optical Carrier standard (OC), 50 optical line terminator (OLT), 46 optical network terminator (ONT), 46 options field, 260</span></p>
<p><span class="font53">orthogonal frequency division multiplexing (OFDM), 601</span></p>
<p><span class="font53">OSPF. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Open Shortest Path First out-of-order packets, 249 output buffer, 54 output port, 342</span></p>
<p><span class="font53">forwarding to, 346</span></p>
<p><span class="font53">output port processing, 349 output queue, 54</span></p>
<p><span class="font53">output queuing, 351-353 outside-AS destinations, 434 OVSDB, 451</span></p>
<p><span class="font55" style="font-weight:bold;">P</span></p>
<p><span class="font53">packet data convergence, 600</span></p>
<p><span class="font53">Packet Data Network Gateway</span></p>
<p><span class="font53">(P-GW), 595 packet-dropping strategies, 352 packet filtering, 699</span></p>
<p><span class="font53">packet header overhead, 226 packet headers</span></p>
<p><span class="font53">routing and, 336, 337 packet loss, 55, 71, 349 packet-marking strategies, 352 packet-radio networks, 89 packets, 34, 53</span></p>
<p><span class="font53">choke, 292</span></p>
<p><span class="font53">control, 342</span></p>
<p><span class="font53">deep inspection of, 377, 390 duplicate, 236</span></p>
<p><span class="font53">duplicate data, 240</span></p>
<p><span class="font53">forwarding, 336</span></p>
<p><span class="font53">in-order delivery of, 339 out-of-order, 249</span></p>
<p><span class="font53">packet-satellite networks, 89</span></p>
<p><span class="font53">packet scheduler, 353</span></p>
<p><span class="font53">packet scheduling</span></p>
<p><span class="font53">FIFO, 355-356</span></p>
<p><span class="font53">priority queuing, 356-357, 359</span></p>
<p><span class="font53">round robin, 359-360</span></p>
<p><span class="font53">WFQ, 359-360</span></p>
<p><span class="font53">packet sniffer, 87, 106</span></p>
<p><span class="font53">packet-switched networks, delays in, 65-76</span></p>
<p><span class="font53">packet switches, 34, 53, 341</span></p>
<p><span class="font53">packet switching, 53-57, 108</span></p>
<p><span class="font53">circuit switching </span><span class="font53" style="font-style:italic;">versus,</span><span class="font53"> 60-61 development of, 88-89 store-and-forward, 53-54</span></p>
<p><span class="font53">paging, 597</span></p>
<p><span class="font53">pairwise communication, 331</span></p>
<p><span class="font53">parallel TCP connections, fairness and, 309</span></p>
<p><span class="font53">parity bit, 486</span></p>
<p><span class="font53">parity checks, 486-488</span></p>
<p><span class="font53">passive optical networks (PONs), 46</span></p>
<p><span class="font53">passive scanning, 576</span></p>
<p><span class="font53">path loss, 566</span></p>
<p><span class="font53">paths, 34, 411</span></p>
<p><span class="font53">least-cost, 412, 414-416, 418-419 multihop, 289-291</span></p>
<p><span class="font53">multiple same-cost, 428 shortest, 412</span></p>
<p><span class="font53">Paxos, 447</span></p>
<p><span class="font53">payload field, 83</span></p>
<p><span class="font53">PDUs. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> protocol data units</span></p>
<p><span class="font53">peering agreements, 438-439 peers, 63</span></p>
<p><span class="font53">peer-to-peer (P2P) architecture, 114, 167-170</span></p>
<p><span class="font53">BitTorrent, 170-173 chunks, 170 DHT, 173 file distribution with, 171 optimistically unchoked, 172 rarest first, 172 torrent, defined, 170 tracker, 171 unchoked, 172</span></p>
<p><span class="font53">per-connection throughput, 286-287 performance enhancement, 390 per-router control, 408-410, 466 persistent connections, 128 PGP. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Pretty Good Privacy P-GW. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Packet Data Network</span></p>
<p><span class="font53">Gateway</span></p>
<p><span class="font53">Photobell, 108</span></p>
<p><span class="font53">physical address, 508 physical layer, 82 physical media, 48-51</span></p>
<p><span class="font53">coaxial cable, 50</span></p>
<p><span class="font53">fiber optics, 50 satellite radio, 51 terrestrial radio, 51 twisted-pair copper wire, 49-50</span></p>
<p><span class="font53">physical medium, 49 piconets, 591</span></p>
<p><span class="font53">piggybacked acknowledgments, 265 ping, 453</span></p>
<p><span class="font53">pipelined reliable data transfer protocols, 241, 243-245</span></p>
<p><span class="font53">pipelining, 245</span></p>
<p><span class="font53">TCP, 267 plaintext, 641, 642 playback attack, 668 plug-and-play, 371 plug-and-play devices, 524 points of presence (PoPs), 63 point-to-point connections, 257 point-to-point link, 491 Point-to-Point Protocol (PPP)</span></p>
<p><span class="font53">MTU, 259 poisoned reverse, 424 polling protocol, 504 polls, 504 polyalphabetic encryption, 643, 644 polynomial codes, 489 PONs. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> passive optical networks PoPs. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> points of presence port numbers, 118, 184, 219-220</span></p>
<p><span class="font53">NAT and, 374-376 socket, 219-220 well-known, 218 port scanning, 222 port-status message, 449 positive acknowledgments, 234 Pouzin, Louis, 90 PPP. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Point-to-Point Protocol preamble, 517 prefix, 345, 346, 366-368 Pretty Good Privacy (PGP), 673-674</span></p>
<p><span class="font53">Prim’s algorithm, 413 priority queuing, 355-357, 359 non-preemptive, 357 privacy, 704-705 private key, 649 private networks, 64, 94, 374, 410 processes, 115 server, 257 transport layer protocols connecting, 212 processing delay, 66 programmable network, 442 propagation delay, 65, 67-69 proprietary networks, 89-91 protocol data units (PDUs), 459, 460 protocol layering, 79-80</span></p>
<p><span class="font53">protocols, 35, 39. </span><span class="font53" style="font-style:italic;">See also</span><span class="font53"> specific protocols</span></p>
<p><span class="font53">defining, 37-39 network, 38-39 routing, 55-56</span></p>
<p><span class="font53">protocol stack, 80 provider, 62</span></p>
<p><span class="font53">provider networks, 438 proxy server, 138 PSH bit, 261 public-key, 649 public key certification, 662-664 public key encryption, 642, 648-654 Public Key Infrastructure (PKI), 661 pull protocol, 181</span></p>
<p><span class="font53">pure ALOHA protocol, 551 push protocol, 182 Python</span></p>
<p><span class="font53">port numbers, 219</span></p>
<p><span class="font53">UDP connections, 219</span></p>
<p><span class="font55" style="font-weight:bold;">Q</span></p>
<p><span class="font53">QoS. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> quality of service quality of service, 597</span></p>
<p><span class="font53">non-default, 379 queuing delays, 54-55, 66, 69-71</span></p>
<p><span class="font53">network congestion and, 287 queuing</span></p>
<p><span class="font53">delays, 65 FIFO, 355-356 input, 350 line speed and, 349-350 non-preemptive priority, 357 output, 351-353 priority, 355-357, 359 round-robin, 355, 359-360 in routers, 349-354 traffic load and, 349 transmission rate and, 349-350 WFQ, 359-360 work-conserving, 359</span></p>
<p><span class="font53">Quick UDP Internet Connections (QUIC), 310-312 connection-oriented and secure, 310-311</span></p>
<p><span class="font53">HTTP, 311-312 streams, 311 TCP-friendly congestion-controlled data transfer, 311</span></p>
<p><span class="font53">QUIC protocol, 226, 227</span></p>
<p><span class="font55" style="font-weight:bold;">R</span></p>
<p><span class="font53">radio link control, 600 Rand Institute, 89 random access protocols, 493, 495 Random Early Detection (RED), 352 RCP. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Routing Control Platform realm with private addresses, 374 real-time conversational applications.</span></p>
<p><span class="font53" style="font-style:italic;">See</span><span class="font53"> Voice-over-IP reassembly, IPv6 datagram, 380 receive buffer, 277, 278 receiver authentication, 639, 670 receiver feedback, 234 receive window, 260, 277, 278 recursive queries, 160, 161 RED. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Random Early Detection regional ISP, 62-63 registrar, 440 registries, 370 reliable data transfer, 119, 216, 255-256 implementing, 330 over channel with bit errors, 233-238</span></p>
<p><span class="font53">over lossy channel with bit errors, 238-241</span></p>
<p><span class="font53">over perfectly reliable channel, 232-233</span></p>
<p><span class="font53">principles of, 230-256 service implementation for, 231, 232 service model for, 230, 231 TCP, 268-376 reliable data transfer protocol, 230 building, 232-241 pipelined, 241, 243-245</span></p>
<p><span class="font53">reliable data transfer service, 268</span></p>
<p><span class="font53">reliable delivery, 482</span></p>
<p><span class="font53">reliable, TCP-friendly congestion-</span></p>
<p><span class="font53">controlled data transfer, 311</span></p>
<p><span class="font53">reliable transport protocol, 330</span></p>
<p><span class="font53">remote procedure call (RPC), 462 repeater, 519</span></p>
<p><span class="font53">request line, 131</span></p>
<p><span class="font53">requests for comments (RFCs), 35</span></p>
<p><span class="font53">Request to Send (RTS) control frame, 581</span></p>
<p><span class="font53">response time, cloud service performance, 299</span></p>
<p><span class="font53">retransmission, 234</span></p>
<p><span class="font53">congestion and, 288-289</span></p>
<p><span class="font53">duplicate packets from, 236 fast, 273-275</span></p>
<p><span class="font53">random access protocols, 495</span></p>
<p><span class="font53">sequence numbers for handling, 236-237</span></p>
<p><span class="font53">slotted ALOHA protocol, 496-498</span></p>
<p><span class="font53">TCP timeout interval for, 266-267 TCP timer management for, 268-269</span></p>
<p><span class="font53">time-based, 240-241</span></p>
<p><span class="font53">Rexford, Jennifer, 476</span></p>
<p><span class="font53">RFC 1422 public key, 664</span></p>
<p><span class="font53">RFCs. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> requests for comments</span></p>
<p><span class="font53">RIP, 413, 420, 546</span></p>
<p><span class="font53">Rivest, Ron, 650</span></p>
<p><span class="font53">roaming, 610</span></p>
<p><span class="font53">Roberts, Lawrence, 89</span></p>
<p><span class="font53">robustness, LS and DV</span></p>
<p><span class="font53">algorithms, 425</span></p>
<p><span class="font53">root DNS servers, 157</span></p>
<p><span class="font53">round-robin queuing, 355, 359-360</span></p>
<p><span class="font53">round-trip time (RTT), 129</span></p>
<p><span class="font53">buffer sizing and, 353</span></p>
<p><span class="font53">TCP estimation for, 265-268</span></p>
<p><span class="font53">TCP Reno throughput, 303</span></p>
<p><span class="font53">TCP variable tracking, 294 route, 34, 432</span></p>
<p><span class="font53">BGP, 433</span></p>
<p><span class="font53">BGP selection algorithm for, 435-436</span></p>
<p><span class="font53">route aggregation, 368 route information, advertising in BGP, 430-432</span></p>
<p><span class="font53">routers, 34, 53, 341, 383 architecture of, 341 border, 428-429, 536 buffer sizing, 353 components of, 341-344 congestion and, 286-291 data plane, 341-360 destination-based forwarding, 343-346</span></p>
<p><span class="font53">edge, 342</span></p>
<p><span class="font53">forwarding plane, 342-343 forwarding tables, 336, 337 gateway, 430</span></p>
<p><span class="font53">input port processing, 344-346 internal, 430</span></p>
<p><span class="font53">NAT-enabled, 374-376 output port processing, 349 per-router control, 408-410 queuing in, 349-354 self-synchronization, 417 switching fabric, 347-349 route summarization, 368 routine, node, 474-475 routing, 336, 337</span></p>
<p><span class="font53">among ISPs, 429-441 hot potato, 434-435 inter-area, 428-429 intra-ASs, 425-429, 439, 450</span></p>
<p><span class="font53">link weights in, 427 logically centralized, 338 multicast, 428 programming assignment, 474-475</span></p>
<p><span class="font53">routing algorithms, 336, 337, 410-425</span></p>
<p><span class="font53">ARPAnet, 413, 420 centralized, 412, 414 convergence speed, 425 decentralized, 412-413 distance-vector, 418-425 dynamic, 413 link-state, 413-417 load sensitivity, 413 static, 413</span></p>
<p><span class="font53">routing controllers</span></p>
<p><span class="font53">logically centralized, 338</span></p>
<p><span class="font53">SDN and, 339</span></p>
<p><span class="font53">Routing Control Platform (RCP), 476 routing loop, 423</span></p>
<p><span class="font53">routing policy, BGP, 437-440</span></p>
<p><span class="font53">routing processor, 342 routing protocols, 55-56 routing tables, 420</span></p>
<p><span class="font53">BGP, 435-436</span></p>
<p><span class="font53">RSA algorithm, 650-652 components of, 650 encryption/decryption, 653</span></p>
<p><span class="font53">RST bit, 260</span></p>
<p><span class="font53">RTT. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> round-trip time rwnd, 294</span></p>
<p><span class="font55" style="font-weight:bold;">S</span></p>
<p><span class="font53">SA. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> security association SAD. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Security Association</span></p>
<p><span class="font53">Database</span></p>
<p><span class="font53">SAL. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Service Abstraction Layer SampleRTT, 266 satellite radio channels, 51 Scantlebury, Roger, 89</span></p>
<p><span class="font53">SCTP. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Stream Control Transmission Protocol</span></p>
<p><span class="font53">SDN. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> software-defined networking</span></p>
<p><span class="font53">SDN control and management, 540 SDN controller, 444-446 secure communication, 638</span></p>
<p><span class="font53">Secure Hash Algorithm (SHA-1), 656 secure shell (SSH) connection, 457 security</span></p>
<p><span class="font53">datagram inspection, 377 firewalls, 377, 383 IDSs, 377</span></p>
<p><span class="font53">network, 638-640</span></p>
<p><span class="font53">network layer, 340</span></p>
<p><span class="font53">operational, 418, 639</span></p>
<p><span class="font53">OSPF and, 428</span></p>
<p><span class="font53">SYN flood attacks, 284 security association (SA), 683 Security Association Database</span></p>
<p><span class="font53">(SAD), 684 security associations, 683-685 Security Parameter Index (SPI), 684 Security Policy Database (SPD), 687 security services, 390 segments, 81, 212, 215</span></p>
<p><span class="font53">acknowledged, 295</span></p>
<p><span class="font53">lost, 295</span></p>
<p><span class="font53">maximum size, 259, 260</span></p>
<p><span class="font53">TCP, 259</span></p>
<p><span class="font53">TCP structure, 260-265 transport-layer, 83</span></p>
<p><span class="font53">UDP structure, 228 selective acknowledgment, 276 selective repeat (SR), 245, 250-256</span></p>
<p><span class="font53">events and actions, 252</span></p>
<p><span class="font53">operation of, 253</span></p>
<p><span class="font53">TCP as, 276</span></p>
<p><span class="font53">window size, 254, 255 self-clocking, 295 self-learning, 523, 544</span></p>
<p><span class="font53">link-layer switches, 523-524 self-replicating malware, 85 self-synchronization, 417 send buffer, 259 sender authentication, 639, 670 sending rate, 288</span></p>
<p><span class="font53">sequence number, 236</span></p>
<p><span class="font53">in GBN protocol, 245-246</span></p>
<p><span class="font53">in pipelined protocols, 245 retransmission handling with, 236-237</span></p>
<p><span class="font53">in SR protocol, 251, 254 TCP, 261-263</span></p>
<p><span class="font53">for TCP segment, 262 Telnet and, 263-265</span></p>
<p><span class="font53">sequence number field, 260 sequence number for segment, 262 server, 116</span></p>
<p><span class="font53">servers, 41</span></p>
<p><span class="font53">managing, 456 network control, 447 processes, 257 web, 92, 223-224</span></p>
<p><span class="font53">Service Abstraction Layer</span></p>
<p><span class="font53">(SAL), 450-451</span></p>
<p><span class="font53">Service Level Agreements (SLAs), 456</span></p>
<p><span class="font53">service model, 79</span></p>
<p><span class="font53">IP, 216 network, 339-340 reliable data transfer, 230, 231 services, 79</span></p>
<p><span class="font53">flow-control, 276 full-duplex, 257 layering, 79</span></p>
<p><span class="font53">network layer, 339-340 TCP, 216</span></p>
<p><span class="font53">unreliable, 216</span></p>
<p><span class="font53">service set identifier (SSID), 575</span></p>
<p><span class="font53">Serving Gateway (S-GW), 595 session key, 652 session management function (SMF), 608</span></p>
<p><span class="font53">S-GW. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Serving Gateway SHA-1. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Secure Hash Algorithm Shamir, Adi, 650 shared medium, 50 delays in, 73</span></p>
<p><span class="font53">shortest path, 412</span></p>
<p><span class="font53">Short Inter-frame Spacing</span></p>
<p><span class="font53">(SIFS), 579</span></p>
<p><span class="font53">SIFS. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Short Inter-frame Spacing signal-to-noise ratio (SNR), 566 signature-based systems, 707 silent periods, 59 simple authentication, 428 Simple Mail Transfer Protocol (SMTP), 80, 146-150</span></p>
<p><span class="font53">Simple Network Management Protocol (SNMP), 451, 458-462</span></p>
<p><span class="font53">Simple Network Management Protocol version 3 (SNMPv3), 458-461</span></p>
<p><span class="font53">single-hop, infrastructure-based networks, 565</span></p>
<p><span class="font53">single-hop, infrastructure-less networks, 565</span></p>
<p><span class="font53">Skype application-layer protocols, 124 internet telephony, 123</span></p>
<p><span class="font53">Slammer worm, 222</span></p>
<p><span class="font53">SLAs. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Service Level Agreements sleep modes, 603-604 sliding-window protocol, 246 slow start, 296-297 small cell stations, 607 small office, home office (SOHO), subnets, 374</span></p>
<p><span class="font53">smart spaces, 109</span></p>
<p><span class="font53">SMI. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Structure of Management Information</span></p>
<p><span class="font53">SMTP. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Simple Mail Transfer Protocol</span></p>
<p><span class="font53">SNA, 90</span></p>
<p><span class="font53">sniffing, 87, 106</span></p>
<p><span class="font53">SNMP. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Simple Network Management Protocol</span></p>
<p><span class="font53">Snort, 708</span></p>
<p><span class="font53">SNR. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> signal-to-noise ratio</span></p>
<p><span class="font53">social networks, 94</span></p>
<p><span class="font53">socket interface, 36</span></p>
<p><span class="font53">socket programming</span></p>
<p><span class="font53">port numbers, 219-220</span></p>
<p><span class="font53">with TCP, 189-195</span></p>
<p><span class="font53">types of, 182, 183</span></p>
<p><span class="font53">with UDP, 184-189</span></p>
<p><span class="font53">sockets, 117, 217</span></p>
<p><span class="font53">port numbers, 219-220 simultaneous, 222</span></p>
<p><span class="font53">welcoming, 221</span></p>
<p><span class="font53">software agents, 109 software-defined networking (SDN), 334, 339, 477</span></p>
<p><span class="font53">architecture of, 443</span></p>
<p><span class="font53">control applications, 444-446 control plane, 343, 441-450 data plane, 442, 448-449 forwarding tables in, 342, 344 generalized forwarding and,</span></p>
<p><span class="font53">383-390</span></p>
<p><span class="font53">key characteristics of, 441-442 link state change in, 448-449 logically centralized control in,</span></p>
<p><span class="font53">409-410</span></p>
<p><span class="font53">packet forwarding and, 340 routing component, 466</span></p>
<p><span class="font53">routing processor responsibilities in, 342</span></p>
<p><span class="font53">source port number, 260</span></p>
<p><span class="font53">source port number field, 218</span></p>
<p><span class="font53">source quench message, 453-454 spanning layer, 392</span></p>
<p><span class="font53">SPD. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Security Policy Database SPI. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Security Parameter Index</span></p>
<p><span class="font53">Spotify</span></p>
<p><span class="font53">DNS vulnerabilities, 165</span></p>
<p><span class="font53">Sprint, 62</span></p>
<p><span class="font53">SR. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> selective repeat</span></p>
<p><span class="font53">SRI. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Stanford Research Institute SSID. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Service Set Identifier ssthresh, 297-300</span></p>
<p><span class="font53">Stanford Research Institute (SRI), 89, 108</span></p>
<p><span class="font53">stateless protocol, 128 state-management layer, SDN, 444 static routing algorithms, 413 status line, 133</span></p>
<p><span class="font53">stop-and-wait protocols, 235,</span></p>
<p><span class="font53">243, 244 store-and-forward transmission, 53-54 Stream Control Transmission Protocol</span></p>
<p><span class="font53">(SCTP), 311</span></p>
<p><span class="font53">streaming</span></p>
<p><span class="font53">content distribution networks, 175-179</span></p>
<p><span class="font53">DASH, 174-175</span></p>
<p><span class="font53">HTTP streaming, 174-175 internet video, 173-174</span></p>
<p><span class="font53">streams, 311</span></p>
<p><span class="font53">Structure of Management Information (SMI), 459</span></p>
<p><span class="font53">subnet mask, 365</span></p>
<p><span class="font53">subnets, 364-368, 513-514</span></p>
<p><span class="font53">obtaining blocks of IP addresses, 370-371</span></p>
<p><span class="font53">in OSPF, 426</span></p>
<p><span class="font53">SOHO, 374</span></p>
<p><span class="font53">SWAN, 410 switch</span></p>
<p><span class="font53">top of rack, 535 switches, 343</span></p>
<p><span class="font53">crossbar, 348-349</span></p>
<p><span class="font53">link-layer, 34, 53, 341, 346 non-blocking, 348</span></p>
<p><span class="font53">switches </span><span class="font53" style="font-style:italic;">vs.</span><span class="font53"> routers, 525-527</span></p>
<p><span class="font53">switching, 341</span></p>
<p><span class="font53">in destination-based forwarding, 346 techniques for, 347-349</span></p>
<p><span class="font53">switching fabric, 342</span></p>
<p><span class="font53">bus, 348</span></p>
<p><span class="font53">crossbar, 347-349 interconnection network, 348-349 memory, 347-348</span></p>
<p><span class="font53">queuing and speed of, 349-350</span></p>
<p><span class="font53">switch poisoning, 525</span></p>
<p><span class="font53">switch table, 521</span></p>
<p><span class="font53">symmetric key encryption, 642-648 block ciphers, 644-646 Caesar cipher, 642 chosen-plaintext attack, 643</span></p>
<p><span class="font53">Cipher Block Chaining (CBC), 647 ciphertext-only attack, 643 in IPsec, 644</span></p>
<p><span class="font53">known-plaintext attack, 643</span></p>
<p><span class="font53">monoalphabetic cipher, 642</span></p>
<p><span class="font53">in PGP, 644</span></p>
<p><span class="font53">polyalphabetic encryption, 643, 644 in TLS, 644</span></p>
<p><span class="font53">SYNACK segment, 279, 283</span></p>
<p><span class="font53">SYN bit, 261</span></p>
<p><span class="font53">SYN cookies, 284</span></p>
<p><span class="font53">SYN flood attack, 284</span></p>
<p><span class="font55" style="font-weight:bold;">T</span></p>
<p><span class="font53">Tag Protocol Identifier (TPID), 529 taking-turns protocols, 493, 504-505</span></p>
<p><span class="font53">TCAMs. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Ternary Content Addressable Memories</span></p>
<p><span class="font53">TCP. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Transmission Control</span></p>
<p><span class="font53">Protocol</span></p>
<p><span class="font53">TCP BBR, 306</span></p>
<p><span class="font53">TCP congestion-control algorithm, 295-300</span></p>
<p><span class="font53">TCP connection, 121</span></p>
<p><span class="font53">TCP CUBIC, 301-303, 309</span></p>
<p><span class="font53">TCP-friendly congestion-controlled data transfer, 311</span></p>
<p><span class="font53">TCP/IP, 35, 258</span></p>
<p><span class="font53">TCP Reno, 300-303</span></p>
<p><span class="font53">TCP segments, 259 TCP socket, 544, 546 TCP splitting, 299 TCP states, 281-283 TCP SYN, 546 TCP Tahoe, 300, 301 TCP Vegas, 305-306</span></p>
<p><span class="font53">TDM. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> time-division multiplexing telco. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> telephone company Telenet, 89 telephone company (telco), 43 Telnet, 263-265, 457 temporary IP addresses, 371 Ternary Content Addressable</span></p>
<p><span class="font53">Memories (TCAMs), 346 terrestrial radio channels, 51 3G, 48</span></p>
<p><span class="font53">Third Generation Partnership</span></p>
<p><span class="font53">Program, 382 three-way handshake, 258, 280-281, 546 throughput, 73-76</span></p>
<p><span class="font53">average, 74 congestion and, 286-291 instantaneous, 73 per-connection, 286-287 TCP Reno, 303</span></p>
<p><span class="font53">tier-1 ISPs, 62-63</span></p>
<p><span class="font53">TikTok</span></p>
<p><span class="font53">video streaming, 173 time-based retransmission, 240-241 time-division multiplexing (TDM), 58-60, 493-494</span></p>
<p><span class="font53">time frames, 494 timeout events</span></p>
<p><span class="font53">in GBN protocol, 248 in SR protocol, 252 TCP, 266-267, 269, 270 timeout intervals</span></p>
<p><span class="font53">doubling, 271-273 TCP, 266-267, 271-273 time slots, 494</span></p>
<p><span class="font53">time-to-live (TTL), 362 token, 505</span></p>
<p><span class="font53">token-passing protocol, 505 Tomlinson, Ray, 89 top-down approach, 80 top-level domain (TLD), 156, 157 Top of Rack (TOR) switch, 535 torrent, 170</span></p>
<p><span class="font53">TOR switch. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Top of Rack switch TOS. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> type of service total nodal delay, 65</span></p>
<p><span class="font53">TPID. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Tag Protocol Identifier Traceroute, 71-73, 454-455 traffic engineering, 427, 534 traffic intensity, 69 traffic load, queuing and, 349 traffic volume, DNS, 156 Transmission Control Protocol (TCP)</span></p>
<p><span class="font53">ACK generation</span></p>
<p><span class="font53">recommendation, 274 acknowledgment number, 261-263 classic congestion control, 293-303 client-server application using, 192 closing connection, 280-281 congestion avoidance, 297-298 congestion-control algorithm, 295-300 congestion control in, 293-309 congestion window, 294, 300 connection, 257-260 connection management,</span></p>
<p><span class="font53">279-283, 285</span></p>
<p><span class="font53">connection requests, 221 cubic, 301-303</span></p>
<p><span class="font53">cumulative acknowledgment, 262 demultiplexing, 220-223 development of, 91</span></p>
<p><span class="font53">establishing connection, 279-280</span></p>
<p><span class="font53">exploring, 330</span></p>
<p><span class="font53">fairness and, 306-309</span></p>
<p><span class="font53">fast recovery, 298-300</span></p>
<p><span class="font53">fast retransmit, 273-275</span></p>
<p><span class="font53">flow control, 276-278</span></p>
<p><span class="font53">full-duplex service, 257</span></p>
<p><span class="font53">handshake protocol, 668</span></p>
<p><span class="font53">multimedia applications using, 226 parallel connection fairness, 309 pipelining, 267</span></p>
<p><span class="font53">point-to-point connections, 257 receive window, 277, 278 reliable data transfer, 268-376 retransmission timeout interval, 266-267</span></p>
<p><span class="font53">RTT estimation, 265-268</span></p>
<p><span class="font53">securing connections, 674-676 segment structure, 260-265 selective acknowledgment, 276 self-clocking, 295</span></p>
<p><span class="font53">sequence number, 261-263 services provided by, 216 simultaneous connection</span></p>
<p><span class="font53">sockets, 222</span></p>
<p><span class="font53">slow start, 296-297</span></p>
<p><span class="font53">socket programming with, 189-195 </span><span class="font53" style="font-style:italic;">(see also</span><span class="font53"> socket programming)</span></p>
<p><span class="font53">steady-state behavior of, 303</span></p>
<p><span class="font53">TCPClient.py, 191-193</span></p>
<p><span class="font53">TCPServer.py, 193-195</span></p>
<p><span class="font53">three-way handshake, 258, 280-281</span></p>
<p><span class="font53">throughput, 303</span></p>
<p><span class="font53">timeout events, 266-267, 269, 270 timeout intervals, 266-267, 271-273</span></p>
<p><span class="font53">timer management, 268-269 transition to, 91-92</span></p>
<p><span class="font53">transport-layer functionality, 309-312 variables, 294, 297, 300 Web servers and, 223-224 transmission delay, 65-69 transmission rate, 34</span></p>
<p><span class="font53">queuing and, 349-350 transparent, 521</span></p>
<p><span class="font53">transport layer, 80-81</span></p>
<p><span class="font53">in Internet, 215-217</span></p>
<p><span class="font53">network layer relationship to, 212-215</span></p>
<p><span class="font53">transport-layer functionality, 309-312 transport-layer multiplexing and</span></p>
<p><span class="font53">demultiplexing, 216 transport-layer protocols (TCP),</span></p>
<p><span class="font53">212, 482</span></p>
<p><span class="font53">and HTTP, 546-547</span></p>
<p><span class="font53">Transport Layer Security (TLS), 122, 462, 674-675</span></p>
<p><span class="font53">connection closure, 680</span></p>
<p><span class="font53">data transfer, 677 handshake phase, 676, 679-680</span></p>
<p><span class="font53">key derivation, 677</span></p>
<p><span class="font53">record, 678</span></p>
<p><span class="font53">transport-layer segment, 83 transport mode, 685</span></p>
<p><span class="font53">triangle routing problem, 615 trunking, VLAN, 529</span></p>
<p><span class="font53">TTL. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> time-to-live tunnel, 381</span></p>
<p><span class="font53">tunnel endpoint identifier (TEID), 601 tunneling, 381</span></p>
<p><span class="font53">tunnel mode, 685 twisted-pair copper wire, 49-50 Twitter</span></p>
<p><span class="font53">DNS vulnerabilities, 165 two-dimensional even parity, 487 two-dimensional parity scheme, 487 Tymnet, 90</span></p>
<p><span class="font53">type of service (TOS), 362</span></p>
<p><span class="font55" style="font-weight:bold;">U</span></p>
<p><span class="font53">ubiquitous WiFi, 593</span></p>
<p><span class="font53">UCLA, 108, 405</span></p>
<p><span class="font53">UDP. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> User Datagram Protocol UDP segment, 543 ultra reliable low-latency communications (URLLC), 606 undetected bit errors, 485 unguided media, 49 unidirectional data transfer, 232 UNIX, Snort, 708 unreliable services, 216 unshielded twisted pair (UTP), 49 URG bit, 261 urgent data pointer field, 261 user agents, 146</span></p>
<p><span class="font53">User Datagram Protocol (UDP), 215, 216, 224-230 advantages of, 225-226 checksum, 228-230 client-server application using, 185 connectionless nature of, 225 DNS using, 225 exploring, 330 fairness and, 308-309 multimedia applications using, 226-227</span></p>
<p><span class="font53">multiplexing and demultiplexing, 219-220</span></p>
<p><span class="font53">reliability with, 227-228 segment structure, 228 socket programming with, 184-189 UDPClient.py, 186-188 UDPServer.py, 188-189</span></p>
<p><span class="font53">User Equipment (UE), 594 user-plane function (UPF), 608 utilization, 243</span></p>
<p><span class="font53">UTP. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> unshielded twisted pair</span></p>
<p><span class="font55" style="font-weight:bold;">V</span></p>
<p><span class="font53">VANET. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> vehicular ad hoc network</span></p>
<p><span class="font53">vehicular ad hoc network (VANET), 565</span></p>
<p><span class="font53">video</span></p>
<p><span class="font53">from remote server, 617 streaming, 606</span></p>
<p><span class="font53">video streaming</span></p>
<p><span class="font53">content distribution networks, 175-179</span></p>
<p><span class="font53">DASH, 174-175</span></p>
<p><span class="font53">HTTP streaming, 174-175</span></p>
<p><span class="font53">internet video, 173-174</span></p>
<p><span class="font53">virtualization, 540-541</span></p>
<p><span class="font53">virtual local area networks</span></p>
<p><span class="font53">(VLANs), 528</span></p>
<p><span class="font53">inefficient use of switches, 528 lack of traffic isolation, 527-528 original ethernet frame, 530 single switch with two, 528</span></p>
<p><span class="font53">tag, 529</span></p>
<p><span class="font53">trunking, 529</span></p>
<p><span class="font53">two switches with two, 530</span></p>
<p><span class="font53">users management, 528</span></p>
<p><span class="font53">virtual private networks (VPNs), 534, 681-683</span></p>
<p><span class="font53">visited network, 610</span></p>
<p><span class="font53">VLANs. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> virtual local area networks</span></p>
<p><span class="font53">Voice-over-IP (VoIP), 65, 73, 356, 358</span></p>
<p><span class="font53">VoIP. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> Voice-over-IP</span></p>
<p><span class="font53">VPNs. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> virtual private networks vulnerability attacks, 85</span></p>
<p><span class="font55" style="font-weight:bold;">W</span></p>
<p><span class="font53">Web browsers, 92-93, 126 conditional GET, 142 parallel connections, 309</span></p>
<p><span class="font53">Web cache, 138</span></p>
<p><span class="font53">web client-server interaction, 546-547</span></p>
<p><span class="font53">Web page, 126</span></p>
<p><span class="font53">Web servers, 92, 126, 306</span></p>
<p><span class="font53">TCP and, 223-224</span></p>
<p><span class="font53">weighted fair queuing (WFQ), 359-360</span></p>
<p><span class="font53">welcoming socket, 221 well-known application protocols,</span></p>
<p><span class="font53">218-219 well-known port numbers, 218 well-know service, 358</span></p>
<p><span class="font53">WFQ. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> weighted fair queuing wide-area wireless Internet</span></p>
<p><span class="font53">access, 48</span></p>
<p><span class="font53">WiFi, 34, 35, 47, 392, 573. </span><span class="font53" style="font-style:italic;">See also</span></p>
<p><span class="font53">IEEE 802.11 wireless LAN address fields, 584-586 advanced features in, 589-590 architecture, 574-578 channels and association, 575-578 clear to send (CTS) control</span></p>
<p><span class="font53">frame, 581 collision avoidance, 582 duration, 586</span></p>
<p><span class="font53">enterprise usage of, 46-47 frame control fields, 586 frames, 583-586</span></p>
<p><span class="font53">hidden terminals, dealing with, 581-583</span></p>
<p><span class="font53">link-layer acknowledgments, 579 MAC protocol, 578-583 mobility in same IP subnet,</span></p>
<p><span class="font53">586-588</span></p>
<p><span class="font53">packet sniffing, 87 payload and CRC fields, 583-584 personal area networks, 590-592 as point-to-point link, 583</span></p>
<p><span class="font53">power management, 590 public access, 93</span></p>
<p><span class="font53">rate adaptation, 589-590 request to send (RTS) control, 581 sequence number, 586 standards, 573</span></p>
<p><span class="font53">transmission rates and range, 564 wide-area wireless </span><span class="font53" style="font-style:italic;">versus,</span><span class="font53"> 48</span></p>
<p><span class="font53">WiFi jungle, 576</span></p>
<p><span class="font53">WiFi Positioning System (WPS), 588</span></p>
<p><span class="font53">WiFi wireless router, 46 wildcards, in flow table entries, 386 window scaling factor, 260 window size, 246</span></p>
<p><span class="font53">in SR, 254, 255</span></p>
<p><span class="font53">Windows platforms</span></p>
<p><span class="font53">Snort, 708</span></p>
<p><span class="font53">wireless and mobile devices, 109</span></p>
<p><span class="font53">wireless communication link, 562 wireless host, 562</span></p>
<p><span class="font53">wireless LANs, 47</span></p>
<p><span class="font53">encryption, 689</span></p>
<p><span class="font53">encryption-key derivation, 690 four-way handshake, 692 mutual authentication, 690 security, 689-694</span></p>
<p><span class="font53">security messaging protocols, 693-694</span></p>
<p><span class="font53">shared symmetric session key derivation, 691</span></p>
<ul style="list-style:none;"><li>
<p class="font53">802.11 wireless LANs. <span class="font53" style="font-style:italic;">See</span><span class="font53"> IEEE</span></p></li></ul>
<ul style="list-style:none;"><li>
<p class="font53">802.11 wireless LAN wireless mesh networks, 565 wireless networks</p></li></ul>
<p><span class="font53">CDMA, 569-572 elements, 562, 563 links and network characteristics, 566-569</span></p>
<p><span class="font53">mesh, 565</span></p>
<p><span class="font53">packet sniffing, 87</span></p>
<p><span class="font53">transmission rates and range, 564</span></p>
<p><span class="font53">WiFi, 572-593</span></p>
<p><span class="font53">wireless personal area networks</span></p>
<p><span class="font53">(WPANs), 591</span></p>
<p><span class="font53">Wireshark, 87, 106-107</span></p>
<p><span class="font53">TCP, 330</span></p>
<p><span class="font53">work-conserving queuing, 359</span></p>
<p><span class="font53">worms, 222</span></p>
<p><span class="font53">WPANs. </span><span class="font53" style="font-style:italic;">See</span><span class="font53"> wireless personal area networks</span></p>
<p><span class="font55" style="font-weight:bold;">X</span></p>
<p><span class="font53">X.509, 664</span></p>
<p><span class="font53">Xerox</span></p>
<p><span class="font53">ethernet, 518</span></p>
<p><span class="font53">X.25 protocol suite, 92</span></p>
<p><span class="font53">XTP, 488</span></p>
<p><span class="font55" style="font-weight:bold;">Y</span></p>
<p><span class="font53">Yahoo, 93</span></p>
<p><span class="font53">YANG, 458, 466</span></p>
<p><span class="font53">YouTube, 306</span></p>
<p><span class="font53">CDN and, 182</span></p>
<p><span class="font53">video streaming, 173</span></p>
<p><span class="font55" style="font-weight:bold;">Z</span></p>
<p><span class="font53">zeroconf, 371</span></p>
<p><span class="font53">Zimmerman, Phil, 673</span></p>
<p><span class="font70" style="font-style:italic;">This page is intentionally left blank</span></p>
<p><sup><a href="#footnote1">1</a></sup><a name="bookmark358"></a></p>
<p><span class="font53"> In the initialization step, the currently known least-cost paths from </span><span class="font53" style="font-style:italic;">u</span><span class="font53"> to its directly attached neighbors, </span><span class="font53" style="font-style:italic;">v, x,</span><span class="font53"> and </span><span class="font53" style="font-style:italic;">w,</span><span class="font53"> are initialized to 2, 1, and 5, respectively. Note in</span></p>
<p><sup><a href="#footnote2">2</a></sup><a name="bookmark429"></a></p>
<p><a name="bookmark477"></a><span class="font51">The terms used below may differ from the terms found in the official Bluetooth Specification. The terms used in the official specification DO NOT align with Pearson’s commitment to promoting diversity, equality, and inclusion, and protecting against bias and stereotyping in the global population of the learners we serve.</span></p>
</body>
</html>